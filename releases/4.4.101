commit 5baf0fb260fc59d632ba150f442a5904650d6170
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Nov 24 08:32:25 2017 +0100

    Linux 4.4.101

commit a3805b10de80953db316985f567453fc18329423
Author: Jann Horn <jannh@google.com>
Date:   Tue Nov 14 01:03:44 2017 +0100

    mm/pagewalk.c: report holes in hugetlb ranges
    
    commit 373c4557d2aa362702c4c2d41288fb1e54990b7c upstream.
    
    This matters at least for the mincore syscall, which will otherwise copy
    uninitialized memory from the page allocator to userspace.  It is
    probably also a correctness error for /proc/$pid/pagemap, but I haven't
    tested that.
    
    Removing the `walk->hugetlb_entry` condition in walk_hugetlb_range() has
    no effect because the caller already checks for that.
    
    This only reports holes in hugetlb ranges to callers who have specified
    a hugetlb_entry callback.
    
    This issue was found using an AFL-based fuzzer.
    
    v2:
     - don't crash on ->pte_hole==NULL (Andrew Morton)
     - add Cc stable (Andrew Morton)
    
    Changed for 4.4/4.9 stable backport:
     - fix up conflict in the huge_pte_offset() call
    
    Fixes: 1e25a271c8ac ("mincore: apply page table walker on do_mincore()")
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3630b28019075639a9db00491349e05fbf0f901e
Author: Jaewon Kim <jaewon31.kim@samsung.com>
Date:   Wed Nov 15 17:39:07 2017 -0800

    mm/page_ext.c: check if page_ext is not prepared
    
    commit e492080e640c2d1235ddf3441cae634cfffef7e1 upstream.
    
    online_page_ext() and page_ext_init() allocate page_ext for each
    section, but they do not allocate if the first PFN is !pfn_present(pfn)
    or !pfn_valid(pfn).  Then section->page_ext remains as NULL.
    lookup_page_ext checks NULL only if CONFIG_DEBUG_VM is enabled.  For a
    valid PFN, __set_page_owner will try to get page_ext through
    lookup_page_ext.  Without CONFIG_DEBUG_VM lookup_page_ext will misuse
    NULL pointer as value 0.  This incurrs invalid address access.
    
    This is the panic example when PFN 0x100000 is not valid but PFN
    0x13FC00 is being used for page_ext.  section->page_ext is NULL,
    get_entry returned invalid page_ext address as 0x1DFA000 for a PFN
    0x13FC00.
    
    To avoid this panic, CONFIG_DEBUG_VM should be removed so that page_ext
    will be checked at all times.
    
      Unable to handle kernel paging request at virtual address 01dfa014
      ------------[ cut here ]------------
      Kernel BUG at ffffff80082371e0 [verbose debug info unavailable]
      Internal error: Oops: 96000045 [#1] PREEMPT SMP
      Modules linked in:
      PC is at __set_page_owner+0x48/0x78
      LR is at __set_page_owner+0x44/0x78
        __set_page_owner+0x48/0x78
        get_page_from_freelist+0x880/0x8e8
        __alloc_pages_nodemask+0x14c/0xc48
        __do_page_cache_readahead+0xdc/0x264
        filemap_fault+0x2ac/0x550
        ext4_filemap_fault+0x3c/0x58
        __do_fault+0x80/0x120
        handle_mm_fault+0x704/0xbb0
        do_page_fault+0x2e8/0x394
        do_mem_abort+0x88/0x124
    
    Pre-4.7 kernels also need commit f86e4271978b ("mm: check the return
    value of lookup_page_ext for all call sites").
    
    Link: http://lkml.kernel.org/r/20171107094131.14621-1-jaewon31.kim@samsung.com
    Fixes: eefa864b701d ("mm/page_ext: resurrect struct page extending code for debugging")
    Signed-off-by: Jaewon Kim <jaewon31.kim@samsung.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e34e744f70a68f8f16f945a286802898c56a8b5a
Author: Yang Shi <yang.shi@linaro.org>
Date:   Fri Jun 3 14:55:38 2016 -0700

    mm: check the return value of lookup_page_ext for all call sites
    
    commit f86e4271978bd93db466d6a95dad4b0fdcdb04f6 upstream.
    
    Per the discussion with Joonsoo Kim [1], we need check the return value
    of lookup_page_ext() for all call sites since it might return NULL in
    some cases, although it is unlikely, i.e.  memory hotplug.
    
    Tested with ltp with "page_owner=0".
    
    [1] http://lkml.kernel.org/r/20160519002809.GA10245@js1304-P5Q-DELUXE
    
    [akpm@linux-foundation.org: fix build-breaking typos]
    [arnd@arndb.de: fix build problems from lookup_page_ext]
      Link: http://lkml.kernel.org/r/6285269.2CksypHdYp@wuerfel
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/1464023768-31025-1-git-send-email-yang.shi@linaro.org
    Signed-off-by: Yang Shi <yang.shi@linaro.org>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7b7a1c39e8394d4232714093882b733b3e435c67
Author: Jan Harkes <jaharkes@cs.cmu.edu>
Date:   Wed Sep 27 15:52:12 2017 -0400

    coda: fix 'kernel memory exposure attempt' in fsync
    
    commit d337b66a4c52c7b04eec661d86c2ef6e168965a2 upstream.
    
    When an application called fsync on a file in Coda a small request with
    just the file identifier was allocated, but the declared length was set
    to the size of union of all possible upcall requests.
    
    This bug has been around for a very long time and is now caught by the
    extra checking in usercopy that was introduced in Linux-4.8.
    
    The exposure happens when the Coda cache manager process reads the fsync
    upcall request at which point it is killed. As a result there is nobody
    servicing any further upcalls, trapping any processes that try to access
    the mounted Coda filesystem.
    
    Signed-off-by: Jan Harkes <jaharkes@cs.cmu.edu>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c1b3703b643f0abce65f10cc7716c9ddc9c0decb
Author: Pavel Tatashin <pasha.tatashin@oracle.com>
Date:   Wed Nov 15 17:38:41 2017 -0800

    mm/page_alloc.c: broken deferred calculation
    
    commit d135e5750205a21a212a19dbb05aeb339e2cbea7 upstream.
    
    In reset_deferred_meminit() we determine number of pages that must not
    be deferred.  We initialize pages for at least 2G of memory, but also
    pages for reserved memory in this node.
    
    The reserved memory is determined in this function:
    memblock_reserved_memory_within(), which operates over physical
    addresses, and returns size in bytes.  However, reset_deferred_meminit()
    assumes that that this function operates with pfns, and returns page
    count.
    
    The result is that in the best case machine boots slower than expected
    due to initializing more pages than needed in single thread, and in the
    worst case panics because fewer than needed pages are initialized early.
    
    Link: http://lkml.kernel.org/r/20171021011707.15191-1-pasha.tatashin@oracle.com
    Fixes: 864b9a393dcb ("mm: consider memblock reservations for deferred memory initialization sizing")
    Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4ecf752738acf14848546b0c7d2e7f3753f1ed3f
Author: Corey Minyard <cminyard@mvista.com>
Date:   Sat Jul 29 21:14:55 2017 -0500

    ipmi: fix unsigned long underflow
    
    commit 392a17b10ec4320d3c0e96e2a23ebaad1123b989 upstream.
    
    When I set the timeout to a specific value such as 500ms, the timeout
    event will not happen in time due to the overflow in function
    check_msg_timeout:
    ...
            ent->timeout -= timeout_period;
            if (ent->timeout > 0)
                    return;
    ...
    
    The type of timeout_period is long, but ent->timeout is unsigned long.
    This patch makes the type consistent.
    
    Reported-by: Weilong Chen <chenweilong@huawei.com>
    Signed-off-by: Corey Minyard <cminyard@mvista.com>
    Tested-by: Weilong Chen <chenweilong@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c4baa4a5870cb02f713def1620052bfca7a82bbb
Author: alex chen <alex.chen@huawei.com>
Date:   Wed Nov 15 17:31:40 2017 -0800

    ocfs2: should wait dio before inode lock in ocfs2_setattr()
    
    commit 28f5a8a7c033cbf3e32277f4cc9c6afd74f05300 upstream.
    
    we should wait dio requests to finish before inode lock in
    ocfs2_setattr(), otherwise the following deadlock will happen:
    
    process 1                  process 2                    process 3
    truncate file 'A'          end_io of writing file 'A'   receiving the bast messages
    ocfs2_setattr
     ocfs2_inode_lock_tracker
      ocfs2_inode_lock_full
     inode_dio_wait
      __inode_dio_wait
      -->waiting for all dio
      requests finish
                                                            dlm_proxy_ast_handler
                                                             dlm_do_local_bast
                                                              ocfs2_blocking_ast
                                                               ocfs2_generic_handle_bast
                                                                set OCFS2_LOCK_BLOCKED flag
                            dio_end_io
                             dio_bio_end_aio
                              dio_complete
                               ocfs2_dio_end_io
                                ocfs2_dio_end_io_write
                                 ocfs2_inode_lock
                                  __ocfs2_cluster_lock
                                   ocfs2_wait_for_mask
                                   -->waiting for OCFS2_LOCK_BLOCKED
                                   flag to be cleared, that is waiting
                                   for 'process 1' unlocking the inode lock
                               inode_dio_end
                               -->here dec the i_dio_count, but will never
                               be called, so a deadlock happened.
    
    Link: http://lkml.kernel.org/r/59F81636.70508@huawei.com
    Signed-off-by: Alex Chen <alex.chen@huawei.com>
    Reviewed-by: Jun Piao <piaojun@huawei.com>
    Reviewed-by: Joseph Qi <jiangqi903@gmail.com>
    Acked-by: Changwei Ge <ge.changwei@h3c.com>
    Cc: Mark Fasheh <mfasheh@versity.com>
    Cc: Joel Becker <jlbec@evilplan.org>
    Cc: Junxiao Bi <junxiao.bi@oracle.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8c325770546a3ae6ec47e4fee68890eb5dbb8939
Author: Keith Busch <keith.busch@intel.com>
Date:   Thu Nov 16 16:57:10 2017 -0700

    nvme: Fix memory order on async queue deletion
    
    This patch is a fix specific to the 3.19 - 4.4 kernels. The 4.5 kernel
    inadvertently fixed this bug differently (db3cbfff5bcc0), but is not
    a stable candidate due it being a complicated re-write of the entire
    feature.
    
    This patch fixes a potential timing bug with nvme's asynchronous queue
    deletion, which causes an allocated request to be accidentally released
    due to the ordering of the shared completion context among the sq/cq
    pair. The completion context saves the request that issued the queue
    deletion. If the submission side deletion happens to reset the active
    request, the completion side will release the wrong request tag back into
    the pool of available tags. This means the driver will create multiple
    commands with the same tag, corrupting the queue context.
    
    The error is observable in the kernel logs like:
    
      "nvme XX:YY:ZZ completed id XX twice on qid:0"
    
    In this particular case, this message occurs because the queue is
    corrupted.
    
    The following timing sequence demonstrates the error:
    
      CPU A                                 CPU B
      -----------------------               -----------------------------
      nvme_irq
       nvme_process_cq
        async_completion
         queue_kthread_work  ----------->   nvme_del_sq_work_handler
                                             nvme_delete_cq
                                              adapter_async_del_queue
                                               nvme_submit_admin_async_cmd
                                                cmdinfo->req = req;
    
         blk_mq_free_request(cmdinfo->req); <-- wrong request!!!
    
    This patch fixes the bug by releasing the request in the completion side
    prior to waking the submission thread, such that that thread can't muck
    with the shared completion context.
    
    Fixes: a4aea5623d4a5 ("NVMe: Convert to blk-mq")
    
    Signed-off-by: Keith Busch <keith.busch@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4310b6bfa8e0f3b16a3919db709136d87c45574c
Author: Mark Rutland <mark.rutland@arm.com>
Date:   Mon Jun 13 11:15:14 2016 +0100

    arm64: fix dump_instr when PAN and UAO are in use
    
    commit c5cea06be060f38e5400d796e61cfc8c36e52924 upstream.
    
    If the kernel is set to show unhandled signals, and a user task does not
    handle a SIGILL as a result of an instruction abort, we will attempt to
    log the offending instruction with dump_instr before killing the task.
    
    We use dump_instr to log the encoding of the offending userspace
    instruction. However, dump_instr is also used to dump instructions from
    kernel space, and internally always switches to KERNEL_DS before dumping
    the instruction with get_user. When both PAN and UAO are in use, reading
    a user instruction via get_user while in KERNEL_DS will result in a
    permission fault, which leads to an Oops.
    
    As we have regs corresponding to the context of the original instruction
    abort, we can inspect this and only flip to KERNEL_DS if the original
    abort was taken from the kernel, avoiding this issue. At the same time,
    remove the redundant (and incorrect) comments regarding the order
    dump_mem and dump_instr are called in.
    
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: James Morse <james.morse@arm.com>
    Cc: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Mark Rutland <mark.rutland@arm.com>
    Reported-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Tested-by: Vladimir Murzin <vladimir.murzin@arm.com>
    Fixes: 57f4959bad0a154a ("arm64: kernel: Add support for User Access Override")
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1df403abfa9e1714161420412876beb7b23fb162
Author: Lukas Wunner <lukas@wunner.de>
Date:   Sat Oct 21 10:50:18 2017 +0200

    serial: omap: Fix EFR write on RTS deassertion
    
    commit 2a71de2f7366fb1aec632116d0549ec56d6a3940 upstream.
    
    Commit 348f9bb31c56 ("serial: omap: Fix RTS handling") sought to enable
    auto RTS upon manual RTS assertion and disable it on deassertion.
    However it seems the latter was done incorrectly, it clears all bits in
    the Extended Features Register *except* auto RTS.
    
    Fixes: 348f9bb31c56 ("serial: omap: Fix RTS handling")
    Cc: Peter Hurley <peter@hurleysoftware.com>
    Signed-off-by: Lukas Wunner <lukas@wunner.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9100b6f1a8af4251107a2d67e98854e8a61cd4b
Author: Roberto Sassu <roberto.sassu@huawei.com>
Date:   Tue Nov 7 11:37:07 2017 +0100

    ima: do not update security.ima if appraisal status is not INTEGRITY_PASS
    
    commit 020aae3ee58c1af0e7ffc4e2cc9fe4dc630338cb upstream.
    
    Commit b65a9cfc2c38 ("Untangling ima mess, part 2: deal with counters")
    moved the call of ima_file_check() from may_open() to do_filp_open() at a
    point where the file descriptor is already opened.
    
    This breaks the assumption made by IMA that file descriptors being closed
    belong to files whose access was granted by ima_file_check(). The
    consequence is that security.ima and security.evm are updated with good
    values, regardless of the current appraisal status.
    
    For example, if a file does not have security.ima, IMA will create it after
    opening the file for writing, even if access is denied. Access to the file
    will be allowed afterwards.
    
    Avoid this issue by checking the appraisal status before updating
    security.ima.
    
    Signed-off-by: Roberto Sassu <roberto.sassu@huawei.com>
    Signed-off-by: Mimi Zohar <zohar@linux.vnet.ibm.com>
    Signed-off-by: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 51b8aea7abdeb522e5450c246912b6f4a491e1c8
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Nov 15 22:17:48 2017 -0600

    net/sctp: Always set scope_id in sctp_inet6_skb_msgname
    
    
    [ Upstream commit 7c8a61d9ee1df0fb4747879fa67a99614eb62fec ]
    
    Alexandar Potapenko while testing the kernel with KMSAN and syzkaller
    discovered that in some configurations sctp would leak 4 bytes of
    kernel stack.
    
    Working with his reproducer I discovered that those 4 bytes that
    are leaked is the scope id of an ipv6 address returned by recvmsg.
    
    With a little code inspection and a shrewd guess I discovered that
    sctp_inet6_skb_msgname only initializes the scope_id field for link
    local ipv6 addresses to the interface index the link local address
    pertains to instead of initializing the scope_id field for all ipv6
    addresses.
    
    That is almost reasonable as scope_id's are meaniningful only for link
    local addresses.  Set the scope_id in all other cases to 0 which is
    not a valid interface index to make it clear there is nothing useful
    in the scope_id field.
    
    There should be no danger of breaking userspace as the stack leak
    guaranteed that previously meaningless random data was being returned.
    
    Fixes: 372f525b495c ("SCTP:  Resync with LKSCTP tree.")
    History-tree: https://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git
    Reported-by: Alexander Potapenko <glider@google.com>
    Tested-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ae93cefb94300fd67c48e68f08c943f2f1f363c8
Author: Huacai Chen <chenhc@lemote.com>
Date:   Thu Nov 16 11:07:15 2017 +0800

    fealnx: Fix building error on MIPS
    
    
    [ Upstream commit cc54c1d32e6a4bb3f116721abf900513173e4d02 ]
    
    This patch try to fix the building error on MIPS. The reason is MIPS
    has already defined the LONG macro, which conflicts with the LONG enum
    in drivers/net/ethernet/fealnx.c.
    
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2a0e60907e54dad75e9b3568d02bec11d6e74f6b
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Oct 17 23:26:10 2017 +0800

    sctp: do not peel off an assoc from one netns to another one
    
    
    [ Upstream commit df80cd9b28b9ebaa284a41df611dbf3a2d05ca74 ]
    
    Now when peeling off an association to the sock in another netns, all
    transports in this assoc are not to be rehashed and keep use the old
    key in hashtable.
    
    As a transport uses sk->net as the hash key to insert into hashtable,
    it would miss removing these transports from hashtable due to the new
    netns when closing the sock and all transports are being freeed, then
    later an use-after-free issue could be caused when looking up an asoc
    and dereferencing those transports.
    
    This is a very old issue since very beginning, ChunYu found it with
    syzkaller fuzz testing with this series:
    
      socket$inet6_sctp()
      bind$inet6()
      sendto$inet6()
      unshare(0x40000000)
      getsockopt$inet_sctp6_SCTP_GET_ASSOC_ID_LIST()
      getsockopt$inet_sctp6_SCTP_SOCKOPT_PEELOFF()
    
    This patch is to block this call when peeling one assoc off from one
    netns to another one, so that the netns of all transport would not
    go out-sync with the key in hashtable.
    
    Note that this patch didn't fix it by rehashing transports, as it's
    difficult to handle the situation when the tuple is already in use
    in the new netns. Besides, no one would like to peel off one assoc
    to another netns, considering ipaddrs, ifaces, etc. are usually
    different.
    
    Reported-by: ChunYu Wang <chunwang@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4cfc0b41af031785a37e12d8de6bc02a61ff8fda
Author: Jason A. Donenfeld <Jason@zx2c4.com>
Date:   Thu Nov 9 13:04:44 2017 +0900

    af_netlink: ensure that NLMSG_DONE never fails in dumps
    
    
    [ Upstream commit 0642840b8bb008528dbdf929cec9f65ac4231ad0 ]
    
    The way people generally use netlink_dump is that they fill in the skb
    as much as possible, breaking when nla_put returns an error. Then, they
    get called again and start filling out the next skb, and again, and so
    forth. The mechanism at work here is the ability for the iterative
    dumping function to detect when the skb is filled up and not fill it
    past the brim, waiting for a fresh skb for the rest of the data.
    
    However, if the attributes are small and nicely packed, it is possible
    that a dump callback function successfully fills in attributes until the
    skb is of size 4080 (libmnl's default page-sized receive buffer size).
    The dump function completes, satisfied, and then, if it happens to be
    that this is actually the last skb, and no further ones are to be sent,
    then netlink_dump will add on the NLMSG_DONE part:
    
      nlh = nlmsg_put_answer(skb, cb, NLMSG_DONE, sizeof(len), NLM_F_MULTI);
    
    It is very important that netlink_dump does this, of course. However, in
    this example, that call to nlmsg_put_answer will fail, because the
    previous filling by the dump function did not leave it enough room. And
    how could it possibly have done so? All of the nla_put variety of
    functions simply check to see if the skb has enough tailroom,
    independent of the context it is in.
    
    In order to keep the important assumptions of all netlink dump users, it
    is therefore important to give them an skb that has this end part of the
    tail already reserved, so that the call to nlmsg_put_answer does not
    fail. Otherwise, library authors are forced to find some bizarre sized
    receive buffer that has a large modulo relative to the common sizes of
    messages received, which is ugly and buggy.
    
    This patch thus saves the NLMSG_DONE for an additional message, for the
    case that things are dangerously close to the brim. This requires
    keeping track of the errno from ->dump() across calls.
    
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ef206ea779a9a356a16246a5fe3e875456dac701
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Thu Nov 9 16:43:13 2017 -0800

    vlan: fix a use-after-free in vlan_device_event()
    
    
    [ Upstream commit 052d41c01b3a2e3371d66de569717353af489d63 ]
    
    After refcnt reaches zero, vlan_vid_del() could free
    dev->vlan_info via RCU:
    
            RCU_INIT_POINTER(dev->vlan_info, NULL);
            call_rcu(&vlan_info->rcu, vlan_info_rcu_free);
    
    However, the pointer 'grp' still points to that memory
    since it is set before vlan_vid_del():
    
            vlan_info = rtnl_dereference(dev->vlan_info);
            if (!vlan_info)
                    goto out;
            grp = &vlan_info->grp;
    
    Depends on when that RCU callback is scheduled, we could
    trigger a use-after-free in vlan_group_for_each_dev()
    right following this vlan_vid_del().
    
    Fix it by moving vlan_vid_del() before setting grp. This
    is also symmetric to the vlan_vid_add() we call in
    vlan_device_event().
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Fixes: efc73f4bbc23 ("net: Fix memory leak - vlan_info struct")
    Cc: Alexander Duyck <alexander.duyck@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Girish Moodalbail <girish.moodalbail@oracle.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Reviewed-by: Girish Moodalbail <girish.moodalbail@oracle.com>
    Tested-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3bb6245e14ea56806ee6a3860c2380e96647593d
Author: Hangbin Liu <liuhangbin@gmail.com>
Date:   Mon Nov 6 09:01:57 2017 +0800

    bonding: discard lowest hash bit for 802.3ad layer3+4
    
    
    [ Upstream commit b5f862180d7011d9575d0499fa37f0f25b423b12 ]
    
    After commit 07f4c90062f8 ("tcp/dccp: try to not exhaust ip_local_port_range
    in connect()"), we will try to use even ports for connect(). Then if an
    application (seen clearly with iperf) opens multiple streams to the same
    destination IP and port, each stream will be given an even source port.
    
    So the bonding driver's simple xmit_hash_policy based on layer3+4 addressing
    will always hash all these streams to the same interface. And the total
    throughput will limited to a single slave.
    
    Change the tcp code will impact the whole tcp behavior, only for bonding
    usage. Paolo Abeni suggested fix this by changing the bonding code only,
    which should be more reasonable, and less impact.
    
    Fix this by discarding the lowest hash bit because it contains little entropy.
    After the fix we can re-balance between slaves.
    
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Hangbin Liu <liuhangbin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 001e9cbe1daee3544c804cc0f0196818f8e38dc3
Author: Ye Yin <hustcat@gmail.com>
Date:   Thu Oct 26 16:57:05 2017 +0800

    netfilter/ipvs: clear ipvs_property flag when SKB net namespace changed
    
    
    [ Upstream commit 2b5ec1a5f9738ee7bf8f5ec0526e75e00362c48f ]
    
    When run ipvs in two different network namespace at the same host, and one
    ipvs transport network traffic to the other network namespace ipvs.
    'ipvs_property' flag will make the second ipvs take no effect. So we should
    clear 'ipvs_property' when SKB network namespace changed.
    
    Fixes: 621e84d6f373 ("dev: introduce skb_scrub_packet()")
    Signed-off-by: Ye Yin <hustcat@gmail.com>
    Signed-off-by: Wei Zhou <chouryzhou@gmail.com>
    Signed-off-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c1282c7f046563b43c69be360b4e05d4edd34fa
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Nov 2 12:30:25 2017 -0700

    tcp: do not mangle skb->cb[] in tcp_make_synack()
    
    
    [ Upstream commit 3b11775033dc87c3d161996c54507b15ba26414a ]
    
    Christoph Paasch sent a patch to address the following issue :
    
    tcp_make_synack() is leaving some TCP private info in skb->cb[],
    then send the packet by other means than tcp_transmit_skb()
    
    tcp_transmit_skb() makes sure to clear skb->cb[] to not confuse
    IPv4/IPV6 stacks, but we have no such cleanup for SYNACK.
    
    tcp_make_synack() should not use tcp_init_nondata_skb() :
    
    tcp_init_nondata_skb() really should be limited to skbs put in write/rtx
    queues (the ones that are only sent via tcp_transmit_skb())
    
    This patch fixes the issue and should even save few cpu cycles ;)
    
    Fixes: 971f10eca186 ("tcp: better TCP_SKB_CB layout to reduce cache line misses")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Christoph Paasch <cpaasch@apple.com>
    Reviewed-by: Christoph Paasch <cpaasch@apple.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
