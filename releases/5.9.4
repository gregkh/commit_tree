commit ad2f76f72d803692f83312b4b5b0ffc03e570698
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 4 21:53:37 2020 +0100

    Linux 5.9.4
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3dc43f5e5c4dbfce7483d206017439bd6507a404
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Oct 5 20:40:25 2020 -0700

    x86/copy_mc: Introduce copy_mc_enhanced_fast_string()
    
    commit 5da8e4a658109e3b7e1f45ae672b7c06ac3e7158 upstream.
    
    The motivations to go rework memcpy_mcsafe() are that the benefit of
    doing slow and careful copies is obviated on newer CPUs, and that the
    current opt-in list of CPUs to instrument recovery is broken relative to
    those CPUs.  There is no need to keep an opt-in list up to date on an
    ongoing basis if pmem/dax operations are instrumented for recovery by
    default. With recovery enabled by default the old "mcsafe_key" opt-in to
    careful copying can be made a "fragile" opt-out. Where the "fragile"
    list takes steps to not consume poison across cachelines.
    
    The discussion with Linus made clear that the current "_mcsafe" suffix
    was imprecise to a fault. The operations that are needed by pmem/dax are
    to copy from a source address that might throw #MC to a destination that
    may write-fault, if it is a user page.
    
    So copy_to_user_mcsafe() becomes copy_mc_to_user() to indicate
    the separate precautions taken on source and destination.
    copy_mc_to_kernel() is introduced as a non-SMAP version that does not
    expect write-faults on the destination, but is still prepared to abort
    with an error code upon taking #MC.
    
    The original copy_mc_fragile() implementation had negative performance
    implications since it did not use the fast-string instruction sequence
    to perform copies. For this reason copy_mc_to_kernel() fell back to
    plain memcpy() to preserve performance on platforms that did not indicate
    the capability to recover from machine check exceptions. However, that
    capability detection was not architectural and now that some platforms
    can recover from fast-string consumption of memory errors the memcpy()
    fallback now causes these more capable platforms to fail.
    
    Introduce copy_mc_enhanced_fast_string() as the fast default
    implementation of copy_mc_to_kernel() and finalize the transition of
    copy_mc_fragile() to be a platform quirk to indicate 'copy-carefully'.
    With this in place, copy_mc_to_kernel() is fast and recovery-ready by
    default regardless of hardware capability.
    
    Thanks to Vivek for identifying that copy_user_generic() is not suitable
    as the copy_mc_to_user() backend since the #MC handler explicitly checks
    ex_has_fault_handler(). Thanks to the 0day robot for catching a
    performance bug in the x86/copy_mc_to_user implementation.
    
     [ bp: Add the "why" for this change from the 0/2th message, massage. ]
    
    Fixes: 92b0729c34ca ("x86/mm, x86/mce: Add memcpy_mcsafe()")
    Reported-by: Erwin Tsaur <erwin.tsaur@intel.com>
    Reported-by: 0day robot <lkp@intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Tested-by: Erwin Tsaur <erwin.tsaur@intel.com>
    Cc: <stable@vger.kernel.org>
    Link: https://lkml.kernel.org/r/160195562556.2163339.18063423034951948973.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5fec7e5a28627138223aa20f5ff484898955ff77
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Oct 5 20:40:16 2020 -0700

    x86, powerpc: Rename memcpy_mcsafe() to copy_mc_to_{user, kernel}()
    
    commit ec6347bb43395cb92126788a1a5b25302543f815 upstream.
    
    In reaction to a proposal to introduce a memcpy_mcsafe_fast()
    implementation Linus points out that memcpy_mcsafe() is poorly named
    relative to communicating the scope of the interface. Specifically what
    addresses are valid to pass as source, destination, and what faults /
    exceptions are handled.
    
    Of particular concern is that even though x86 might be able to handle
    the semantics of copy_mc_to_user() with its common copy_user_generic()
    implementation other archs likely need / want an explicit path for this
    case:
    
      On Fri, May 1, 2020 at 11:28 AM Linus Torvalds <torvalds@linux-foundation.org> wrote:
      >
      > On Thu, Apr 30, 2020 at 6:21 PM Dan Williams <dan.j.williams@intel.com> wrote:
      > >
      > > However now I see that copy_user_generic() works for the wrong reason.
      > > It works because the exception on the source address due to poison
      > > looks no different than a write fault on the user address to the
      > > caller, it's still just a short copy. So it makes copy_to_user() work
      > > for the wrong reason relative to the name.
      >
      > Right.
      >
      > And it won't work that way on other architectures. On x86, we have a
      > generic function that can take faults on either side, and we use it
      > for both cases (and for the "in_user" case too), but that's an
      > artifact of the architecture oddity.
      >
      > In fact, it's probably wrong even on x86 - because it can hide bugs -
      > but writing those things is painful enough that everybody prefers
      > having just one function.
    
    Replace a single top-level memcpy_mcsafe() with either
    copy_mc_to_user(), or copy_mc_to_kernel().
    
    Introduce an x86 copy_mc_fragile() name as the rename for the
    low-level x86 implementation formerly named memcpy_mcsafe(). It is used
    as the slow / careful backend that is supplanted by a fast
    copy_mc_generic() in a follow-on patch.
    
    One side-effect of this reorganization is that separating copy_mc_64.S
    to its own file means that perf no longer needs to track dependencies
    for its memcpy_64.S benchmarks.
    
     [ bp: Massage a bit. ]
    
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Tony Luck <tony.luck@intel.com>
    Acked-by: Michael Ellerman <mpe@ellerman.id.au>
    Cc: <stable@vger.kernel.org>
    Link: http://lore.kernel.org/r/CAHk-=wjSqtXAqfUJxFtWNwmguFASTgB0dz1dT3V-78Quiezqbg@mail.gmail.com
    Link: https://lkml.kernel.org/r/160195561680.2163339.11574962055305783722.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8b5145ba3afc24f9749e57d3c0e6bba0b129dc4d
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 4 18:05:30 2020 +0100

    Revert "x86, powerpc: Rename memcpy_mcsafe() to copy_mc_to_{user, kernel}()"
    
    This reverts commit a85748ed9eb70108f9605558f2754ca94ee91401 which is
    commit ec6347bb43395cb92126788a1a5b25302543f815 upstream.
    
    We had a mistake when merging a later patch in this series due to some
    file movements, so revert this change for now, as we will add it back in
    a later commit.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8406c90cdc780dc86d9daabe9d38f0583467dc4b
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Nov 4 18:05:21 2020 +0100

    Revert "x86/copy_mc: Introduce copy_mc_enhanced_fast_string()"
    
    This reverts commit 4f28b1fb9d1daf3b98710a4b0520fa0c1767cd16 which is
    commit 5da8e4a658109e3b7e1f45ae672b7c06ac3e7158 upstream.
    
    We had a mistake when merging a later patch in this series due to some
    file movements, so revert this change for now, as we will add it back in
    a later commit.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
