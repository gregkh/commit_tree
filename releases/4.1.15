commit 07cc49f66973f49a391c91bf4b158fa0f2562ca8
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Dec 14 21:24:51 2015 -0800

    Linux 4.1.15

commit 296bf2e45cb117a0face3e0e5c94d371d8781e0e
Author: Lu, Han <han.lu@intel.com>
Date:   Wed Nov 11 16:54:27 2015 +0800

    ALSA: hda/hdmi - apply Skylake fix-ups to Broxton display codec
    
    commit e2656412f2a7343ecfd13eb74bac0a6e6e9c5aad upstream.
    
    Broxton and Skylake have the same behavior on display audio. So this patch
    applys Skylake fix-ups to Broxton.
    
    Signed-off-by: Lu, Han <han.lu@intel.com>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3b16e641542a19e5624858d66b2c6f78b21be29e
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Sep 30 15:04:42 2015 +0200

    ceph: fix message length computation
    
    commit 777d738a5e58ba3b6f3932ab1543ce93703f4873 upstream.
    
    create_request_message() computes the maximum length of a message,
    but uses the wrong type for the time stamp: sizeof(struct timespec)
    may be 8 or 16 depending on the architecture, while sizeof(struct
    ceph_timespec) is always 8, and that is what gets put into the
    message.
    
    Found while auditing the uses of timespec for y2038 problems.
    
    Fixes: b8e69066d8af ("ceph: include time stamp in every MDS request")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Yan, Zheng <zyan@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 273ef13347658915da382a970326b1b1cbd3764a
Author: Junxiao Bi <junxiao.bi@oracle.com>
Date:   Fri Nov 20 15:57:30 2015 -0800

    ocfs2: fix umask ignored issue
    
    commit 8f1eb48758aacf6c1ffce18179295adbf3bd7640 upstream.
    
    New created file's mode is not masked with umask, and this makes umask not
    work for ocfs2 volume.
    
    Fixes: 702e5bc ("ocfs2: use generic posix ACL infrastructure")
    Signed-off-by: Junxiao Bi <junxiao.bi@oracle.com>
    Cc: Gang He <ghe@suse.com>
    Cc: Mark Fasheh <mfasheh@suse.de>
    Cc: Joel Becker <jlbec@evilplan.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2cc11ce906598181b1bd3d6c57311959e47446b4
Author: Jeff Layton <jlayton@kernel.org>
Date:   Wed Nov 25 13:50:11 2015 -0500

    nfs: if we have no valid attrs, then don't declare the attribute cache valid
    
    commit c812012f9ca7cf89c9e1a1cd512e6c3b5be04b85 upstream.
    
    If we pass in an empty nfs_fattr struct to nfs_update_inode, it will
    (correctly) not update any of the attributes, but it then clears the
    NFS_INO_INVALID_ATTR flag, which indicates that the attributes are
    up to date. Don't clear the flag if the fattr struct has no valid
    attrs to apply.
    
    Reviewed-by: Steve French <steve.french@primarydata.com>
    Signed-off-by: Jeff Layton <jeff.layton@primarydata.com>
    Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 254cbeb139be712a9dbcfcaea997a3e3dfd9be52
Author: Benjamin Coddington <bcodding@redhat.com>
Date:   Fri Nov 20 09:56:20 2015 -0500

    nfs4: start callback_ident at idr 1
    
    commit c68a027c05709330fe5b2f50c50d5fa02124b5d8 upstream.
    
    If clp->cl_cb_ident is zero, then nfs_cb_idr_remove_locked() skips removing
    it when the nfs_client is freed.  A decoding or server bug can then find
    and try to put that first nfs_client which would lead to a crash.
    
    Signed-off-by: Benjamin Coddington <bcodding@redhat.com>
    Fixes: d6870312659d ("nfs4client: convert to idr_alloc()")
    Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03ecddec2c94e41d31fc1e9b5545f6ba7ced9985
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu Nov 5 00:01:51 2015 +0100

    debugfs: fix refcount imbalance in start_creating
    
    commit 0ee9608c89e81a1ccee52ecb58a7ff040e2522d9 upstream.
    
    In debugfs' start_creating(), we pin the file system to safely access
    its root. When we failed to create a file, we unpin the file system via
    failed_creating() to release the mount count and eventually the reference
    of the vfsmount.
    
    However, when we run into an error during lookup_one_len() when still
    in start_creating(), we only release the parent's mutex but not so the
    reference on the mount. Looks like it was done in the past, but after
    splitting portions of __create_file() into start_creating() and
    end_creating() via 190afd81e4a5 ("debugfs: split the beginning and the
    end of __create_file() off"), this seemed missed. Noticed during code
    review.
    
    Fixes: 190afd81e4a5 ("debugfs: split the beginning and the end of __create_file() off")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3c10560e50f845881cdecfbc22fea7939720ad38
Author: Andrew Elble <aweits@rit.edu>
Date:   Thu Oct 15 12:07:28 2015 -0400

    nfsd: eliminate sending duplicate and repeated delegations
    
    commit 34ed9872e745fa56f10e9bef2cf3d2336c6c8816 upstream.
    
    We've observed the nfsd server in a state where there are
    multiple delegations on the same nfs4_file for the same client.
    The nfs client does attempt to DELEGRETURN these when they are presented to
    it - but apparently under some (unknown) circumstances the client does not
    manage to return all of them. This leads to the eventual
    attempt to CB_RECALL more than one delegation with the same nfs
    filehandle to the same client. The first recall will succeed, but the
    next recall will fail with NFS4ERR_BADHANDLE. This leads to the server
    having delegations on cl_revoked that the client has no way to FREE
    or DELEGRETURN, with resulting inability to recover. The state manager
    on the server will continually assert SEQ4_STATUS_RECALLABLE_STATE_REVOKED,
    and the state manager on the client will be looping unable to satisfy
    the server.
    
    List discussion also reports a race between OPEN and DELEGRETURN that
    will be avoided by only sending the delegation once to the
    client. This is also logically in accordance with RFC5561 9.1.1 and 10.2.
    
    So, let's:
    
    1.) Not hand out duplicate delegations.
    2.) Only send them to the client once.
    
    RFC 5561:
    
    9.1.1:
    "Delegations and layouts, on the other hand, are not associated with a
    specific owner but are associated with the client as a whole
    (identified by a client ID)."
    
    10.2:
    "...the stateid for a delegation is associated with a client ID and may be
    used on behalf of all the open-owners for the given client.  A
    delegation is made to the client as a whole and not to any specific
    process or thread of control within it."
    
    Reported-by: Eric Meddaugh <etmsys@rit.edu>
    Cc: Trond Myklebust <trond.myklebust@primarydata.com>
    Cc: Olga Kornievskaia <aglo@umich.edu>
    Signed-off-by: Andrew Elble <aweits@rit.edu>
    Signed-off-by: J. Bruce Fields <bfields@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 35b2e295e669a6f6817f51a6f14d821e3f5f7ce0
Author: Jeff Layton <jlayton@kernel.org>
Date:   Thu Sep 17 07:47:08 2015 -0400

    nfsd: serialize state seqid morphing operations
    
    commit 35a92fe8770ce54c5eb275cd76128645bea2d200 upstream.
    
    Andrew was seeing a race occur when an OPEN and OPEN_DOWNGRADE were
    running in parallel. The server would receive the OPEN_DOWNGRADE first
    and check its seqid, but then an OPEN would race in and bump it. The
    OPEN_DOWNGRADE would then complete and bump the seqid again.  The result
    was that the OPEN_DOWNGRADE would be applied after the OPEN, even though
    it should have been rejected since the seqid changed.
    
    The only recourse we have here I think is to serialize operations that
    bump the seqid in a stateid, particularly when we're given a seqid in
    the call. To address this, we add a new rw_semaphore to the
    nfs4_ol_stateid struct. We do a down_write prior to checking the seqid
    after looking up the stateid to ensure that nothing else is going to
    bump it while we're operating on it.
    
    In the case of OPEN, we do a down_read, as the call doesn't contain a
    seqid. Those can run in parallel -- we just need to serialize them when
    there is a concurrent OPEN_DOWNGRADE or CLOSE.
    
    LOCK and LOCKU however always take the write lock as there is no
    opportunity for parallelizing those.
    
    Reported-and-Tested-by: Andrew W Elble <aweits@rit.edu>
    Signed-off-by: Jeff Layton <jeff.layton@primarydata.com>
    Signed-off-by: J. Bruce Fields <bfields@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 16693ba9dea8ec10ba94efa683e0530672aad27d
Author: Stefan Richter <stefanr@s5r6.in-berlin.de>
Date:   Tue Nov 3 01:46:21 2015 +0100

    firewire: ohci: fix JMicron JMB38x IT context discovery
    
    commit 100ceb66d5c40cc0c7018e06a9474302470be73c upstream.
    
    Reported by Clifford and Craig for JMicron OHCI-1394 + SDHCI combo
    controllers:  Often or even most of the time, the controller is
    initialized with the message "added OHCI v1.10 device as card 0, 4 IR +
    0 IT contexts, quirks 0x10".  With 0 isochronous transmit DMA contexts
    (IT contexts), applications like audio output are impossible.
    
    However, OHCI-1394 demands that at least 4 IT contexts are implemented
    by the link layer controller, and indeed JMicron JMB38x do implement
    four of them.  Only their IsoXmitIntMask register is unreliable at early
    access.
    
    With my own JMB381 single function controller I found:
      - I can reproduce the problem with a lower probability than Craig's.
      - If I put a loop around the section which clears and reads
        IsoXmitIntMask, then either the first or the second attempt will
        return the correct initial mask of 0x0000000f.  I never encountered
        a case of needing more than a second attempt.
      - Consequently, if I put a dummy reg_read(...IsoXmitIntMaskSet)
        before the first write, the subsequent read will return the correct
        result.
      - If I merely ignore a wrong read result and force the known real
        result, later isochronous transmit DMA usage works just fine.
    
    So let's just fix this chip bug up by the latter method.  Tested with
    JMB381 on kernel 3.13 and 4.3.
    
    Since OHCI-1394 generally requires 4 IT contexts at a minium, this
    workaround is simply applied whenever the initial read of IsoXmitIntMask
    returns 0, regardless whether it's a JMicron chip or not.  I never heard
    of this issue together with any other chip though.
    
    I am not 100% sure that this fix works on the OHCI-1394 part of JMB380
    and JMB388 combo controllers exactly the same as on the JMB381 single-
    function controller, but so far I haven't had a chance to let an owner
    of a combo chip run a patched kernel.
    
    Strangely enough, IsoRecvIntMask is always reported correctly, even
    though it is probed right before IsoXmitIntMask.
    
    Reported-by: Clifford Dunn
    Reported-by: Craig Moore <craig.moore@qenos.com>
    Signed-off-by: Stefan Richter <stefanr@s5r6.in-berlin.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e447b618b9d6f486ab441bc4bd4507628318209
Author: Daeho Jeong <daeho.jeong@samsung.com>
Date:   Sun Oct 18 17:02:56 2015 -0400

    ext4, jbd2: ensure entering into panic after recording an error in superblock
    
    commit 4327ba52afd03fc4b5afa0ee1d774c9c5b0e85c5 upstream.
    
    If a EXT4 filesystem utilizes JBD2 journaling and an error occurs, the
    journaling will be aborted first and the error number will be recorded
    into JBD2 superblock and, finally, the system will enter into the
    panic state in "errors=panic" option.  But, in the rare case, this
    sequence is little twisted like the below figure and it will happen
    that the system enters into panic state, which means the system reset
    in mobile environment, before completion of recording an error in the
    journal superblock. In this case, e2fsck cannot recognize that the
    filesystem failure occurred in the previous run and the corruption
    wouldn't be fixed.
    
    Task A                        Task B
    ext4_handle_error()
    -> jbd2_journal_abort()
      -> __journal_abort_soft()
        -> __jbd2_journal_abort_hard()
        | -> journal->j_flags |= JBD2_ABORT;
        |
        |                         __ext4_abort()
        |                         -> jbd2_journal_abort()
        |                         | -> __journal_abort_soft()
        |                         |   -> if (journal->j_flags & JBD2_ABORT)
        |                         |           return;
        |                         -> panic()
        |
        -> jbd2_journal_update_sb_errno()
    
    Tested-by: Hobin Woo <hobin.woo@samsung.com>
    Signed-off-by: Daeho Jeong <daeho.jeong@samsung.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 456dd91e06dd5194d263c0693811852308c4cc09
Author: Lukas Czerner <lczerner@redhat.com>
Date:   Sat Oct 17 22:57:06 2015 -0400

    ext4: fix potential use after free in __ext4_journal_stop
    
    commit 6934da9238da947628be83635e365df41064b09b upstream.
    
    There is a use-after-free possibility in __ext4_journal_stop() in the
    case that we free the handle in the first jbd2_journal_stop() because
    we're referencing handle->h_err afterwards. This was introduced in
    9705acd63b125dee8b15c705216d7186daea4625 and it is wrong. Fix it by
    storing the handle->h_err value beforehand and avoid referencing
    potentially freed handle.
    
    Fixes: 9705acd63b125dee8b15c705216d7186daea4625
    Signed-off-by: Lukas Czerner <lczerner@redhat.com>
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b8a7a30104317fd37389b2e2b75cc6f3fa7aef2a
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Fri Oct 2 23:54:58 2015 -0400

    ext4 crypto: fix memory leak in ext4_bio_write_page()
    
    commit 937d7b84dca58f2565715f2c8e52f14c3d65fb22 upstream.
    
    There are times when ext4_bio_write_page() is called even though we
    don't actually need to do any I/O.  This happens when ext4_writepage()
    gets called by the jbd2 commit path when an inode needs to force its
    pages written out in order to provide data=ordered guarantees --- and
    a page is backed by an unwritten (e.g., uninitialized) block on disk,
    or if delayed allocation means the page's backing store hasn't been
    allocated yet.  In that case, we need to skip the call to
    ext4_encrypt_page(), since in addition to wasting CPU, it leads to a
    bounce page and an ext4 crypto context getting leaked.
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0330982c45ec56b0855c9288bf07d5c5edb12faf
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Fri Nov 27 19:23:24 2015 +0100

    rbd: don't put snap_context twice in rbd_queue_workfn()
    
    commit 70b16db86f564977df074072143284aec2cb1162 upstream.
    
    Commit 4e752f0ab0e8 ("rbd: access snapshot context and mapping size
    safely") moved ceph_get_snap_context() out of rbd_img_request_create()
    and into rbd_queue_workfn(), adding a ceph_put_snap_context() to the
    error path in rbd_queue_workfn().  However, rbd_img_request_create()
    consumes a ref on snapc, so calling ceph_put_snap_context() after
    a successful rbd_img_request_create() leads to an extra put.  Fix it.
    
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Reviewed-by: Josh Durgin <jdurgin@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c39df1cf3663f94d5453942aaf4922e18122ca0b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Nov 9 18:06:38 2015 +0000

    Btrfs: fix race when listing an inode's xattrs
    
    commit f1cd1f0b7d1b5d4aaa5711e8f4e4898b0045cb6d upstream.
    
    When listing a inode's xattrs we have a time window where we race against
    a concurrent operation for adding a new hard link for our inode that makes
    us not return any xattr to user space. In order for this to happen, the
    first xattr of our inode needs to be at slot 0 of a leaf and the previous
    leaf must still have room for an inode ref (or extref) item, and this can
    happen because an inode's listxattrs callback does not lock the inode's
    i_mutex (nor does the VFS does it for us), but adding a hard link to an
    inode makes the VFS lock the inode's i_mutex before calling the inode's
    link callback.
    
    If we have the following leafs:
    
                   Leaf X (has N items)                    Leaf Y
    
     [ ... (257 INODE_ITEM 0) (257 INODE_REF 256) ]  [ (257 XATTR_ITEM 12345), ... ]
               slot N - 2         slot N - 1              slot 0
    
    The race illustrated by the following sequence diagram is possible:
    
           CPU 1                                               CPU 2
    
      btrfs_listxattr()
    
        searches for key (257 XATTR_ITEM 0)
    
        gets path with path->nodes[0] == leaf X
        and path->slots[0] == N
    
        because path->slots[0] is >=
        btrfs_header_nritems(leaf X), it calls
        btrfs_next_leaf()
    
        btrfs_next_leaf()
          releases the path
    
                                                       adds key (257 INODE_REF 666)
                                                       to the end of leaf X (slot N),
                                                       and leaf X now has N + 1 items
    
          searches for the key (257 INODE_REF 256),
          with path->keep_locks == 1, because that
          is the last key it saw in leaf X before
          releasing the path
    
          ends up at leaf X again and it verifies
          that the key (257 INODE_REF 256) is no
          longer the last key in leaf X, so it
          returns with path->nodes[0] == leaf X
          and path->slots[0] == N, pointing to
          the new item with key (257 INODE_REF 666)
    
        btrfs_listxattr's loop iteration sees that
        the type of the key pointed by the path is
        different from the type BTRFS_XATTR_ITEM_KEY
        and so it breaks the loop and stops looking
        for more xattr items
          --> the application doesn't get any xattr
              listed for our inode
    
    So fix this by breaking the loop only if the key's type is greater than
    BTRFS_XATTR_ITEM_KEY and skip the current key if its type is smaller.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d22b284391fc9bb00857b02de3dfe0ccc0ff73b9
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon Nov 9 00:33:58 2015 +0000

    Btrfs: fix race leading to BUG_ON when running delalloc for nodatacow
    
    commit 1d512cb77bdbda80f0dd0620a3b260d697fd581d upstream.
    
    If we are using the NO_HOLES feature, we have a tiny time window when
    running delalloc for a nodatacow inode where we can race with a concurrent
    link or xattr add operation leading to a BUG_ON.
    
    This happens because at run_delalloc_nocow() we end up casting a leaf item
    of type BTRFS_INODE_[REF|EXTREF]_KEY or of type BTRFS_XATTR_ITEM_KEY to a
    file extent item (struct btrfs_file_extent_item) and then analyse its
    extent type field, which won't match any of the expected extent types
    (values BTRFS_FILE_EXTENT_[REG|PREALLOC|INLINE]) and therefore trigger an
    explicit BUG_ON(1).
    
    The following sequence diagram shows how the race happens when running a
    no-cow dellaloc range [4K, 8K[ for inode 257 and we have the following
    neighbour leafs:
    
                 Leaf X (has N items)                    Leaf Y
    
     [ ... (257 INODE_ITEM 0) (257 INODE_REF 256) ]  [ (257 EXTENT_DATA 8192), ... ]
                  slot N - 2         slot N - 1              slot 0
    
     (Note the implicit hole for inode 257 regarding the [0, 8K[ range)
    
           CPU 1                                         CPU 2
    
     run_dealloc_nocow()
       btrfs_lookup_file_extent()
         --> searches for a key with value
             (257 EXTENT_DATA 4096) in the
             fs/subvol tree
         --> returns us a path with
             path->nodes[0] == leaf X and
             path->slots[0] == N
    
       because path->slots[0] is >=
       btrfs_header_nritems(leaf X), it
       calls btrfs_next_leaf()
    
       btrfs_next_leaf()
         --> releases the path
    
                                                  hard link added to our inode,
                                                  with key (257 INODE_REF 500)
                                                  added to the end of leaf X,
                                                  so leaf X now has N + 1 keys
    
         --> searches for the key
             (257 INODE_REF 256), because
             it was the last key in leaf X
             before it released the path,
             with path->keep_locks set to 1
    
         --> ends up at leaf X again and
             it verifies that the key
             (257 INODE_REF 256) is no longer
             the last key in the leaf, so it
             returns with path->nodes[0] ==
             leaf X and path->slots[0] == N,
             pointing to the new item with
             key (257 INODE_REF 500)
    
       the loop iteration of run_dealloc_nocow()
       does not break out the loop and continues
       because the key referenced in the path
       at path->nodes[0] and path->slots[0] is
       for inode 257, its type is < BTRFS_EXTENT_DATA_KEY
       and its offset (500) is less then our delalloc
       range's end (8192)
    
       the item pointed by the path, an inode reference item,
       is (incorrectly) interpreted as a file extent item and
       we get an invalid extent type, leading to the BUG_ON(1):
    
       if (extent_type == BTRFS_FILE_EXTENT_REG ||
          extent_type == BTRFS_FILE_EXTENT_PREALLOC) {
           (...)
       } else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {
           (...)
       } else {
           BUG_ON(1)
       }
    
    The same can happen if a xattr is added concurrently and ends up having
    a key with an offset smaller then the delalloc's range end.
    
    So fix this by skipping keys with a type smaller than
    BTRFS_EXTENT_DATA_KEY.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 51ac5edb612f7890bdce6b67d9c84697aaac96e3
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Nov 6 13:33:33 2015 +0000

    Btrfs: fix race leading to incorrect item deletion when dropping extents
    
    commit aeafbf8486c9e2bd53f5cc3c10c0b7fd7149d69c upstream.
    
    While running a stress test I got the following warning triggered:
    
      [191627.672810] ------------[ cut here ]------------
      [191627.673949] WARNING: CPU: 8 PID: 8447 at fs/btrfs/file.c:779 __btrfs_drop_extents+0x391/0xa50 [btrfs]()
      (...)
      [191627.701485] Call Trace:
      [191627.702037]  [<ffffffff8145f077>] dump_stack+0x4f/0x7b
      [191627.702992]  [<ffffffff81095de5>] ? console_unlock+0x356/0x3a2
      [191627.704091]  [<ffffffff8104b3b0>] warn_slowpath_common+0xa1/0xbb
      [191627.705380]  [<ffffffffa0664499>] ? __btrfs_drop_extents+0x391/0xa50 [btrfs]
      [191627.706637]  [<ffffffff8104b46d>] warn_slowpath_null+0x1a/0x1c
      [191627.707789]  [<ffffffffa0664499>] __btrfs_drop_extents+0x391/0xa50 [btrfs]
      [191627.709155]  [<ffffffff8115663c>] ? cache_alloc_debugcheck_after.isra.32+0x171/0x1d0
      [191627.712444]  [<ffffffff81155007>] ? kmemleak_alloc_recursive.constprop.40+0x16/0x18
      [191627.714162]  [<ffffffffa06570c9>] insert_reserved_file_extent.constprop.40+0x83/0x24e [btrfs]
      [191627.715887]  [<ffffffffa065422b>] ? start_transaction+0x3bb/0x610 [btrfs]
      [191627.717287]  [<ffffffffa065b604>] btrfs_finish_ordered_io+0x273/0x4e2 [btrfs]
      [191627.728865]  [<ffffffffa065b888>] finish_ordered_fn+0x15/0x17 [btrfs]
      [191627.730045]  [<ffffffffa067d688>] normal_work_helper+0x14c/0x32c [btrfs]
      [191627.731256]  [<ffffffffa067d96a>] btrfs_endio_write_helper+0x12/0x14 [btrfs]
      [191627.732661]  [<ffffffff81061119>] process_one_work+0x24c/0x4ae
      [191627.733822]  [<ffffffff810615b0>] worker_thread+0x206/0x2c2
      [191627.734857]  [<ffffffff810613aa>] ? process_scheduled_works+0x2f/0x2f
      [191627.736052]  [<ffffffff810613aa>] ? process_scheduled_works+0x2f/0x2f
      [191627.737349]  [<ffffffff810669a6>] kthread+0xef/0xf7
      [191627.738267]  [<ffffffff810f3b3a>] ? time_hardirqs_on+0x15/0x28
      [191627.739330]  [<ffffffff810668b7>] ? __kthread_parkme+0xad/0xad
      [191627.741976]  [<ffffffff81465592>] ret_from_fork+0x42/0x70
      [191627.743080]  [<ffffffff810668b7>] ? __kthread_parkme+0xad/0xad
      [191627.744206] ---[ end trace bbfddacb7aaada8d ]---
    
      $ cat -n fs/btrfs/file.c
      691  int __btrfs_drop_extents(struct btrfs_trans_handle *trans,
      (...)
      758                  btrfs_item_key_to_cpu(leaf, &key, path->slots[0]);
      759                  if (key.objectid > ino ||
      760                      key.type > BTRFS_EXTENT_DATA_KEY || key.offset >= end)
      761                          break;
      762
      763                  fi = btrfs_item_ptr(leaf, path->slots[0],
      764                                      struct btrfs_file_extent_item);
      765                  extent_type = btrfs_file_extent_type(leaf, fi);
      766
      767                  if (extent_type == BTRFS_FILE_EXTENT_REG ||
      768                      extent_type == BTRFS_FILE_EXTENT_PREALLOC) {
      (...)
      774                  } else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {
      (...)
      778                  } else {
      779                          WARN_ON(1);
      780                          extent_end = search_start;
      781                  }
      (...)
    
    This happened because the item we were processing did not match a file
    extent item (its key type != BTRFS_EXTENT_DATA_KEY), and even on this
    case we cast the item to a struct btrfs_file_extent_item pointer and
    then find a type field value that does not match any of the expected
    values (BTRFS_FILE_EXTENT_[REG|PREALLOC|INLINE]). This scenario happens
    due to a tiny time window where a race can happen as exemplified below.
    For example, consider the following scenario where we're using the
    NO_HOLES feature and we have the following two neighbour leafs:
    
                   Leaf X (has N items)                    Leaf Y
    
    [ ... (257 INODE_ITEM 0) (257 INODE_REF 256) ]  [ (257 EXTENT_DATA 8192), ... ]
              slot N - 2         slot N - 1              slot 0
    
    Our inode 257 has an implicit hole in the range [0, 8K[ (implicit rather
    than explicit because NO_HOLES is enabled). Now if our inode has an
    ordered extent for the range [4K, 8K[ that is finishing, the following
    can happen:
    
              CPU 1                                       CPU 2
    
      btrfs_finish_ordered_io()
        insert_reserved_file_extent()
          __btrfs_drop_extents()
             Searches for the key
              (257 EXTENT_DATA 4096) through
              btrfs_lookup_file_extent()
    
             Key not found and we get a path where
             path->nodes[0] == leaf X and
             path->slots[0] == N
    
             Because path->slots[0] is >=
             btrfs_header_nritems(leaf X), we call
             btrfs_next_leaf()
    
             btrfs_next_leaf() releases the path
    
                                                      inserts key
                                                      (257 INODE_REF 4096)
                                                      at the end of leaf X,
                                                      leaf X now has N + 1 keys,
                                                      and the new key is at
                                                      slot N
    
             btrfs_next_leaf() searches for
             key (257 INODE_REF 256), with
             path->keep_locks set to 1,
             because it was the last key it
             saw in leaf X
    
               finds it in leaf X again and
               notices it's no longer the last
               key of the leaf, so it returns 0
               with path->nodes[0] == leaf X and
               path->slots[0] == N (which is now
               < btrfs_header_nritems(leaf X)),
               pointing to the new key
               (257 INODE_REF 4096)
    
             __btrfs_drop_extents() casts the
             item at path->nodes[0], slot
             path->slots[0], to a struct
             btrfs_file_extent_item - it does
             not skip keys for the target
             inode with a type less than
             BTRFS_EXTENT_DATA_KEY
             (BTRFS_INODE_REF_KEY < BTRFS_EXTENT_DATA_KEY)
    
             sees a bogus value for the type
             field triggering the WARN_ON in
             the trace shown above, and sets
             extent_end = search_start (4096)
    
             does the if-then-else logic to
             fixup 0 length extent items created
             by a past bug from hole punching:
    
               if (extent_end == key.offset &&
                   extent_end >= search_start)
                   goto delete_extent_item;
    
             that evaluates to true and it ends
             up deleting the key pointed to by
             path->slots[0], (257 INODE_REF 4096),
             from leaf X
    
    The same could happen for example for a xattr that ends up having a key
    with an offset value that matches search_start (very unlikely but not
    impossible).
    
    So fix this by ensuring that keys smaller than BTRFS_EXTENT_DATA_KEY are
    skipped, never casted to struct btrfs_file_extent_item and never deleted
    by accident. Also protect against the unexpected case of getting a key
    for a lower inode number by skipping that key and issuing a warning.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f1008f6d21ec52d533f7473e2e46218408fb4580
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri Oct 16 12:34:25 2015 +0100

    Btrfs: fix truncation of compressed and inlined extents
    
    commit 0305cd5f7fca85dae392b9ba85b116896eb7c1c7 upstream.
    
    When truncating a file to a smaller size which consists of an inline
    extent that is compressed, we did not discard (or made unusable) the
    data between the new file size and the old file size, wasting metadata
    space and allowing for the truncated data to be leaked and the data
    corruption/loss mentioned below.
    We were also not correctly decrementing the number of bytes used by the
    inode, we were setting it to zero, giving a wrong report for callers of
    the stat(2) syscall. The fsck tool also reported an error about a mismatch
    between the nbytes of the file versus the real space used by the file.
    
    Now because we weren't discarding the truncated region of the file, it
    was possible for a caller of the clone ioctl to actually read the data
    that was truncated, allowing for a security breach without requiring root
    access to the system, using only standard filesystem operations. The
    scenario is the following:
    
       1) User A creates a file which consists of an inline and compressed
          extent with a size of 2000 bytes - the file is not accessible to
          any other users (no read, write or execution permission for anyone
          else);
    
       2) The user truncates the file to a size of 1000 bytes;
    
       3) User A makes the file world readable;
    
       4) User B creates a file consisting of an inline extent of 2000 bytes;
    
       5) User B issues a clone operation from user A's file into its own
          file (using a length argument of 0, clone the whole range);
    
       6) User B now gets to see the 1000 bytes that user A truncated from
          its file before it made its file world readbale. User B also lost
          the bytes in the range [1000, 2000[ bytes from its own file, but
          that might be ok if his/her intention was reading stale data from
          user A that was never supposed to be public.
    
    Note that this contrasts with the case where we truncate a file from 2000
    bytes to 1000 bytes and then truncate it back from 1000 to 2000 bytes. In
    this case reading any byte from the range [1000, 2000[ will return a value
    of 0x00, instead of the original data.
    
    This problem exists since the clone ioctl was added and happens both with
    and without my recent data loss and file corruption fixes for the clone
    ioctl (patch "Btrfs: fix file corruption and data loss after cloning
    inline extents").
    
    So fix this by truncating the compressed inline extents as we do for the
    non-compressed case, which involves decompressing, if the data isn't already
    in the page cache, compressing the truncated version of the extent, writing
    the compressed content into the inline extent and then truncate it.
    
    The following test case for fstests reproduces the problem. In order for
    the test to pass both this fix and my previous fix for the clone ioctl
    that forbids cloning a smaller inline extent into a larger one,
    which is titled "Btrfs: fix file corruption and data loss after cloning
    inline extents", are needed. Without that other fix the test fails in a
    different way that does not leak the truncated data, instead part of
    destination file gets replaced with zeroes (because the destination file
    has a larger inline extent than the source).
    
      seq=`basename $0`
      seqres=$RESULT_DIR/$seq
      echo "QA output created by $seq"
      tmp=/tmp/$$
      status=1      # failure is the default!
      trap "_cleanup; exit \$status" 0 1 2 3 15
    
      _cleanup()
      {
          rm -f $tmp.*
      }
    
      # get standard environment, filters and checks
      . ./common/rc
      . ./common/filter
    
      # real QA test starts here
      _need_to_be_root
      _supported_fs btrfs
      _supported_os Linux
      _require_scratch
      _require_cloner
    
      rm -f $seqres.full
    
      _scratch_mkfs >>$seqres.full 2>&1
      _scratch_mount "-o compress"
    
      # Create our test files. File foo is going to be the source of a clone operation
      # and consists of a single inline extent with an uncompressed size of 512 bytes,
      # while file bar consists of a single inline extent with an uncompressed size of
      # 256 bytes. For our test's purpose, it's important that file bar has an inline
      # extent with a size smaller than foo's inline extent.
      $XFS_IO_PROG -f -c "pwrite -S 0xa1 0 128"   \
              -c "pwrite -S 0x2a 128 384" \
              $SCRATCH_MNT/foo | _filter_xfs_io
      $XFS_IO_PROG -f -c "pwrite -S 0xbb 0 256" $SCRATCH_MNT/bar | _filter_xfs_io
    
      # Now durably persist all metadata and data. We do this to make sure that we get
      # on disk an inline extent with a size of 512 bytes for file foo.
      sync
    
      # Now truncate our file foo to a smaller size. Because it consists of a
      # compressed and inline extent, btrfs did not shrink the inline extent to the
      # new size (if the extent was not compressed, btrfs would shrink it to 128
      # bytes), it only updates the inode's i_size to 128 bytes.
      $XFS_IO_PROG -c "truncate 128" $SCRATCH_MNT/foo
    
      # Now clone foo's inline extent into bar.
      # This clone operation should fail with errno EOPNOTSUPP because the source
      # file consists only of an inline extent and the file's size is smaller than
      # the inline extent of the destination (128 bytes < 256 bytes). However the
      # clone ioctl was not prepared to deal with a file that has a size smaller
      # than the size of its inline extent (something that happens only for compressed
      # inline extents), resulting in copying the full inline extent from the source
      # file into the destination file.
      #
      # Note that btrfs' clone operation for inline extents consists of removing the
      # inline extent from the destination inode and copy the inline extent from the
      # source inode into the destination inode, meaning that if the destination
      # inode's inline extent is larger (N bytes) than the source inode's inline
      # extent (M bytes), some bytes (N - M bytes) will be lost from the destination
      # file. Btrfs could copy the source inline extent's data into the destination's
      # inline extent so that we would not lose any data, but that's currently not
      # done due to the complexity that would be needed to deal with such cases
      # (specially when one or both extents are compressed), returning EOPNOTSUPP, as
      # it's normally not a very common case to clone very small files (only case
      # where we get inline extents) and copying inline extents does not save any
      # space (unlike for normal, non-inlined extents).
      $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/foo $SCRATCH_MNT/bar
    
      # Now because the above clone operation used to succeed, and due to foo's inline
      # extent not being shinked by the truncate operation, our file bar got the whole
      # inline extent copied from foo, making us lose the last 128 bytes from bar
      # which got replaced by the bytes in range [128, 256[ from foo before foo was
      # truncated - in other words, data loss from bar and being able to read old and
      # stale data from foo that should not be possible to read anymore through normal
      # filesystem operations. Contrast with the case where we truncate a file from a
      # size N to a smaller size M, truncate it back to size N and then read the range
      # [M, N[, we should always get the value 0x00 for all the bytes in that range.
    
      # We expected the clone operation to fail with errno EOPNOTSUPP and therefore
      # not modify our file's bar data/metadata. So its content should be 256 bytes
      # long with all bytes having the value 0xbb.
      #
      # Without the btrfs bug fix, the clone operation succeeded and resulted in
      # leaking truncated data from foo, the bytes that belonged to its range
      # [128, 256[, and losing data from bar in that same range. So reading the
      # file gave us the following content:
      #
      # 0000000 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1
      # *
      # 0000200 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a 2a
      # *
      # 0000400
      echo "File bar's content after the clone operation:"
      od -t x1 $SCRATCH_MNT/bar
    
      # Also because the foo's inline extent was not shrunk by the truncate
      # operation, btrfs' fsck, which is run by the fstests framework everytime a
      # test completes, failed reporting the following error:
      #
      #  root 5 inode 257 errors 400, nbytes wrong
    
      status=0
      exit
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 83881c15e5cef225beec81a37e0906125e636d75
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Oct 13 15:15:00 2015 +0100

    Btrfs: fix file corruption and data loss after cloning inline extents
    
    commit 8039d87d9e473aeb740d4fdbd59b9d2f89b2ced9 upstream.
    
    Currently the clone ioctl allows to clone an inline extent from one file
    to another that already has other (non-inlined) extents. This is a problem
    because btrfs is not designed to deal with files having inline and regular
    extents, if a file has an inline extent then it must be the only extent
    in the file and must start at file offset 0. Having a file with an inline
    extent followed by regular extents results in EIO errors when doing reads
    or writes against the first 4K of the file.
    
    Also, the clone ioctl allows one to lose data if the source file consists
    of a single inline extent, with a size of N bytes, and the destination
    file consists of a single inline extent with a size of M bytes, where we
    have M > N. In this case the clone operation removes the inline extent
    from the destination file and then copies the inline extent from the
    source file into the destination file - we lose the M - N bytes from the
    destination file, a read operation will get the value 0x00 for any bytes
    in the the range [N, M] (the destination inode's i_size remained as M,
    that's why we can read past N bytes).
    
    So fix this by not allowing such destructive operations to happen and
    return errno EOPNOTSUPP to user space.
    
    Currently the fstest btrfs/035 tests the data loss case but it totally
    ignores this - i.e. expects the operation to succeed and does not check
    the we got data loss.
    
    The following test case for fstests exercises all these cases that result
    in file corruption and data loss:
    
      seq=`basename $0`
      seqres=$RESULT_DIR/$seq
      echo "QA output created by $seq"
      tmp=/tmp/$$
      status=1      # failure is the default!
      trap "_cleanup; exit \$status" 0 1 2 3 15
    
      _cleanup()
      {
          rm -f $tmp.*
      }
    
      # get standard environment, filters and checks
      . ./common/rc
      . ./common/filter
    
      # real QA test starts here
      _need_to_be_root
      _supported_fs btrfs
      _supported_os Linux
      _require_scratch
      _require_cloner
      _require_btrfs_fs_feature "no_holes"
      _require_btrfs_mkfs_feature "no-holes"
    
      rm -f $seqres.full
    
      test_cloning_inline_extents()
      {
          local mkfs_opts=$1
          local mount_opts=$2
    
          _scratch_mkfs $mkfs_opts >>$seqres.full 2>&1
          _scratch_mount $mount_opts
    
          # File bar, the source for all the following clone operations, consists
          # of a single inline extent (50 bytes).
          $XFS_IO_PROG -f -c "pwrite -S 0xbb 0 50" $SCRATCH_MNT/bar \
              | _filter_xfs_io
    
          # Test cloning into a file with an extent (non-inlined) where the
          # destination offset overlaps that extent. It should not be possible to
          # clone the inline extent from file bar into this file.
          $XFS_IO_PROG -f -c "pwrite -S 0xaa 0K 16K" $SCRATCH_MNT/foo \
              | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo
    
          # Doing IO against any range in the first 4K of the file should work.
          # Due to a past clone ioctl bug which allowed cloning the inline extent,
          # these operations resulted in EIO errors.
          echo "File foo data after clone operation:"
          # All bytes should have the value 0xaa (clone operation failed and did
          # not modify our file).
          od -t x1 $SCRATCH_MNT/foo
          $XFS_IO_PROG -c "pwrite -S 0xcc 0 100" $SCRATCH_MNT/foo | _filter_xfs_io
    
          # Test cloning the inline extent against a file which has a hole in its
          # first 4K followed by a non-inlined extent. It should not be possible
          # as well to clone the inline extent from file bar into this file.
          $XFS_IO_PROG -f -c "pwrite -S 0xdd 4K 12K" $SCRATCH_MNT/foo2 \
              | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo2
    
          # Doing IO against any range in the first 4K of the file should work.
          # Due to a past clone ioctl bug which allowed cloning the inline extent,
          # these operations resulted in EIO errors.
          echo "File foo2 data after clone operation:"
          # All bytes should have the value 0x00 (clone operation failed and did
          # not modify our file).
          od -t x1 $SCRATCH_MNT/foo2
          $XFS_IO_PROG -c "pwrite -S 0xee 0 90" $SCRATCH_MNT/foo2 | _filter_xfs_io
    
          # Test cloning the inline extent against a file which has a size of zero
          # but has a prealloc extent. It should not be possible as well to clone
          # the inline extent from file bar into this file.
          $XFS_IO_PROG -f -c "falloc -k 0 1M" $SCRATCH_MNT/foo3 | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo3
    
          # Doing IO against any range in the first 4K of the file should work.
          # Due to a past clone ioctl bug which allowed cloning the inline extent,
          # these operations resulted in EIO errors.
          echo "First 50 bytes of foo3 after clone operation:"
          # Should not be able to read any bytes, file has 0 bytes i_size (the
          # clone operation failed and did not modify our file).
          od -t x1 $SCRATCH_MNT/foo3
          $XFS_IO_PROG -c "pwrite -S 0xff 0 90" $SCRATCH_MNT/foo3 | _filter_xfs_io
    
          # Test cloning the inline extent against a file which consists of a
          # single inline extent that has a size not greater than the size of
          # bar's inline extent (40 < 50).
          # It should be possible to do the extent cloning from bar to this file.
          $XFS_IO_PROG -f -c "pwrite -S 0x01 0 40" $SCRATCH_MNT/foo4 \
              | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo4
    
          # Doing IO against any range in the first 4K of the file should work.
          echo "File foo4 data after clone operation:"
          # Must match file bar's content.
          od -t x1 $SCRATCH_MNT/foo4
          $XFS_IO_PROG -c "pwrite -S 0x02 0 90" $SCRATCH_MNT/foo4 | _filter_xfs_io
    
          # Test cloning the inline extent against a file which consists of a
          # single inline extent that has a size greater than the size of bar's
          # inline extent (60 > 50).
          # It should not be possible to clone the inline extent from file bar
          # into this file.
          $XFS_IO_PROG -f -c "pwrite -S 0x03 0 60" $SCRATCH_MNT/foo5 \
              | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo5
    
          # Reading the file should not fail.
          echo "File foo5 data after clone operation:"
          # Must have a size of 60 bytes, with all bytes having a value of 0x03
          # (the clone operation failed and did not modify our file).
          od -t x1 $SCRATCH_MNT/foo5
    
          # Test cloning the inline extent against a file which has no extents but
          # has a size greater than bar's inline extent (16K > 50).
          # It should not be possible to clone the inline extent from file bar
          # into this file.
          $XFS_IO_PROG -f -c "truncate 16K" $SCRATCH_MNT/foo6 | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo6
    
          # Reading the file should not fail.
          echo "File foo6 data after clone operation:"
          # Must have a size of 16K, with all bytes having a value of 0x00 (the
          # clone operation failed and did not modify our file).
          od -t x1 $SCRATCH_MNT/foo6
    
          # Test cloning the inline extent against a file which has no extents but
          # has a size not greater than bar's inline extent (30 < 50).
          # It should be possible to clone the inline extent from file bar into
          # this file.
          $XFS_IO_PROG -f -c "truncate 30" $SCRATCH_MNT/foo7 | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo7
    
          # Reading the file should not fail.
          echo "File foo7 data after clone operation:"
          # Must have a size of 50 bytes, with all bytes having a value of 0xbb.
          od -t x1 $SCRATCH_MNT/foo7
    
          # Test cloning the inline extent against a file which has a size not
          # greater than the size of bar's inline extent (20 < 50) but has
          # a prealloc extent that goes beyond the file's size. It should not be
          # possible to clone the inline extent from bar into this file.
          $XFS_IO_PROG -f -c "falloc -k 0 1M" \
                          -c "pwrite -S 0x88 0 20" \
                          $SCRATCH_MNT/foo8 | _filter_xfs_io
          $CLONER_PROG -s 0 -d 0 -l 0 $SCRATCH_MNT/bar $SCRATCH_MNT/foo8
    
          echo "File foo8 data after clone operation:"
          # Must have a size of 20 bytes, with all bytes having a value of 0x88
          # (the clone operation did not modify our file).
          od -t x1 $SCRATCH_MNT/foo8
    
          _scratch_unmount
      }
    
      echo -e "\nTesting without compression and without the no-holes feature...\n"
      test_cloning_inline_extents
    
      echo -e "\nTesting with compression and without the no-holes feature...\n"
      test_cloning_inline_extents "" "-o compress"
    
      echo -e "\nTesting without compression and with the no-holes feature...\n"
      test_cloning_inline_extents "-O no-holes" ""
    
      echo -e "\nTesting with compression and with the no-holes feature...\n"
      test_cloning_inline_extents "-O no-holes" "-o compress"
    
      status=0
      exit
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3d817ad351a182e94172ce0a2bbe4a168995ff53
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Dec 1 20:08:51 2015 -0800

    net_sched: fix qdisc_tree_decrease_qlen() races
    
    [ Upstream commit 4eaf3b84f2881c9c028f1d5e76c52ab575fe3a66 ]
    
    qdisc_tree_decrease_qlen() suffers from two problems on multiqueue
    devices.
    
    One problem is that it updates sch->q.qlen and sch->qstats.drops
    on the mq/mqprio root qdisc, while it should not : Daniele
    reported underflows errors :
    [  681.774821] PAX: sch->q.qlen: 0 n: 1
    [  681.774825] PAX: size overflow detected in function qdisc_tree_decrease_qlen net/sched/sch_api.c:769 cicus.693_49 min, count: 72, decl: qlen; num: 0; context: sk_buff_head;
    [  681.774954] CPU: 2 PID: 19 Comm: ksoftirqd/2 Tainted: G           O    4.2.6.201511282239-1-grsec #1
    [  681.774955] Hardware name: ASUSTeK COMPUTER INC. X302LJ/X302LJ, BIOS X302LJ.202 03/05/2015
    [  681.774956]  ffffffffa9a04863 0000000000000000 0000000000000000 ffffffffa990ff7c
    [  681.774959]  ffffc90000d3bc38 ffffffffa95d2810 0000000000000007 ffffffffa991002b
    [  681.774960]  ffffc90000d3bc68 ffffffffa91a44f4 0000000000000001 0000000000000001
    [  681.774962] Call Trace:
    [  681.774967]  [<ffffffffa95d2810>] dump_stack+0x4c/0x7f
    [  681.774970]  [<ffffffffa91a44f4>] report_size_overflow+0x34/0x50
    [  681.774972]  [<ffffffffa94d17e2>] qdisc_tree_decrease_qlen+0x152/0x160
    [  681.774976]  [<ffffffffc02694b1>] fq_codel_dequeue+0x7b1/0x820 [sch_fq_codel]
    [  681.774978]  [<ffffffffc02680a0>] ? qdisc_peek_dequeued+0xa0/0xa0 [sch_fq_codel]
    [  681.774980]  [<ffffffffa94cd92d>] __qdisc_run+0x4d/0x1d0
    [  681.774983]  [<ffffffffa949b2b2>] net_tx_action+0xc2/0x160
    [  681.774985]  [<ffffffffa90664c1>] __do_softirq+0xf1/0x200
    [  681.774987]  [<ffffffffa90665ee>] run_ksoftirqd+0x1e/0x30
    [  681.774989]  [<ffffffffa90896b0>] smpboot_thread_fn+0x150/0x260
    [  681.774991]  [<ffffffffa9089560>] ? sort_range+0x40/0x40
    [  681.774992]  [<ffffffffa9085fe4>] kthread+0xe4/0x100
    [  681.774994]  [<ffffffffa9085f00>] ? kthread_worker_fn+0x170/0x170
    [  681.774995]  [<ffffffffa95d8d1e>] ret_from_fork+0x3e/0x70
    
    mq/mqprio have their own ways to report qlen/drops by folding stats on
    all their queues, with appropriate locking.
    
    A second problem is that qdisc_tree_decrease_qlen() calls qdisc_lookup()
    without proper locking : concurrent qdisc updates could corrupt the list
    that qdisc_match_from_root() parses to find a qdisc given its handle.
    
    Fix first problem adding a TCQ_F_NOPARENT qdisc flag that
    qdisc_tree_decrease_qlen() can use to abort its tree traversal,
    as soon as it meets a mq/mqprio qdisc children.
    
    Second problem can be fixed by RCU protection.
    Qdisc are already freed after RCU grace period, so qdisc_list_add() and
    qdisc_list_del() simply have to use appropriate rcu list variants.
    
    A future patch will add a per struct netdev_queue list anchor, so that
    qdisc_tree_decrease_qlen() can have more efficient lookups.
    
    Reported-by: Daniele Fucini <dfucini@gmail.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Cong Wang <cwang@twopensource.com>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cbff65fb298f5b9d147eb39fd4fc540d57748f69
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Dec 1 07:20:07 2015 -0800

    ipv6: sctp: implement sctp_v6_destroy_sock()
    
    [ Upstream commit 602dd62dfbda3e63a2d6a3cbde953ebe82bf5087 ]
    
    Dmitry Vyukov reported a memory leak using IPV6 SCTP sockets.
    
    We need to call inet6_destroy_sock() to properly release
    inet6 specific fields.
    
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e08ca7be16f178988ccf95f96edf6eff5d89bb0a
Author: Konstantin Khlebnikov <koct9i@gmail.com>
Date:   Tue Dec 1 01:14:48 2015 +0300

    net/neighbour: fix crash at dumping device-agnostic proxy entries
    
    [ Upstream commit 6adc5fd6a142c6e2c80574c1db0c7c17dedaa42e ]
    
    Proxy entries could have null pointer to net-device.
    
    Signed-off-by: Konstantin Khlebnikov <koct9i@gmail.com>
    Fixes: 84920c1420e2 ("net: Allow ipv6 proxies and arp proxies be shown with iproute2")
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 81ed463384847813faa59e692285fe775da7375f
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Nov 29 19:37:57 2015 -0800

    ipv6: add complete rcu protection around np->opt
    
    [ Upstream commit 45f6fad84cc305103b28d73482b344d7f5b76f39 ]
    
    This patch addresses multiple problems :
    
    UDP/RAW sendmsg() need to get a stable struct ipv6_txoptions
    while socket is not locked : Other threads can change np->opt
    concurrently. Dmitry posted a syzkaller
    (http://github.com/google/syzkaller) program desmonstrating
    use-after-free.
    
    Starting with TCP/DCCP lockless listeners, tcp_v6_syn_recv_sock()
    and dccp_v6_request_recv_sock() also need to use RCU protection
    to dereference np->opt once (before calling ipv6_dup_options())
    
    This patch adds full RCU protection to np->opt
    
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 879e7d33bea095c7c3ed51fc19a58b6001e26797
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Mon Nov 30 13:02:56 2015 +0100

    bpf, array: fix heap out-of-bounds access when updating elements
    
    [ Upstream commit fbca9d2d35c6ef1b323fae75cc9545005ba25097 ]
    
    During own review but also reported by Dmitry's syzkaller [1] it has been
    noticed that we trigger a heap out-of-bounds access on eBPF array maps
    when updating elements. This happens with each map whose map->value_size
    (specified during map creation time) is not multiple of 8 bytes.
    
    In array_map_alloc(), elem_size is round_up(attr->value_size, 8) and
    used to align array map slots for faster access. However, in function
    array_map_update_elem(), we update the element as ...
    
    memcpy(array->value + array->elem_size * index, value, array->elem_size);
    
    ... where we access 'value' out-of-bounds, since it was allocated from
    map_update_elem() from syscall side as kmalloc(map->value_size, GFP_USER)
    and later on copied through copy_from_user(value, uvalue, map->value_size).
    Thus, up to 7 bytes, we can access out-of-bounds.
    
    Same could happen from within an eBPF program, where in worst case we
    access beyond an eBPF program's designated stack.
    
    Since 1be7f75d1668 ("bpf: enable non-root eBPF programs") didn't hit an
    official release yet, it only affects priviledged users.
    
    In case of array_map_lookup_elem(), the verifier prevents eBPF programs
    from accessing beyond map->value_size through check_map_access(). Also
    from syscall side map_lookup_elem() only copies map->value_size back to
    user, so nothing could leak.
    
      [1] http://github.com/google/syzkaller
    
    Fixes: 28fbcfa08d8e ("bpf: add array type of eBPF maps")
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28492d307272fa3090f026d559e0d3ea8328b4dd
Author: Quentin Casasnovas <quentin.casasnovas@oracle.com>
Date:   Tue Nov 24 17:13:21 2015 -0500

    RDS: fix race condition when sending a message on unbound socket
    
    [ Upstream commit 8c7188b23474cca017b3ef354c4a58456f68303a ]
    
    Sasha's found a NULL pointer dereference in the RDS connection code when
    sending a message to an apparently unbound socket.  The problem is caused
    by the code checking if the socket is bound in rds_sendmsg(), which checks
    the rs_bound_addr field without taking a lock on the socket.  This opens a
    race where rs_bound_addr is temporarily set but where the transport is not
    in rds_bind(), leading to a NULL pointer dereference when trying to
    dereference 'trans' in __rds_conn_create().
    
    Vegard wrote a reproducer for this issue, so kindly ask him to share if
    you're interested.
    
    I cannot reproduce the NULL pointer dereference using Vegard's reproducer
    with this patch, whereas I could without.
    
    Complete earlier incomplete fix to CVE-2015-6937:
    
      74e98eb08588 ("RDS: verify the underlying transport exists before creating a connection")
    
    Cc: David S. Miller <davem@davemloft.net>
    Cc: stable@vger.kernel.org
    
    Reviewed-by: Vegard Nossum <vegard.nossum@oracle.com>
    Reviewed-by: Sasha Levin <sasha.levin@oracle.com>
    Acked-by: Santosh Shilimkar <santosh.shilimkar@oracle.com>
    Signed-off-by: Quentin Casasnovas <quentin.casasnovas@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9cc12699e4ca4dd3f74ea7050668a48fbbc9212
Author: Michal Kubeček <mkubecek@suse.cz>
Date:   Tue Nov 24 15:07:11 2015 +0100

    ipv6: distinguish frag queues by device for multicast and link-local packets
    
    [ Upstream commit 264640fc2c5f4f913db5c73fa3eb1ead2c45e9d7 ]
    
    If a fragmented multicast packet is received on an ethernet device which
    has an active macvlan on top of it, each fragment is duplicated and
    received both on the underlying device and the macvlan. If some
    fragments for macvlan are processed before the whole packet for the
    underlying device is reassembled, the "overlapping fragments" test in
    ip6_frag_queue() discards the whole fragment queue.
    
    To resolve this, add device ifindex to the search key and require it to
    match reassembling multicast packets and packets to link-local
    addresses.
    
    Note: similar patch has been already submitted by Yoshifuji Hideaki in
    
      http://patchwork.ozlabs.org/patch/220979/
    
    but got lost and forgotten for some reason.
    
    Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ed454cb60aad2600fd466c11c2b71fef86c746c5
Author: Aaro Koskinen <aaro.koskinen@iki.fi>
Date:   Sun Nov 22 01:08:54 2015 +0200

    broadcom: fix PHY_ID_BCM5481 entry in the id table
    
    [ Upstream commit 3c25a860d17b7378822f35d8c9141db9507e3beb ]
    
    Commit fcb26ec5b18d ("broadcom: move all PHY_ID's to header")
    updated broadcom_tbl to use PHY_IDs, but incorrectly replaced 0x0143bca0
    with PHY_ID_BCM5482 (making a duplicate entry, and completely omitting
    the original). Fix that.
    
    Fixes: fcb26ec5b18d ("broadcom: move all PHY_ID's to header")
    Signed-off-by: Aaro Koskinen <aaro.koskinen@iki.fi>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c3c060bbdaaced093f3a2ab43b30a8038fa1476
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Fri Nov 20 13:54:20 2015 +0100

    net: ip6mr: fix static mfc/dev leaks on table destruction
    
    [ Upstream commit 4c6980462f32b4f282c5d8e5f7ea8070e2937725 ]
    
    Similar to ipv4, when destroying an mrt table the static mfc entries and
    the static devices are kept, which leads to devices that can never be
    destroyed (because of refcnt taken) and leaked memory. Make sure that
    everything is cleaned up on netns destruction.
    
    Fixes: 8229efdaef1e ("netns: ip6mr: enable namespace support in ipv6 multicast forwarding code")
    CC: Benjamin Thery <benjamin.thery@bull.net>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Reviewed-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3621421a35c3070ab86741f2e7ac8da635f79980
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Fri Nov 20 13:54:19 2015 +0100

    net: ipmr: fix static mfc/dev leaks on table destruction
    
    [ Upstream commit 0e615e9601a15efeeb8942cf7cd4dadba0c8c5a7 ]
    
    When destroying an mrt table the static mfc entries and the static
    devices are kept, which leads to devices that can never be destroyed
    (because of refcnt taken) and leaked memory, for example:
    unreferenced object 0xffff880034c144c0 (size 192):
      comm "mfc-broken", pid 4777, jiffies 4320349055 (age 46001.964s)
      hex dump (first 32 bytes):
        98 53 f0 34 00 88 ff ff 98 53 f0 34 00 88 ff ff  .S.4.....S.4....
        ef 0a 0a 14 01 02 03 04 00 00 00 00 01 00 00 00  ................
      backtrace:
        [<ffffffff815c1b9e>] kmemleak_alloc+0x4e/0xb0
        [<ffffffff811ea6e0>] kmem_cache_alloc+0x190/0x300
        [<ffffffff815931cb>] ip_mroute_setsockopt+0x5cb/0x910
        [<ffffffff8153d575>] do_ip_setsockopt.isra.11+0x105/0xff0
        [<ffffffff8153e490>] ip_setsockopt+0x30/0xa0
        [<ffffffff81564e13>] raw_setsockopt+0x33/0x90
        [<ffffffff814d1e14>] sock_common_setsockopt+0x14/0x20
        [<ffffffff814d0b51>] SyS_setsockopt+0x71/0xc0
        [<ffffffff815cdbf6>] entry_SYSCALL_64_fastpath+0x16/0x7a
        [<ffffffffffffffff>] 0xffffffffffffffff
    
    Make sure that everything is cleaned on netns destruction.
    
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Reviewed-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8f1c1d107722db69c6bf2536982b8d65d53d087f
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Fri Nov 20 00:11:56 2015 +0100

    net, scm: fix PaX detected msg_controllen overflow in scm_detach_fds
    
    [ Upstream commit 6900317f5eff0a7070c5936e5383f589e0de7a09 ]
    
    David and HacKurx reported a following/similar size overflow triggered
    in a grsecurity kernel, thanks to PaX's gcc size overflow plugin:
    
    (Already fixed in later grsecurity versions by Brad and PaX Team.)
    
    [ 1002.296137] PAX: size overflow detected in function scm_detach_fds net/core/scm.c:314
                   cicus.202_127 min, count: 4, decl: msg_controllen; num: 0; context: msghdr;
    [ 1002.296145] CPU: 0 PID: 3685 Comm: scm_rights_recv Not tainted 4.2.3-grsec+ #7
    [ 1002.296149] Hardware name: Apple Inc. MacBookAir5,1/Mac-66F35F19FE2A0D05, [...]
    [ 1002.296153]  ffffffff81c27366 0000000000000000 ffffffff81c27375 ffffc90007843aa8
    [ 1002.296162]  ffffffff818129ba 0000000000000000 ffffffff81c27366 ffffc90007843ad8
    [ 1002.296169]  ffffffff8121f838 fffffffffffffffc fffffffffffffffc ffffc90007843e60
    [ 1002.296176] Call Trace:
    [ 1002.296190]  [<ffffffff818129ba>] dump_stack+0x45/0x57
    [ 1002.296200]  [<ffffffff8121f838>] report_size_overflow+0x38/0x60
    [ 1002.296209]  [<ffffffff816a979e>] scm_detach_fds+0x2ce/0x300
    [ 1002.296220]  [<ffffffff81791899>] unix_stream_read_generic+0x609/0x930
    [ 1002.296228]  [<ffffffff81791c9f>] unix_stream_recvmsg+0x4f/0x60
    [ 1002.296236]  [<ffffffff8178dc00>] ? unix_set_peek_off+0x50/0x50
    [ 1002.296243]  [<ffffffff8168fac7>] sock_recvmsg+0x47/0x60
    [ 1002.296248]  [<ffffffff81691522>] ___sys_recvmsg+0xe2/0x1e0
    [ 1002.296257]  [<ffffffff81693496>] __sys_recvmsg+0x46/0x80
    [ 1002.296263]  [<ffffffff816934fc>] SyS_recvmsg+0x2c/0x40
    [ 1002.296271]  [<ffffffff8181a3ab>] entry_SYSCALL_64_fastpath+0x12/0x85
    
    Further investigation showed that this can happen when an *odd* number of
    fds are being passed over AF_UNIX sockets.
    
    In these cases CMSG_LEN(i * sizeof(int)) and CMSG_SPACE(i * sizeof(int)),
    where i is the number of successfully passed fds, differ by 4 bytes due
    to the extra CMSG_ALIGN() padding in CMSG_SPACE() to an 8 byte boundary
    on 64 bit. The padding is used to align subsequent cmsg headers in the
    control buffer.
    
    When the control buffer passed in from the receiver side *lacks* these 4
    bytes (e.g. due to buggy/wrong API usage), then msg->msg_controllen will
    overflow in scm_detach_fds():
    
      int cmlen = CMSG_LEN(i * sizeof(int));  <--- cmlen w/o tail-padding
      err = put_user(SOL_SOCKET, &cm->cmsg_level);
      if (!err)
        err = put_user(SCM_RIGHTS, &cm->cmsg_type);
      if (!err)
        err = put_user(cmlen, &cm->cmsg_len);
      if (!err) {
        cmlen = CMSG_SPACE(i * sizeof(int));  <--- cmlen w/ 4 byte extra tail-padding
        msg->msg_control += cmlen;
        msg->msg_controllen -= cmlen;         <--- iff no tail-padding space here ...
      }                                            ... wrap-around
    
    F.e. it will wrap to a length of 18446744073709551612 bytes in case the
    receiver passed in msg->msg_controllen of 20 bytes, and the sender
    properly transferred 1 fd to the receiver, so that its CMSG_LEN results
    in 20 bytes and CMSG_SPACE in 24 bytes.
    
    In case of MSG_CMSG_COMPAT (scm_detach_fds_compat()), I haven't seen an
    issue in my tests as alignment seems always on 4 byte boundary. Same
    should be in case of native 32 bit, where we end up with 4 byte boundaries
    as well.
    
    In practice, passing msg->msg_controllen of 20 to recvmsg() while receiving
    a single fd would mean that on successful return, msg->msg_controllen is
    being set by the kernel to 24 bytes instead, thus more than the input
    buffer advertised. It could f.e. become an issue if such application later
    on zeroes or copies the control buffer based on the returned msg->msg_controllen
    elsewhere.
    
    Maximum number of fds we can send is a hard upper limit SCM_MAX_FD (253).
    
    Going over the code, it seems like msg->msg_controllen is not being read
    after scm_detach_fds() in scm_recv() anymore by the kernel, good!
    
    Relevant recvmsg() handler are unix_dgram_recvmsg() (unix_seqpacket_recvmsg())
    and unix_stream_recvmsg(). Both return back to their recvmsg() caller,
    and ___sys_recvmsg() places the updated length, that is, new msg_control -
    old msg_control pointer into msg->msg_controllen (hence the 24 bytes seen
    in the example).
    
    Long time ago, Wei Yongjun fixed something related in commit 1ac70e7ad24a
    ("[NET]: Fix function put_cmsg() which may cause usr application memory
    overflow").
    
    RFC3542, section 20.2. says:
    
      The fields shown as "XX" are possible padding, between the cmsghdr
      structure and the data, and between the data and the next cmsghdr
      structure, if required by the implementation. While sending an
      application may or may not include padding at the end of last
      ancillary data in msg_controllen and implementations must accept both
      as valid. On receiving a portable application must provide space for
      padding at the end of the last ancillary data as implementations may
      copy out the padding at the end of the control message buffer and
      include it in the received msg_controllen. When recvmsg() is called
      if msg_controllen is too small for all the ancillary data items
      including any trailing padding after the last item an implementation
      may set MSG_CTRUNC.
    
    Since we didn't place MSG_CTRUNC for already quite a long time, just do
    the same as in 1ac70e7ad24a to avoid an overflow.
    
    Btw, even man-page author got this wrong :/ See db939c9b26e9 ("cmsg.3: Fix
    error in SCM_RIGHTS code sample"). Some people must have copied this (?),
    thus it got triggered in the wild (reported several times during boot by
    David and HacKurx).
    
    No Fixes tag this time as pre 2002 (that is, pre history tree).
    
    Reported-by: David Sterba <dave@jikos.cz>
    Reported-by: HacKurx <hackurx@gmail.com>
    Cc: PaX Team <pageexec@freemail.hu>
    Cc: Emese Revfy <re.emese@gmail.com>
    Cc: Brad Spengler <spender@grsecurity.net>
    Cc: Wei Yongjun <yongjun_wei@trendmicro.com.cn>
    Cc: Eric Dumazet <edumazet@google.com>
    Reviewed-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 967ade52834309a4bf19f2f16403407ba3e30041
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Nov 26 08:18:14 2015 -0800

    tcp: initialize tp->copied_seq in case of cross SYN connection
    
    [ Upstream commit 142a2e7ece8d8ac0e818eb2c91f99ca894730e2a ]
    
    Dmitry provided a syzkaller (http://github.com/google/syzkaller)
    generated program that triggers the WARNING at
    net/ipv4/tcp.c:1729 in tcp_recvmsg() :
    
    WARN_ON(tp->copied_seq != tp->rcv_nxt &&
            !(flags & (MSG_PEEK | MSG_TRUNC)));
    
    His program is specifically attempting a Cross SYN TCP exchange,
    that we support (for the pleasure of hackers ?), but it looks we
    lack proper tcp->copied_seq initialization.
    
    Thanks again Dmitry for your report and testings.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ddb686ac700f589d138b39c5306d04299cb805a2
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Nov 18 21:03:33 2015 -0800

    tcp: fix potential huge kmalloc() calls in TCP_REPAIR
    
    [ Upstream commit 5d4c9bfbabdb1d497f21afd81501e5c54b0c85d9 ]
    
    tcp_send_rcvq() is used for re-injecting data into tcp receive queue.
    
    Problems :
    
    - No check against size is performed, allowed user to fool kernel in
      attempting very large memory allocations, eventually triggering
      OOM when memory is fragmented.
    
    - In case of fault during the copy we do not return correct errno.
    
    Lets use alloc_skb_with_frags() to cook optimal skbs.
    
    Fixes: 292e8d8c8538 ("tcp: Move rcvq sending to tcp_input.c")
    Fixes: c0e88ff0f256 ("tcp: Repair socket queues")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Pavel Emelyanov <xemul@parallels.com>
    Acked-by: Pavel Emelyanov <xemul@parallels.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 039abed64e076c4be1306febf3a723ecf096cc47
Author: Yuchung Cheng <ycheng@google.com>
Date:   Wed Nov 18 18:17:30 2015 -0800

    tcp: disable Fast Open on timeouts after handshake
    
    [ Upstream commit 0e45f4da5981895e885dd72fe912a3f8e32bae73 ]
    
    Some middle-boxes black-hole the data after the Fast Open handshake
    (https://www.ietf.org/proceedings/94/slides/slides-94-tcpm-13.pdf).
    The exact reason is unknown. The work-around is to disable Fast Open
    temporarily after multiple recurring timeouts with few or no data
    delivered in the established state.
    
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Christoph Paasch <cpaasch@apple.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec8769e1a662e06421d61b4dc52fe5235b7e4f99
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Nov 18 12:40:13 2015 -0800

    tcp: md5: fix lockdep annotation
    
    [ Upstream commit 1b8e6a01e19f001e9f93b39c32387961c91ed3cc ]
    
    When a passive TCP is created, we eventually call tcp_md5_do_add()
    with sk pointing to the child. It is not owner by the user yet (we
    will add this socket into listener accept queue a bit later anyway)
    
    But we do own the spinlock, so amend the lockdep annotation to avoid
    following splat :
    
    [ 8451.090932] net/ipv4/tcp_ipv4.c:923 suspicious rcu_dereference_protected() usage!
    [ 8451.090932]
    [ 8451.090932] other info that might help us debug this:
    [ 8451.090932]
    [ 8451.090934]
    [ 8451.090934] rcu_scheduler_active = 1, debug_locks = 1
    [ 8451.090936] 3 locks held by socket_sockopt_/214795:
    [ 8451.090936]  #0:  (rcu_read_lock){.+.+..}, at: [<ffffffff855c6ac1>] __netif_receive_skb_core+0x151/0xe90
    [ 8451.090947]  #1:  (rcu_read_lock){.+.+..}, at: [<ffffffff85618143>] ip_local_deliver_finish+0x43/0x2b0
    [ 8451.090952]  #2:  (slock-AF_INET){+.-...}, at: [<ffffffff855acda5>] sk_clone_lock+0x1c5/0x500
    [ 8451.090958]
    [ 8451.090958] stack backtrace:
    [ 8451.090960] CPU: 7 PID: 214795 Comm: socket_sockopt_
    
    [ 8451.091215] Call Trace:
    [ 8451.091216]  <IRQ>  [<ffffffff856fb29c>] dump_stack+0x55/0x76
    [ 8451.091229]  [<ffffffff85123b5b>] lockdep_rcu_suspicious+0xeb/0x110
    [ 8451.091235]  [<ffffffff8564544f>] tcp_md5_do_add+0x1bf/0x1e0
    [ 8451.091239]  [<ffffffff85645751>] tcp_v4_syn_recv_sock+0x1f1/0x4c0
    [ 8451.091242]  [<ffffffff85642b27>] ? tcp_v4_md5_hash_skb+0x167/0x190
    [ 8451.091246]  [<ffffffff85647c78>] tcp_check_req+0x3c8/0x500
    [ 8451.091249]  [<ffffffff856451ae>] ? tcp_v4_inbound_md5_hash+0x11e/0x190
    [ 8451.091253]  [<ffffffff85647170>] tcp_v4_rcv+0x3c0/0x9f0
    [ 8451.091256]  [<ffffffff85618143>] ? ip_local_deliver_finish+0x43/0x2b0
    [ 8451.091260]  [<ffffffff856181b6>] ip_local_deliver_finish+0xb6/0x2b0
    [ 8451.091263]  [<ffffffff85618143>] ? ip_local_deliver_finish+0x43/0x2b0
    [ 8451.091267]  [<ffffffff85618d38>] ip_local_deliver+0x48/0x80
    [ 8451.091270]  [<ffffffff85618510>] ip_rcv_finish+0x160/0x700
    [ 8451.091273]  [<ffffffff8561900e>] ip_rcv+0x29e/0x3d0
    [ 8451.091277]  [<ffffffff855c74b7>] __netif_receive_skb_core+0xb47/0xe90
    
    Fixes: a8afca0329988 ("tcp: md5: protects md5sig_info with RCU")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 36c1943d828ebd990ea0b870b0a10bba85b7f26f
Author: Bjørn Mork <bjorn@mork.no>
Date:   Wed Nov 18 21:13:07 2015 +0100

    net: qmi_wwan: add XS Stick W100-2 from 4G Systems
    
    [ Upstream commit 68242a5a1e2edce39b069385cbafb82304eac0f1 ]
    
    Thomas reports
    "
    4gsystems sells two total different LTE-surfsticks under the same name.
    ..
    The newer version of XS Stick W100 is from "omega"
    ..
    Under windows the driver switches to the same ID, and uses MI03\6 for
    network and MI01\6 for modem.
    ..
    echo "1c9e 9b01" > /sys/bus/usb/drivers/qmi_wwan/new_id
    echo "1c9e 9b01" > /sys/bus/usb-serial/drivers/option1/new_id
    
    T:  Bus=01 Lev=01 Prnt=01 Port=03 Cnt=01 Dev#=  4 Spd=480 MxCh= 0
    D:  Ver= 2.00 Cls=00(>ifc ) Sub=00 Prot=00 MxPS=64 #Cfgs=  1
    P:  Vendor=1c9e ProdID=9b01 Rev=02.32
    S:  Manufacturer=USB Modem
    S:  Product=USB Modem
    S:  SerialNumber=
    C:  #Ifs= 5 Cfg#= 1 Atr=80 MxPwr=500mA
    I:  If#= 0 Alt= 0 #EPs= 2 Cls=ff(vend.) Sub=ff Prot=ff Driver=option
    I:  If#= 1 Alt= 0 #EPs= 3 Cls=ff(vend.) Sub=ff Prot=ff Driver=option
    I:  If#= 2 Alt= 0 #EPs= 3 Cls=ff(vend.) Sub=ff Prot=ff Driver=option
    I:  If#= 3 Alt= 0 #EPs= 3 Cls=ff(vend.) Sub=ff Prot=ff Driver=qmi_wwan
    I:  If#= 4 Alt= 0 #EPs= 2 Cls=08(stor.) Sub=06 Prot=50 Driver=usb-storage
    
    Now all important things are there:
    
    wwp0s29f7u2i3 (net), ttyUSB2 (at), cdc-wdm0 (qmi), ttyUSB1 (at)
    
    There is also ttyUSB0, but it is not usable, at least not for at.
    
    The device works well with qmi and ModemManager-NetworkManager.
    "
    
    Reported-by: Thomas Schäfer <tschaefer@t-online.de>
    Signed-off-by: Bjørn Mork <bjorn@mork.no>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 97546faaba70ac9323e088ca57644d2a2179cdd6
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Mon Nov 16 13:09:10 2015 -0500

    snmp: Remove duplicate OUTMCAST stat increment
    
    [ Upstream commit 41033f029e393a64e81966cbe34d66c6cf8a2e7e ]
    
    the OUTMCAST stat is double incremented, getting bumped once in the mcast code
    itself, and again in the common ip output path.  Remove the mcast bump, as its
    not needed
    
    Validated by the reporter, with good results
    
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Reported-by: Claus Jensen <claus.jensen@microsemi.com>
    CC: Claus Jensen <claus.jensen@microsemi.com>
    CC: David Miller <davem@davemloft.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6cb5485ed1ddeedb9c56af19ebcf69b484c36ca9
Author: Jason A. Donenfeld <Jason@zx2c4.com>
Date:   Thu Nov 12 17:35:58 2015 +0100

    ip_tunnel: disable preemption when updating per-cpu tstats
    
    [ Upstream commit b4fe85f9c9146f60457e9512fb6055e69e6a7a65 ]
    
    Drivers like vxlan use the recently introduced
    udp_tunnel_xmit_skb/udp_tunnel6_xmit_skb APIs. udp_tunnel6_xmit_skb
    makes use of ip6tunnel_xmit, and ip6tunnel_xmit, after sending the
    packet, updates the struct stats using the usual
    u64_stats_update_begin/end calls on this_cpu_ptr(dev->tstats).
    udp_tunnel_xmit_skb makes use of iptunnel_xmit, which doesn't touch
    tstats, so drivers like vxlan, immediately after, call
    iptunnel_xmit_stats, which does the same thing - calls
    u64_stats_update_begin/end on this_cpu_ptr(dev->tstats).
    
    While vxlan is probably fine (I don't know?), calling a similar function
    from, say, an unbound workqueue, on a fully preemptable kernel causes
    real issues:
    
    [  188.434537] BUG: using smp_processor_id() in preemptible [00000000] code: kworker/u8:0/6
    [  188.435579] caller is debug_smp_processor_id+0x17/0x20
    [  188.435583] CPU: 0 PID: 6 Comm: kworker/u8:0 Not tainted 4.2.6 #2
    [  188.435607] Call Trace:
    [  188.435611]  [<ffffffff8234e936>] dump_stack+0x4f/0x7b
    [  188.435615]  [<ffffffff81915f3d>] check_preemption_disabled+0x19d/0x1c0
    [  188.435619]  [<ffffffff81915f77>] debug_smp_processor_id+0x17/0x20
    
    The solution would be to protect the whole
    this_cpu_ptr(dev->tstats)/u64_stats_update_begin/end blocks with
    disabling preemption and then reenabling it.
    
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 32c3ff4e847888df0b54f8ccfb864d01108be38c
Author: lucien <lucien.xin@gmail.com>
Date:   Thu Nov 12 13:07:07 2015 +0800

    sctp: translate host order to network order when setting a hmacid
    
    [ Upstream commit ed5a377d87dc4c87fb3e1f7f698cba38cd893103 ]
    
    now sctp auth cannot work well when setting a hmacid manually, which
    is caused by that we didn't use the network order for hmacid, so fix
    it by adding the transformation in sctp_auth_ep_set_hmacs.
    
    even we set hmacid with the network order in userspace, it still
    can't work, because of this condition in sctp_auth_ep_set_hmacs():
    
                    if (id > SCTP_AUTH_HMAC_ID_MAX)
                            return -EOPNOTSUPP;
    
    so this wasn't working before and thus it won't break compatibility.
    
    Fixes: 65b07e5d0d09 ("[SCTP]: API updates to suport SCTP-AUTH extensions.")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b89d1e92c7844931b2b257f156c4eed10f4b15af
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Nov 11 23:25:44 2015 +0100

    packet: fix tpacket_snd max frame len
    
    [ Upstream commit 5cfb4c8d05b4409c4044cb9c05b19705c1d9818b ]
    
    Since it's introduction in commit 69e3c75f4d54 ("net: TX_RING and
    packet mmap"), TX_RING could be used from SOCK_DGRAM and SOCK_RAW
    side. When used with SOCK_DGRAM only, the size_max > dev->mtu +
    reserve check should have reserve as 0, but currently, this is
    unconditionally set (in it's original form as dev->hard_header_len).
    
    I think this is not correct since tpacket_fill_skb() would then
    take dev->mtu and dev->hard_header_len into account for SOCK_DGRAM,
    the extra VLAN_HLEN could be possible in both cases. Presumably, the
    reserve code was copied from packet_snd(), but later on missed the
    check. Make it similar as we have it in packet_snd().
    
    Fixes: 69e3c75f4d54 ("net: TX_RING and packet mmap")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 292d3287bbd5913f6c8a8989899a54c6e6aee3ca
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Nov 11 23:25:43 2015 +0100

    packet: infer protocol from ethernet header if unset
    
    [ Upstream commit c72219b75fde768efccf7666342282fab7f9e4e7 ]
    
    In case no struct sockaddr_ll has been passed to packet
    socket's sendmsg() when doing a TX_RING flush run, then
    skb->protocol is set to po->num instead, which is the protocol
    passed via socket(2)/bind(2).
    
    Applications only xmitting can go the path of allocating the
    socket as socket(PF_PACKET, <mode>, 0) and do a bind(2) on the
    TX_RING with sll_protocol of 0. That way, register_prot_hook()
    is neither called on creation nor on bind time, which saves
    cycles when there's no interest in capturing anyway.
    
    That leaves us however with po->num 0 instead and therefore
    the TX_RING flush run sets skb->protocol to 0 as well. Eric
    reported that this leads to problems when using tools like
    trafgen over bonding device. I.e. the bonding's hash function
    could invoke the kernel's flow dissector, which depends on
    skb->protocol being properly set. In the current situation, all
    the traffic is then directed to a single slave.
    
    Fix it up by inferring skb->protocol from the Ethernet header
    when not set and we have ARPHRD_ETHER device type. This is only
    done in case of SOCK_RAW and where we have a dev->hard_header_len
    length. In case of ARPHRD_ETHER devices, this is guaranteed to
    cover ETH_HLEN, and therefore being accessed on the skb after
    the skb_store_bits().
    
    Reported-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c59fd2eaa2b6c98233d1d264153335c202c4163d
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Nov 11 23:25:42 2015 +0100

    packet: only allow extra vlan len on ethernet devices
    
    [ Upstream commit 3c70c132488794e2489ab045559b0ce0afcf17de ]
    
    Packet sockets can be used by various net devices and are not
    really restricted to ARPHRD_ETHER device types. However, when
    currently checking for the extra 4 bytes that can be transmitted
    in VLAN case, our assumption is that we generally probe on
    ARPHRD_ETHER devices. Therefore, before looking into Ethernet
    header, check the device type first.
    
    This also fixes the issue where non-ARPHRD_ETHER devices could
    have no dev->hard_header_len in TX_RING SOCK_RAW case, and thus
    the check would test unfilled linear part of the skb (instead
    of non-linear).
    
    Fixes: 57f89bfa2140 ("network: Allow af_packet to transmit +4 bytes for VLAN packets.")
    Fixes: 52f1454f629f ("packet: allow to transmit +4 byte in TX_RING slot for VLAN case")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 302f6f05fec37e4a75d668b23251ed366b408f25
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Nov 11 23:25:41 2015 +0100

    packet: always probe for transport header
    
    [ Upstream commit 8fd6c80d9dd938ca338c70698533a7e304752846 ]
    
    We concluded that the skb_probe_transport_header() should better be
    called unconditionally. Avoiding the call into the flow dissector has
    also not really much to do with the direct xmit mode.
    
    While it seems that only virtio_net code makes use of GSO from non
    RX/TX ring packet socket paths, we should probe for a transport header
    nevertheless before they hit devices.
    
    Reference: http://thread.gmane.org/gmane.linux.network/386173/
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 01c0b875a4199a969a6c71807fceecc6d9c533e7
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Nov 11 23:25:40 2015 +0100

    packet: do skb_probe_transport_header when we actually have data
    
    [ Upstream commit efdfa2f7848f64517008136fb41f53c4a1faf93a ]
    
    In tpacket_fill_skb() commit c1aad275b029 ("packet: set transport
    header before doing xmit") and later on 40893fd0fd4e ("net: switch
    to use skb_probe_transport_header()") was probing for a transport
    header on the skb from a ring buffer slot, but at a time, where
    the skb has _not even_ been filled with data yet. So that call into
    the flow dissector is pretty useless. Lets do it after we've set
    up the skb frags.
    
    Fixes: c1aad275b029 ("packet: set transport header before doing xmit")
    Reported-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 393914a470e4c90527b09e220c7d355c617c3aa3
Author: Kamal Mostafa <kamal@canonical.com>
Date:   Wed Nov 11 14:24:27 2015 -0800

    tools/net: Use include/uapi with __EXPORTED_HEADERS__
    
    [ Upstream commit d7475de58575c904818efa369c82e88c6648ce2e ]
    
    Use the local uapi headers to keep in sync with "recently" added #define's
    (e.g. SKF_AD_VLAN_TPID).  Refactored CFLAGS, and bpf_asm doesn't need -I.
    
    Fixes: 3f356385e8a4 ("filter: bpf_asm: add minimal bpf asm tool")
    Signed-off-by: Kamal Mostafa <kamal@canonical.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5c77e26862ce604edea05b3442ed765e9756fe0f
Author: Rainer Weikusat <rweikusat@mobileactivedefense.com>
Date:   Fri Nov 20 22:07:23 2015 +0000

    unix: avoid use-after-free in ep_remove_wait_queue
    
    [ Upstream commit 7d267278a9ece963d77eefec61630223fce08c6c ]
    
    Rainer Weikusat <rweikusat@mobileactivedefense.com> writes:
    An AF_UNIX datagram socket being the client in an n:1 association with
    some server socket is only allowed to send messages to the server if the
    receive queue of this socket contains at most sk_max_ack_backlog
    datagrams. This implies that prospective writers might be forced to go
    to sleep despite none of the message presently enqueued on the server
    receive queue were sent by them. In order to ensure that these will be
    woken up once space becomes again available, the present unix_dgram_poll
    routine does a second sock_poll_wait call with the peer_wait wait queue
    of the server socket as queue argument (unix_dgram_recvmsg does a wake
    up on this queue after a datagram was received). This is inherently
    problematic because the server socket is only guaranteed to remain alive
    for as long as the client still holds a reference to it. In case the
    connection is dissolved via connect or by the dead peer detection logic
    in unix_dgram_sendmsg, the server socket may be freed despite "the
    polling mechanism" (in particular, epoll) still has a pointer to the
    corresponding peer_wait queue. There's no way to forcibly deregister a
    wait queue with epoll.
    
    Based on an idea by Jason Baron, the patch below changes the code such
    that a wait_queue_t belonging to the client socket is enqueued on the
    peer_wait queue of the server whenever the peer receive queue full
    condition is detected by either a sendmsg or a poll. A wake up on the
    peer queue is then relayed to the ordinary wait queue of the client
    socket via wake function. The connection to the peer wait queue is again
    dissolved if either a wake up is about to be relayed or the client
    socket reconnects or a dead peer is detected or the client socket is
    itself closed. This enables removing the second sock_poll_wait from
    unix_dgram_poll, thus avoiding the use-after-free, while still ensuring
    that no blocked writer sleeps forever.
    
    Signed-off-by: Rainer Weikusat <rweikusat@mobileactivedefense.com>
    Fixes: ec0d215f9420 ("af_unix: fix 'poll for write'/connected DGRAM sockets")
    Reviewed-by: Jason Baron <jbaron@akamai.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
