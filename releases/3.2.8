commit 1de504ea25617f701ac3a246a1c9dfd2246d4900
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Feb 27 10:26:22 2012 -0800

    Linux 3.2.8

commit 9016ec427136d5b5d025948319cf1114dc7734e4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 18 12:56:35 2012 -0800

    i387: re-introduce FPU state preloading at context switch time
    
    commit 34ddc81a230b15c0e345b6b253049db731499f7e upstream.
    
    After all the FPU state cleanups and finally finding the problem that
    caused all our FPU save/restore problems, this re-introduces the
    preloading of FPU state that was removed in commit b3b0870ef3ff ("i387:
    do not preload FPU state at task switch time").
    
    However, instead of simply reverting the removal, this reimplements
    preloading with several fixes, most notably
    
     - properly abstracted as a true FPU state switch, rather than as
       open-coded save and restore with various hacks.
    
       In particular, implementing it as a proper FPU state switch allows us
       to optimize the CR0.TS flag accesses: there is no reason to set the
       TS bit only to then almost immediately clear it again.  CR0 accesses
       are quite slow and expensive, don't flip the bit back and forth for
       no good reason.
    
     - Make sure that the same model works for both x86-32 and x86-64, so
       that there are no gratuitous differences between the two due to the
       way they save and restore segment state differently due to
       architectural differences that really don't matter to the FPU state.
    
     - Avoid exposing the "preload" state to the context switch routines,
       and in particular allow the concept of lazy state restore: if nothing
       else has used the FPU in the meantime, and the process is still on
       the same CPU, we can avoid restoring state from memory entirely, just
       re-expose the state that is still in the FPU unit.
    
       That optimized lazy restore isn't actually implemented here, but the
       infrastructure is set up for it.  Of course, older CPU's that use
       'fnsave' to save the state cannot take advantage of this, since the
       state saving also trashes the state.
    
    In other words, there is now an actual _design_ to the FPU state saving,
    rather than just random historical baggage.  Hopefully it's easier to
    follow as a result.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 555558c5bf8e8d9919fbcbe4b1cfe920f692c0cb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Feb 17 21:48:54 2012 -0800

    i387: move TS_USEDFPU flag from thread_info to task_struct
    
    commit f94edacf998516ac9d849f7bc6949a703977a7f3 upstream.
    
    This moves the bit that indicates whether a thread has ownership of the
    FPU from the TS_USEDFPU bit in thread_info->status to a word of its own
    (called 'has_fpu') in task_struct->thread.has_fpu.
    
    This fixes two independent bugs at the same time:
    
     - changing 'thread_info->status' from the scheduler causes nasty
       problems for the other users of that variable, since it is defined to
       be thread-synchronous (that's what the "TS_" part of the naming was
       supposed to indicate).
    
       So perfectly valid code could (and did) do
    
            ti->status |= TS_RESTORE_SIGMASK;
    
       and the compiler was free to do that as separate load, or and store
       instructions.  Which can cause problems with preemption, since a task
       switch could happen in between, and change the TS_USEDFPU bit. The
       change to TS_USEDFPU would be overwritten by the final store.
    
       In practice, this seldom happened, though, because the 'status' field
       was seldom used more than once, so gcc would generally tend to
       generate code that used a read-modify-write instruction and thus
       happened to avoid this problem - RMW instructions are naturally low
       fat and preemption-safe.
    
     - On x86-32, the current_thread_info() pointer would, during interrupts
       and softirqs, point to a *copy* of the real thread_info, because
       x86-32 uses %esp to calculate the thread_info address, and thus the
       separate irq (and softirq) stacks would cause these kinds of odd
       thread_info copy aliases.
    
       This is normally not a problem, since interrupts aren't supposed to
       look at thread information anyway (what thread is running at
       interrupt time really isn't very well-defined), but it confused the
       heck out of irq_fpu_usable() and the code that tried to squirrel
       away the FPU state.
    
       (It also caused untold confusion for us poor kernel developers).
    
    It also turns out that using 'task_struct' is actually much more natural
    for most of the call sites that care about the FPU state, since they
    tend to work with the task struct for other reasons anyway (ie
    scheduling).  And the FPU data that we are going to save/restore is
    found there too.
    
    Thanks to Arjan Van De Ven <arjan@linux.intel.com> for pointing us to
    the %esp issue.
    
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Reported-and-tested-by: Raphael Prevost <raphael@buro.asia>
    Acked-and-tested-by: Suresh Siddha <suresh.b.siddha@intel.com>
    Tested-by: Peter Anvin <hpa@zytor.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9147fbe60acc9125e7b0deae409f1da5c3f8bdda
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 16 19:11:15 2012 -0800

    i387: move AMD K7/K8 fpu fxsave/fxrstor workaround from save to restore
    
    commit 4903062b5485f0e2c286a23b44c9b59d9b017d53 upstream.
    
    The AMD K7/K8 CPUs don't save/restore FDP/FIP/FOP unless an exception is
    pending.  In order to not leak FIP state from one process to another, we
    need to do a floating point load after the fxsave of the old process,
    and before the fxrstor of the new FPU state.  That resets the state to
    the (uninteresting) kernel load, rather than some potentially sensitive
    user information.
    
    We used to do this directly after the FPU state save, but that is
    actually very inconvenient, since it
    
     (a) corrupts what is potentially perfectly good FPU state that we might
         want to lazy avoid restoring later and
    
     (b) on x86-64 it resulted in a very annoying ordering constraint, where
         "__unlazy_fpu()" in the task switch needs to be delayed until after
         the DS segment has been reloaded just to get the new DS value.
    
    Coupling it to the fxrstor instead of the fxsave automatically avoids
    both of these issues, and also ensures that we only do it when actually
    necessary (the FP state after a save may never actually get used).  It's
    simply a much more natural place for the leaked state cleanup.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ba6aaed5cc8f55b77644daf56e9ae3a75f042908
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 16 15:45:23 2012 -0800

    i387: do not preload FPU state at task switch time
    
    commit b3b0870ef3ffed72b92415423da864f440f57ad6 upstream.
    
    Yes, taking the trap to re-load the FPU/MMX state is expensive, but so
    is spending several days looking for a bug in the state save/restore
    code.  And the preload code has some rather subtle interactions with
    both paravirtualization support and segment state restore, so it's not
    nearly as simple as it should be.
    
    Also, now that we no longer necessarily depend on a single bit (ie
    TS_USEDFPU) for keeping track of the state of the FPU, we migth be able
    to do better.  If we are really switching between two processes that
    keep touching the FP state, save/restore is inevitable, but in the case
    of having one process that does most of the FPU usage, we may actually
    be able to do much better than the preloading.
    
    In particular, we may be able to keep track of which CPU the process ran
    on last, and also per CPU keep track of which process' FP state that CPU
    has.  For modern CPU's that don't destroy the FPU contents on save time,
    that would allow us to do a lazy restore by just re-enabling the
    existing FPU state - with no restore cost at all!
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 29515b215b9bbbad0368a5039ba6e53ed3fa7f25
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 16 13:33:12 2012 -0800

    i387: don't ever touch TS_USEDFPU directly, use helper functions
    
    commit 6d59d7a9f5b723a7ac1925c136e93ec83c0c3043 upstream.
    
    This creates three helper functions that do the TS_USEDFPU accesses, and
    makes everybody that used to do it by hand use those helpers instead.
    
    In addition, there's a couple of helper functions for the "change both
    CR0.TS and TS_USEDFPU at the same time" case, and the places that do
    that together have been changed to use those.  That means that we have
    fewer random places that open-code this situation.
    
    The intent is partly to clarify the code without actually changing any
    semantics yet (since we clearly still have some hard to reproduce bug in
    this area), but also to make it much easier to use another approach
    entirely to caching the CR0.TS bit for software accesses.
    
    Right now we use a bit in the thread-info 'status' variable (this patch
    does not change that), but we might want to make it a full field of its
    own or even make it a per-cpu variable.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 38358b6185298df66ef4ddb4ceaaa1baf8521b28
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 16 12:22:48 2012 -0800

    i387: move TS_USEDFPU clearing out of __save_init_fpu and into callers
    
    commit b6c66418dcad0fcf83cd1d0a39482db37bf4fc41 upstream.
    
    Touching TS_USEDFPU without touching CR0.TS is confusing, so don't do
    it.  By moving it into the callers, we always do the TS_USEDFPU next to
    the CR0.TS accesses in the source code, and it's much easier to see how
    the two go hand in hand.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a5c28716652f9f71c848452b67795e5af690a91f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Feb 16 09:15:04 2012 -0800

    i387: fix x86-64 preemption-unsafe user stack save/restore
    
    commit 15d8791cae75dca27bfda8ecfe87dca9379d6bb0 upstream.
    
    Commit 5b1cbac37798 ("i387: make irq_fpu_usable() tests more robust")
    added a sanity check to the #NM handler to verify that we never cause
    the "Device Not Available" exception in kernel mode.
    
    However, that check actually pinpointed a (fundamental) race where we do
    cause that exception as part of the signal stack FPU state save/restore
    code.
    
    Because we use the floating point instructions themselves to save and
    restore state directly from user mode, we cannot do that atomically with
    testing the TS_USEDFPU bit: the user mode access itself may cause a page
    fault, which causes a task switch, which saves and restores the FP/MMX
    state from the kernel buffers.
    
    This kind of "recursive" FP state save is fine per se, but it means that
    when the signal stack save/restore gets restarted, it will now take the
    '#NM' exception we originally tried to avoid.  With preemption this can
    happen even without the page fault - but because of the user access, we
    cannot just disable preemption around the save/restore instruction.
    
    There are various ways to solve this, including using the
    "enable/disable_page_fault()" helpers to not allow page faults at all
    during the sequence, and fall back to copying things by hand without the
    use of the native FP state save/restore instructions.
    
    However, the simplest thing to do is to just allow the #NM from kernel
    space, but fix the race in setting and clearing CR0.TS that this all
    exposed: the TS bit changes and the TS_USEDFPU bit absolutely have to be
    atomic wrt scheduling, so while the actual state save/restore can be
    interrupted and restarted, the act of actually clearing/setting CR0.TS
    and the TS_USEDFPU bit together must not.
    
    Instead of just adding random "preempt_disable/enable()" calls to what
    is already excessively ugly code, this introduces some helper functions
    that mostly mirror the "kernel_fpu_begin/end()" functionality, just for
    the user state instead.
    
    Those helper functions should probably eventually replace the other
    ad-hoc CR0.TS and TS_USEDFPU tests too, but I'll need to think about it
    some more: the task switching functionality in particular needs to
    expose the difference between the 'prev' and 'next' threads, while the
    new helper functions intentionally were written to only work with
    'current'.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0a7ea9d5aa1e2cab84a48c0380f7f8c305006224
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 15 08:05:18 2012 -0800

    i387: fix sense of sanity check
    
    commit c38e23456278e967f094b08247ffc3711b1029b2 upstream.
    
    The check for save_init_fpu() (introduced in commit 5b1cbac37798: "i387:
    make irq_fpu_usable() tests more robust") was the wrong way around, but
    I hadn't noticed, because my "tests" were bogus: the FPU exceptions are
    disabled by default, so even doing a divide by zero never actually
    triggers this code at all unless you do extra work to enable them.
    
    So if anybody did enable them, they'd get one spurious warning.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 42f2560ed6e9b040ef64e18a5030bf2d2cb05d7f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Feb 13 13:56:14 2012 -0800

    i387: make irq_fpu_usable() tests more robust
    
    commit 5b1cbac37798805c1fee18c8cebe5c0a13975b17 upstream.
    
    Some code - especially the crypto layer - wants to use the x86
    FP/MMX/AVX register set in what may be interrupt (typically softirq)
    context.
    
    That *can* be ok, but the tests for when it was ok were somewhat
    suspect.  We cannot touch the thread-specific status bits either, so
    we'd better check that we're not going to try to save FP state or
    anything like that.
    
    Now, it may be that the TS bit is always cleared *before* we set the
    USEDFPU bit (and only set when we had already cleared the USEDFP
    before), so the TS bit test may actually have been sufficient, but it
    certainly was not obviously so.
    
    So this explicitly verifies that we will not touch the TS_USEDFPU bit,
    and adds a few related sanity-checks.  Because it seems that somehow
    AES-NI is corrupting user FP state.  The cause is not clear, and this
    patch doesn't fix it, but while debugging it I really wanted the code to
    be more obviously correct and robust.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4733009df6d45db10f1f7551e65147576f224a06
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Feb 13 13:47:25 2012 -0800

    i387: math_state_restore() isn't called from asm
    
    commit be98c2cdb15ba26148cd2bd58a857d4f7759ed38 upstream.
    
    It was marked asmlinkage for some really old and stale legacy reasons.
    Fix that and the equally stale comment.
    
    Noticed when debugging the irq_fpu_usable() bugs.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
