commit 762b585c492fedda1b0bc4c6d0a867307bf7cd0f
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jul 25 10:18:33 2018 +0200

    Linux 4.4.144

commit f891ee97d9df8407ba1a46f9a7b89d8d57a70b7a
Author: Sascha Hauer <s.hauer@pengutronix.de>
Date:   Tue Dec 5 16:01:20 2017 +0100

    ubi: fastmap: Erase outdated anchor PEBs during attach
    
    commit f78e5623f45bab2b726eec29dc5cefbbab2d0b1c upstream.
    
    The fastmap update code might erase the current fastmap anchor PEB
    in case it doesn't find any new free PEB. When a power cut happens
    in this situation we must not have any outdated fastmap anchor PEB
    on the device, because that would be used to attach during next
    boot.
    The easiest way to make that sure is to erase all outdated fastmap
    anchor PEBs synchronously during attach.
    
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Reviewed-by: Richard Weinberger <richard@nod.at>
    Fixes: dbb7d2a88d2a ("UBI: Add fastmap core")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a5f958c4eadb8c9214c75b69330d4b5aa03d16e6
Author: Richard Weinberger <richard@nod.at>
Date:   Wed Aug 24 14:36:15 2016 +0200

    ubi: Fix Fastmap's update_vol()
    
    commit f7d11b33d4e8cedf19367c09b891bbc705163976 upstream.
    
    Usually Fastmap is free to consider every PEB in one of the pools
    as newer than the existing PEB. Since PEBs in a pool are by definition
    newer than everything else.
    But update_vol() missed the case that a pool can contain more than
    one candidate.
    
    Cc: <stable@vger.kernel.org>
    Fixes: dbb7d2a88d ("UBI: Add fastmap core")
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Reviewed-by: Boris Brezillon <boris.brezillon@free-electrons.com>
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 000b4c28bb28d471662a7d8fed80c9f511afe4cf
Author: Richard Weinberger <richard@nod.at>
Date:   Wed Aug 24 14:36:14 2016 +0200

    ubi: Fix races around ubi_refill_pools()
    
    commit 2e8f08deabbc7eefe4c5838aaa6aa9a23a8acf2e upstream.
    
    When writing a new Fastmap the first thing that happens
    is refilling the pools in memory.
    At this stage it is possible that new PEBs from the new pools
    get already claimed and written with data.
    If this happens before the new Fastmap data structure hits the
    flash and we face power cut the freshly written PEB will not
    scanned and unnoticed.
    
    Solve the issue by locking the pools until Fastmap is written.
    
    Cc: <stable@vger.kernel.org>
    Fixes: dbb7d2a88d ("UBI: Add fastmap core")
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit faf2b8d929a47809eab04f17e21f44ebae377dc6
Author: Richard Weinberger <richard@nod.at>
Date:   Tue Jun 14 10:12:17 2016 +0200

    ubi: Be more paranoid while seaching for the most recent Fastmap
    
    commit 74f2c6e9a47cf4e508198c8594626cc82906a13d upstream.
    
    Since PEB erasure is asynchornous it can happen that there is
    more than one Fastmap on the MTD. This is fine because the attach logic
    will pick the Fastmap data structure with the highest sequence number.
    
    On a not so well configured MTD stack spurious ECC errors are common.
    Causes can be different, bad hardware, wrong operating modes, etc...
    If the most current Fastmap renders bad due to ECC errors UBI might
    pick an older Fastmap to attach from.
    While this can only happen on an anyway broken setup it will show
    completely different sympthoms and makes finding the root cause much
    more difficult.
    So, be debug friendly and fall back to scanning mode of we're facing
    an ECC error while scanning for Fastmap.
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6fdca47fcc1a26b770ce1eb1a440ea06f8d804c5
Author: Richard Weinberger <richard@nod.at>
Date:   Tue Jun 14 10:12:15 2016 +0200

    ubi: Rework Fastmap attach base code
    
    commit fdf10ed710c0aa177e8dfcd84e65e4e5e8e0956b upstream.
    
    Introduce a new list to the UBI attach information
    object to be able to deal better with old and corrupted
    Fastmap eraseblocks.
    Also move more Fastmap specific code into fastmap.c.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1ee52929e64c4bd185884ebc22d437ff93f97e3a
Author: Richard Weinberger <richard@nod.at>
Date:   Tue Jun 14 10:12:13 2016 +0200

    ubi: Introduce vol_ignored()
    
    commit 243a4f8126fcf7facb04b324dbb7c85d10b11ce9 upstream.
    
    This makes the logic more easy to follow.
    
    Signed-off-by: Richard Weinberger <richard@nod.at>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 470ee7ab7776085fe5573788df2dea8140d7a0c1
Author: Lucas Stach <dev@lynxeye.de>
Date:   Mon Feb 29 21:46:07 2016 +0100

    clk: tegra: Fix PLL_U post divider and initial rate on Tegra30
    
    commit 797097301860c64b63346d068ba4fe4992bd5021 upstream.
    
    The post divider value in the frequency table is wrong as it would lead
    to the PLL producing an output rate of 960 MHz instead of the desired
    480 MHz. This wasn't a problem as nothing used the table to actually
    initialize the PLL rate, but the bootloader configuration was used
    unaltered.
    
    If the bootloader does not set up the PLL it will fail to come when used
    under Linux. To fix this don't rely on the bootloader, but set the
    correct rate in the clock driver.
    
    Signed-off-by: Lucas Stach <dev@lynxeye.de>
    Signed-off-by: Thierry Reding <treding@nvidia.com>
    [jonathanh@nvidia.com: Back-ported to stable v4.4.y]
    Signed-off-by: Jon Hunter <jonathanh@nvidia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9ae49135d83243f12b5a66044302d4a17e0dcfe
Author: Alan Jenkins <alan.christopher.jenkins@gmail.com>
Date:   Thu Apr 12 19:11:58 2018 +0100

    block: do not use interruptible wait anywhere
    
    commit 1dc3039bc87ae7d19a990c3ee71cfd8a9068f428 upstream.
    
    When blk_queue_enter() waits for a queue to unfreeze, or unset the
    PREEMPT_ONLY flag, do not allow it to be interrupted by a signal.
    
    The PREEMPT_ONLY flag was introduced later in commit 3a0a529971ec
    ("block, scsi: Make SCSI quiesce and resume work reliably").  Note the SCSI
    device is resumed asynchronously, i.e. after un-freezing userspace tasks.
    
    So that commit exposed the bug as a regression in v4.15.  A mysterious
    SIGBUS (or -EIO) sometimes happened during the time the device was being
    resumed.  Most frequently, there was no kernel log message, and we saw Xorg
    or Xwayland killed by SIGBUS.[1]
    
    [1] E.g. https://bugzilla.redhat.com/show_bug.cgi?id=1553979
    
    Without this fix, I get an IO error in this test:
    
    # dd if=/dev/sda of=/dev/null iflag=direct & \
      while killall -SIGUSR1 dd; do sleep 0.1; done & \
      echo mem > /sys/power/state ; \
      sleep 5; killall dd  # stop after 5 seconds
    
    The interruptible wait was added to blk_queue_enter in
    commit 3ef28e83ab15 ("block: generic request_queue reference counting").
    Before then, the interruptible wait was only in blk-mq, but I don't think
    it could ever have been correct.
    
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Alan Jenkins <alan.christopher.jenkins@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 42a8fe474e0c3e9babad09b4d3e882d7a0f09c76
Author: Andy Lutomirski <luto@kernel.org>
Date:   Wed Jan 18 11:15:39 2017 -0800

    x86/cpu: Re-apply forced caps every time CPU caps are re-read
    
    commit 60d3450167433f2d099ce2869dc52dd9e7dc9b29 upstream.
    
    Calling get_cpu_cap() will reset a bunch of CPU features.  This will
    cause the system to lose track of force-set and force-cleared
    features in the words that are reset until the end of CPU
    initialization.  This can cause X86_FEATURE_FPU, for example, to
    change back and forth during boot and potentially confuse CPU setup.
    
    To minimize the chance of confusion, re-apply forced caps every time
    get_cpu_cap() is called.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Matthew Whitehead <tedheadster@gmail.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: One Thousand Gnomes <gnomes@lxorguk.ukuu.org.uk>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Yu-cheng Yu <yu-cheng.yu@intel.com>
    Link: http://lkml.kernel.org/r/c817eb373d2c67c2c81413a70fc9b845fa34a37e.1484705016.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 399a9d0cc466b0100feee5c6e9de7e6378b18fab
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Jun 21 10:43:31 2018 +0200

    x86/xen: Add call of speculative_store_bypass_ht_init() to PV paths
    
    commit 74899d92e66663dc7671a8017b3146dcd4735f3b upstream.
    
    Commit:
    
      1f50ddb4f418 ("x86/speculation: Handle HT correctly on AMD")
    
    ... added speculative_store_bypass_ht_init() to the per-CPU initialization sequence.
    
    speculative_store_bypass_ht_init() needs to be called on each CPU for
    PV guests, too.
    
    Reported-by: Brian Woods <brian.woods@amd.com>
    Tested-by: Brian Woods <brian.woods@amd.com>
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Cc: <stable@vger.kernel.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: boris.ostrovsky@oracle.com
    Cc: xen-devel@lists.xenproject.org
    Fixes: 1f50ddb4f4189243c05926b842dc1a0332195f31 ("x86/speculation: Handle HT correctly on AMD")
    Link: https://lore.kernel.org/lkml/20180621084331.21228-1-jgross@suse.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cadb98135daf474648d646db5625e9c663b94a3d
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:40:10 2018 -0700

    x86/bugs: Rename SSBD_NO to SSB_NO
    
    commit 240da953fcc6a9008c92fae5b1f727ee5ed167ab upstream
    
    The "336996 Speculative Execution Side Channel Mitigations" from
    May defines this as SSB_NO, hence lets sync-up.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 48805280d05c968e0883e8debf5e33f40f8e56c5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:40:03 2018 -0700

    x86/speculation, KVM: Implement support for VIRT_SPEC_CTRL/LS_CFG
    
    commit 47c61b3955cf712cadfc25635bf9bc174af030ea upstream
    
    Add the necessary logic for supporting the emulated VIRT_SPEC_CTRL MSR to
    x86_virt_spec_ctrl().  If either X86_FEATURE_LS_CFG_SSBD or
    X86_FEATURE_VIRT_SPEC_CTRL is set then use the new guest_virt_spec_ctrl
    argument to check whether the state must be modified on the host. The
    update reuses speculative_store_bypass_update() so the ZEN-specific sibling
    coordination can be reused.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 80d7439fb0c446d006599b6347efd255a86a93ca
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:39:55 2018 -0700

    x86/bugs: Rework spec_ctrl base and mask logic
    
    commit be6fcb5478e95bb1c91f489121238deb3abca46a upstream
    
    x86_spec_ctrL_mask is intended to mask out bits from a MSR_SPEC_CTRL value
    which are not to be modified. However the implementation is not really used
    and the bitmask was inverted to make a check easier, which was removed in
    "x86/bugs: Remove x86_spec_ctrl_set()"
    
    Aside of that it is missing the STIBP bit if it is supported by the
    platform, so if the mask would be used in x86_virt_spec_ctrl() then it
    would prevent a guest from setting STIBP.
    
    Add the STIBP bit if supported and use the mask in x86_virt_spec_ctrl() to
    sanitize the value which is supplied by the guest.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 90cfa767bc12a9931e5e45ed275b069d5b35b52e
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:39:46 2018 -0700

    x86/bugs: Remove x86_spec_ctrl_set()
    
    commit 4b59bdb569453a60b752b274ca61f009e37f4dae upstream
    
    x86_spec_ctrl_set() is only used in bugs.c and the extra mask checks there
    provide no real value as both call sites can just write x86_spec_ctrl_base
    to MSR_SPEC_CTRL. x86_spec_ctrl_base is valid and does not need any extra
    masking or checking.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9ed7ee52e4e06364f47d6a6e898610bae5f04e93
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:39:38 2018 -0700

    x86/bugs: Expose x86_spec_ctrl_base directly
    
    commit fa8ac4988249c38476f6ad678a4848a736373403 upstream
    
    x86_spec_ctrl_base is the system wide default value for the SPEC_CTRL MSR.
    x86_spec_ctrl_get_default() returns x86_spec_ctrl_base and was intended to
    prevent modification to that variable. Though the variable is read only
    after init and globaly visible already.
    
    Remove the function and export the variable instead.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d5aec90670c378b6d05e5f904b1a8c8cffb17eef
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Jul 14 02:39:30 2018 -0700

    x86/bugs: Unify x86_spec_ctrl_{set_guest, restore_host}
    
    commit cc69b34989210f067b2c51d5539b5f96ebcc3a01 upstream
    
    Function bodies are very similar and are going to grow more almost
    identical code. Add a bool arg to determine whether SPEC_CTRL is being set
    for the guest or restored to the host.
    
    No functional changes.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3d60492cea89c0a0fb06c73ee49cc14c55f527dd
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:39:22 2018 -0700

    x86/speculation: Rework speculative_store_bypass_update()
    
    commit 0270be3e34efb05a88bc4c422572ece038ef3608 upstream
    
    The upcoming support for the virtual SPEC_CTRL MSR on AMD needs to reuse
    speculative_store_bypass_update() to avoid code duplication. Add an
    argument for supplying a thread info (TIF) value and create a wrapper
    speculative_store_bypass_update_current() which is used at the existing
    call site.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ecfe9bf30e4b7cd13f3b28f40a587a932b5cb457
Author: Tom Lendacky <thomas.lendacky@amd.com>
Date:   Sat Jul 14 02:39:14 2018 -0700

    x86/speculation: Add virtualized speculative store bypass disable support
    
    commit 11fb0683493b2da112cd64c9dada221b52463bf7 upstream
    
    Some AMD processors only support a non-architectural means of enabling
    speculative store bypass disable (SSBD).  To allow a simplified view of
    this to a guest, an architectural definition has been created through a new
    CPUID bit, 0x80000008_EBX[25], and a new MSR, 0xc001011f.  With this, a
    hypervisor can virtualize the existence of this definition and provide an
    architectural method for using SSBD to a guest.
    
    Add the new CPUID feature, the new MSR and update the existing SSBD
    support to use this MSR when present.
    
    Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e13a6f0955bb5ee6daca1f08027d6561d0830daf
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:39:06 2018 -0700

    x86/bugs, KVM: Extend speculation control for VIRT_SPEC_CTRL
    
    commit ccbcd2674472a978b48c91c1fbfb66c0ff959f24 upstream
    
    AMD is proposing a VIRT_SPEC_CTRL MSR to handle the Speculative Store
    Bypass Disable via MSR_AMD64_LS_CFG so that guests do not have to care
    about the bit position of the SSBD bit and thus facilitate migration.
    Also, the sibling coordination on Family 17H CPUs can only be done on
    the host.
    
    Extend x86_spec_ctrl_set_guest() and x86_spec_ctrl_restore_host() with an
    extra argument for the VIRT_SPEC_CTRL MSR.
    
    Hand in 0 from VMX and in SVM add a new virt_spec_ctrl member to the CPU
    data structure which is going to be used in later patches for the actual
    implementation.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [ Srivatsa: Backported to 4.4.y, skipping the KVM changes in this patch. ]
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ea8efcd4415f70766acb4bb9553fad855eea48e1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:38:58 2018 -0700

    x86/speculation: Handle HT correctly on AMD
    
    commit 1f50ddb4f4189243c05926b842dc1a0332195f31 upstream
    
    The AMD64_LS_CFG MSR is a per core MSR on Family 17H CPUs. That means when
    hyperthreading is enabled the SSBD bit toggle needs to take both cores into
    account. Otherwise the following situation can happen:
    
    CPU0            CPU1
    
    disable SSB
                    disable SSB
                    enable  SSB <- Enables it for the Core, i.e. for CPU0 as well
    
    So after the SSB enable on CPU1 the task on CPU0 runs with SSB enabled
    again.
    
    On Intel the SSBD control is per core as well, but the synchronization
    logic is implemented behind the per thread SPEC_CTRL MSR. It works like
    this:
    
      CORE_SPEC_CTRL = THREAD0_SPEC_CTRL | THREAD1_SPEC_CTRL
    
    i.e. if one of the threads enables a mitigation then this affects both and
    the mitigation is only disabled in the core when both threads disabled it.
    
    Add the necessary synchronization logic for AMD family 17H. Unfortunately
    that requires a spinlock to serialize the access to the MSR, but the locks
    are only shared between siblings.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 21757fc8bafd50ce477fff2bcec6faec27c5548d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:38:50 2018 -0700

    x86/cpufeatures: Add FEATURE_ZEN
    
    commit d1035d971829dcf80e8686ccde26f94b0a069472 upstream
    
    Add a ZEN feature bit so family-dependent static_cpu_has() optimizations
    can be built for ZEN.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4ba461d426490b6ed7e8298c4d3b7a13aa5d2686
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Jul 14 02:38:41 2018 -0700

    x86/cpu/AMD: Fix erratum 1076 (CPB bit)
    
    commit f7f3dc00f61261cdc9ccd8b886f21bc4dffd6fd9 upstream
    
    CPUID Fn8000_0007_EDX[CPB] is wrongly 0 on models up to B1. But they do
    support CPB (AMD's Core Performance Boosting cpufreq CPU feature), so fix that.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Sherry Hurwitz <sherry.hurwitz@amd.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20170907170821.16021-1-bp@alien8.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 11a0b92f6d57853550f927fe91190b745a5ab945
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:38:33 2018 -0700

    x86/cpufeatures: Disentangle SSBD enumeration
    
    commit 52817587e706686fcdb27f14c1b000c92f266c96 upstream
    
    The SSBD enumeration is similarly to the other bits magically shared
    between Intel and AMD though the mechanisms are different.
    
    Make X86_FEATURE_SSBD synthetic and set it depending on the vendor specific
    features or family dependent setup.
    
    Change the Intel bit to X86_FEATURE_SPEC_CTRL_SSBD to denote that SSBD is
    controlled via MSR_SPEC_CTRL and fix up the usage sites.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e4bb3382cbe9173e7f6e3a13fd1cb39c3a72671f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:38:25 2018 -0700

    x86/cpufeatures: Disentangle MSR_SPEC_CTRL enumeration from IBRS
    
    commit 7eb8956a7fec3c1f0abc2a5517dada99ccc8a961 upstream
    
    The availability of the SPEC_CTRL MSR is enumerated by a CPUID bit on
    Intel and implied by IBRS or STIBP support on AMD. That's just confusing
    and in case an AMD CPU has IBRS not supported because the underlying
    problem has been fixed but has another bit valid in the SPEC_CTRL MSR,
    the thing falls apart.
    
    Add a synthetic feature bit X86_FEATURE_MSR_SPEC_CTRL to denote the
    availability on both Intel and AMD.
    
    While at it replace the boot_cpu_has() checks with static_cpu_has() where
    possible. This prevents late microcode loading from exposing SPEC_CTRL, but
    late loading is already very limited as it does not reevaluate the
    mitigation options and other bits and pieces. Having static_cpu_has() is
    the simplest and least fragile solution.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4f4a2c70cf2ecd17ef3899c754fee30caa343286
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Jul 14 02:38:17 2018 -0700

    x86/speculation: Use synthetic bits for IBRS/IBPB/STIBP
    
    commit e7c587da125291db39ddf1f49b18e5970adbac17 upstream
    
    Intel and AMD have different CPUID bits hence for those use synthetic bits
    which get set on the respective vendor's in init_speculation_control(). So
    that debacles like what the commit message of
    
      c65732e4f721 ("x86/cpu: Restore CPUID_8000_0008_EBX reload")
    
    talks about don't happen anymore.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Tested-by: JÃ¶rg Otte <jrg.otte@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Link: https://lkml.kernel.org/r/20180504161815.GG9257@pd.tnic
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [ Srivatsa: Backported to 4.4.y, skipping the KVM changes in this patch. ]
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 714f18858ceda6f2b8335686f1f019560fe89283
Author: Jim Mattson <jmattson@google.com>
Date:   Sat Jul 14 02:38:08 2018 -0700

    x86/cpu: Make alternative_msr_write work for 32-bit code
    
    commit 5f2b745f5e1304f438f9b2cd03ebc8120b6e0d3b upstream
    
    Cast val and (val >> 32) to (u32), so that they fit in a
    general-purpose register in both 32-bit and 64-bit code.
    
    [ tglx: Made it u32 instead of uintptr_t ]
    
    Fixes: c65732e4f721 ("x86/cpu: Restore CPUID_8000_0008_EBX reload")
    Signed-off-by: Jim Mattson <jmattson@google.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 95bef2217ece77c345e627eba9cd2e85ada8eeb2
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:38:01 2018 -0700

    x86/bugs: Fix the parameters alignment and missing void
    
    commit ffed645e3be0e32f8e9ab068d257aee8d0fe8eec upstream
    
    Fixes: 7bb4d366c ("x86/bugs: Make cpu_show_common() static")
    Fixes: 24f7fc83b ("x86/bugs: Provide boot parameters for the spec_store_bypass_disable mitigation")
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 103b28d8a271c1d650eb5b09bd7a53d8915b51d6
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Sat Jul 14 02:37:53 2018 -0700

    x86/bugs: Make cpu_show_common() static
    
    commit 7bb4d366cba992904bffa4820d24e70a3de93e76 upstream
    
    cpu_show_common() is not used outside of arch/x86/kernel/cpu/bugs.c, so
    make it static.
    
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 631474e1cee0fbc0f346664aea5ee5b1c3600649
Author: Jiri Kosina <jkosina@suse.cz>
Date:   Sat Jul 14 02:37:45 2018 -0700

    x86/bugs: Fix __ssb_select_mitigation() return type
    
    commit d66d8ff3d21667b41eddbe86b35ab411e40d8c5f upstream
    
    __ssb_select_mitigation() returns one of the members of enum ssb_mitigation,
    not ssb_mitigation_cmd; fix the prototype to reflect that.
    
    Fixes: 24f7fc83b9204 ("x86/bugs: Provide boot parameters for the spec_store_bypass_disable mitigation")
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e5eea0486470acbe7aa20a0533543c47c942ec93
Author: Borislav Petkov <bp@suse.de>
Date:   Sat Jul 14 02:37:37 2018 -0700

    Documentation/spec_ctrl: Do some minor cleanups
    
    commit dd0792699c4058e63c0715d9a7c2d40226fcdddc upstream
    
    Fix some typos, improve formulations, end sentences with a fullstop.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 765897c6486de605eae3f94f77f2c800c9a2a254
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:37:29 2018 -0700

    proc: Use underscores for SSBD in 'status'
    
    commit e96f46ee8587607a828f783daa6eb5b44d25004d upstream
    
    The style for the 'status' file is CamelCase or this. _.
    
    Fixes: fae1fa0fc ("proc: Provide details on speculation flaw mitigations")
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6e2119e4b8767a6c3a415875ad09596ada00755c
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:37:21 2018 -0700

    x86/bugs: Rename _RDS to _SSBD
    
    commit 9f65fb29374ee37856dbad847b4e121aab72b510 upstream
    
    Intel collateral will reference the SSB mitigation bit in IA32_SPEC_CTL[2]
    as SSBD (Speculative Store Bypass Disable).
    
    Hence changing it.
    
    It is unclear yet what the MSR_IA32_ARCH_CAPABILITIES (0x10a) Bit(4) name
    is going to be. Following the rename it would be SSBD_NO but that rolls out
    to Speculative Store Bypass Disable No.
    
    Also fixed the missing space in X86_FEATURE_AMD_SSBD.
    
    [ tglx: Fixup x86_amd_rds_enable() and rds_tif_to_amd_ls_cfg() as well ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [ Srivatsa: Backported to 4.4.y, skipping the KVM changes in this patch. ]
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit afc6bf9131efc36d4ae8a003e8597119a2190661
Author: Kees Cook <keescook@chromium.org>
Date:   Sat Jul 14 02:37:13 2018 -0700

    x86/speculation: Make "seccomp" the default mode for Speculative Store Bypass
    
    commit f21b53b20c754021935ea43364dbf53778eeba32 upstream
    
    Unless explicitly opted out of, anything running under seccomp will have
    SSB mitigations enabled. Choosing the "prctl" mode will disable this.
    
    [ tglx: Adjusted it to the new arch_seccomp_spec_mitigate() mechanism ]
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9237a1b0828962191107e702cf56c88db9f9d455
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:37:05 2018 -0700

    seccomp: Move speculation migitation control to arch code
    
    commit 8bf37d8c067bb7eb8e7c381bdadf9bd89182b6bc upstream
    
    The migitation control is simpler to implement in architecture code as it
    avoids the extra function call to check the mode. Aside of that having an
    explicit seccomp enabled mode in the architecture mitigations would require
    even more workarounds.
    
    Move it into architecture code and provide a weak function in the seccomp
    code. Remove the 'which' argument as this allows the architecture to decide
    which mitigations are relevant for seccomp.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c463c0f037f2d83aea54415ed7c61deb0b90333b
Author: Kees Cook <keescook@chromium.org>
Date:   Sat Jul 14 02:36:57 2018 -0700

    seccomp: Add filter flag to opt-out of SSB mitigation
    
    commit 00a02d0c502a06d15e07b857f8ff921e3e402675 upstream
    
    If a seccomp user is not interested in Speculative Store Bypass mitigation
    by default, it can set the new SECCOMP_FILTER_FLAG_SPEC_ALLOW flag when
    adding filters.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a08c3f484c34df1e3bec3c47818d570483bf67fa
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:36:49 2018 -0700

    seccomp: Use PR_SPEC_FORCE_DISABLE
    
    commit b849a812f7eb92e96d1c8239b06581b2cfd8b275 upstream
    
    Use PR_SPEC_FORCE_DISABLE in seccomp() because seccomp does not allow to
    widen restrictions.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3f9cb20f9126db1edb1fad78a0e94ff8e9ae94e2
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:36:41 2018 -0700

    prctl: Add force disable speculation
    
    commit 356e4bfff2c5489e016fdb925adbf12a1e3950ee upstream
    
    For certain use cases it is desired to enforce mitigations so they cannot
    be undone afterwards. That's important for loader stubs which want to
    prevent a child from disabling the mitigation again. Will also be used for
    seccomp(). The extra state preserving of the prctl state for SSB is a
    preparatory step for EBPF dymanic speculation control.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0b1174054e0f4afd999c56ddecbbfb18f598f099
Author: Kees Cook <keescook@chromium.org>
Date:   Sat Jul 14 02:36:33 2018 -0700

    seccomp: Enable speculation flaw mitigations
    
    commit 5c3070890d06ff82eecb808d02d2ca39169533ef upstream
    
    When speculation flaw mitigations are opt-in (via prctl), using seccomp
    will automatically opt-in to these protections, since using seccomp
    indicates at least some level of sandboxing is desired.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 484964fa3e5a0d8467891aab8368dab34e8eb13c
Author: Kees Cook <keescook@chromium.org>
Date:   Sat Jul 14 02:36:25 2018 -0700

    proc: Provide details on speculation flaw mitigations
    
    commit fae1fa0fc6cca8beee3ab8ed71d54f9a78fa3f64 upstream
    
    As done with seccomp and no_new_privs, also show speculation flaw
    mitigation state in /proc/$pid/status.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b6f4a6285d7979b45d629e65c880279930b98ef1
Author: Kees Cook <keescook@chromium.org>
Date:   Sat Jul 14 02:36:17 2018 -0700

    nospec: Allow getting/setting on non-current task
    
    commit 7bbf1373e228840bb0295a2ca26d548ef37f448e upstream
    
    Adjust arch_prctl_get/set_spec_ctrl() to operate on tasks other than
    current.
    
    This is needed both for /proc/$pid/status queries and for seccomp (since
    thread-syncing can trigger seccomp in non-current threads).
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2cb00ce1273d48dafce848f4e0ea353eb5839475
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:36:09 2018 -0700

    x86/speculation: Add prctl for Speculative Store Bypass mitigation
    
    commit a73ec77ee17ec556fe7f165d00314cb7c047b1ac upstream
    
    Add prctl based control for Speculative Store Bypass mitigation and make it
    the default mitigation for Intel and AMD.
    
    Andi Kleen provided the following rationale (slightly redacted):
    
     There are multiple levels of impact of Speculative Store Bypass:
    
     1) JITed sandbox.
        It cannot invoke system calls, but can do PRIME+PROBE and may have call
        interfaces to other code
    
     2) Native code process.
        No protection inside the process at this level.
    
     3) Kernel.
    
     4) Between processes.
    
     The prctl tries to protect against case (1) doing attacks.
    
     If the untrusted code can do random system calls then control is already
     lost in a much worse way. So there needs to be system call protection in
     some way (using a JIT not allowing them or seccomp). Or rather if the
     process can subvert its environment somehow to do the prctl it can already
     execute arbitrary code, which is much worse than SSB.
    
     To put it differently, the point of the prctl is to not allow JITed code
     to read data it shouldn't read from its JITed sandbox. If it already has
     escaped its sandbox then it can already read everything it wants in its
     address space, and do much worse.
    
     The ability to control Speculative Store Bypass allows to enable the
     protection selectively without affecting overall system performance.
    
    Based on an initial patch from Tim Chen. Completely rewritten.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b04a020d0745a7ba18800e86ea678676aeb21278
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:36:00 2018 -0700

    x86/process: Allow runtime control of Speculative Store Bypass
    
    commit 885f82bfbc6fefb6664ea27965c3ab9ac4194b8c upstream
    
    The Speculative Store Bypass vulnerability can be mitigated with the
    Reduced Data Speculation (RDS) feature. To allow finer grained control of
    this eventually expensive mitigation a per task mitigation control is
    required.
    
    Add a new TIF_RDS flag and put it into the group of TIF flags which are
    evaluated for mismatch in switch_to(). If these bits differ in the previous
    and the next task, then the slow path function __switch_to_xtra() is
    invoked. Implement the TIF_RDS dependent mitigation control in the slow
    path.
    
    If the prctl for controlling Speculative Store Bypass is disabled or no
    task uses the prctl then there is no overhead in the switch_to() fast
    path.
    
    Update the KVM related speculation control functions to take TID_RDS into
    account as well.
    
    Based on a patch from Tim Chen. Completely rewritten.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a1cb23a5e2ea4ed75d3ac37c6a0739c5435406ff
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:35:52 2018 -0700

    x86/process: Optimize TIF_NOTSC switch
    
    commit 5a920155e388ec22a22e0532fb695b9215c9b34d upstream
    
    Provide and use a toggle helper instead of doing it with a branch.
    
    x86_64: arch/x86/kernel/process.o
    text       data     bss     dec     hex
    3008       8577      16   11601    2d51 Before
    2976       8577      16   11569    2d31 After
    
    i386: arch/x86/kernel/process.o
    text       data     bss     dec     hex
    2925       8673       8   11606    2d56 Before
    2893       8673       8   11574    2d36 After
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: http://lkml.kernel.org/r/20170214081104.9244-4-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5c5e95c4e50fbec4f101e057520a762662d6e7d7
Author: Kyle Huey <me@kylehuey.com>
Date:   Sat Jul 14 02:35:44 2018 -0700

    x86/process: Correct and optimize TIF_BLOCKSTEP switch
    
    commit b9894a2f5bd18b1691cb6872c9afe32b148d0132 upstream
    
    The debug control MSR is "highly magical" as the blockstep bit can be
    cleared by hardware under not well documented circumstances.
    
    So a task switch relying on the bit set by the previous task (according to
    the previous tasks thread flags) can trip over this and not update the flag
    for the next task.
    
    To fix this its required to handle DEBUGCTLMSR_BTF when either the previous
    or the next or both tasks have the TIF_BLOCKSTEP flag set.
    
    While at it avoid branching within the TIF_BLOCKSTEP case and evaluating
    boot_cpu_data twice in kernels without CONFIG_X86_DEBUGCTLMSR.
    
    x86_64: arch/x86/kernel/process.o
    text    data    bss     dec      hex
    3024    8577    16      11617    2d61   Before
    3008    8577    16      11601    2d51   After
    
    i386: No change
    
    [ tglx: Made the shift value explicit, use a local variable to make the
    code readable and massaged changelog]
    
    Originally-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: http://lkml.kernel.org/r/20170214081104.9244-3-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1a529899c65aff1f4f2f4875e876457d0c2341c5
Author: Kyle Huey <me@kylehuey.com>
Date:   Sat Jul 14 02:35:36 2018 -0700

    x86/process: Optimize TIF checks in __switch_to_xtra()
    
    commit af8b3cd3934ec60f4c2a420d19a9d416554f140b upstream
    
    Help the compiler to avoid reevaluating the thread flags for each checked
    bit by reordering the bit checks and providing an explicit xor for
    evaluation.
    
    With default defconfigs for each arch,
    
    x86_64: arch/x86/kernel/process.o
    text       data     bss     dec     hex
    3056       8577      16   11649    2d81 Before
    3024       8577      16   11617    2d61 After
    
    i386: arch/x86/kernel/process.o
    text       data     bss     dec     hex
    2957       8673       8   11638    2d76 Before
    2925       8673       8   11606    2d56 After
    
    Originally-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kyle Huey <khuey@kylehuey.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Link: http://lkml.kernel.org/r/20170214081104.9244-2-khuey@kylehuey.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
    [dwmw2: backported to make TIF_RDS handling simpler.
            No deferred TR reload.]
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 13fa2c65c9a8c2cd5f2a9799891582c40b6f5cfa
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:35:28 2018 -0700

    prctl: Add speculation control prctls
    
    commit b617cfc858161140d69cc0b5cc211996b557a1c7 upstream
    
    Add two new prctls to control aspects of speculation related vulnerabilites
    and their mitigations to provide finer grained control over performance
    impacting mitigations.
    
    PR_GET_SPECULATION_CTRL returns the state of the speculation misfeature
    which is selected with arg2 of prctl(2). The return value uses bit 0-2 with
    the following meaning:
    
    Bit  Define           Description
    0    PR_SPEC_PRCTL    Mitigation can be controlled per task by
                          PR_SET_SPECULATION_CTRL
    1    PR_SPEC_ENABLE   The speculation feature is enabled, mitigation is
                          disabled
    2    PR_SPEC_DISABLE  The speculation feature is disabled, mitigation is
                          enabled
    
    If all bits are 0 the CPU is not affected by the speculation misfeature.
    
    If PR_SPEC_PRCTL is set, then the per task control of the mitigation is
    available. If not set, prctl(PR_SET_SPECULATION_CTRL) for the speculation
    misfeature will fail.
    
    PR_SET_SPECULATION_CTRL allows to control the speculation misfeature, which
    is selected by arg2 of prctl(2) per task. arg3 is used to hand in the
    control value, i.e. either PR_SPEC_ENABLE or PR_SPEC_DISABLE.
    
    The common return values are:
    
    EINVAL  prctl is not implemented by the architecture or the unused prctl()
            arguments are not 0
    ENODEV  arg2 is selecting a not supported speculation misfeature
    
    PR_SET_SPECULATION_CTRL has these additional return values:
    
    ERANGE  arg3 is incorrect, i.e. it's not either PR_SPEC_ENABLE or PR_SPEC_DISABLE
    ENXIO   prctl control of the selected speculation misfeature is disabled
    
    The first supported controlable speculation misfeature is
    PR_SPEC_STORE_BYPASS. Add the define so this can be shared between
    architectures.
    
    Based on an initial patch from Tim Chen and mostly rewritten.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 49d8e36618f7524611409b8608dd54d399e7097f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sat Jul 14 02:35:20 2018 -0700

    x86/speculation: Create spec-ctrl.h to avoid include hell
    
    commit 28a2775217b17208811fa43a9e96bd1fdf417b86 upstream
    
    Having everything in nospec-branch.h creates a hell of dependencies when
    adding the prctl based switching mechanism. Move everything which is not
    required in nospec-branch.h to spec-ctrl.h and fix up the includes in the
    relevant files.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec5bf1a308faac133951877c8b5fbbb0413529cb
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:35:12 2018 -0700

    x86/bugs/AMD: Add support to disable RDS on Fam[15, 16, 17]h if requested
    
    commit 764f3c21588a059cd783c6ba0734d4db2d72822d upstream
    
    AMD does not need the Speculative Store Bypass mitigation to be enabled.
    
    The parameters for this are already available and can be done via MSR
    C001_1020. Each family uses a different bit in that MSR for this.
    
    [ tglx: Expose the bit mask via a variable and move the actual MSR fiddling
            into the bugs code as that's the right thing to do and also required
            to prepare for dynamic enable/disable ]
    
    [ Srivatsa: Removed __ro_after_init for 4.4.y ]
    
    Suggested-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d9a58c4316857347b0ef77e94bde43379c87a746
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:35:03 2018 -0700

    x86/bugs: Whitelist allowed SPEC_CTRL MSR values
    
    commit 1115a859f33276fe8afb31c60cf9d8e657872558 upstream
    
    Intel and AMD SPEC_CTRL (0x48) MSR semantics may differ in the
    future (or in fact use different MSRs for the same functionality).
    
    As such a run-time mechanism is required to whitelist the appropriate MSR
    values.
    
    [ tglx: Made the variable __ro_after_init ]
    [ Srivatsa: Removed __ro_after_init for 4.4.y ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7dc950c1ce909c11c3985802b1aba6b655d8dc23
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:34:55 2018 -0700

    x86/bugs/intel: Set proper CPU features and setup RDS
    
    commit 772439717dbf703b39990be58d8d4e3e4ad0598a upstream
    
    Intel CPUs expose methods to:
    
     - Detect whether RDS capability is available via CPUID.7.0.EDX[31],
    
     - The SPEC_CTRL MSR(0x48), bit 2 set to enable RDS.
    
     - MSR_IA32_ARCH_CAPABILITIES, Bit(4) no need to enable RRS.
    
    With that in mind if spec_store_bypass_disable=[auto,on] is selected set at
    boot-time the SPEC_CTRL MSR to enable RDS if the platform requires it.
    
    Note that this does not fix the KVM case where the SPEC_CTRL is exposed to
    guests which can muck with it, see patch titled :
     KVM/SVM/VMX/x86/spectre_v2: Support the combination of guest and host IBRS.
    
    And for the firmware (IBRS to be set), see patch titled:
     x86/spectre_v2: Read SPEC_CTRL MSR during boot and re-use reserved bits
    
    [ tglx: Distangled it from the intel implementation and kept the call order ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 46ea6e547d0595f88086bc56c2f032b0e2f3f9ac
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:34:47 2018 -0700

    x86/bugs: Provide boot parameters for the spec_store_bypass_disable mitigation
    
    commit 24f7fc83b9204d20f878c57cb77d261ae825e033 upstream
    
    Contemporary high performance processors use a common industry-wide
    optimization known as "Speculative Store Bypass" in which loads from
    addresses to which a recent store has occurred may (speculatively) see an
    older value. Intel refers to this feature as "Memory Disambiguation" which
    is part of their "Smart Memory Access" capability.
    
    Memory Disambiguation can expose a cache side-channel attack against such
    speculatively read values. An attacker can create exploit code that allows
    them to read memory outside of a sandbox environment (for example,
    malicious JavaScript in a web page), or to perform more complex attacks
    against code running within the same privilege level, e.g. via the stack.
    
    As a first step to mitigate against such attacks, provide two boot command
    line control knobs:
    
     nospec_store_bypass_disable
     spec_store_bypass_disable=[off,auto,on]
    
    By default affected x86 processors will power on with Speculative
    Store Bypass enabled. Hence the provided kernel parameters are written
    from the point of view of whether to enable a mitigation or not.
    The parameters are as follows:
    
     - auto - Kernel detects whether your CPU model contains an implementation
              of Speculative Store Bypass and picks the most appropriate
              mitigation.
    
     - on   - disable Speculative Store Bypass
     - off  - enable Speculative Store Bypass
    
    [ tglx: Reordered the checks so that the whole evaluation is not done
            when the CPU does not support RDS ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1cdf94bc21610ffbabedd5b6d85700ed1017037d
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:34:39 2018 -0700

    x86/cpufeatures: Add X86_FEATURE_RDS
    
    commit 0cc5fa00b0a88dad140b4e5c2cead9951ad36822 upstream
    
    Add the CPU feature bit CPUID.7.0.EDX[31] which indicates whether the CPU
    supports Reduced Data Speculation.
    
    [ tglx: Split it out from a later patch ]
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d8067aba239cbd2bfd64cdd548a914b20c58d189
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:34:31 2018 -0700

    x86/bugs: Expose /sys/../spec_store_bypass
    
    commit c456442cd3a59eeb1d60293c26cbe2ff2c4e42cf upstream
    
    Add the sysfs file for the new vulerability. It does not do much except
    show the words 'Vulnerable' for recent x86 cores.
    
    Intel cores prior to family 6 are known not to be vulnerable, and so are
    some Atoms and some Xeon Phi.
    
    It assumes that older Cyrix, Centaur, etc. cores are immune.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 05f8bae8e6b68ee20a26ec6a0683b1bcc31aef28
Author: Piotr Luc <piotr.luc@intel.com>
Date:   Sat Jul 14 02:34:22 2018 -0700

    x86/cpu/intel: Add Knights Mill to Intel family
    
    commit 0047f59834e5947d45f34f5f12eb330d158f700b upstream
    
    Add CPUID of Knights Mill (KNM) processor to Intel family list.
    
    Signed-off-by: Piotr Luc <piotr.luc@intel.com>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20161012180520.30976-1-piotr.luc@intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 498efb90b8ad36de4a51a2298887acbfc3cab616
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Sat Jul 14 02:34:13 2018 -0700

    x86/cpu: Rename Merrifield2 to Moorefield
    
    commit f5fbf848303c8704d0e1a1e7cabd08fd0a49552f upstream
    
    Merrifield2 is actually Moorefield.
    
    Rename it accordingly and drop tail digit from Merrifield1.
    
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20160906184254.94440-1-andriy.shevchenko@linux.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e1ec1698244de1b808ae0142dd653e5aded91d7
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:34:05 2018 -0700

    x86/bugs, KVM: Support the combination of guest and host IBRS
    
    commit 5cf687548705412da47c9cec342fd952d71ed3d5 upstream
    
    A guest may modify the SPEC_CTRL MSR from the value used by the
    kernel. Since the kernel doesn't use IBRS, this means a value of zero is
    what is needed in the host.
    
    But the 336996-Speculative-Execution-Side-Channel-Mitigations.pdf refers to
    the other bits as reserved so the kernel should respect the boot time
    SPEC_CTRL value and use that.
    
    This allows to deal with future extensions to the SPEC_CTRL interface if
    any at all.
    
    Note: This uses wrmsrl() instead of native_wrmsl(). I does not make any
    difference as paravirt will over-write the callq *0xfff.. with the wrmsrl
    assembler code.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [ Srivatsa: Backported to 4.4.y, skipping the KVM changes in this patch. ]
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 51f37b2f0248911465d8f84fb6f547be5316a261
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:33:57 2018 -0700

    x86/bugs: Read SPEC_CTRL MSR during boot and re-use reserved bits
    
    commit 1b86883ccb8d5d9506529d42dbe1a5257cb30b18 upstream
    
    The 336996-Speculative-Execution-Side-Channel-Mitigations.pdf refers to all
    the other bits as reserved. The Intel SDM glossary defines reserved as
    implementation specific - aka unknown.
    
    As such at bootup this must be taken it into account and proper masking for
    the bits in use applied.
    
    A copy of this document is available at
    https://bugzilla.kernel.org/show_bug.cgi?id=199511
    
    [ tglx: Made x86_spec_ctrl_base __ro_after_init ]
    [ Srivatsa: Removed __ro_after_init for 4.4.y ]
    
    Suggested-by: Jon Masters <jcm@redhat.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 96df48c0c42c6816d5b2808ed9e18a428cbf9598
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:33:49 2018 -0700

    x86/bugs: Concentrate bug reporting into a separate function
    
    commit d1059518b4789cabe34bb4b714d07e6089c82ca1 upstream
    
    Those SysFS functions have a similar preamble, as such make common
    code to handle them.
    
    Suggested-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d77421663170a2d660fa63a50c664805d132e69d
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:33:40 2018 -0700

    x86/bugs: Concentrate bug detection into a separate function
    
    commit 4a28bfe3267b68e22c663ac26185aa16c9b879ef upstream
    
    Combine the various logic which goes through all those
    x86_cpu_id matching structures in one function.
    
    Suggested-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b2dab2dc776cea8e1f190523456b32b850506ce3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 14 02:33:32 2018 -0700

    x86/nospec: Simplify alternative_msr_write()
    
    commit 1aa7a5735a41418d8e01fa7c9565eb2657e2ea3f upstream
    
    The macro is not type safe and I did look for why that "g" constraint for
    the asm doesn't work: it's because the asm is more fundamentally wrong.
    
    It does
    
            movl %[val], %%eax
    
    but "val" isn't a 32-bit value, so then gcc will pass it in a register,
    and generate code like
    
            movl %rsi, %eax
    
    and gas will complain about a nonsensical 'mov' instruction (it's moving a
    64-bit register to a 32-bit one).
    
    Passing it through memory will just hide the real bug - gcc still thinks
    the memory location is 64-bit, but the "movl" will only load the first 32
    bits and it all happens to work because x86 is little-endian.
    
    Convert it to a type safe inline function with a little trick which hands
    the feature into the ALTERNATIVE macro.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e57a81c43ca5ea32bf28c4634e903e7a4a1cbbd3
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:33:24 2018 -0700

    x86/amd: don't set X86_BUG_SYSRET_SS_ATTRS when running under Xen
    
    commit def9331a12977770cc6132d79f8e6565871e8e38 upstream
    
    When running as Xen pv guest X86_BUG_SYSRET_SS_ATTRS must not be set
    on AMD cpus.
    
    This bug/feature bit is kind of special as it will be used very early
    when switching threads. Setting the bit and clearing it a little bit
    later leaves a critical window where things can go wrong. This time
    window has enlarged a little bit by using setup_clear_cpu_cap() instead
    of the hypervisor's set_cpu_features callback. It seems this larger
    window now makes it rather easy to hit the problem.
    
    The proper solution is to never set the bit in case of Xen.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 237a1870da36fcd10f67503928c485d964726d83
Author: Juergen Gross <jgross@suse.com>
Date:   Sat Jul 14 02:33:16 2018 -0700

    xen: set cpu capabilities from xen_start_kernel()
    
    Upstream commit: 0808e80cb760de2733c0527d2090ed2205a1eef8 ("xen: set
    cpu capabilities from xen_start_kernel()")
    
    There is no need to set the same capabilities for each cpu
    individually. This can easily be done for all cpus when starting the
    kernel.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9f62897343da5fbbbd0db7441750ecc4c833a6ef
Author: MickaÃ«l SalaÃ¼n <mic@digikod.net>
Date:   Sat Jul 14 02:33:08 2018 -0700

    selftest/seccomp: Fix the seccomp(2) signature
    
    commit 505ce68c6da3432454c62e43c24a22ea5b1d754b upstream
    
    Signed-off-by: MickaÃ«l SalaÃ¼n <mic@digikod.net>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Cc: Will Drewry <wad@chromium.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b4553a4ec2f64b818193ba85434b1f42c68d5aff
Author: MickaÃ«l SalaÃ¼n <mic@digikod.net>
Date:   Sat Jul 14 02:33:00 2018 -0700

    selftest/seccomp: Fix the flag name SECCOMP_FILTER_FLAG_TSYNC
    
    commit 6c045d07bb305c527140bdec4cf8ab50f7c980d8 upstream
    
    Rename SECCOMP_FLAG_FILTER_TSYNC to SECCOMP_FILTER_FLAG_TSYNC to match
    the UAPI.
    
    Signed-off-by: MickaÃ«l SalaÃ¼n <mic@digikod.net>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Cc: Will Drewry <wad@chromium.org>
    Acked-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0990b1ff53bec71e4fdce971b6c4c5e1b7b91d01
Author: Alexander Sergeyev <sergeev917@gmail.com>
Date:   Sat Jul 14 02:32:52 2018 -0700

    x86/speculation: Remove Skylake C2 from Speculation Control microcode blacklist
    
    commit e3b3121fa8da94cb20f9e0c64ab7981ae47fd085 upstream.
    
    In accordance with Intel's microcode revision guidance from March 6 MCU
    rev 0xc2 is cleared on both Skylake H/S and Skylake Xeon E3 processors
    that share CPUID 506E3.
    
    Signed-off-by: Alexander Sergeyev <sergeev917@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jia Zhang <qianyue.zj@alibaba-inc.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Kyle Huey <me@kylehuey.com>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Link: https://lkml.kernel.org/r/20180313193856.GA8580@localhost.localdomain
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bdf186811576fdec0a42b554b884ed8ae2df54a2
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jul 14 02:32:43 2018 -0700

    x86/speculation: Move firmware_restrict_branch_speculation_*() from C to CPP
    
    commit d72f4e29e6d84b7ec02ae93088aa459ac70e733b upstream.
    
    firmware_restrict_branch_speculation_*() recently started using
    preempt_enable()/disable(), but those are relatively high level
    primitives and cause build failures on some 32-bit builds.
    
    Since we want to keep <asm/nospec-branch.h> low level, convert
    them to macros to avoid header hell...
    
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: arjan.van.de.ven@intel.com
    Cc: bp@alien8.de
    Cc: dave.hansen@intel.com
    Cc: jmattson@google.com
    Cc: karahmed@amazon.de
    Cc: kvm@vger.kernel.org
    Cc: pbonzini@redhat.com
    Cc: rkrcmar@redhat.com
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7ec391255421d5d311c66d6fbfb33cdfca789b9f
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:32:33 2018 -0700

    x86/speculation: Use IBRS if available before calling into firmware
    
    commit dd84441a797150dcc49298ec95c459a8891d8bb1 upstream.
    
    Retpoline means the kernel is safe because it has no indirect branches.
    But firmware isn't, so use IBRS for firmware calls if it's available.
    
    Block preemption while IBRS is set, although in practice the call sites
    already had to be doing that.
    
    Ignore hpwdt.c for now. It's taking spinlocks and calling into firmware
    code, from an NMI handler. I don't want to touch that with a bargepole.
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: arjan.van.de.ven@intel.com
    Cc: bp@alien8.de
    Cc: dave.hansen@intel.com
    Cc: jmattson@google.com
    Cc: karahmed@amazon.de
    Cc: kvm@vger.kernel.org
    Cc: pbonzini@redhat.com
    Cc: rkrcmar@redhat.com
    Link: http://lkml.kernel.org/r/1519037457-7643-2-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [ Srivatsa: Backported to 4.4.y, patching the efi_call_virt() family of functions,
      which are the 4.4.y-equivalents of arch_efi_call_virt_setup()/teardown() ]
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 56c4a02fe0fc9fbdeee19eaef11c5b67c8bef371
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Sat Jul 14 02:32:25 2018 -0700

    x86/spectre_v2: Don't check microcode versions when running under hypervisors
    
    commit 36268223c1e9981d6cfc33aff8520b3bde4b8114 upstream.
    
    As:
    
     1) It's known that hypervisors lie about the environment anyhow (host
        mismatch)
    
     2) Even if the hypervisor (Xen, KVM, VMWare, etc) provided a valid
        "correct" value, it all gets to be very murky when migration happens
        (do you provide the "new" microcode of the machine?).
    
    And in reality the cloud vendors are the ones that should make sure that
    the microcode that is running is correct and we should just sing lalalala
    and trust them.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Wanpeng Li <kernellwp@gmail.com>
    Cc: kvm <kvm@vger.kernel.org>
    Cc: KrÄmÃ¡Å <rkrcmar@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    CC: "H. Peter Anvin" <hpa@zytor.com>
    CC: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20180226213019.GE9497@char.us.oracle.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2997b0617b252f6e8630c1aa410697e2b0ed3b0d
Author: Tim Chen <tim.c.chen@linux.intel.com>
Date:   Sat Jul 14 02:32:16 2018 -0700

    x86/speculation: Use Indirect Branch Prediction Barrier in context switch
    
    commit 18bf3c3ea8ece8f03b6fc58508f2dfd23c7711c7 upstream.
    
    Flush indirect branches when switching into a process that marked itself
    non dumpable. This protects high value processes like gpg better,
    without having too high performance overhead.
    
    If done naÃ¯vely, we could switch to a kernel idle thread and then back
    to the original process, such as:
    
        process A -> idle -> process A
    
    In such scenario, we do not have to do IBPB here even though the process
    is non-dumpable, as we are switching back to the same process after a
    hiatus.
    
    To avoid the redundant IBPB, which is expensive, we track the last mm
    user context ID. The cost is to have an extra u64 mm context id to track
    the last mm we were using before switching to the init_mm used by idle.
    Avoiding the extra IBPB is probably worth the extra memory for this
    common scenario.
    
    For those cases where tlb_defer_switch_to_init_mm() returns true (non
    PCID), lazy tlb will defer switch to init_mm, so we will not be changing
    the mm for the process A -> idle -> process A switch. So IBPB will be
    skipped for this case.
    
    Thanks to the reviewers and Andy Lutomirski for the suggestion of
    using ctx_id which got rid of the problem of mm pointer recycling.
    
    Signed-off-by: Tim Chen <tim.c.chen@linux.intel.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: ak@linux.intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: linux@dominikbrodowski.net
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: luto@kernel.org
    Cc: pbonzini@redhat.com
    Link: https://lkml.kernel.org/r/1517263487-3708-1-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 937dad078f557ddd6151e62f7f0028c136ffba4a
Author: Andy Lutomirski <luto@kernel.org>
Date:   Sat Jul 14 02:32:07 2018 -0700

    x86/mm: Give each mm TLB flush generation a unique ID
    
    commit f39681ed0f48498b80455095376f11535feea332 upstream.
    
    This adds two new variables to mmu_context_t: ctx_id and tlb_gen.
    ctx_id uniquely identifies the mm_struct and will never be reused.
    For a given mm_struct (and hence ctx_id), tlb_gen is a monotonic
    count of the number of times that a TLB flush has been requested.
    The pair (ctx_id, tlb_gen) can be used as an identifier for TLB
    flush actions and will be used in subsequent patches to reliably
    determine whether all needed TLB flushes have occurred on a given
    CPU.
    
    This patch is split out for ease of review.  By itself, it has no
    real effect other than creating and updating the new variables.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Nadav Amit <nadav.amit@gmail.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/413a91c24dab3ed0caa5f4e4d017d87b0857f920.1498751203.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Tim Chen <tim.c.chen@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 58ac8c59dbb3a8e8b6414524c2d8f4f0a7bbeaa4
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Sat Jul 14 02:31:57 2018 -0700

    x86/mm: Factor out LDT init from context init
    
    commit 39a0526fb3f7d93433d146304278477eb463f8af upstream
    
    The arch-specific mm_context_t is a great place to put
    protection-key allocation state.
    
    But, we need to initialize the allocation state because pkey 0 is
    always "allocated".  All of the runtime initialization of
    mm_context_t is done in *_ldt() manipulation functions.  This
    renames the existing LDT functions like this:
    
            init_new_context() -> init_new_context_ldt()
            destroy_context() -> destroy_context_ldt()
    
    and makes init_new_context() and destroy_context() available for
    generic use.
    
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Dave Hansen <dave@sr71.net>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/20160212210234.DB34FCC5@viggo.jf.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7c55236675b8426f861a6e63b75ec1e17057c8a0
Author: Juergen Gross <jgross@suse.com>
Date:   Sat Jul 14 02:31:49 2018 -0700

    x86/xen: Zero MSR_IA32_SPEC_CTRL before suspend
    
    commit 71c208dd54ab971036d83ff6d9837bae4976e623 upstream.
    
    Older Xen versions (4.5 and before) might have problems migrating pv
    guests with MSR_IA32_SPEC_CTRL having a non-zero value. So before
    suspending zero that MSR and restore it after being resumed.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Jan Beulich <jbeulich@suse.com>
    Cc: stable@vger.kernel.org
    Cc: xen-devel@lists.xenproject.org
    Cc: boris.ostrovsky@oracle.com
    Link: https://lkml.kernel.org/r/20180226140818.4849-1-jgross@suse.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4b9593083546b76299b28f0abb76505b4988860f
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Jul 14 02:31:40 2018 -0700

    x86/speculation: Add <asm/msr-index.h> dependency
    
    commit ea00f301285ea2f07393678cd2b6057878320c9d upstream.
    
    Joe Konno reported a compile failure resulting from using an MSR
    without inclusion of <asm/msr-index.h>, and while the current code builds
    fine (by accident) this needs fixing for future patches.
    
    Reported-by: Joe Konno <joe.konno@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: arjan@linux.intel.com
    Cc: bp@alien8.de
    Cc: dan.j.williams@intel.com
    Cc: dave.hansen@linux.intel.com
    Cc: dwmw2@infradead.org
    Cc: dwmw@amazon.co.uk
    Cc: gregkh@linuxfoundation.org
    Cc: hpa@zytor.com
    Cc: jpoimboe@redhat.com
    Cc: linux-tip-commits@vger.kernel.org
    Cc: luto@kernel.org
    Fixes: 20ffa1caecca ("x86/speculation: Add basic IBPB (Indirect Branch Prediction Barrier) support")
    Link: http://lkml.kernel.org/r/20180213132819.GJ25201@hirez.programming.kicks-ass.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1af5c9661555bff49d50d38b5723a11ad85fbc97
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Jul 14 02:31:32 2018 -0700

    x86/speculation: Fix up array_index_nospec_mask() asm constraint
    
    commit be3233fbfcb8f5acb6e3bcd0895c3ef9e100d470 upstream.
    
    Allow the compiler to handle @size as an immediate value or memory
    directly rather than allocating a register.
    
    Reported-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/151797010204.1289.1510000292250184993.stgit@dwillia2-desk3.amr.corp.intel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d10b55dd5a1612a76e58bb80c7b0ec92672c0e5b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Jul 14 02:31:23 2018 -0700

    x86/speculation: Clean up various Spectre related details
    
    commit 21e433bdb95bdf3aa48226fd3d33af608437f293 upstream.
    
    Harmonize all the Spectre messages so that a:
    
        dmesg | grep -i spectre
    
    ... gives us most Spectre related kernel boot messages.
    
    Also fix a few other details:
    
     - clarify a comment about firmware speculation control
    
     - s/KPTI/PTI
    
     - remove various line-breaks that made the code uglier
    
    Acked-by: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 307261be84cca663b9497a68c2fbc8bc1061f494
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:31:13 2018 -0700

    x86/speculation: Correct Speculation Control microcode blacklist again
    
    commit d37fc6d360a404b208547ba112e7dabb6533c7fc upstream.
    
    Arjan points out that the Intel document only clears the 0xc2 microcode
    on *some* parts with CPUID 506E3 (INTEL_FAM6_SKYLAKE_DESKTOP stepping 3).
    For the Skylake H/S platform it's OK but for Skylake E3 which has the
    same CPUID it isn't (yet) cleared.
    
    So removing it from the blacklist was premature. Put it back for now.
    
    Also, Arjan assures me that the 0x84 microcode for Kaby Lake which was
    featured in one of the early revisions of the Intel document was never
    released to the public, and won't be until/unless it is also validated
    as safe. So those can change to 0x80 which is what all *other* versions
    of the doc have identified.
    
    Once the retrospective testing of existing public microcodes is done, we
    should be back into a mode where new microcodes are only released in
    batches and we shouldn't even need to update the blacklist for those
    anyway, so this tweaking of the list isn't expected to be a thing which
    keeps happening.
    
    Requested-by: Arjan van de Ven <arjan.van.de.ven@intel.com>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: arjan.van.de.ven@intel.com
    Cc: dave.hansen@intel.com
    Cc: kvm@vger.kernel.org
    Cc: pbonzini@redhat.com
    Link: http://lkml.kernel.org/r/1518449255-2182-1-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b7c492fb9e33857cf983c7807929f1410655765c
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:31:04 2018 -0700

    x86/speculation: Update Speculation Control microcode blacklist
    
    commit 1751342095f0d2b36fa8114d8e12c5688c455ac4 upstream.
    
    Intel have retroactively blessed the 0xc2 microcode on Skylake mobile
    and desktop parts, and the Gemini Lake 0x22 microcode is apparently fine
    too. We blacklisted the latter purely because it was present with all
    the other problematic ones in the 2018-01-08 release, but now it's
    explicitly listed as OK.
    
    We still list 0x84 for the various Kaby Lake / Coffee Lake parts, as
    that appeared in one version of the blacklist and then reverted to
    0x80 again. We can change it if 0x84 is actually announced to be safe.
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Arjan van de Ven <arjan@linux.intel.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@linux.intel.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: arjan.van.de.ven@intel.com
    Cc: jmattson@google.com
    Cc: karahmed@amazon.de
    Cc: kvm@vger.kernel.org
    Cc: pbonzini@redhat.com
    Cc: rkrcmar@redhat.com
    Cc: sironi@amazon.de
    Link: http://lkml.kernel.org/r/1518305967-31356-2-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5c91dde1312e8d9cc2b7e6a60cdc22debc711c8e
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Sat Jul 14 02:30:55 2018 -0700

    x86/entry/64/compat: Clear registers for compat syscalls, to reduce speculation attack surface
    
    commit 6b8cf5cc9965673951f1ab3f0e3cf23d06e3e2ee upstream.
    
    At entry userspace may have populated registers with values that could
    otherwise be useful in a speculative execution attack. Clear them to
    minimize the kernel's attack surface.
    
    Originally-From: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Cc: <stable@vger.kernel.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/151787989697.7847.4083702787288600552.stgit@dwillia2-desk3.amr.corp.intel.com
    [ Made small improvements to the changelog. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 659cc61a987662a6674022d5980a5b5eb0a9b4fe
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Sat Jul 14 02:30:46 2018 -0700

    x86/asm/entry/32: Simplify pushes of zeroed pt_regs->REGs
    
    commit 778843f934e362ed4ed734520f60a44a78a074b4 upstream
    
    Use of a temporary R8 register here seems to be unnecessary.
    
    "push %r8" is a two-byte insn (it needs REX prefix to specify R8),
    "push $0" is two-byte too. It seems just using the latter would be
    no worse.
    
    Thus, code had an unnecessary "xorq %r8,%r8" insn.
    It probably costs nothing in execution time here since we are probably
    limited by store bandwidth at this point, but still.
    
    Run-tested under QEMU: 32-bit calls still work:
    
     / # ./test_syscall_vdso32
     [RUN]  Executing 6-argument 32-bit syscall via VDSO
     [OK]   Arguments are preserved across syscall
     [NOTE] R11 has changed:0000000000200ed7 - assuming clobbered by SYSRET insn
     [OK]   R8..R15 did not leak kernel data
     [RUN]  Executing 6-argument 32-bit syscall via INT 80
     [OK]   Arguments are preserved across syscall
     [OK]   R8..R15 did not leak kernel data
     [RUN]  Running tests under ptrace
     [RUN]  Executing 6-argument 32-bit syscall via VDSO
     [OK]   Arguments are preserved across syscall
     [NOTE] R11 has changed:0000000000200ed7 - assuming clobbered by SYSRET insn
     [OK]   R8..R15 did not leak kernel data
     [RUN]  Executing 6-argument 32-bit syscall via INT 80
     [OK]   Arguments are preserved across syscall
     [OK]   R8..R15 did not leak kernel data
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Drewry <wad@chromium.org>
    Cc: linux-kernel@vger.kernel.org
    Link: http://lkml.kernel.org/r/1462201010-16846-1-git-send-email-dvlasenk@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1aae84c2807e6ee1358725aee9eabf1137d055e6
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sat Jul 14 02:30:37 2018 -0700

    x86/pti: Mark constant arrays as __initconst
    
    (cherry picked from commit 4bf5d56d429cbc96c23d809a08f63cd29e1a702e)
    
    I'm seeing build failures from the two newly introduced arrays that
    are marked 'const' and '__initdata', which are mutually exclusive:
    
    arch/x86/kernel/cpu/common.c:882:43: error: 'cpu_no_speculation' causes a section type conflict with 'e820_table_firmware_init'
    arch/x86/kernel/cpu/common.c:895:43: error: 'cpu_no_meltdown' causes a section type conflict with 'e820_table_firmware_init'
    
    The correct annotation is __initconst.
    
    Fixes: fec9434a12f3 ("x86/pti: Do not enable PTI on CPUs which are not vulnerable to Meltdown")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Thomas Garnier <thgarnie@google.com>
    Cc: David Woodhouse <dwmw@amazon.co.uk>
    Link: https://lkml.kernel.org/r/20180202213959.611210-1-arnd@arndb.de
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 769b27207746415f530615a0f4faca12c432bbc4
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:30:29 2018 -0700

    x86/cpuid: Fix up "virtual" IBRS/IBPB/STIBP feature bits on Intel
    
    (cherry picked from commit 7fcae1118f5fd44a862aa5c3525248e35ee67c3b)
    
    Despite the fact that all the other code there seems to be doing it, just
    using set_cpu_cap() in early_intel_init() doesn't actually work.
    
    For CPUs with PKU support, setup_pku() calls get_cpu_cap() after
    c->c_init() has set those feature bits. That resets those bits back to what
    was queried from the hardware.
    
    Turning the bits off for bad microcode is easy to fix. That can just use
    setup_clear_cpu_cap() to force them off for all CPUs.
    
    I was less keen on forcing the feature bits *on* that way, just in case
    of inconsistencies. I appreciate that the kernel is going to get this
    utterly wrong if CPU features are not consistent, because it has already
    applied alternatives by the time secondary CPUs are brought up.
    
    But at least if setup_force_cpu_cap() isn't being used, we might have a
    chance of *detecting* the lack of the corresponding bit and either
    panicking or refusing to bring the offending CPU online.
    
    So ensure that the appropriate feature bits are set within get_cpu_cap()
    regardless of how many extra times it's called.
    
    Fixes: 2961298e ("x86/cpufeatures: Clean up Spectre v2 related CPUID flags")
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: karahmed@amazon.de
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Link: https://lkml.kernel.org/r/1517322623-15261-1-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9a016c16d87fef47ad24ce8a9f30e8fce030225e
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:30:20 2018 -0700

    x86/cpufeatures: Clean up Spectre v2 related CPUID flags
    
    (cherry picked from commit 2961298efe1ea1b6fc0d7ee8b76018fa6c0bcef2)
    
    We want to expose the hardware features simply in /proc/cpuinfo as "ibrs",
    "ibpb" and "stibp". Since AMD has separate CPUID bits for those, use them
    as the user-visible bits.
    
    When the Intel SPEC_CTRL bit is set which indicates both IBRS and IBPB
    capability, set those (AMD) bits accordingly. Likewise if the Intel STIBP
    bit is set, set the AMD STIBP that's used for the generic hardware
    capability.
    
    Hide the rest from /proc/cpuinfo by putting "" in the comments. Including
    RETPOLINE and RETPOLINE_AMD which shouldn't be visible there. There are
    patches to make the sysfs vulnerabilities information non-readable by
    non-root, and the same should apply to all information about which
    mitigations are actually in use. Those *shouldn't* appear in /proc/cpuinfo.
    
    The feature bit for whether IBPB is actually used, which is needed for
    ALTERNATIVEs, is renamed to X86_FEATURE_USE_IBPB.
    
    Originally-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: ak@linux.intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1517070274-12128-2-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5ff6b14190322e92489254dc4d10c28f203ee5fc
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:30:10 2018 -0700

    x86/speculation: Add basic IBPB (Indirect Branch Prediction Barrier) support
    
    (cherry picked from commit 20ffa1caecca4db8f79fe665acdeaa5af815a24d)
    
    Expose indirect_branch_prediction_barrier() for use in subsequent patches.
    
    [ tglx: Add IBPB status to spectre_v2 sysfs file ]
    
    Co-developed-by: KarimAllah Ahmed <karahmed@amazon.de>
    Signed-off-by: KarimAllah Ahmed <karahmed@amazon.de>
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-8-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c64410cf4d3abd6c9f5abdd38db0a855926304c5
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:30:01 2018 -0700

    x86/cpufeature: Blacklist SPEC_CTRL/PRED_CMD on early Spectre v2 microcodes
    
    (cherry picked from commit a5b2966364538a0e68c9fa29bc0a3a1651799035)
    
    This doesn't refuse to load the affected microcodes; it just refuses to
    use the Spectre v2 mitigation features if they're detected, by clearing
    the appropriate feature bits.
    
    The AMD CPUID bits are handled here too, because hypervisors *may* have
    been exposing those bits even on Intel chips, for fine-grained control
    of what's available.
    
    It is non-trivial to use x86_match_cpu() for this table because that
    doesn't handle steppings. And the approach taken in commit bd9240a18
    almost made me lose my lunch.
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-7-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4ef0c99359c55ce60ba3859eb615c36c6cbc392c
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:29:52 2018 -0700

    x86/pti: Do not enable PTI on CPUs which are not vulnerable to Meltdown
    
    (cherry picked from commit fec9434a12f38d3aeafeb75711b71d8a1fdef621)
    
    Also, for CPUs which don't speculate at all, don't report that they're
    vulnerable to the Spectre variants either.
    
    Leave the cpu_no_meltdown[] match table with just X86_VENDOR_AMD in it
    for now, even though that could be done with a simple comparison, on the
    assumption that we'll have more to add.
    
    Based on suggestions from Dave Hansen and Alan Cox.
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Dave Hansen <dave.hansen@intel.com>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-6-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4fbcf1a84d8ad1bf15937fa6f9623045da153b4e
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:29:43 2018 -0700

    x86/msr: Add definitions for new speculation control MSRs
    
    (cherry picked from commit 1e340c60d0dd3ae07b5bedc16a0469c14b9f3410)
    
    Add MSR and bit definitions for SPEC_CTRL, PRED_CMD and ARCH_CAPABILITIES.
    
    See Intel's 336996-Speculative-Execution-Side-Channel-Mitigations.pdf
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-5-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b00f820b5143a2fc0a9c859a52be2ef2244834ba
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:29:33 2018 -0700

    x86/cpufeatures: Add AMD feature bits for Speculation Control
    
    (cherry picked from commit 5d10cbc91d9eb5537998b65608441b592eec65e7)
    
    AMD exposes the PRED_CMD/SPEC_CTRL MSRs slightly differently to Intel.
    See http://lkml.kernel.org/r/2b3e25cc-286d-8bd0-aeaf-9ac4aae39de8@amd.com
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Tom Lendacky <thomas.lendacky@amd.com>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-4-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7169b43e7c68edd550efa812c295685947ffa8a0
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:29:24 2018 -0700

    x86/cpufeatures: Add Intel feature bits for Speculation Control
    
    (cherry picked from commit fc67dd70adb711a45d2ef34e12d1a8be75edde61)
    
    Add three feature bits exposed by new microcode on Intel CPUs for
    speculation control.
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-3-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8cee8b4cdd50c5f90f8c63b63bcfba6d1f3839b7
Author: David Woodhouse <dwmw@amazon.co.uk>
Date:   Sat Jul 14 02:29:15 2018 -0700

    x86/cpufeatures: Add CPUID_7_EDX CPUID leaf
    
    (cherry picked from commit 95ca0ee8636059ea2800dfbac9ecac6212d6b38f)
    
    This is a pure feature bits leaf. There are two AVX512 feature bits in it
    already which were handled as scattered bits, and three more from this leaf
    are going to be added for speculation control features.
    
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: gnomes@lxorguk.ukuu.org.uk
    Cc: ak@linux.intel.com
    Cc: ashok.raj@intel.com
    Cc: dave.hansen@intel.com
    Cc: karahmed@amazon.de
    Cc: arjan@linux.intel.com
    Cc: torvalds@linux-foundation.org
    Cc: peterz@infradead.org
    Cc: bp@alien8.de
    Cc: pbonzini@redhat.com
    Cc: tim.c.chen@linux.intel.com
    Cc: gregkh@linux-foundation.org
    Link: https://lkml.kernel.org/r/1516896855-7642-2-git-send-email-dwmw@amazon.co.uk
    Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa@csail.mit.edu>
    Reviewed-by: Matt Helsley (VMware) <matt.helsley@gmail.com>
    Reviewed-by: Alexey Makhalov <amakhalov@vmware.com>
    Reviewed-by: Bo Gan <ganb@vmware.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f868639bf8896908ad45adf1e7c1f786bb3568cc
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Jun 21 09:23:24 2018 -0700

    x86/paravirt: Make native_save_fl() extern inline
    
    commit d0a8d9378d16eb3c69bd8e6d23779fbdbee3a8c7 upstream.
    
    native_save_fl() is marked static inline, but by using it as
    a function pointer in arch/x86/kernel/paravirt.c, it MUST be outlined.
    
    paravirt's use of native_save_fl() also requires that no GPRs other than
    %rax are clobbered.
    
    Compilers have different heuristics which they use to emit stack guard
    code, the emittance of which can break paravirt's callee saved assumption
    by clobbering %rcx.
    
    Marking a function definition extern inline means that if this version
    cannot be inlined, then the out-of-line version will be preferred. By
    having the out-of-line version be implemented in assembly, it cannot be
    instrumented with a stack protector, which might violate custom calling
    conventions that code like paravirt rely on.
    
    The semantics of extern inline has changed since gnu89. This means that
    folks using GCC versions >= 5.1 may see symbol redefinition errors at
    link time for subdirs that override KBUILD_CFLAGS (making the C standard
    used implicit) regardless of this patch. This has been cleaned up
    earlier in the patch set, but is left as a note in the commit message
    for future travelers.
    
    Reports:
     https://lkml.org/lkml/2018/5/7/534
     https://github.com/ClangBuiltLinux/linux/issues/16
    
    Discussion:
     https://bugs.llvm.org/show_bug.cgi?id=37512
     https://lkml.org/lkml/2018/5/24/1371
    
    Thanks to the many folks that participated in the discussion.
    
    [Backport for 4.4. 4.4 is missing commit 784d5699eddc "x86: move exports to
    actual definitions" which doesn't apply cleanly, and not really worth
    backporting IMO. It's simpler to change this patch from upstream:
      + #include <asm-generic/export.h>
    rather than
      + #include <asm/export.h>]
    
    Debugged-by: Alistair Strachan <astrachan@google.com>
    Debugged-by: Matthias Kaehlcke <mka@chromium.org>
    Suggested-by: Arnd Bergmann <arnd@arndb.de>
    Suggested-by: H. Peter Anvin <hpa@zytor.com>
    Suggested-by: Tom Stellar <tstellar@redhat.com>
    Reported-by: Sedat Dilek <sedat.dilek@gmail.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Acked-by: Juergen Gross <jgross@suse.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: acme@redhat.com
    Cc: akataria@vmware.com
    Cc: akpm@linux-foundation.org
    Cc: andrea.parri@amarulasolutions.com
    Cc: ard.biesheuvel@linaro.org
    Cc: aryabinin@virtuozzo.com
    Cc: astrachan@google.com
    Cc: boris.ostrovsky@oracle.com
    Cc: brijesh.singh@amd.com
    Cc: caoj.fnst@cn.fujitsu.com
    Cc: geert@linux-m68k.org
    Cc: ghackmann@google.com
    Cc: gregkh@linuxfoundation.org
    Cc: jan.kiszka@siemens.com
    Cc: jarkko.sakkinen@linux.intel.com
    Cc: joe@perches.com
    Cc: jpoimboe@redhat.com
    Cc: keescook@google.com
    Cc: kirill.shutemov@linux.intel.com
    Cc: kstewart@linuxfoundation.org
    Cc: linux-efi@vger.kernel.org
    Cc: linux-kbuild@vger.kernel.org
    Cc: manojgupta@google.com
    Cc: mawilcox@microsoft.com
    Cc: michal.lkml@markovi.net
    Cc: mjg59@google.com
    Cc: mka@chromium.org
    Cc: pombredanne@nexb.com
    Cc: rientjes@google.com
    Cc: rostedt@goodmis.org
    Cc: thomas.lendacky@amd.com
    Cc: tweek@google.com
    Cc: virtualization@lists.linux-foundation.org
    Cc: will.deacon@arm.com
    Cc: yamada.masahiro@socionext.com
    Link: http://lkml.kernel.org/r/20180621162324.36656-4-ndesaulniers@google.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fce27138ceeb47c2644d1bdabc36dfc4cf025e83
Author: Mathias Nyman <mathias.nyman@linux.intel.com>
Date:   Thu Jun 21 16:19:41 2018 +0300

    xhci: Fix perceived dead host due to runtime suspend race with event handler
    
    commit 229bc19fd7aca4f37964af06e3583c1c8f36b5d6 upstream.
    
    Don't rely on event interrupt (EINT) bit alone to detect pending port
    change in resume. If no change event is detected the host may be suspended
    again, oterwise roothubs are resumed.
    
    There is a lag in xHC setting EINT. If we don't notice the pending change
    in resume, and the controller is runtime suspeded again, it causes the
    event handler to assume host is dead as it will fail to read xHC registers
    once PCI puts the controller to D3 state.
    
    [  268.520969] xhci_hcd: xhci_resume: starting port polling.
    [  268.520985] xhci_hcd: xhci_hub_status_data: stopping port polling.
    [  268.521030] xhci_hcd: xhci_suspend: stopping port polling.
    [  268.521040] xhci_hcd: // Setting command ring address to 0x349bd001
    [  268.521139] xhci_hcd: Port Status Change Event for port 3
    [  268.521149] xhci_hcd: resume root hub
    [  268.521163] xhci_hcd: port resume event for port 3
    [  268.521168] xhci_hcd: xHC is not running.
    [  268.521174] xhci_hcd: handle_port_status: starting port polling.
    [  268.596322] xhci_hcd: xhci_hc_died: xHCI host controller not responding, assume dead
    
    The EINT lag is described in a additional note in xhci specs 4.19.2:
    
    "Due to internal xHC scheduling and system delays, there will be a lag
    between a change bit being set and the Port Status Change Event that it
    generated being written to the Event Ring. If SW reads the PORTSC and
    sees a change bit set, there is no guarantee that the corresponding Port
    Status Change Event has already been written into the Event Ring."
    
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Mathias Nyman <mathias.nyman@linux.intel.com>
    Signed-off-by: Kai-Heng Feng <kai.heng.feng@canonical.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 80a80f51cc3aeea3d7d9d2b859357f611de7a87d
Author: Stefano Brivio <sbrivio@redhat.com>
Date:   Fri Jul 13 13:21:07 2018 +0200

    skbuff: Unconditionally copy pfmemalloc in __skb_clone()
    
    [ Upstream commit e78bfb0751d4e312699106ba7efbed2bab1a53ca ]
    
    Commit 8b7008620b84 ("net: Don't copy pfmemalloc flag in
    __copy_skb_header()") introduced a different handling for the
    pfmemalloc flag in copy and clone paths.
    
    In __skb_clone(), now, the flag is set only if it was set in the
    original skb, but not cleared if it wasn't. This is wrong and
    might lead to socket buffers being flagged with pfmemalloc even
    if the skb data wasn't allocated from pfmemalloc reserves. Copy
    the flag instead of ORing it.
    
    Reported-by: Sabrina Dubroca <sd@queasysnail.net>
    Fixes: 8b7008620b84 ("net: Don't copy pfmemalloc flag in __copy_skb_header()")
    Signed-off-by: Stefano Brivio <sbrivio@redhat.com>
    Tested-by: Sabrina Dubroca <sd@queasysnail.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d629be850ac6e296dfe156604d7bb5202f1613da
Author: Stefano Brivio <sbrivio@redhat.com>
Date:   Wed Jul 11 14:39:42 2018 +0200

    net: Don't copy pfmemalloc flag in __copy_skb_header()
    
    [ Upstream commit 8b7008620b8452728cadead460a36f64ed78c460 ]
    
    The pfmemalloc flag indicates that the skb was allocated from
    the PFMEMALLOC reserves, and the flag is currently copied on skb
    copy and clone.
    
    However, an skb copied from an skb flagged with pfmemalloc
    wasn't necessarily allocated from PFMEMALLOC reserves, and on
    the other hand an skb allocated that way might be copied from an
    skb that wasn't.
    
    So we should not copy the flag on skb copy, and rather decide
    whether to allow an skb to be associated with sockets unrelated
    to page reclaim depending only on how it was allocated.
    
    Move the pfmemalloc flag before headers_start[0] using an
    existing 1-bit hole, so that __copy_skb_header() doesn't copy
    it.
    
    When cloning, we'll now take care of this flag explicitly,
    contravening to the warning comment of __skb_clone().
    
    While at it, restore the newline usage introduced by commit
    b19372273164 ("net: reorganize sk_buff for faster
    __copy_skb_header()") to visually separate bytes used in
    bitfields after headers_start[0], that was gone after commit
    a9e419dc7be6 ("netfilter: merge ctinfo into nfct pointer storage
    area"), and describe the pfmemalloc flag in the kernel-doc
    structure comment.
    
    This doesn't change the size of sk_buff or cacheline boundaries,
    but consolidates the 15 bits hole before tc_index into a 2 bytes
    hole before csum, that could now be filled more easily.
    
    Reported-by: Patrick Talbert <ptalbert@redhat.com>
    Fixes: c93bdd0e03e8 ("netvm: allow skb allocation to use PFMEMALLOC reserves")
    Signed-off-by: Stefano Brivio <sbrivio@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8a82aee2d2f349afbfaee3754af7cf40c16c16a8
Author: Sanjeev Bansal <sanjeevb.bansal@broadcom.com>
Date:   Mon Jul 16 11:13:32 2018 +0530

    tg3: Add higher cpu clock for 5762.
    
    [ Upstream commit 3a498606bb04af603a46ebde8296040b2de350d1 ]
    
    This patch has fix for TX timeout while running bi-directional
    traffic with 100 Mbps using 5762.
    
    Signed-off-by: Sanjeev Bansal <sanjeevb.bansal@broadcom.com>
    Signed-off-by: Siva Reddy Kallam <siva.kallam@broadcom.com>
    Reviewed-by: Michael Chan <michael.chan@broadcom.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 67aaf36e0da9b5008d6732520bcb4046f0cf8962
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Tue Jul 17 20:17:33 2018 -0500

    ptp: fix missing break in switch
    
    [ Upstream commit 9ba8376ce1e2cbf4ce44f7e4bee1d0648e10d594 ]
    
    It seems that a *break* is missing in order to avoid falling through
    to the default case. Otherwise, checking *chan* makes no sense.
    
    Fixes: 72df7a7244c0 ("ptp: Allow reassigning calibration pin function")
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 92b0c8dd9ea76cf215b1f740d06f8de430326289
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Tue Jul 3 22:34:54 2018 +0200

    net: phy: fix flag masking in __set_phy_supported
    
    [ Upstream commit df8ed346d4a806a6eef2db5924285e839604b3f9 ]
    
    Currently also the pause flags are removed from phydev->supported because
    they're not included in PHY_DEFAULT_FEATURES. I don't think this is
    intended, especially when considering that this function can be called
    via phy_set_max_speed() anywhere in a driver. Change the masking to mask
    out only the values we're going to change. In addition remove the
    misleading comment, job of this small function is just to adjust the
    supported and advertised speeds.
    
    Fixes: f3a6bd393c2c ("phylib: Add phy_set_max_speed helper")
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit be64f9f7a253184b733072ccd69a90350e86c46d
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jul 7 16:15:26 2018 -0700

    net/ipv4: Set oif in fib_compute_spec_dst
    
    [ Upstream commit e7372197e15856ec4ee66b668020a662994db103 ]
    
    Xin reported that icmp replies may not use the address on the device the
    echo request is received if the destination address is broadcast. Instead
    a route lookup is done without considering VRF context. Fix by setting
    oif in flow struct to the master device if it is enslaved. That directs
    the lookup to the VRF table. If the device is not enslaved, oif is still
    0 so no affect.
    
    Fixes: cd2fbe1b6b51 ("net: Use VRF device index for lookups on RX")
    Reported-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b67a684222441668cf326427d02c34a8dfedb6be
Author: Davidlohr Bueso <dave@stgolabs.net>
Date:   Mon Jul 16 13:26:13 2018 -0700

    lib/rhashtable: consider param->min_size when setting initial table size
    
    [ Upstream commit 107d01f5ba10f4162c38109496607eb197059064 ]
    
    rhashtable_init() currently does not take into account the user-passed
    min_size parameter unless param->nelem_hint is set as well. As such,
    the default size (number of buckets) will always be HASH_DEFAULT_SIZE
    even if the smallest allowed size is larger than that. Remediate this
    by unconditionally calling into rounded_hashtable_size() and handling
    things accordingly.
    
    Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2be7797acd1bb9ec30920b2aac29e474184ede4e
Author: Colin Ian King <colin.king@canonical.com>
Date:   Tue Jul 17 17:12:39 2018 +0100

    ipv6: fix useless rol32 call on hash
    
    [ Upstream commit 169dc027fb02492ea37a0575db6a658cf922b854 ]
    
    The rol32 call is currently rotating hash but the rol'd value is
    being discarded. I believe the current code is incorrect and hash
    should be assigned the rotated value returned from rol32.
    
    Thanks to David Lebrun for spotting this.
    
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5a95ecebc7083533c8ac384146de991c29145aee
Author: Tyler Hicks <tyhicks@canonical.com>
Date:   Thu Jul 5 18:49:23 2018 +0000

    ipv4: Return EINVAL when ping_group_range sysctl doesn't map to user ns
    
    [ Upstream commit 70ba5b6db96ff7324b8cfc87e0d0383cf59c9677 ]
    
    The low and high values of the net.ipv4.ping_group_range sysctl were
    being silently forced to the default disabled state when a write to the
    sysctl contained GIDs that didn't map to the associated user namespace.
    Confusingly, the sysctl's write operation would return success and then
    a subsequent read of the sysctl would indicate that the low and high
    values are the overflowgid.
    
    This patch changes the behavior by clearly returning an error when the
    sysctl write operation receives a GID range that doesn't map to the
    associated user namespace. In such a situation, the previous value of
    the sysctl is preserved and that range will be returned in a subsequent
    read of the sysctl.
    
    Signed-off-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 08a0dc770c40f9d28c28d21c4728a329e489a57b
Author: Jing Xia <jing.xia.mail@gmail.com>
Date:   Fri Jul 20 17:53:48 2018 -0700

    mm: memcg: fix use after free in mem_cgroup_iter()
    
    commit 9f15bde671355c351cf20d9f879004b234353100 upstream.
    
    It was reported that a kernel crash happened in mem_cgroup_iter(), which
    can be triggered if the legacy cgroup-v1 non-hierarchical mode is used.
    
    Unable to handle kernel paging request at virtual address 6b6b6b6b6b6b8f
    ......
    Call trace:
      mem_cgroup_iter+0x2e0/0x6d4
      shrink_zone+0x8c/0x324
      balance_pgdat+0x450/0x640
      kswapd+0x130/0x4b8
      kthread+0xe8/0xfc
      ret_from_fork+0x10/0x20
    
      mem_cgroup_iter():
          ......
          if (css_tryget(css))    <-- crash here
                break;
          ......
    
    The crashing reason is that mem_cgroup_iter() uses the memcg object whose
    pointer is stored in iter->position, which has been freed before and
    filled with POISON_FREE(0x6b).
    
    And the root cause of the use-after-free issue is that
    invalidate_reclaim_iterators() fails to reset the value of iter->position
    to NULL when the css of the memcg is released in non- hierarchical mode.
    
    Link: http://lkml.kernel.org/r/1531994807-25639-1-git-send-email-jing.xia@unisoc.com
    Fixes: 6df38689e0e9 ("mm: memcontrol: fix possible memcg leak due to interrupted reclaim")
    Signed-off-by: Jing Xia <jing.xia.mail@gmail.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: <chunyan.zhang@unisoc.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cfebfe7a80e35b582fd8d7f6400f9a1d10003583
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Wed Jul 11 10:42:20 2018 -0700

    ARC: mm: allow mprotect to make stack mappings executable
    
    commit 93312b6da4df31e4102ce5420e6217135a16c7ea upstream.
    
    mprotect(EXEC) was failing for stack mappings as default vm flags was
    missing MAYEXEC.
    
    This was triggered by glibc test suite nptl/tst-execstack testcase
    
    What is surprising is that despite running LTP for years on, we didn't
    catch this issue as it lacks a directed test case.
    
    gcc dejagnu tests with nested functions also requiring exec stack work
    fine though because they rely on the GNU_STACK segment spit out by
    compiler and handled in kernel elf loader.
    
    This glibc case is different as the stack is non exec to begin with and
    a dlopen of shared lib with GNU_STACK segment triggers the exec stack
    proceedings using a mprotect(PROT_EXEC) which was broken.
    
    CC: stable@vger.kernel.org
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b3e0971a733e67d15aa114a4b42b4f4e67618b55
Author: Alexey Brodkin <abrodkin@synopsys.com>
Date:   Thu Jun 28 16:59:14 2018 -0700

    ARC: Fix CONFIG_SWAP
    
    commit 6e3761145a9ba3ce267c330b6bff51cf6a057b06 upstream.
    
    swap was broken on ARC due to silly copy-paste issue.
    
    We encode offset from swapcache page in __swp_entry() as (off << 13) but
    were not decoding back in __swp_offset() as (off >> 13) - it was still
    (off << 13).
    
    This finally fixes swap usage on ARC.
    
    | # mkswap /dev/sda2
    |
    | # swapon -a -e /dev/sda2
    | Adding 500728k swap on /dev/sda2.  Priority:-2 extents:1 across:500728k
    |
    | # free
    |              total       used       free     shared    buffers     cached
    | Mem:        765104      13456     751648       4736          8       4736
    | -/+ buffers/cache:       8712     756392
    | Swap:       500728          0     500728
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Alexey Brodkin <abrodkin@synopsys.com>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 01b6ca65e10f2669965fbc62440cb9b09a25d086
Author: Takashi Iwai <tiwai@suse.de>
Date:   Tue Jul 17 17:26:43 2018 +0200

    ALSA: rawmidi: Change resized buffers atomically
    
    commit 39675f7a7c7e7702f7d5341f1e0d01db746543a0 upstream.
    
    The SNDRV_RAWMIDI_IOCTL_PARAMS ioctl may resize the buffers and the
    current code is racy.  For example, the sequencer client may write to
    buffer while it being resized.
    
    As a simple workaround, let's switch to the resized buffer inside the
    stream runtime lock.
    
    Reported-by: syzbot+52f83f0ea8df16932f7f@syzkaller.appspotmail.com
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0cb6eaf5e5be88ddfda51100adc7149d00a28bb2
Author: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
Date:   Fri Jul 20 17:53:42 2018 -0700

    fat: fix memory allocation failure handling of match_strdup()
    
    commit 35033ab988c396ad7bce3b6d24060c16a9066db8 upstream.
    
    In parse_options(), if match_strdup() failed, parse_options() leaves
    opts->iocharset in unexpected state (i.e.  still pointing the freed
    string).  And this can be the cause of double free.
    
    To fix, this initialize opts->iocharset always when freeing.
    
    Link: http://lkml.kernel.org/r/8736wp9dzc.fsf@mail.parknet.co.jp
    Signed-off-by: OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
    Reported-by: syzbot+90b8e10515ae88228a92@syzkaller.appspotmail.com
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d0f4cd75aee1d5e55303de347f5a89431480ec7b
Author: Dewet Thibaut <thibaut.dewet@nokia.com>
Date:   Mon Jul 16 10:49:27 2018 +0200

    x86/MCE: Remove min interval polling limitation
    
    commit fbdb328c6bae0a7c78d75734a738b66b86dffc96 upstream.
    
    commit b3b7c4795c ("x86/MCE: Serialize sysfs changes") introduced a min
    interval limitation when setting the check interval for polled MCEs.
    However, the logic is that 0 disables polling for corrected MCEs, see
    Documentation/x86/x86_64/machinecheck. The limitation prevents disabling.
    
    Remove this limitation and allow the value 0 to disable polling again.
    
    Fixes: b3b7c4795c ("x86/MCE: Serialize sysfs changes")
    Signed-off-by: Dewet Thibaut <thibaut.dewet@nokia.com>
    Signed-off-by: Alexander Sverdlin <alexander.sverdlin@nokia.com>
    [ Massage commit message. ]
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: linux-edac <linux-edac@vger.kernel.org>
    Cc: stable@vger.kernel.org
    Link: http://lkml.kernel.org/r/20180716084927.24869-1-alexander.sverdlin@nokia.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 49e065f5049f2b8d69f29ddc641498f46108dd12
Author: Lan Tianyu <tianyu.lan@intel.com>
Date:   Thu Dec 21 21:10:36 2017 -0500

    KVM/Eventfd: Avoid crash when assign and deassign specific eventfd in parallel.
    
    commit b5020a8e6b54d2ece80b1e7dedb33c79a40ebd47 upstream.
    
    Syzbot reports crashes in kvm_irqfd_assign(), caused by use-after-free
    when kvm_irqfd_assign() and kvm_irqfd_deassign() run in parallel
    for one specific eventfd. When the assign path hasn't finished but irqfd
    has been added to kvm->irqfds.items list, another thead may deassign the
    eventfd and free struct kvm_kernel_irqfd(). The assign path then uses
    the struct kvm_kernel_irqfd that has been freed by deassign path. To avoid
    such issue, keep irqfd under kvm->irq_srcu protection after the irqfd
    has been added to kvm->irqfds.items list, and call synchronize_srcu()
    in irq_shutdown() to make sure that irqfd has been fully initialized in
    the assign path.
    
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim KrÄmÃ¡Å <rkrcmar@redhat.com>
    Cc: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: Tianyu Lan <tianyu.lan@intel.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
