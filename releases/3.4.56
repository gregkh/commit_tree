commit 7b17c57914788c370756ddc7ed8ca1b43394ef0f
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Sun Aug 4 16:35:23 2013 +0800

    Linux 3.4.56

commit 19d22ea89933ca48bcb10fc7919ed7bbefd52362
Author: Wanpeng Li <liwanp@linux.vnet.ibm.com>
Date:   Wed Jul 3 15:02:40 2013 -0700

    mm/memory-hotplug: fix lowmem count overflow when offline pages
    
    commit cea27eb2a202959783f81254c48c250ddd80e129 upstream.
    
    The logic for the memory-remove code fails to correctly account the
    Total High Memory when a memory block which contains High Memory is
    offlined as shown in the example below.  The following patch fixes it.
    
    Before logic memory remove:
    
    MemTotal:        7603740 kB
    MemFree:         6329612 kB
    Buffers:           94352 kB
    Cached:           872008 kB
    SwapCached:            0 kB
    Active:           626932 kB
    Inactive:         519216 kB
    Active(anon):     180776 kB
    Inactive(anon):   222944 kB
    Active(file):     446156 kB
    Inactive(file):   296272 kB
    Unevictable:           0 kB
    Mlocked:               0 kB
    HighTotal:       7294672 kB
    HighFree:        5704696 kB
    LowTotal:         309068 kB
    LowFree:          624916 kB
    
    After logic memory remove:
    
    MemTotal:        7079452 kB
    MemFree:         5805976 kB
    Buffers:           94372 kB
    Cached:           872000 kB
    SwapCached:            0 kB
    Active:           626936 kB
    Inactive:         519236 kB
    Active(anon):     180780 kB
    Inactive(anon):   222944 kB
    Active(file):     446156 kB
    Inactive(file):   296292 kB
    Unevictable:           0 kB
    Mlocked:               0 kB
    HighTotal:       7294672 kB
    HighFree:        5181024 kB
    LowTotal:       4294752076 kB
    LowFree:          624952 kB
    
    [mhocko@suse.cz: fix CONFIG_HIGHMEM=n build]
    Signed-off-by: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: <stable@vger.kernel.org>    [2.6.24+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Zhouping Liu <zliu@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 40a017c96a98a29c9d39bf0ca34651288984e9ce
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Sun Aug 4 16:26:06 2013 +0800

    virtio_net: fix race in RX VQ processing
    
    commit cbdadbbf0c790f79350a8f36029208944c5487d0 upstream
    
    virtio net called virtqueue_enable_cq on RX path after napi_complete, so
    with NAPI_STATE_SCHED clear - outside the implicit napi lock.
    This violates the requirement to synchronize virtqueue_enable_cq wrt
    virtqueue_add_buf.  In particular, used event can move backwards,
    causing us to lose interrupts.
    In a debug build, this can trigger panic within START_USE.
    
    Jason Wang reports that he can trigger the races artificially,
    by adding udelay() in virtqueue_enable_cb() after virtio_mb().
    
    However, we must call napi_complete to clear NAPI_STATE_SCHED before
    polling the virtqueue for used buffers, otherwise napi_schedule_prep in
    a callback will fail, causing us to lose RX events.
    
    To fix, call virtqueue_enable_cb_prepare with NAPI_STATE_SCHED
    set (under napi lock), later call virtqueue_poll with
    NAPI_STATE_SCHED clear (outside the lock).
    
    Reported-by: Jason Wang <jasowang@redhat.com>
    Tested-by: Jason Wang <jasowang@redhat.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [wg: Backported to 3.2]
    Signed-off-by: Wolfram Gloger <wmglo@dent.med.uni-muenchen.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2010fa31f8f5c5fa8385459dff03cb844cf79dd1
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Tue Jul 9 13:19:18 2013 +0300

    virtio: support unlocked queue poll
    
    commit cc229884d3f77ec3b1240e467e0236c3e0647c0c upstream.
    
    This adds a way to check ring empty state after enable_cb outside any
    locks. Will be used by virtio_net.
    
    Note: there's room for more optimization: caller is likely to have a
    memory barrier already, which means we might be able to get rid of a
    barrier here.  Deferring this optimization until we do some
    benchmarking.
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [wg: Backported to 3.2]
    Signed-off-by: Wolfram Gloger <wmglo@dent.med.uni-muenchen.de>
    [bwh: Backported to 3.4: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c733e1a2c459c09fe2510bfa49e2571b532be97c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 17 08:46:19 2013 -0700

    s390: move dummy io_remap_pfn_range() to asm/pgtable.h
    
    commit 4f2e29031e6c67802e7370292dd050fd62f337ee upstream.
    
    Commit b4cbb197c7e7 ("vm: add vm_iomap_memory() helper function") added
    a helper function wrapper around io_remap_pfn_range(), and every other
    architecture defined it in <asm/pgtable.h>.
    
    The s390 choice of <asm/io.h> may make sense, but is not very convenient
    for this case, and gratuitous differences like that cause unexpected errors like this:
    
       mm/memory.c: In function 'vm_iomap_memory':
       mm/memory.c:2439:2: error: implicit declaration of function 'io_remap_pfn_range' [-Werror=implicit-function-declaration]
    
    Glory be the kbuild test robot who noticed this, bisected it, and
    reported it to the guilty parties (ie me).
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
    [bwh: Backported to 3.2: the macro was not defined, so this is an addition
     and not a move]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 17a9afa3e0039e9f0d0caa3a1a5a92b2b7671c3e
Author: Steffen Maier <maier@linux.vnet.ibm.com>
Date:   Fri Apr 26 17:34:54 2013 +0200

    zfcp: status read buffers on first adapter open with link down
    
    commit 9edf7d75ee5f21663a0183d21f702682d0ef132f upstream.
    
    Commit 64deb6efdc5504ce97b5c1c6f281fffbc150bd93
    "[SCSI] zfcp: Use status_read_buf_num provided by FCP channel"
    started using a value returned by the channel but only evaluated the value
    if the fabric link is up.
    Commit 8d88cf3f3b9af4713642caeb221b6d6a42019001
    "[SCSI] zfcp: Update status read mempool"
    introduced mempool resizings based on the above value.
    On setting an FCP device online for the very first time since boot, a new
    zeroed adapter object is allocated. If the link is down, the number of
    status read requests remains zero. Since just the config data exchange is
    incomplete, we proceed with adapter open recovery. However, we
    unconditionally call mempool_resize with adapter->stat_read_buf_num == 0 in
    this case.
    
    This causes a kernel message "kernel BUG at mm/mempool.c:131!" in process
    "zfcperp<FCP-device-bus-ID>" with last function mempool_resize in Krnl PSW
    and zfcp_erp_thread in the Call Trace.
    
    Don't evaluate channel values which are invalid on link down. The number of
    status read requests is always valid, evaluated, and set to a positive
    minimum greater than zero. The adapter open recovery can proceed and the
    channel has status read buffers to inform us on a future link up event.
    While we are not aware of any other code path that could result in mempool
    resize attempts of size zero, we still also initialize the number of status
    read buffers to be posted to a static minimum number on adapter object
    allocation.
    
    Backported for 3.4-stable. commit a53c8fa since v3.6-rc1 unified
    copyright messages, e.g: revise such messages 'Copyright IBM Corporation'
    as 'Copyright IBM Corp', so updated the messages as a53c8fa did.
    
    Signed-off-by: Steffen Maier <maier@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org> #2.6.35+
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>
    Signed-off-by: Zhouping Liu <zliu@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a90a3adeda28c4b701b11770817cf86d92db3228
Author: Clemens Ladisch <clemens@ladisch.de>
Date:   Mon Jul 22 21:32:09 2013 +0200

    firewire: fix libdc1394/FlyCap2 iso event regression
    
    commit 0699a73af3811b66b1ab5650575acee5eea841ab upstream.
    
    Commit 18d627113b83 (firewire: prevent dropping of completed iso packet
    header data) was intended to be an obvious bug fix, but libdc1394 and
    FlyCap2 depend on the old behaviour by ignoring all returned information
    and thus not noticing that not all packets have been received yet.  The
    result was that the video frame buffers would be saved before they
    contained the correct data.
    
    Reintroduce the old behaviour for old clients.
    
    Tested-by: Stepan Salenikovich <stepan.salenikovich@gmail.com>
    Tested-by: Josep Bosch <jep250@gmail.com>
    Cc: <stable@vger.kernel.org> # 3.4+
    Signed-off-by: Clemens Ladisch <clemens@ladisch.de>
    Signed-off-by: Stefan Richter <stefanr@s5r6.in-berlin.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8924588cf02036c239cfec4302f8b44ca6e2c6bb
Author: David Vrabel <david.vrabel@citrix.com>
Date:   Fri Jul 19 15:51:58 2013 +0100

    xen/evtchn: avoid a deadlock when unbinding an event channel
    
    commit 179fbd5a45f0d4034cc6fd37b8d367a3b79663c4 upstream.
    
    Unbinding an event channel (either with the ioctl or when the evtchn
    device is closed) may deadlock because disable_irq() is called with
    port_user_lock held which is also locked by the interrupt handler.
    
    Think of the IOCTL_EVTCHN_UNBIND is being serviced, the routine has
    just taken the lock, and an interrupt happens. The evtchn_interrupt
    is invoked, tries to take the lock and spins forever.
    
    A quick glance at the code shows that the spinlock is a local IRQ
    variant. Unfortunately that does not help as "disable_irq() waits for
    the interrupt handler on all CPUs to stop running.  If the irq occurs
    on another VCPU, it tries to take port_user_lock and can't because
    the unbind ioctl is holding it." (from David). Hence we cannot
    depend on the said spinlock to protect us. We could make it a system
    wide IRQ disable spinlock but there is a better way.
    
    We can piggyback on the fact that the existence of the spinlock is
    to make get_port_user() checks be up-to-date. And we can alter those
    checks to not depend on the spin lock (as it's protected by u->bind_mutex
    in the ioctl) and can remove the unnecessary locking (this is
    IOCTL_EVTCHN_UNBIND) path.
    
    In the interrupt handler we cannot use the mutex, but we do not
    need it.
    
    "The unbind disables the irq before making the port user stale, so when
    you clear it you are guaranteed that the interrupt handler that might
    use that port cannot be running." (from David).
    
    Hence this patch removes the spinlock usage on the teardown path
    and piggybacks on disable_irq happening before we muck with the
    get_port_user() data. This ensures that the interrupt handler will
    never run on stale data.
    
    Signed-off-by: David Vrabel <david.vrabel@citrix.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    [v1: Expanded the commit description a bit]
    Signed-off-by: Jonghwan Choi <jhbird.choi@samsung.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit aa2f8abe27dd7058fd7bfe52401121037a285406
Author: NeilBrown <neilb@suse.de>
Date:   Wed Jul 24 15:37:42 2013 +1000

    md/raid10: remove use-after-free bug.
    
    commit 0eb25bb027a100f5a9df8991f2f628e7d851bc1e upstream.
    
    We always need to be careful when calling generic_make_request, as it
    can start a chain of events which might free something that we are
    using.
    
    Here is one place I wasn't careful enough.  If the wbio2 is not in
    use, then it might get freed at the first generic_make_request call.
    So perform all necessary tests first.
    
    This bug was introduced in 3.3-rc3 (24afd80d99) and can cause an
    oops, so fix is suitable for any -stable since then.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0761d079bbc23ffd309c586ddd142b3cb5f11e0d
Author: NeilBrown <neilb@suse.de>
Date:   Mon Jul 22 12:57:21 2013 +1000

    md/raid5: fix interaction of 'replace' and 'recovery'.
    
    commit f94c0b6658c7edea8bc19d13be321e3860a3fa54 upstream.
    
    If a device in a RAID4/5/6 is being replaced while another is being
    recovered, then the writes to the replacement device currently don't
    happen, resulting in corruption when the replacement completes and the
    new drive takes over.
    
    This is because the replacement writes are only triggered when
    's.replacing' is set and not when the similar 's.sync' is set (which
    is the case during resync and recovery - it means all devices need to
    be read).
    
    So schedule those writes when s.replacing is set as well.
    
    In this case we cannot use "STRIPE_INSYNC" to record that the
    replacement has happened as that is needed for recording that any
    parity calculation is complete.  So introduce STRIPE_REPLACED to
    record if the replacement has happened.
    
    For safety we should also check that STRIPE_COMPUTE_RUN is not set.
    This has a similar effect to the "s.locked == 0" test.  The latter
    ensure that now IO has been flagged but not started.  The former
    checks if any parity calculation has been flagged by not started.
    We must wait for both of these to complete before triggering the
    'replace'.
    
    Add a similar test to the subsequent check for "are we finished yet".
    This possibly isn't needed (is subsumed in the STRIPE_INSYNC test),
    but it makes it more obvious that the REPLACE will happen before we
    think we are finished.
    
    Finally if a NeedReplace device is not UPTODATE then that is an
    error.  We really must trigger a warning.
    
    This bug was introduced in commit 9a3e1101b827a59ac9036a672f5fa8d5279d0fe2
    (md/raid5:  detect and handle replacements during recovery.)
    which introduced replacement for raid5.
    That was in 3.3-rc3, so any stable kernel since then would benefit
    from this fix.
    
    Reported-by: qindehua <13691222965@163.com>
    Tested-by: qindehua <qindehua@163.com>
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 257e1c5c8162d71b1006a4d46aaad6d6d7431011
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Sat Jul 20 03:13:55 2013 +0400

    livelock avoidance in sget()
    
    commit acfec9a5a892f98461f52ed5770de99a3e571ae2 upstream.
    
    Eric Sandeen has found a nasty livelock in sget() - take a mount(2) about
    to fail.  The superblock is on ->fs_supers, ->s_umount is held exclusive,
    ->s_active is 1.  Along comes two more processes, trying to mount the same
    thing; sget() in each is picking that superblock, bumping ->s_count and
    trying to grab ->s_umount.  ->s_active is 3 now.  Original mount(2)
    finally gets to deactivate_locked_super() on failure; ->s_active is 2,
    superblock is still ->fs_supers because shutdown will *not* happen until
    ->s_active hits 0.  ->s_umount is dropped and now we have two processes
    chasing each other:
    s_active = 2, A acquired ->s_umount, B blocked
    A sees that the damn thing is stillborn, does deactivate_locked_super()
    s_active = 1, A drops ->s_umount, B gets it
    A restarts the search and finds the same superblock.  And bumps it ->s_active.
    s_active = 2, B holds ->s_umount, A blocked on trying to get it
    ... and we are in the earlier situation with A and B switched places.
    
    The root cause, of course, is that ->s_active should not grow until we'd
    got MS_BORN.  Then failing ->mount() will have deactivate_locked_super()
    shut the damn thing down.  Fortunately, it's easy to do - the key point
    is that grab_super() is called only for superblocks currently on ->fs_supers,
    so it can bump ->s_count and grab ->s_umount first, then check MS_BORN and
    bump ->s_active; we must never increment ->s_count for superblocks past
    ->kill_sb(), but grab_super() is never called for those.
    
    The bug is pretty old; we would've caught it by now, if not for accidental
    exclusion between sget() for block filesystems; the things like cgroup or
    e.g. mtd-based filesystems don't have anything of that sort, so they get
    bitten.  The right way to deal with that is obviously to fix sget()...
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 428f268ed0c72fb48e72029d8d0ca540d63ec717
Author: Rick Farina (Zero_Chaos) <zerochaos@gentoo.org>
Date:   Mon Jul 29 15:17:59 2013 -0400

    USB: serial: ftdi_sio: add more RT Systems ftdi devices
    
    commit fed1f1ed90bce42ea010e2904cbc04e7b8304940 upstream.
    
    RT Systems makes many usb serial cables based on the ftdi_sio driver for
    programming various amateur radios.  This patch is a full listing of
    their current product offerings and should allow these cables to all
    be recognized.
    
    Signed-off-by: Rick Farina (Zero_Chaos) <zerochaos@gentoo.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1996c98030fc41e8c0ff296b0508acca598acfee
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Jul 30 00:22:53 2013 -0400

    drm/radeon/atom: initialize more atom interpretor elements to 0
    
    commit 42a21826dc54583cdb79cc8477732e911ac9c376 upstream.
    
    The ProcessAuxChannel table on some rv635 boards assumes
    the divmul members are initialized to 0 otherwise we get
    an invalid fb offset since it has a bad mask set when
    setting the fb base.  While here initialize all the
    atom interpretor elements to 0.
    
    Fixes:
    https://bugzilla.kernel.org/show_bug.cgi?id=60639
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e41f203de6370aa097df7fb9166ccb61ae75be05
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Fri Jul 19 17:44:43 2013 -0400

    drm/radeon: improve dac adjust heuristics for legacy pdac
    
    commit 03ed8cf9b28d886c64c7e705c7bb1a365fd8fb95 upstream.
    
    Hopefully avoid more quirks in the future due to bogus
    vbios dac data.
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b076cb4efdcedb34f5cbac343ff609318a9b2eb0
Author: Mark Kettenis <kettenis@openbsd.org>
Date:   Sun Jul 21 16:44:09 2013 -0400

    drm/radeon: fix combios tables on older cards
    
    commit cef1d00cd56f600121ad121875655ad410a001b8 upstream.
    
    Noticed that my old Radeon 7500 hung after printing
    
       drm: GPU not posted. posting now...
    
    when it wasn't selected as the primary card the BIOS.  Some digging
    revealed that it was hanging in combios_parse_mmio_table() while
    parsing the ASIC INIT 3 table.  Looking at the BIOS ROM for the card,
    it becomes obvious that there is no ASIC INIT 3 table in the BIOS.
    The code is just processing random garbage.  No surprise it hangs!
    
    Why do I say that there is no ASIC INIT 3 table is the BIOS?  This
    table is found through the MISC INFO table.  The MISC INFO table can
    be found at offset 0x5e in the COMBIOS header.  But the header is
    smaller than that.  The COMBIOS header starts at offset 0x126.  The
    standard PCI Data Structure (the bit that starts with 'PCIR') lives at
    offset 0x180.  That means that the COMBIOS header can not be larger
    than 0x5a bytes and therefore cannot contain a MISC INFO table.
    
    I looked at a dozen or so BIOS images, some my own, some downloaded from:
    
        <http://www.techpowerup.com/vgabios/index.php?manufacturer=ATI&page=1>
    
    It is fairly obvious that the size of the COMBIOS header can be found
    at offset 0x6 of the header.  Not sure if it is a 16-bit number or
    just an 8-bit number, but that doesn't really matter since the tables
    seems to be always smaller than 256 bytes.
    
    So I think combios_get_table_offset() should check if the requested
    table is present.  This can be done by checking the offset against the
    size of the header.  See the diff below.  The diff is against the WIP
    OpenBSD codebase that roughly corresponds to Linux 3.8.13 at this
    point.  But I don't think this bit of the code changed much since
    then.
    
    For what it is worth:
    
    Signed-off-by: Mark Kettenis <kettenis@openbsd.org>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03223102914853b4b9421c60f6b562c6eb5dafaf
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu Jul 18 11:13:53 2013 -0400

    drm/radeon: fix endian issues with DP handling (v3)
    
    commit 34be8c9af7b8728465963740fc11136ae90dfc36 upstream.
    
    The atom interpreter expects data in LE format, so
    swap the message buffer as apprioriate.
    
    v2: properly handle non-dw aligned byte counts.
    v3: properly handle remainder
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: Dong He <hedonghust@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0990072e0fd7d50e08b9ea77e77ff936ae41705c
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Jul 10 23:41:16 2013 +0100

    dm verity: fix inability to use a few specific devices sizes
    
    commit b1bf2de07271932326af847a3c6a01fdfd29d4be upstream.
    
    Fix a boundary condition that caused failure for certain device sizes.
    
    The problem is reported at
      http://code.google.com/p/cryptsetup/issues/detail?id=160
    
    For certain device sizes the number of hashes at a specific level was
    calculated incorrectly.
    
    It happens for example for a device with data and metadata block size 4096
    that has 16385 blocks and algorithm sha256.
    
    The user can test if he is affected by this bug by running the
    "veritysetup verify" command and also by activating the dm-verity kernel
    driver and reading the whole block device. If it passes without an error,
    then the user is not affected.
    
    The condition for the bug is:
    
    Split the total number of data blocks (data_block_bits) into bit strings,
    each string has hash_per_block_bits bits. hash_per_block_bits is
    rounddown(log2(metadata_block_size/hash_digest_size)). Equivalently, you
    can say that you convert data_blocks_bits to 2^hash_per_block_bits base.
    
    If there some zero bit string below the most significant bit string and at
    least one bit below this zero bit string is set, then the bug happens.
    
    The same bug exists in the userspace veritysetup tool, so you must use
    fixed veritysetup too if you want to use devices that are affected by
    this boundary condition.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Cc: Milan Broz <gmazyland@gmail.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5201cbf11ac566b2eee6eebf334f71ecec3e1724
Author: Toshi Kani <toshi.kani@hp.com>
Date:   Wed Jul 10 10:47:13 2013 -0600

    ACPI / memhotplug: Fix a stale pointer in error path
    
    commit d19f503e22316a84c39bc19445e0e4fdd49b3532 upstream.
    
    device->driver_data needs to be cleared when releasing its data,
    mem_device, in an error path of acpi_memory_device_add().
    
    The function evaluates the _CRS of memory device objects, and fails
    when it gets an unexpected resource or cannot allocate memory.  A
    kernel crash or data corruption may occur when the kernel accesses
    the stale pointer.
    
    Signed-off-by: Toshi Kani <toshi.kani@hp.com>
    Reviewed-by: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ef445a321016a464e32b1b4d581efa61706b12cf
Author: Anton Blanchard <anton@samba.org>
Date:   Mon Jul 15 14:04:50 2013 +1000

    powerpc/modules: Module CRC relocation fix causes perf issues
    
    commit 0e0ed6406e61434d3f38fb58aa8464ec4722b77e upstream.
    
    Module CRCs are implemented as absolute symbols that get resolved by
    a linker script. We build an intermediate .o that contains an
    unresolved symbol for each CRC. genksysms parses this .o, calculates
    the CRCs and writes a linker script that "resolves" the symbols to
    the calculated CRC.
    
    Unfortunately the ppc64 relocatable kernel sees these CRCs as symbols
    that need relocating and relocates them at boot. Commit d4703aef
    (module: handle ppc64 relocating kcrctabs when CONFIG_RELOCATABLE=y)
    added a hook to reverse the bogus relocations. Part of this patch
    created a symbol at 0x0:
    
    # head -2 /proc/kallsyms
    0000000000000000 T reloc_start
    c000000000000000 T .__start
    
    This reloc_start symbol is causing lots of confusion to perf. It
    thinks reloc_start is a massive function that stretches from 0x0 to
    0xc000000000000000 and we get various cryptic errors out of perf,
    including:
    
    problem incrementing symbol count, skipping event
    
    This patch removes the  reloc_start linker script label and instead
    defines it as PHYSICAL_START. We also need to wrap it with
    CONFIG_PPC64 because the ppc32 kernel can set a non zero
    PHYSICAL_START at compile time and we wouldn't want to subtract
    it from the CRCs in that case.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Acked-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit af5697cdc86f43647931aa78ade17c4ee9fc5523
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Jul 22 16:53:36 2013 -0400

    libata: make it clear that sata_inic162x is experimental
    
    commit bb9696192826a7d9279caf872e95b41bc26c7eff upstream.
    
    sata_inic162x never reached a state where it's reliable enough for
    production use and data corruption is a relatively common occurrence.
    Make the driver generate warning about the issues and mark the Kconfig
    option as experimental.
    
    If the situation doesn't improve, we'd be better off making it depend
    on CONFIG_BROKEN.  Let's wait for several cycles and see if the kernel
    message draws any attention.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Martin Braure de Calignon <braurede@free.fr>
    Reported-by: Ben Hutchings <ben@decadent.org.uk>
    Reported-by: risc4all@yahoo.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 82627ff3dbb67837206fd305d1afe361055aead7
Author: Youquan Song <youquan.song@intel.com>
Date:   Thu Jul 11 21:15:57 2013 -0400

    ata: Fix DVD not dectected at some platform with Wellsburg PCH
    
    commit eac27f04a71e1f39f196f7e520d16dcefc955d77 upstream.
    
    There is a patch b55f84e2d527182e7c611d466cd0bb6ddce201de "ata_piix: Fix DVD
     not dectected at some Haswell platforms" to fix an issue of DVD not
    recognized on Haswell Desktop platform with Lynx Point.
    Recently, it is also found the same issue at some platformas with Wellsburg PCH.
    
    So deliver a similar patch to fix it by disables 32bit PIO in IDE mode.
    
    Signed-off-by: Youquan Song <youquan.song@intel.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8f5a2856d99634204cf68605b8c70fcd92c47d47
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Wed Jan 16 11:33:52 2013 -0500

    xen/blkback: Check device permissions before allowing OP_DISCARD
    
    commit 604c499cbbcc3d5fe5fb8d53306aa0fae1990109 upstream.
    
    We need to make sure that the device is not RO or that
    the request is not past the number of sectors we want to
    issue the DISCARD operation for.
    
    This fixes CVE-2013-2140.
    
    Acked-by: Jan Beulich <JBeulich@suse.com>
    Acked-by: Ian Campbell <Ian.Campbell@citrix.com>
    [v1: Made it pr_warn instead of pr_debug]
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e94d695ac4f0f047eef5c5b71dae1c2aefd59def
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Wed Jul 17 19:30:20 2013 -0400

    Btrfs: re-add root to dead root list if we stop dropping it
    
    commit d29a9f629e009c9b90e5859bce581070fd6247fc upstream.
    
    If we stop dropping a root for whatever reason we need to add it back to the
    dead root list so that we will re-start the dropping next transaction commit.
    The other case this happens is if we recover a drop because we will add a root
    without adding it to the fs radix tree, so we can leak it's root and commit root
    extent buffer, adding this to the dead root list makes this cleanup happen.
    Thanks,
    
    Reported-by: Alex Lyakas <alex.btrfs@zadarastorage.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 849f48aea9edb426a418b7b38f5c903fcc84fdf5
Author: Josef Bacik <jbacik@fusionio.com>
Date:   Mon Jul 15 12:41:42 2013 -0400

    Btrfs: fix lock leak when resuming snapshot deletion
    
    commit fec386ac1428f9c0e672df952cbca5cebd4e4e2f upstream.
    
    We aren't setting path->locks[level] when we resume a snapshot deletion which
    means we won't unlock the buffer when we free the path.  This causes deadlocks
    if we happen to re-allocate the block before we've evicted the extent buffer
    from cache.  Thanks,
    
    Reported-by: Alex Lyakas <alex.btrfs@zadarastorage.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cf63fbd49c23ad07983e629febfc3cbcc9382d05
Author: Ian Abbott <abbotti@mev.co.uk>
Date:   Mon Jul 8 13:36:19 2013 +0100

    staging: comedi: COMEDI_CANCEL ioctl should wake up read/write
    
    commit 69acbaac303e8cb948801a9ddd0ac24e86cc4a1b upstream.
    
    Comedi devices can do blocking read() or write() (or poll()) if an
    asynchronous command has been set up, blocking for data (for read()) or
    buffer space (for write()).  Various events associated with the
    asynchronous command will wake up the blocked reader or writer (or
    poller).  It is also possible to force the asynchronous command to
    terminate by issuing a `COMEDI_CANCEL` ioctl.  That shuts down the
    asynchronous command, but does not currently wake up the blocked reader
    or writer (or poller).  If the blocked task could be woken up, it would
    see that the command is no longer active and return.  The caller of the
    `COMEDI_CANCEL` ioctl could attempt to wake up the blocked task by
    sending a signal, but that's a nasty workaround.
    
    Change `do_cancel_ioctl()` to wake up the wait queue after it returns
    from `do_cancel()`.  `do_cancel()` can propagate an error return value
    from the low-level comedi driver's cancel routine, but it always shuts
    the command down regardless, so `do_cancel_ioctl()` can wake up he wait
    queue regardless of the return value from `do_cancel()`.
    
    Signed-off-by: Ian Abbott <abbotti@mev.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9e914980a5d558f38ba9a0176a4bdea8def9b99b
Author: William Gulland <wgulland@google.com>
Date:   Thu Jun 27 16:10:20 2013 -0700

    usb: Clear both buffers when clearing a control transfer TT buffer.
    
    commit 2c7b871b9102c497ba8f972aa5d38532f05b654d upstream.
    
    Control transfers have both IN and OUT (or SETUP) packets, so when
    clearing TT buffers for a control transfer it's necessary to send
    two HUB_CLEAR_TT_BUFFER requests to the hub.
    
    Signed-off-by: William Gulland <wgulland@google.com>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 06b19056b9fe16a5b235510acd125974db9d7678
Author: Jóhann B. Guðmundsson <johannbg@fedoraproject.org>
Date:   Thu Jul 4 21:47:52 2013 +0000

    USB: misc: Add Manhattan Hi-Speed USB DVI Converter to sisusbvga
    
    commit 58fc90db8261b571c026bb8bf23aad48a7233118 upstream.
    
    Signed-off-by: Jóhann B. Guðmundsson <johannbg@fedoraproject.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9f510a82588f91ca1d83606fcde730104e70b348
Author: Johan Hovold <johan@kernel.org>
Date:   Fri Jun 28 12:24:26 2013 +0200

    USB: ti_usb_3410_5052: fix dynamic-id matching
    
    commit 1fad56424f5ad3ce4973505a357212b2e2282b3f upstream.
    
    The driver failed to take the dynamic ids into account when determining
    the device type and therefore all devices were detected as 2-port
    devices when using the dynamic-id interface.
    
    Match on the usb-serial-driver field instead of doing redundant id-table
    searches.
    
    Reported-by: Anders Hammarquist <iko@iko.pp.se>
    Signed-off-by: Johan Hovold <jhovold@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1b5c94b7ed5a0037d7327a385967763fa41ba72c
Author: Felipe Balbi <balbi@ti.com>
Date:   Mon Jul 15 12:36:35 2013 +0300

    usb: dwc3: gadget: don't prevent gadget from being probed if we fail
    
    commit cdcedd6981194e511cc206887db661d016069d68 upstream.
    
    In case we fail our ->udc_start() callback, we
    should be ready to accept another modprobe following
    the failed one.
    
    We had forgotten to clear dwc->gadget_driver back
    to NULL and, because of that, we were preventing
    gadget driver modprobe from being retried.
    
    Signed-off-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 76d54f0afc8f8cfea8ad8ea1b7c9e2fda617d48a
Author: Huang Rui <ray.huang@amd.com>
Date:   Thu Jun 27 01:08:11 2013 +0800

    usb: dwc3: fix wrong bit mask in dwc3_event_type
    
    commit 1974d494dea05ea227cb42f5e918828801e237aa upstream.
    
    Per dwc3 2.50a spec, the is_devspec bit is used to distinguish the
    Device Endpoint-Specific Event or Device-Specific Event (DEVT). If the
    bit is 1, the event is represented Device-Specific Event, then use
    [7:1] bits as Device Specific Event to marked the type. It has 7 bits,
    and we can see the reserved8_31 variable name which means from 8 to 31
    bits marked reserved, actually there are 24 bits not 25 bits between
    that. And 1 + 7 + 24 = 32, the event size is 4 byes.
    
    So in dwc3_event_type, the bit mask should be:
    is_devspec      [0]             1  bit
    type            [7:1]           7  bits
    reserved8_31    [31:8]          24 bits
    
    This patch should be backported to kernels as old as 3.2, that contain
    the commit 72246da40f3719af3bfd104a2365b32537c27d83 "usb: Introduce
    DesignWare USB3 DRD Driver".
    
    Signed-off-by: Huang Rui <ray.huang@amd.com>
    Signed-off-by: Felipe Balbi <balbi@ti.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 79bc1750fe6730db008745dee617f2e32789d3f9
Author: Sarah Sharp <sarah.a.sharp@linux.intel.com>
Date:   Wed Jul 24 10:27:13 2013 -0700

    xhci: Avoid NULL pointer deref when host dies.
    
    commit 203a86613fb3bf2767335659513fa98563a3eb71 upstream.
    
    When the host controller fails to respond to an Enable Slot command, and
    the host fails to respond to the register write to abort the command
    ring, the xHCI driver will assume the host is dead, and call
    usb_hc_died().
    
    The USB device's slot_id is still set to zero, and the pointer stored at
    xhci->devs[0] will always be NULL.  The call to xhci_check_args in
    xhci_free_dev should have caught the NULL virt_dev pointer.
    
    However, xhci_free_dev is designed to free the xhci_virt_device
    structures, even if the host is dead, so that we don't leak kernel
    memory.  xhci_free_dev checks the return value from the generic
    xhci_check_args function.  If the return value is -ENODEV, it carries on
    trying to free the virtual device.
    
    The issue is that xhci_check_args looks at the host controller state
    before it looks at the xhci_virt_device pointer.  It will return -ENIVAL
    because the host is dead, and xhci_free_dev will ignore the return
    value, and happily dereference the NULL xhci_virt_device pointer.
    
    The fix is to make sure that xhci_check_args checks the xhci_virt_device
    pointer before it checks the host state.
    
    See https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1203453 for
    further details.  This patch doesn't solve the underlying issue, but
    will ensure we don't see any more NULL pointer dereferences because of
    the issue.
    
    This patch should be backported to kernels as old as 3.1, that
    contain the commit 7bd89b4017f46a9b92853940fd9771319acb578a "xhci: Don't
    submit commands or URBs to halted hosts."
    
    Signed-off-by: Sarah Sharp <sarah.a.sharp@linux.intel.com>
    Reported-by: Vincent Thiele <vincentthiele@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 00a71cc4ea7cfdc02cf494fbeecb110466480c87
Author: Oleksij Rempel <linux@rempel-privat.de>
Date:   Sun Jul 21 15:36:19 2013 +0200

    xhci: fix null pointer dereference on ring_doorbell_for_active_rings
    
    commit d66eaf9f89502971fddcb0de550b01fa6f409d83 upstream.
    
    in some cases where device is attched to xhci port and do not responding,
    for example ath9k_htc with stalled firmware, kernel will
    crash on ring_doorbell_for_active_rings.
    This patch check if pointer exist before it is used.
    
    This patch should be backported to kernels as old as 2.6.35, that
    contain the commit e9df17eb1408cfafa3d1844bfc7f22c7237b31b8 "USB: xhci:
    Correct assumptions about number of rings per endpoint"
    
    Signed-off-by: Oleksij Rempel <linux@rempel-privat.de>
    Signed-off-by: Sarah Sharp <sarah.a.sharp@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2d75d5d8384dc3a2abc1113d0bb0c7333e669042
Author: George Cherian <george.cherian@ti.com>
Date:   Mon Jul 1 10:59:12 2013 +0530

    usb: host: xhci: Enable XHCI_SPURIOUS_SUCCESS for all controllers with xhci 1.0
    
    commit 07f3cb7c28bf3f4dd80bfb136cf45810c46ac474 upstream.
    
    Xhci controllers with hci_version > 0.96 gives spurious success
    events on short packet completion. During webcam capture the
    "ERROR Transfer event TRB DMA ptr not part of current TD" was observed.
    The same application works fine with synopsis controllers hci_version 0.96.
    The same issue is seen with Intel Pantherpoint xhci controller. So enabling
    this quirk in xhci_gen_setup if controller verion is greater than 0.96.
    For xhci-pci move the quirk to much generic place xhci_gen_setup.
    
    Note from Sarah:
    
    The xHCI 1.0 spec changed how hardware handles short packets.  The HW
    will notify SW of the TRB where the short packet occurred, and it will
    also give a successful status for the last TRB in a TD (the one with the
    IOC flag set).  On the second successful status, that warning will be
    triggered in the driver.
    
    Software is now supposed to not assume the TD is not completed until it
    gets that last successful status.  That means we have a slight race
    condition, although it should have little practical impact.  This patch
    papers over that issue.
    
    It's on my long-term to-do list to fix this race condition, but it is a
    much more involved patch that will probably be too big for stable.  This
    patch is needed for stable to avoid serious log spam.
    
    This patch should be backported to kernels as old as 3.0, that
    contain the commit ad808333d8201d53075a11bc8dd83b81f3d68f0b "Intel xhci:
    Ignore spurious successful event."
    
    The patch will have to be modified for kernels older than 3.2, since
    that kernel added the xhci_gen_setup function for xhci platform devices.
    The correct conflict resolution for kernels older than 3.2 is to set
    XHCI_SPURIOUS_SUCCESS in xhci_pci_quirks for all xHCI 1.0 hosts.
    
    Signed-off-by: George Cherian <george.cherian@ti.com>
    Signed-off-by: Sarah Sharp <sarah.a.sharp@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 352b6418a2d14c754b41f23e0698f0006c914b95
Author: zhangwei(Jovi) <jovi.zhangwei@huawei.com>
Date:   Mon Jul 29 09:33:58 2013 +0800

    tracing: Fix irqs-off tag display in syscall tracing
    
    commit 11034ae9c20f4057a6127fc965906417978e69b2 upstream
    
    Initialization of variable irq_flags and pc was missed when backport
    11034ae9c to linux-3.0.y and linux-3.4.y, my fault.
    
    Signed-off-by: zhangwei(Jovi) <jovi.zhangwei@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e5f8b2d71c3b617d2d5ce9568067b1458b47a517
Author: Saurav Kashyap <saurav.kashyap@qlogic.com>
Date:   Fri Jul 12 14:47:51 2013 -0400

    SCSI: qla2xxx: Properly set the tagging for commands.
    
    commit c3ccb1d7cf4c4549151876dd37c0944a682fd9e1 upstream.
    
    This fixes a regression where Xyratex controllers and disks were lost by the
    driver:
    
    https://bugzilla.kernel.org/show_bug.cgi?id=59601
    
    Reported-by: Jack Hill <jackhill@jackhill.us>
    Signed-off-by: Saurav Kashyap <saurav.kashyap@qlogic.com>
    Signed-off-by: Giridhar Malavali <giridhar.malavali@qlogic.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 970f226f08005c3a9b631a6b0dc5d40afd6c27a7
Author: Ewan D. Milne <emilne@redhat.com>
Date:   Fri Nov 2 09:38:34 2012 -0400

    SCSI: sd: fix crash when UA received on DIF enabled device
    
    commit 085b513f97d8d799d28491239be4b451bcd8c2c5 upstream.
    
    sd_prep_fn will allocate a larger CDB for the command via mempool_alloc
    for devices using DIF type 2 protection.  This CDB was being freed
    in sd_done, which results in a kernel crash if the command is retried
    due to a UNIT ATTENTION.  This change moves the code to free the larger
    CDB into sd_unprep_fn instead, which is invoked after the request is
    complete.
    
    It is no longer necessary to call scsi_print_command separately for
    this case as the ->cmnd will no longer be NULL in the normal code path.
    
    Also removed conditional test for DIF type 2 when freeing the larger
    CDB because the protection_type could have been changed via sysfs while
    the command was executing.
    
    Signed-off-by: Ewan D. Milne <emilne@redhat.com>
    Acked-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a38de994b080d7f30faf349cdc5c88cf4ed1aa6e
Author: Nicolin Chen <b42378@freescale.com>
Date:   Fri Jun 14 12:34:50 2013 +0800

    ASoC: wm8962: Remove remaining direct register cache accesses
    
    commit 2e7ee15ced914e109a1a5b6dfcd463d846a13bd5 upstream.
    
    Also fix return values for headphone switch updates.
    
    Signed-off-by: Nicolin Chen <b42378@freescale.com>
    Signed-off-by: Mark Brown <broonie@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c541a6f5d2b36e8b65e2b1525a5256c541ce414f
Author: Chih-Chung Chang <chihchung@chromium.org>
Date:   Mon Jul 15 09:38:46 2013 -0700

    ASoC: max98088 - fix element type of the register cache.
    
    commit cb6f66a2d278e57a6c9d8fb59bd9ebd8ab3965c2 upstream.
    
    The registers of max98088 are 8 bits, not 16 bits. This bug causes the
    contents of registers to be overwritten with bad values when the codec
    is suspended and then resumed.
    
    Signed-off-by: Chih-Chung Chang <chihchung@chromium.org>
    Signed-off-by: Dylan Reid <dgreid@chromium.org>
    Signed-off-by: Mark Brown <broonie@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 975e6b1a5a5c74c91cf5a57932ff348576d1268d
Author: Ren Bigcren <bigcren.ren@sonymobile.com>
Date:   Tue Jul 2 13:34:30 2013 +0200

    USB: storage: Add MicroVault Flash Drive to unusual_devs
    
    commit e7a6121f4929c17215f0cdca3726f4bf3e4e9529 upstream.
    
    The device report an error capacity when read_capacity_16().
    Using read_capacity_10() can get the correct capacity.
    
    Signed-off-by: Ren Bigcren <bigcren.ren@sonymobile.com>
    Cc: Matthew Dharm <mdharm-usb@one-eyed-alien.net>
    Signed-off-by: Oskar Andero <oskar.andero@sonymobile.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c447fb2bd2b310e34c74580a494e001312a58a68
Author: Joern Engel <joern@logfs.org>
Date:   Wed Jul 3 11:35:11 2013 -0400

    iscsi-target: Fix tfc_tpg_nacl_auth_cit configfs length overflow
    
    commit 0fbfc46fb0b2f543a8b539e94c6c293ebc0b05a6 upstream.
    
    This patch fixes a potential buffer overflow while processing
    iscsi_node_auth input for configfs attributes within NodeACL
    tfc_tpg_nacl_auth_cit context.
    
    Signed-off-by: Joern Engel <joern@logfs.org>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
