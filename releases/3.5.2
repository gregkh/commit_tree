commit 684012d815c70359162d8b9cc9879b83855e59bf
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Aug 15 07:55:25 2012 -0700

    Linux 3.5.2

commit 667b6fd34e95ac34244f42bfa895e83fc39d2b8a
Author: Stanislaw Gruszka <sgruszka@redhat.com>
Date:   Fri Aug 3 12:49:14 2012 +0200

    rt61pci: fix NULL pointer dereference in config_lna_gain
    
    commit deee0214def5d8a32b8112f11d9c2b1696e9c0cb upstream.
    
    We can not pass NULL libconf->conf->channel to rt61pci_config() as it
    is dereferenced unconditionally in rt61pci_config_lna_gain() subroutine.
    
    Resolves:
    https://bugzilla.kernel.org/show_bug.cgi?id=44361
    
    Reported-and-tested-by: <dolohow@gmail.com>
    Signed-off-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec6942d015aab53df3a3b4aaf6755b4a039355a1
Author: Chris Bagwell <chris@cnpbagwell.com>
Date:   Tue Jun 12 00:25:48 2012 -0700

    Input: wacom - Bamboo One 1024 pressure fix
    
    commit 6dc463511d4a690f01a9248df3b384db717e0b1c upstream.
    
    Bamboo One's with ID of 0x6a and 0x6b were added with correct
    indication of 1024 pressure levels but the Graphire packet routine
    was only looking at 9 bits.  Increased to 10 bits.
    
    This bug caused these devices to roll over to zero pressure at half
    way mark.
    
    The other devices using this routine only support 256 or 512 range
    and look to fix unused bits at zero.
    
    Signed-off-by: Chris Bagwell <chris@cnpbagwell.com>
    Reported-by: Tushant Mirchandani <tushantin@gmail.com>
    Reviewed-by: Ping Cheng <pingc@wacom.com>
    Signed-off-by: Dmitry Torokhov <dtor@mail.ru>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3aea730ce57eed9a71ae1aa3bfa65527fbf4192d
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Apr 30 16:21:37 2012 +0000

    Input: eeti_ts: pass gpio value instead of IRQ
    
    commit 4eef6cbfcc03b294d9d334368a851b35b496ce53 upstream.
    
    The EETI touchscreen asserts its IRQ line as soon as it has data in its
    internal buffers. The line is automatically deasserted once all data has
    been read via I2C. Hence, the driver has to monitor the GPIO line and
    cannot simply rely on the interrupt handler reception.
    
    In the current implementation of the driver, irq_to_gpio() is used to
    determine the GPIO number from the i2c_client's IRQ value.
    
    As irq_to_gpio() is not available on all platforms, this patch changes
    this and makes the driver ignore the passed in IRQ. Instead, a GPIO is
    added to the platform_data struct and gpio_to_irq is used to derive the
    IRQ from that GPIO. If this fails, bail out. The driver is only able to
    work in environments where the touchscreen GPIO can be mapped to an
    IRQ.
    
    Without this patch, building raumfeld_defconfig results in:
    
    drivers/input/touchscreen/eeti_ts.c: In function 'eeti_ts_irq_active':
    drivers/input/touchscreen/eeti_ts.c:65:2: error: implicit declaration of function 'irq_to_gpio' [-Werror=implicit-function-declaration]
    
    Signed-off-by: Daniel Mack <zonque@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: Sven Neumann <s.neumann@raumfeld.com>
    Cc: linux-input@vger.kernel.org
    Cc: Haojian Zhuang <haojian.zhuang@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b9285018a1d259ab7c3a0c3d097849ab6e426931
Author: Tushar Dave <tushar.n.dave@intel.com>
Date:   Tue Jul 31 02:02:43 2012 +0000

    e1000e: NIC goes up and immediately goes down
    
    commit b7ec70be01a87f2c85df3ae11046e74f9b67e323 upstream.
    
    Found that commit d478eb44 was a bad commit.
    If the link partner is transmitting codeword (even if NULL codeword),
    then the RXCW.C bit will be set so check for RXCW.CW is unnecessary.
    Ref: RH BZ 840642
    
    Reported-by: Fabio Futigami <ffutigam@redhat.com>
    Signed-off-by: Tushar Dave <tushar.n.dave@intel.com>
    CC: Marcelo Ricardo Leitner <mleitner@redhat.com>
    Tested-by: Aaron Brown <aaron.f.brown@intel.com>
    Signed-off-by: Peter P Waskiewicz Jr <peter.p.waskiewicz.jr@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1e6729d254227d275543d33a77363b07d327bc1b
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Sun Aug 5 18:31:46 2012 +0200

    iwlwifi: disable greenfield transmissions as a workaround
    
    commit 50e2a30cf6fcaeb2d27360ba614dd169a10041c5 upstream.
    
    There's a bug that causes the rate scaling to get stuck
    when it has to use single-stream rates with a peer that
    can do GF and SGI; the two are incompatible so we can't
    use them together, but that causes the algorithm to not
    work at all, it always rejects updates.
    
    Disable greenfield for now to prevent that problem.
    
    Reviewed-by: Emmanuel Grumbach <emmanuel.grumbach@intel.com>
    Tested-by: Cesar Eduardo Barros <cesarb@cesarb.net>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c7d190158502024773de8bc4822fbd737a2bb9d0
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Aug 9 19:01:26 2012 -0700

    Yama: higher restrictions should block PTRACE_TRACEME
    
    commit 9d8dad742ad1c74d7e7210ee05d0b44961d5ea16 upstream.
    
    The higher ptrace restriction levels should be blocking even
    PTRACE_TRACEME requests. The comments in the LSM documentation are
    misleading about when the checks happen (the parent does not go through
    security_ptrace_access_check() on a PTRACE_TRACEME call).
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d534db404b17a81f1edbe10de0f1b67f1813d427
Author: Stanislav Kinsbursky <skinsbursky@parallels.com>
Date:   Thu Aug 9 02:50:40 2012 +0000

    tun: don't zeroize sock->file on detach
    
    commit 66d1b9263a371abd15806c53f486f0645ef31a8f upstream.
    
    This is a fix for bug, introduced in 3.4 kernel by commit
    1ab5ecb90cb6a3df1476e052f76a6e8f6511cb3d ("tun: don't hold network
    namespace by tun sockets"), which, among other things, replaced simple
    sock_put() by sk_release_kernel(). Below is sequence, which leads to
    oops for non-persistent devices:
    
    tun_chr_close()
    tun_detach()                            <== tun->socket.file = NULL
    tun_free_netdev()
    sk_release_sock()
    sock_release(sock->file == NULL)
    iput(SOCK_INODE(sock))                  <== dereference on NULL pointer
    
    This patch just removes zeroing of socket's file from __tun_detach().
    sock_release() will do this.
    
    Reported-by: Ruan Zhijie <ruanzhijie@hotmail.com>
    Tested-by: Ruan Zhijie <ruanzhijie@hotmail.com>
    Acked-by: Al Viro <viro@ZenIV.linux.org.uk>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Stanislav Kinsbursky <skinsbursky@parallels.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6fd9636dc32ee59c03434a3c6044b41621d806e8
Author: Jeff Mahoney <jeffm@suse.com>
Date:   Fri Aug 10 15:07:09 2012 -0400

    printk: Fix calculation of length used to discard records
    
    commit e3756477aec028427fec767957c0d4b6cfb87208 upstream.
    
    While tracking down a weird buffer overflow issue in a program that
    looked to be sane, I started double checking the length returned by
    syslog(SYSLOG_ACTION_READ_ALL, ...) to make sure it wasn't overflowing
    the buffer.
    
    Sure enough, it was.  I saw this in strace:
    
      11339 syslog(SYSLOG_ACTION_READ_ALL, "<5>[244017.708129] REISERFS (dev"..., 8192) = 8279
    
    It turns out that the loops that calculate how much space the entries
    will take when they're copied don't include the newlines and prefixes
    that will be included in the final output since prev flags is passed as
    zero.
    
    This patch properly accounts for it and fixes the overflow.
    
    Signed-off-by: Jeff Mahoney <jeffm@suse.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9b9efe7459c14ccb49e87f1bc46289a9a26e8602
Author: Daniel Drake <dsd@laptop.org>
Date:   Thu Aug 2 18:41:48 2012 +0100

    cfg80211: process pending events when unregistering net device
    
    commit 1f6fc43e621167492ed4b7f3b4269c584c3d6ccc upstream.
    
    libertas currently calls cfg80211_disconnected() when it is being
    brought down. This causes an event to be allocated, but since the
    wdev is already removed from the rdev by the time that the event
    processing work executes, the event is never processed or freed.
    http://article.gmane.org/gmane.linux.kernel.wireless.general/95666
    
    Fix this leak, and other possible situations, by processing the event
    queue when a device is being unregistered. Thanks to Johannes Berg for
    the suggestion.
    
    Signed-off-by: Daniel Drake <dsd@laptop.org>
    Reviewed-by: Johannes Berg <johannes@sipsolutions.net>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5d16505b11ba551e59d2b61485549a36e9694f47
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sun Aug 5 14:58:37 2012 +0000

    ARM: pxa: remove irq_to_gpio from ezx-pcap driver
    
    commit 59ee93a528b94ef4e81a08db252b0326feff171f upstream.
    
    The irq_to_gpio function was removed from the pxa platform
    in linux-3.2, and this driver has been broken since.
    
    There is actually no in-tree user of this driver that adds
    this platform device, but the driver can and does get enabled
    on some platforms.
    
    Without this patch, building ezx_defconfig results in:
    
    drivers/mfd/ezx-pcap.c: In function 'pcap_isr_work':
    drivers/mfd/ezx-pcap.c:205:2: error: implicit declaration of function 'irq_to_gpio' [-Werror=implicit-function-declaration]
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Haojian Zhuang <haojian.zhuang@gmail.com>
    Cc: Samuel Ortiz <sameo@linux.intel.com>
    Cc: Daniel Ribeiro <drwyrm@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a90ebf555d15e00928fd34b02379c84230068841
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Thu Aug 2 22:48:39 2012 +0800

    ARM: dts: imx53-ard: add regulators for lan9220
    
    commit 1eec0c569523782392b5e6245effddb626213b8c upstream.
    
    Since commit c7e963f (net/smsc911x: Add regulator support), the lan9220
    device tree probe fails on imx53-ard board, because the commit makes
    VDD33A and VDDVARIO supplies mandatory for the driver.
    
    Add a fixed dummy 3V3 supplying lan9220 to fix the regression.
    
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 94a062fa3695d5fb249bde1df679fbe5d997e1ca
Author: Marek Vasut <marex@denx.de>
Date:   Fri Aug 3 20:54:48 2012 +0200

    ARM: mxs: Remove MMAP_MIN_ADDR setting from mxs_defconfig
    
    commit 3bed491c8d28329e34f8a31e3fe64d03f3a350f1 upstream.
    
    The CONFIG_DEFAULT_MMAP_MIN_ADDR was set to 65536 in mxs_defconfig,
    this caused severe breakage of userland applications since the upper
    limit for ARM is 32768. By default CONFIG_DEFAULT_MMAP_MIN_ADDR is
    set to 4096 and can also be changed via /proc/sys/vm/mmap_min_addr
    if needed.
    
    Quoting Russell King [1]:
    
    "4096 is also fine for ARM too. There's not much point in having
    defconfigs change it - that would just be pure noise in the config
    files."
    
    the CONFIG_DEFAULT_MMAP_MIN_ADDR can be removed from the defconfig
    altogether.
    
    This problem was introduced by commit cde7c41 (ARM: configs: add
    defconfig for mach-mxs).
    
    [1] http://marc.info/?l=linux-arm-kernel&m=134401593807820&w=2
    
    Signed-off-by: Marek Vasut <marex@denx.de>
    Cc: Russell King <linux@arm.linux.org.uk>
    Cc: Wolfgang Denk <wd@denx.de>
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7901d43578f09b7648deed2f137269a5e18183fb
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Thu Aug 2 22:28:49 2012 +0800

    ARM: imx: enable emi_slow_gate clock for imx5
    
    commit 68b0562df90a76ba964423986b2472c7e791729a upstream.
    
    The imx5 common clock migration causes a regression with smsc911x
    driver on imx53-ard board, where a smsc lan9220 controller gets
    connected on imx53 with EIM interface.  EIM needs clock emi_slow_gate
    to be functional.  In the new imx5 clock driver, there is no use count
    incremented for the clock by enabling it, so the framework closes the
    clock at late init time and makes EIM stop working then.
    
    Enable emi_slow_gate in clock driver initialization to fix the
    regression.
    
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Acked-by: Sascha Hauer <s.hauer@pengutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7238feb0348d3a080d5b55e33fba676fe8a29aed
Author: Fabio Estevam <fabio.estevam@freescale.com>
Date:   Thu Jul 26 16:08:53 2012 -0300

    ARM: clk-imx31: Fix the keypad clock name
    
    commit 8cc7a2b9f75355f60922db4adf27742ba7f2f6bc upstream.
    
    Fix the keypad clock name, in order to fix the following error:
    
    imx-keypad imx-keypad: failed to get keypad clock
    imx-keypad: probe of imx-keypad failed with error -2
    
    Signed-off-by: Fabio Estevam <fabio.estevam@freescale.com>
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 120d8b93b0eb7d868c612db14ca7f47d032dfc6f
Author: Roland Dreier <roland@purestorage.com>
Date:   Mon Jul 16 15:34:25 2012 -0700

    target: Check number of unmap descriptors against our limit
    
    commit 7409a6657aebf8be74c21d0eded80709b27275cb upstream.
    
    Fail UNMAP commands that have more than our reported limit on unmap
    descriptors.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    [bwh: Backported to 3.2: adjust filename]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 69722bcb5130778d70e34a2706cd041cecd98b1b
Author: Roland Dreier <roland@purestorage.com>
Date:   Mon Jul 16 15:34:24 2012 -0700

    target: Fix possible integer underflow in UNMAP emulation
    
    commit b7fc7f3777582dea85156a821d78a522a0c083aa upstream.
    
    It's possible for an initiator to send us an UNMAP command with a
    descriptor that is less than 8 bytes; in that case it's really bad for
    us to set an unsigned int to that value, subtract 8 from it, and then
    use that as a limit for our loop (since the value will wrap around to
    a huge positive value).
    
    Fix this by making size be signed and only looping if size >= 16 (ie
    if we have at least a full descriptor available).
    
    Also remove offset as an obfuscated name for the constant 8.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    [bwh: Backported to 3.2: adjust filename, context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8ed22428989de32402369198483f33ddfc957c64
Author: Roland Dreier <roland@purestorage.com>
Date:   Mon Jul 16 15:34:23 2012 -0700

    target: Fix reading of data length fields for UNMAP commands
    
    commit 1a5fa4576ec8a462313c7516b31d7453481ddbe8 upstream.
    
    The UNMAP DATA LENGTH and UNMAP BLOCK DESCRIPTOR DATA LENGTH fields
    are in the unmap descriptor (the payload transferred to our data out
    buffer), not in the CDB itself.  Read them from the correct place in
    target_emulated_unmap.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    [bwh: Backported to 3.2: adjust filename, context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit db72573b925c8258376aecaf7df99debfae11384
Author: Roland Dreier <roland@purestorage.com>
Date:   Mon Jul 16 15:34:22 2012 -0700

    target: Add range checking to UNMAP emulation
    
    commit 2594e29865c291db162313187612cd9f14538f33 upstream.
    
    When processing an UNMAP command, we need to make sure that the number
    of blocks we're asked to UNMAP does not exceed our reported maximum
    number of blocks per UNMAP, and that the range of blocks we're
    unmapping doesn't go past the end of the device.
    
    Signed-off-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    [bwh: Backported to 3.2: adjust filename, context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a29d332e9ac886c15af3911b43fba26bfc45ed9e
Author: Mel Gorman <mgorman@suse.de>
Date:   Tue Jul 31 16:46:20 2012 -0700

    mm: hugetlbfs: close race during teardown of hugetlbfs shared page tables
    
    commit d833352a4338dc31295ed832a30c9ccff5c7a183 upstream.
    
    If a process creates a large hugetlbfs mapping that is eligible for page
    table sharing and forks heavily with children some of whom fault and
    others which destroy the mapping then it is possible for page tables to
    get corrupted.  Some teardowns of the mapping encounter a "bad pmd" and
    output a message to the kernel log.  The final teardown will trigger a
    BUG_ON in mm/filemap.c.
    
    This was reproduced in 3.4 but is known to have existed for a long time
    and goes back at least as far as 2.6.37.  It was probably was introduced
    in 2.6.20 by [39dde65c: shared page table for hugetlb page].  The messages
    look like this;
    
    [  ..........] Lots of bad pmd messages followed by this
    [  127.164256] mm/memory.c:391: bad pmd ffff880412e04fe8(80000003de4000e7).
    [  127.164257] mm/memory.c:391: bad pmd ffff880412e04ff0(80000003de6000e7).
    [  127.164258] mm/memory.c:391: bad pmd ffff880412e04ff8(80000003de0000e7).
    [  127.186778] ------------[ cut here ]------------
    [  127.186781] kernel BUG at mm/filemap.c:134!
    [  127.186782] invalid opcode: 0000 [#1] SMP
    [  127.186783] CPU 7
    [  127.186784] Modules linked in: af_packet cpufreq_conservative cpufreq_userspace cpufreq_powersave acpi_cpufreq mperf ext3 jbd dm_mod coretemp crc32c_intel usb_storage ghash_clmulni_intel aesni_intel i2c_i801 r8169 mii uas sr_mod cdrom sg iTCO_wdt iTCO_vendor_support shpchp serio_raw cryptd aes_x86_64 e1000e pci_hotplug dcdbas aes_generic container microcode ext4 mbcache jbd2 crc16 sd_mod crc_t10dif i915 drm_kms_helper drm i2c_algo_bit ehci_hcd ahci libahci usbcore rtc_cmos usb_common button i2c_core intel_agp video intel_gtt fan processor thermal thermal_sys hwmon ata_generic pata_atiixp libata scsi_mod
    [  127.186801]
    [  127.186802] Pid: 9017, comm: hugetlbfs-test Not tainted 3.4.0-autobuild #53 Dell Inc. OptiPlex 990/06D7TR
    [  127.186804] RIP: 0010:[<ffffffff810ed6ce>]  [<ffffffff810ed6ce>] __delete_from_page_cache+0x15e/0x160
    [  127.186809] RSP: 0000:ffff8804144b5c08  EFLAGS: 00010002
    [  127.186810] RAX: 0000000000000001 RBX: ffffea000a5c9000 RCX: 00000000ffffffc0
    [  127.186811] RDX: 0000000000000000 RSI: 0000000000000009 RDI: ffff88042dfdad00
    [  127.186812] RBP: ffff8804144b5c18 R08: 0000000000000009 R09: 0000000000000003
    [  127.186813] R10: 0000000000000000 R11: 000000000000002d R12: ffff880412ff83d8
    [  127.186814] R13: ffff880412ff83d8 R14: 0000000000000000 R15: ffff880412ff83d8
    [  127.186815] FS:  00007fe18ed2c700(0000) GS:ffff88042dce0000(0000) knlGS:0000000000000000
    [  127.186816] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [  127.186817] CR2: 00007fe340000503 CR3: 0000000417a14000 CR4: 00000000000407e0
    [  127.186818] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  127.186819] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    [  127.186820] Process hugetlbfs-test (pid: 9017, threadinfo ffff8804144b4000, task ffff880417f803c0)
    [  127.186821] Stack:
    [  127.186822]  ffffea000a5c9000 0000000000000000 ffff8804144b5c48 ffffffff810ed83b
    [  127.186824]  ffff8804144b5c48 000000000000138a 0000000000001387 ffff8804144b5c98
    [  127.186825]  ffff8804144b5d48 ffffffff811bc925 ffff8804144b5cb8 0000000000000000
    [  127.186827] Call Trace:
    [  127.186829]  [<ffffffff810ed83b>] delete_from_page_cache+0x3b/0x80
    [  127.186832]  [<ffffffff811bc925>] truncate_hugepages+0x115/0x220
    [  127.186834]  [<ffffffff811bca43>] hugetlbfs_evict_inode+0x13/0x30
    [  127.186837]  [<ffffffff811655c7>] evict+0xa7/0x1b0
    [  127.186839]  [<ffffffff811657a3>] iput_final+0xd3/0x1f0
    [  127.186840]  [<ffffffff811658f9>] iput+0x39/0x50
    [  127.186842]  [<ffffffff81162708>] d_kill+0xf8/0x130
    [  127.186843]  [<ffffffff81162812>] dput+0xd2/0x1a0
    [  127.186845]  [<ffffffff8114e2d0>] __fput+0x170/0x230
    [  127.186848]  [<ffffffff81236e0e>] ? rb_erase+0xce/0x150
    [  127.186849]  [<ffffffff8114e3ad>] fput+0x1d/0x30
    [  127.186851]  [<ffffffff81117db7>] remove_vma+0x37/0x80
    [  127.186853]  [<ffffffff81119182>] do_munmap+0x2d2/0x360
    [  127.186855]  [<ffffffff811cc639>] sys_shmdt+0xc9/0x170
    [  127.186857]  [<ffffffff81410a39>] system_call_fastpath+0x16/0x1b
    [  127.186858] Code: 0f 1f 44 00 00 48 8b 43 08 48 8b 00 48 8b 40 28 8b b0 40 03 00 00 85 f6 0f 88 df fe ff ff 48 89 df e8 e7 cb 05 00 e9 d2 fe ff ff <0f> 0b 55 83 e2 fd 48 89 e5 48 83 ec 30 48 89 5d d8 4c 89 65 e0
    [  127.186868] RIP  [<ffffffff810ed6ce>] __delete_from_page_cache+0x15e/0x160
    [  127.186870]  RSP <ffff8804144b5c08>
    [  127.186871] ---[ end trace 7cbac5d1db69f426 ]---
    
    The bug is a race and not always easy to reproduce.  To reproduce it I was
    doing the following on a single socket I7-based machine with 16G of RAM.
    
    $ hugeadm --pool-pages-max DEFAULT:13G
    $ echo $((18*1048576*1024)) > /proc/sys/kernel/shmmax
    $ echo $((18*1048576*1024)) > /proc/sys/kernel/shmall
    $ for i in `seq 1 9000`; do ./hugetlbfs-test; done
    
    On my particular machine, it usually triggers within 10 minutes but
    enabling debug options can change the timing such that it never hits.
    Once the bug is triggered, the machine is in trouble and needs to be
    rebooted.  The machine will respond but processes accessing proc like "ps
    aux" will hang due to the BUG_ON.  shutdown will also hang and needs a
    hard reset or a sysrq-b.
    
    The basic problem is a race between page table sharing and teardown.  For
    the most part page table sharing depends on i_mmap_mutex.  In some cases,
    it is also taking the mm->page_table_lock for the PTE updates but with
    shared page tables, it is the i_mmap_mutex that is more important.
    
    Unfortunately it appears to be also insufficient. Consider the following
    situation
    
    Process A                                       Process B
    ---------                                       ---------
    hugetlb_fault                                   shmdt
                                                    LockWrite(mmap_sem)
                                                      do_munmap
                                                        unmap_region
                                                          unmap_vmas
                                                            unmap_single_vma
                                                              unmap_hugepage_range
                                                                Lock(i_mmap_mutex)
                                                                Lock(mm->page_table_lock)
                                                                huge_pmd_unshare/unmap tables <--- (1)
                                                                Unlock(mm->page_table_lock)
                                                                Unlock(i_mmap_mutex)
      huge_pte_alloc                                      ...
        Lock(i_mmap_mutex)                                ...
        vma_prio_walk, find svma, spte                    ...
        Lock(mm->page_table_lock)                         ...
        share spte                                        ...
        Unlock(mm->page_table_lock)                       ...
        Unlock(i_mmap_mutex)                              ...
      hugetlb_no_page                                                                         <--- (2)
                                                          free_pgtables
                                                            unlink_file_vma
                                                            hugetlb_free_pgd_range
                                                        remove_vma_list
    
    In this scenario, it is possible for Process A to share page tables with
    Process B that is trying to tear them down.  The i_mmap_mutex on its own
    does not prevent Process A walking Process B's page tables.  At (1) above,
    the page tables are not shared yet so it unmaps the PMDs.  Process A sets
    up page table sharing and at (2) faults a new entry.  Process B then trips
    up on it in free_pgtables.
    
    This patch fixes the problem by adding a new function
    __unmap_hugepage_range_final that is only called when the VMA is about to
    be destroyed.  This function clears VM_MAYSHARE during
    unmap_hugepage_range() under the i_mmap_mutex.  This makes the VMA
    ineligible for sharing and avoids the race.  Superficially this looks like
    it would then be vunerable to truncate and madvise issues but hugetlbfs
    has its own truncate handlers so does not use unmap_mapping_range() and
    does not support madvise(DONTNEED).
    
    This should be treated as a -stable candidate if it is merged.
    
    Test program is as follows. The test case was mostly written by Michal
    Hocko with a few minor changes to reproduce this bug.
    
    ==== CUT HERE ====
    
    static size_t huge_page_size = (2UL << 20);
    static size_t nr_huge_page_A = 512;
    static size_t nr_huge_page_B = 5632;
    
    unsigned int get_random(unsigned int max)
    {
            struct timeval tv;
    
            gettimeofday(&tv, NULL);
            srandom(tv.tv_usec);
            return random() % max;
    }
    
    static void play(void *addr, size_t size)
    {
            unsigned char *start = addr,
                          *end = start + size,
                          *a;
            start += get_random(size/2);
    
            /* we could itterate on huge pages but let's give it more time. */
            for (a = start; a < end; a += 4096)
                    *a = 0;
    }
    
    int main(int argc, char **argv)
    {
            key_t key = IPC_PRIVATE;
            size_t sizeA = nr_huge_page_A * huge_page_size;
            size_t sizeB = nr_huge_page_B * huge_page_size;
            int shmidA, shmidB;
            void *addrA = NULL, *addrB = NULL;
            int nr_children = 300, n = 0;
    
            if ((shmidA = shmget(key, sizeA, IPC_CREAT|SHM_HUGETLB|0660)) == -1) {
                    perror("shmget:");
                    return 1;
            }
    
            if ((addrA = shmat(shmidA, addrA, SHM_R|SHM_W)) == (void *)-1UL) {
                    perror("shmat");
                    return 1;
            }
            if ((shmidB = shmget(key, sizeB, IPC_CREAT|SHM_HUGETLB|0660)) == -1) {
                    perror("shmget:");
                    return 1;
            }
    
            if ((addrB = shmat(shmidB, addrB, SHM_R|SHM_W)) == (void *)-1UL) {
                    perror("shmat");
                    return 1;
            }
    
    fork_child:
            switch(fork()) {
                    case 0:
                            switch (n%3) {
                            case 0:
                                    play(addrA, sizeA);
                                    break;
                            case 1:
                                    play(addrB, sizeB);
                                    break;
                            case 2:
                                    break;
                            }
                            break;
                    case -1:
                            perror("fork:");
                            break;
                    default:
                            if (++n < nr_children)
                                    goto fork_child;
                            play(addrA, sizeA);
                            break;
            }
            shmdt(addrA);
            shmdt(addrB);
            do {
                    wait(NULL);
            } while (--n > 0);
            shmctl(shmidA, IPC_RMID, NULL);
            shmctl(shmidB, IPC_RMID, NULL);
            return 0;
    }
    
    [akpm@linux-foundation.org: name the declaration's args, fix CONFIG_HUGETLBFS=n build]
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9e3fe186758c27c3113dc3ff0d789bd01f42916b
Author: Cyrus Lien <cyrus.lien@canonical.com>
Date:   Mon Jul 23 17:11:51 2012 +0800

    HID: add ASUS AIO keyboard model AK1D
    
    commit 2d8767bb421574dfcf48e4be0751ce7d8f73d5d7 upstream.
    
    Add Asus All-In-One PC keyboard model AK1D.
    
    BugLink: https://bugs.launchpad.net/bugs/1027789
    
    Signed-off-by: Cyrus Lien <cyrus.lien@canonical.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2d65287a464480153d110b3d4efd31080fe91742
Author: Lionel Vaux <lionel.vaux@free.fr>
Date:   Sun Jul 22 11:32:20 2012 +0200

    HID: add support for Cypress barcode scanner 04B4:ED81
    
    commit 76c9d8fe2c7fc34ffc387d8022c5828d6ff9df48 upstream.
    
    Add yet another device to the list of Cypress barcode scanners
    needing the CP_RDESC_SWAPPED_MIN_MAX quirk.
    
    Signed-off-by: Lionel Vaux (iouri) <lionel.vaux@free.fr>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1e9aa138a6a60e6cfb9634f081394176449cd91f
Author: Austin Hendrix <ahendrix@willowgarage.com>
Date:   Mon Jun 4 15:27:51 2012 -0700

    HID: multitouch: add support for Novatek touchscreen
    
    commit 4db703ead4535792ea54dba7275fdd1527848e74 upstream.
    
    Add support for a Novatek touchscreen panel as a generic HID multitouch
    panel.
    
    Signed-off-by: Austin Hendrix <ahendrix@willowgarage.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bb60c3fa114c3565fa88a827e497af7640dd09e8
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Fri Jul 27 22:26:08 2012 -0400

    random: mix in architectural randomness in extract_buf()
    
    commit d2e7c96af1e54b507ae2a6a7dd2baf588417a7e5 upstream.
    
    Mix in any architectural randomness in extract_buf() instead of
    xfer_secondary_buf().  This allows us to mix in more architectural
    randomness, and it also makes xfer_secondary_buf() faster, moving a
    tiny bit of additional CPU overhead to process which is extracting the
    randomness.
    
    [ Commit description modified by tytso to remove an extended
      advertisement for the RDRAND instruction. ]
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Cc: DJ Johnston <dj.johnston@intel.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 33fc625ce55e037eceb04efd57aa4c094a064dbd
Author: Tony Luck <tony.luck@intel.com>
Date:   Fri Jul 20 13:15:20 2012 -0700

    dmi: Feed DMI table to /dev/random driver
    
    commit d114a33387472555188f142ed8e98acdb8181c6d upstream.
    
    Send the entire DMI (SMBIOS) table to the /dev/random driver to
    help seed its pools.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 91e66eea0fe522c44a8ac10e09e05c4422f56512
Author: Tony Luck <tony.luck@intel.com>
Date:   Mon Jul 23 09:47:57 2012 -0700

    random: Add comment to random_initialize()
    
    commit cbc96b7594b5691d61eba2db8b2ea723645be9ca upstream.
    
    Many platforms have per-machine instance data (serial numbers,
    asset tags, etc.) squirreled away in areas that are accessed
    during early system bringup. Mixing this data into the random
    pools has a very high value in providing better random data,
    so we should allow (and even encourage) architecture code to
    call add_device_randomness() from the setup_arch() paths.
    
    However, this limits our options for internal structure of
    the random driver since random_initialize() is not called
    until long after setup_arch().
    
    Add a big fat comment to rand_initialize() spelling out
    this requirement.
    
    Suggested-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 458f9b009bce81a9f5644a08018579abc60d865b
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jul 14 20:27:52 2012 -0400

    random: remove rand_initialize_irq()
    
    commit c5857ccf293968348e5eb4ebedc68074de3dcda6 upstream.
    
    With the new interrupt sampling system, we are no longer using the
    timer_rand_state structure in the irq descriptor, so we can stop
    initializing it now.
    
    [ Merged in fixes from Sedat to find some last missing references to
      rand_initialize_irq() ]
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Sedat Dilek <sedat.dilek@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e5f6e64fd1a3bc64cb80c87c3ad3329fab952258
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Thu Jul 5 20:23:21 2012 +0000

    mfd: wm831x: Feed the device UUID into device_add_randomness()
    
    commit 27130f0cc3ab97560384da437e4621fc4e94f21c upstream.
    
    wm831x devices contain a unique ID value. Feed this into the newly added
    device_add_randomness() to add some per device seed data to the pool.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bb1f7df1f0673247e16e96873bf99db0913bcf7f
Author: Mark Brown <broonie@opensource.wolfsonmicro.com>
Date:   Thu Jul 5 20:19:17 2012 +0000

    rtc: wm831x: Feed the write counter into device_add_randomness()
    
    commit 9dccf55f4cb011a7552a8a2749a580662f5ed8ed upstream.
    
    The tamper evident features of the RTC include the "write counter" which
    is a pseudo-random number regenerated whenever we set the RTC. Since this
    value is unpredictable it should provide some useful seeding to the random
    number generator.
    
    Only do this on boot since the goal is to seed the pool rather than add
    useful entropy.
    
    Signed-off-by: Mark Brown <broonie@opensource.wolfsonmicro.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5835ac8ab3c5ab7dd8ed0719dbc90265991fc155
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jul 4 11:32:48 2012 -0400

    MAINTAINERS: Theodore Ts'o is taking over the random driver
    
    commit 330e0a01d54c2b8606c56816f99af6ebc58ec92c upstream.
    
    Matt Mackall stepped down as the /dev/random driver maintainer last
    year, so Theodore Ts'o is taking back the /dev/random driver.
    
    Cc: Matt Mackall <mpm@selenic.com>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fdd8b7a5b8bb0f66d8bf7bcef3e855db6db15f84
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jul 4 16:19:30 2012 -0400

    random: add tracepoints for easier debugging and verification
    
    commit 00ce1db1a634746040ace24c09a4e3a7949a3145 upstream.
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 24ea0461e5159b28c8b0c141d1da6a7f9bed0332
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Thu Jul 5 10:35:23 2012 -0400

    random: add new get_random_bytes_arch() function
    
    commit c2557a303ab6712bb6e09447df828c557c710ac9 upstream.
    
    Create a new function, get_random_bytes_arch() which will use the
    architecture-specific hardware random number generator if it is
    present.  Change get_random_bytes() to not use the HW RNG, even if it
    is avaiable.
    
    The reason for this is that the hw random number generator is fast (if
    it is present), but it requires that we trust the hardware
    manufacturer to have not put in a back door.  (For example, an
    increasing counter encrypted by an AES key known to the NSA.)
    
    It's unlikely that Intel (for example) was paid off by the US
    Government to do this, but it's impossible for them to prove otherwise
      --- especially since Bull Mountain is documented to use AES as a
    whitener.  Hence, the output of an evil, trojan-horse version of
    RDRAND is statistically indistinguishable from an RDRAND implemented
    to the specifications claimed by Intel.  Short of using a tunnelling
    electronic microscope to reverse engineer an Ivy Bridge chip and
    disassembling and analyzing the CPU microcode, there's no way for us
    to tell for sure.
    
    Since users of get_random_bytes() in the Linux kernel need to be able
    to support hardware systems where the HW RNG is not present, most
    time-sensitive users of this interface have already created their own
    cryptographic RNG interface which uses get_random_bytes() as a seed.
    So it's much better to use the HW RNG to improve the existing random
    number generator, by mixing in any entropy returned by the HW RNG into
    /dev/random's entropy pool, but to always _use_ /dev/random's entropy
    pool.
    
    This way we get almost of the benefits of the HW RNG without any
    potential liabilities.  The only benefits we forgo is the
    speed/performance enhancements --- and generic kernel code can't
    depend on depend on get_random_bytes() having the speed of a HW RNG
    anyway.
    
    For those places that really want access to the arch-specific HW RNG,
    if it is available, we provide get_random_bytes_arch().
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 478fe5fdd419c03f8238df275c23530548a83763
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Thu Jul 5 10:21:01 2012 -0400

    random: use the arch-specific rng in xfer_secondary_pool
    
    commit e6d4947b12e8ad947add1032dd754803c6004824 upstream.
    
    If the CPU supports a hardware random number generator, use it in
    xfer_secondary_pool(), where it will significantly improve things and
    where we can afford it.
    
    Also, remove the use of the arch-specific rng in
    add_timer_randomness(), since the call is significantly slower than
    get_cycles(), and we're much better off using it in
    xfer_secondary_pool() anyway.
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b8570c10637c4e3666b6da473a17fa5484d3b06c
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jul 4 21:23:25 2012 -0400

    net: feed /dev/random with the MAC address when registering a device
    
    commit 7bf2357524408b97fec58344caf7397f8140c3fd upstream.
    
    Cc: David Miller <davem@davemloft.net>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 13789430b1125b638c1546d248784b18ca589aaa
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jul 4 11:22:20 2012 -0400

    usb: feed USB device information to the /dev/random driver
    
    commit b04b3156a20d395a7faa8eed98698d1e17a36000 upstream.
    
    Send the USB device's serial, product, and manufacturer strings to the
    /dev/random driver to help seed its pools.
    
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Acked-by: Greg KH <greg@kroah.com>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dfa1451f56ef326cc8a698134198d4b97a43093f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 4 11:16:01 2012 -0400

    random: create add_device_randomness() interface
    
    commit a2080a67abe9e314f9e9c2cc3a4a176e8a8f8793 upstream.
    
    Add a new interface, add_device_randomness() for adding data to the
    random pool that is likely to differ between two devices (or possibly
    even per boot).  This would be things like MAC addresses or serial
    numbers, or the read-out of the RTC. This does *not* add any actual
    entropy to the pool, but it initializes the pool to different values
    for devices that might otherwise be identical and have very little
    entropy available to them (particularly common in the embedded world).
    
    [ Modified by tytso to mix in a timestamp, since there may be some
      variability caused by the time needed to detect/configure the hardware
      in question. ]
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5850d859a076ed117ad3c3c3f4efef03fb034168
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jul 4 10:38:30 2012 -0400

    random: use lockless techniques in the interrupt path
    
    commit 902c098a3663de3fa18639efbb71b6080f0bcd3c upstream.
    
    The real-time Linux folks don't like add_interrupt_randomness() taking
    a spinlock since it is called in the low-level interrupt routine.
    This also allows us to reduce the overhead in the fast path, for the
    random driver, which is the interrupt collection path.
    
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3041b916a8c4b444b275c7df8a5a03eb61a007bb
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Mon Jul 2 07:52:16 2012 -0400

    random: make 'add_interrupt_randomness()' do something sane
    
    commit 775f4b297b780601e61787b766f306ed3e1d23eb upstream.
    
    We've been moving away from add_interrupt_randomness() for various
    reasons: it's too expensive to do on every interrupt, and flooding the
    CPU with interrupts could theoretically cause bogus floods of entropy
    from a somewhat externally controllable source.
    
    This solves both problems by limiting the actual randomness addition
    to just once a second or after 64 interrupts, whicever comes first.
    During that time, the interrupt cycle data is buffered up in a per-cpu
    pool.  Also, we make sure the the nonblocking pool used by urandom is
    initialized before we start feeding the normal input pool.  This
    assures that /dev/urandom is returning unpredictable data as soon as
    possible.
    
    (Based on an original patch by Linus, but significantly modified by
    tytso.)
    
    Tested-by: Eric Wustrow <ewust@umich.edu>
    Reported-by: Eric Wustrow <ewust@umich.edu>
    Reported-by: Nadia Heninger <nadiah@cs.ucsd.edu>
    Reported-by: Zakir Durumeric <zakir@umich.edu>
    Reported-by: J. Alex Halderman <jhalderm@umich.edu>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit afcbdbdebc0a84e8a1495487e1736345122b3fba
Author: Seth Forshee <seth.forshee@canonical.com>
Date:   Tue Jul 24 23:54:11 2012 -0700

    Input: synaptics - handle out of bounds values from the hardware
    
    commit c0394506e69b37c47d391c2a7bbea3ea236d8ec8 upstream.
    
    The touchpad on the Acer Aspire One D250 will report out of range values
    in the extreme lower portion of the touchpad. These appear as abrupt
    changes in the values reported by the hardware from very low values to
    very high values, which can cause unexpected vertical jumps in the
    position of the mouse pointer.
    
    What seems to be happening is that the value is wrapping to a two's
    compliment negative value of higher resolution than the 13-bit value
    reported by the hardware, with the high-order bits being truncated. This
    patch adds handling for these values by converting them to the
    appropriate negative values.
    
    The only tricky part about this is deciding when to treat a number as
    negative. It stands to reason that if out of range values can be
    reported on the low end then it could also happen on the high end, so
    not all out of range values should be treated as negative. The approach
    taken here is to split the difference between the maximum legitimate
    value for the axis and the maximum possible value that the hardware can
    report, treating values greater than this number as negative and all
    other values as positive. This can be tweaked later if hardware is found
    that operates outside of these parameters.
    
    BugLink: http://bugs.launchpad.net/bugs/1001251
    Signed-off-by: Seth Forshee <seth.forshee@canonical.com>
    Reviewed-by: Daniel Kurtz <djkurtz@chromium.org>
    Signed-off-by: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b004b02f82b8b8ec02d223610b9769d92fffbc64
Author: H. Peter Anvin <hpa@linux.intel.com>
Date:   Wed Aug 1 15:59:58 2012 -0700

    x86-64, kcmp: The kcmp system call can be common
    
    commit eaf4ce6c5fed6b4c55f7efcd5fc3477435cab5e9 upstream.
    
    We already use the same system call handler for i386 and x86-64, there
    is absolutely no reason x32 can't use the same system call, too.
    
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>
    Cc: H.J. Lu <hjl.tools@gmail.com>
    Cc: Cyrill Gorcunov <gorcunov@openvz.org>
    Link: http://lkml.kernel.org/n/tip-vwzk3qbcr3yjyxjg2j38vgy9@git.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7eb54cf0b55d2160064a28a3fb929ddffed8b324
Author: Alan Cox <alan@linux.intel.com>
Date:   Wed Jul 25 16:28:19 2012 +0100

    x86, nops: Missing break resulting in incorrect selection on Intel
    
    commit d6250a3f12edb3a86db9598ffeca3de8b4a219e9 upstream.
    
    The Intel case falls through into the generic case which then changes
    the values.  For cases like the P6 it doesn't do the right thing so
    this seems to be a screwup.
    
    Signed-off-by: Alan Cox <alan@linux.intel.com>
    Link: http://lkml.kernel.org/n/tip-lww2uirad4skzjlmrm0vru8o@git.kernel.org
    Signed-off-by: H. Peter Anvin <hpa@zytor.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a0300e970dfc2f70b161106e3fe3db1edb5dea03
Author: Stanislaw Gruszka <sgruszka@redhat.com>
Date:   Tue Jul 24 08:35:39 2012 +0200

    wireless: reg: restore previous behaviour of chan->max_power calculations
    
    commit 5e31fc0815a4e2c72b1b495fe7a0d8f9bfb9e4b4 upstream.
    
    commit eccc068e8e84c8fe997115629925e0422a98e4de
    Author: Hong Wu <Hong.Wu@dspg.com>
    Date:   Wed Jan 11 20:33:39 2012 +0200
    
        wireless: Save original maximum regulatory transmission power for the calucation of the local maximum transmit pow
    
    changed the way we calculate chan->max_power as min(chan->max_power,
    chan->max_reg_power). That broke rt2x00 (and perhaps some other
    drivers) that do not set chan->max_power. It is not so easy to fix this
    problem correctly in rt2x00.
    
    According to commit eccc068e8 changelog, change claim only to save
    maximum regulatory power - changing setting of chan->max_power was side
    effect. This patch restore previous calculations of chan->max_power and
    do not touch chan->max_reg_power.
    
    Signed-off-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Acked-by: Luis R. Rodriguez <mcgrof@qca.qualcomm.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fb942b111cd680bf92bb3a60d35337d170902b09
Author: Mohammed Shafi Shajakhan <mohammed@qca.qualcomm.com>
Date:   Thu Aug 2 11:58:50 2012 +0530

    ath9k: Add PID/VID support for AR1111
    
    commit d4e5979c0da95791aa717c18e162540c7a596360 upstream.
    
    AR1111 is same as AR9485. The h/w
    difference between them is quite insignificant,
    Felix suggests only very few baseband features
    may not be available in AR1111. The h/w code for
    AR9485 is already present, so AR1111 should
    work fine with the addition of its PID/VID.
    
    Reported-by: Tim Bentley <Tim.Bentley@Gmail.com>
    Cc: Felix Bitterli <felixb@qca.qualcomm.com>
    Signed-off-by: Mohammed Shafi Shajakhan <mohammed@qca.qualcomm.com>
    Tested-by: Tim Bentley <Tim.Bentley@Gmail.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a43de96a1a79bc4eb797a57834fa6e5fc439ecfe
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Wed Aug 1 21:03:21 2012 +0200

    mac80211: cancel mesh path timer
    
    commit dd4c9260e7f23f2e951cbfb2726e468c6d30306c upstream.
    
    The mesh path timer needs to be canceled when
    leaving the mesh as otherwise it could fire
    after the interface has been removed already.
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ea02ff4c40e462d62b9f6d2985bcf290b5148db9
Author: Karsten Keil <keil@b1-systems.de>
Date:   Sat Aug 4 00:14:25 2012 +0000

    mISDN: Bugfix for layer2 fixed TEI mode
    
    commit 25099335944a23db75d4916644122c746684e093 upstream.
    
    If a fixed TEI is used, the initial state of the layer 2 statmachine need to be
    4 (TEI assigned). This was true only for Point to Point connections, but not
    for the other fixed TEIs. It was not found before, because usually only the
    TEI 0 is used as fixed TEI for PtP mode, but if you try X31 packet mode
    connections with SAPI 16, TEI 1, it did fail.
    
    Signed-off-by: Karsten Keil <keil@b1-systems.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a555658b20781b8aff35ce660a4618a30b5f7120
Author: Feng Tang <feng.tang@intel.com>
Date:   Tue Jul 31 12:44:43 2012 +0800

    ACPI processor: Fix tick_broadcast_mask online/offline regression
    
    commit b7db60f45d74497c723dc7ae1370cf0b37dfb0d8 upstream.
    
    In commit 99b725084 "ACPI processor hotplug: Delay acpi_processor_start()
    call for hotplugged cores", acpi_processor_hotplug(pr) was wrongly replaced
    by acpi_processor_cst_has_changed() inside the acpi_cpu_soft_notify(). This
    patch will restore it back, fixing the tick_broadcast_mask regression:
            https://lkml.org/lkml/2012/7/30/169
    
    Signed-off-by: Feng Tang <feng.tang@intel.com>
    Cc: Thomas Renninger <trenn@suse.de>
    Reviewed-by: Rafael J. Wysocki <rjw@sisk.pl>
    Reviewed-by: Deepthi Dharwar <deepthi@linux.vnet.ibm.com>
    Signed-off-by: Len Brown <len.brown@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b7f247a15d46221aa53c5066524dd475ea7ef9da
Author: Boaz Harrosh <bharrosh@panasas.com>
Date:   Wed Aug 1 17:48:36 2012 +0300

    ore: Fix out-of-bounds access in _ios_obj()
    
    commit 9e62bb4458ad2cf28bd701aa5fab380b846db326 upstream.
    
    _ios_obj() is accessed by group_index not device_table index.
    
    The oc->comps array is only a group_full of devices at a time
    it is not like ore_comp_dev() which is indexed by a global
    device_table index.
    
    This did not BUG until now because exofs only uses a single
    COMP for all devices. But with other FSs like PanFS this is
    not true.
    
    This bug was only in the write_path, all other users were
    using it correctly
    
    [This is a bug since 3.2 Kernel]
    
    Signed-off-by: Boaz Harrosh <bharrosh@panasas.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit daa0139a3430417f55160daf93af4537cdc0e126
Author: Paul Mundt <lethal@linux-sh.org>
Date:   Tue Jul 24 13:15:54 2012 +0900

    sh: Fix up recursive fault in oops with unset TTB.
    
    commit 90eed7d87b748f9c0d11b9bad64a4c41e31b78c4 upstream.
    
    Presently the oops code looks for the pgd either from the mm context or
    the cached TTB value. There are presently cases where the TTB can be
    unset or otherwise cleared by hardware, which we weren't handling,
    resulting in recursive faults on the NULL pgd. In these cases we can
    simply reload from swapper_pg_dir and continue on as normal.
    
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bd60cd238b0b3056cc610fad8f52fa5f0e6bdb38
Author: Olof Johansson <olof@lixom.net>
Date:   Wed Aug 1 12:17:27 2012 +0200

    block: uninitialized ioc->nr_tasks triggers WARN_ON
    
    commit 4638a83e8615de9c16c39dfed234951d0f468cf1 upstream.
    
    Hi,
    
    I'm using the old-fashioned 'dump' backup tool, and I noticed that it spews the
    below warning as of 3.5-rc1 and later (3.4 is fine):
    
    [   10.886893] ------------[ cut here ]------------
    [   10.886904] WARNING: at include/linux/iocontext.h:140 copy_process+0x1488/0x1560()
    [   10.886905] Hardware name: Bochs
    [   10.886906] Modules linked in:
    [   10.886908] Pid: 2430, comm: dump Not tainted 3.5.0-rc7+ #27
    [   10.886908] Call Trace:
    [   10.886911]  [<ffffffff8107ce8a>] warn_slowpath_common+0x7a/0xb0
    [   10.886912]  [<ffffffff8107ced5>] warn_slowpath_null+0x15/0x20
    [   10.886913]  [<ffffffff8107c088>] copy_process+0x1488/0x1560
    [   10.886914]  [<ffffffff8107c244>] do_fork+0xb4/0x340
    [   10.886918]  [<ffffffff8108effa>] ? recalc_sigpending+0x1a/0x50
    [   10.886919]  [<ffffffff8108f6b2>] ? __set_task_blocked+0x32/0x80
    [   10.886920]  [<ffffffff81091afa>] ? __set_current_blocked+0x3a/0x60
    [   10.886923]  [<ffffffff81051db3>] sys_clone+0x23/0x30
    [   10.886925]  [<ffffffff8179bd73>] stub_clone+0x13/0x20
    [   10.886927]  [<ffffffff8179baa2>] ? system_call_fastpath+0x16/0x1b
    [   10.886928] ---[ end trace 32a14af7ee6a590b ]---
    
    Reproducing is easy, I can hit it on a KVM system with a very basic
    config (x86_64 make defconfig + enable the drivers needed). To hit it,
    just install dump (on debian/ubuntu, not sure what the package might be
    called on Fedora), and:
    
    dump -o -f /tmp/foo /
    
    You'll see the warning in dmesg once it forks off the I/O process and
    starts dumping filesystem contents.
    
    I bisected it down to the following commit:
    
    commit f6e8d01bee036460e03bd4f6a79d014f98ba712e
    Author: Tejun Heo <tj@kernel.org>
    Date:   Mon Mar 5 13:15:26 2012 -0800
    
        block: add io_context->active_ref
    
        Currently ioc->nr_tasks is used to decide two things - whether an ioc
        is done issuing IOs and whether it's shared by multiple tasks.  This
        patch separate out the first into ioc->active_ref, which is acquired
        and released using {get|put}_io_context_active() respectively.
    
        This will be used to associate bio's with a given task.  This patch
        doesn't introduce any visible behavior change.
    
        Signed-off-by: Tejun Heo <tj@kernel.org>
        Cc: Vivek Goyal <vgoyal@redhat.com>
        Signed-off-by: Jens Axboe <axboe@kernel.dk>
    
    It seems like the init of ioc->nr_tasks was removed in that patch,
    so it starts out at 0 instead of 1.
    
    Tejun, is the right thing here to add back the init, or should something else
    be done?
    
    The below patch removes the warning, but I haven't done any more extensive
    testing on it.
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0d59ffaa10a3fec0b7209e4665fbccf4bab0bd6a
Author: Alexander Holler <holler@ahsoftware.de>
Date:   Sat Apr 21 00:11:07 2012 +0200

    video/smscufx: fix line counting in fb_write
    
    commit 2fe2d9f47cfe1a3e66e7d087368b3d7155b04c15 upstream.
    
    Line 0 and 1 were both written to line 0 (on the display) and all subsequent
    lines had an offset of -1. The result was that the last line on the display
    was never overwritten by writes to /dev/fbN.
    
    The origin of this bug seems to have been udlfb.
    
    Signed-off-by: Alexander Holler <holler@ahsoftware.de>
    Signed-off-by: Florian Tobias Schandinat <FlorianSchandinat@gmx.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8f605e2a8b7910bfe810c05d25c7d6a45b708dc7
Author: NeilBrown <neilb@suse.de>
Date:   Tue Jul 31 10:05:34 2012 +1000

    md/raid1: don't abort a resync on the first badblock.
    
    commit b7219ccb33aa0df9949a60c68b5e9f712615e56f upstream.
    
    If a resync of a RAID1 array with 2 devices finds a known bad block
    one device it will neither read from, or write to, that device for
    this block offset.
    So there will be one read_target (The other device) and zero write
    targets.
    This condition causes md/raid1 to abort the resync assuming that it
    has finished - without known bad blocks this would be true.
    
    When there are no write targets because of the presence of bad blocks
    we should only skip over the area covered by the bad block.
    RAID10 already gets this right, raid1 doesn't.  Or didn't.
    
    As this can cause a 'sync' to abort early and appear to have succeeded
    it could lead to some data corruption, so it suitable for -stable.
    
    Reported-by: Alexander Lyakas <alex.bolshoy@gmail.com>
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 10c3d285453e077745a0d8a581201fc485712f82
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Tue Jul 31 16:45:52 2012 -0700

    mm: mmu_notifier: fix freed page still mapped in secondary MMU
    
    commit 3ad3d901bbcfb15a5e4690e55350db0899095a68 upstream.
    
    mmu_notifier_release() is called when the process is exiting.  It will
    delete all the mmu notifiers.  But at this time the page belonging to the
    process is still present in page tables and is present on the LRU list, so
    this race will happen:
    
          CPU 0                 CPU 1
    mmu_notifier_release:    try_to_unmap:
       hlist_del_init_rcu(&mn->hlist);
                                ptep_clear_flush_notify:
                                      mmu nofifler not found
                                free page  !!!!!!
                                /*
                                 * At the point, the page has been
                                 * freed, but it is still mapped in
                                 * the secondary MMU.
                                 */
    
      mn->ops->release(mn, mm);
    
    Then the box is not stable and sometimes we can get this bug:
    
    [  738.075923] BUG: Bad page state in process migrate-perf  pfn:03bec
    [  738.075931] page:ffffea00000efb00 count:0 mapcount:0 mapping:          (null) index:0x8076
    [  738.075936] page flags: 0x20000000000014(referenced|dirty)
    
    The same issue is present in mmu_notifier_unregister().
    
    We can call ->release before deleting the notifier to ensure the page has
    been unmapped from the secondary MMU before it is freed.
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9d8d64b7800fbadd8415622fcb3014a065ad14a4
Author: Xishi Qiu <qiuxishi@huawei.com>
Date:   Tue Jul 31 16:43:19 2012 -0700

    mm: setup pageblock_order before it's used by sparsemem
    
    commit ca57df79d4f64e1a4886606af4289d40636189c5 upstream.
    
    On architectures with CONFIG_HUGETLB_PAGE_SIZE_VARIABLE set, such as
    Itanium, pageblock_order is a variable with default value of 0.  It's set
    to the right value by set_pageblock_order() in function
    free_area_init_core().
    
    But pageblock_order may be used by sparse_init() before free_area_init_core()
    is called along path:
    sparse_init()
        ->sparse_early_usemaps_alloc_node()
            ->usemap_size()
                ->SECTION_BLOCKFLAGS_BITS
                    ->((1UL << (PFN_SECTION_SHIFT - pageblock_order)) *
    NR_PAGEBLOCK_BITS)
    
    The uninitialized pageblock_size will cause memory wasting because
    usemap_size() returns a much bigger value then it's really needed.
    
    For example, on an Itanium platform,
    sparse_init() pageblock_order=0 usemap_size=24576
    free_area_init_core() before pageblock_order=0, usemap_size=24576
    free_area_init_core() after pageblock_order=12, usemap_size=8
    
    That means 24K memory has been wasted for each section, so fix it by calling
    set_pageblock_order() from sparse_init().
    
    Signed-off-by: Xishi Qiu <qiuxishi@huawei.com>
    Signed-off-by: Jiang Liu <liuj97@gmail.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Keping Chen <chenkeping@huawei.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 48fe8dbe398d9e05937b23e9a7f6f1696b9d1834
Author: David Henningsson <david.henningsson@canonical.com>
Date:   Wed Aug 8 08:43:37 2012 +0200

    ALSA: hda - Fix double quirk for Quanta FL1 / Lenovo Ideapad
    
    commit 012e7eb1e501d0120e0383b81477f63091f5e365 upstream.
    
    The same ID is twice in the quirk table, so the second one is not used.
    
    Signed-off-by: David Henningsson <david.henningsson@canonical.com>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a469d83b2d27a5cd73ee71877719e2afd0bba4c0
Author: David Henningsson <david.henningsson@canonical.com>
Date:   Tue Aug 7 14:03:29 2012 +0200

    ALSA: hda - remove quirk for Dell Vostro 1015
    
    commit e9fc83cb2e5877801a255a37ddbc5be996ea8046 upstream.
    
    This computer is confirmed working with model=auto on kernel 3.2.
    Also, parsing fails with hda-emu with the current model.
    
    Signed-off-by: David Henningsson <david.henningsson@canonical.com>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e9b411f53f82dbdcc7e2d828b54bff829764dc4c
Author: Felix Kaechele <felix@fetzig.org>
Date:   Mon Aug 6 23:02:01 2012 +0200

    ALSA: hda - add dock support for Thinkpad X230
    
    commit c8415a48fcb7a29889f4405d38c57db351e4b50a upstream.
    
    As with the ThinkPad Models X230 Tablet and T530 the X230 needs a qurik to
    correctly set up the pins for the dock port.
    
    Signed-off-by: Felix Kaechele <felix@fetzig.org>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 870f98b4dd034f7e367fdeb88a377ed73f2e0f16
Author: Philipp A. Mohrenweiser <phiamo@googlemail.com>
Date:   Mon Aug 6 13:14:18 2012 +0200

    ALSA: hda - add dock support for Thinkpad T430s
    
    commit 4407be6ba217514b1bc01488f8b56467d309e416 upstream.
    
    Add a model/fixup string "lenovo-dock", for Thinkpad T430s, to allow
    sound in docking station.
    
    Tested on Lenovo T430s with ThinkPad Mini Dock Plus Series 3
    
    Signed-off-by: Philipp A. Mohrenweiser <phiamo@googlemail.com>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 276bbdb82abdb65769e152b7a0282ef2e0b4b5b6
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Mon Jul 30 19:42:10 2012 +0100

    ARM: Fix undefined instruction exception handling
    
    commit 15ac49b65024f55c4371a53214879a9c77c4fbf9 upstream.
    
    While trying to get a v3.5 kernel booted on the cubox, I noticed that
    VFP does not work correctly with VFP bounce handling.  This is because
    of the confusion over 16-bit vs 32-bit instructions, and where PC is
    supposed to point to.
    
    The rule is that FP handlers are entered with regs->ARM_pc pointing at
    the _next_ instruction to be executed.  However, if the exception is
    not handled, regs->ARM_pc points at the faulting instruction.
    
    This is easy for ARM mode, because we know that the next instruction and
    previous instructions are separated by four bytes.  This is not true of
    Thumb2 though.
    
    Since all FP instructions are 32-bit in Thumb2, it makes things easy.
    We just need to select the appropriate adjustment.  Do this by moving
    the adjustment out of do_undefinstr() into the assembly code, as only
    the assembly code knows whether it's dealing with a 32-bit or 16-bit
    instruction.
    
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 909397450a68f80282bd30cbd25efb5dba955531
Author: Javier Martinez Canillas <javier@dowhile0.org>
Date:   Sat Jul 28 15:19:55 2012 +0100

    ARM: 7480/1: only call smp_send_stop() on SMP
    
    commit c5dff4ffd327088d85035bec535b7d0c9ea03151 upstream.
    
    On reboot or poweroff (machine_shutdown()) a call to smp_send_stop() is
    made (to stop the others CPU's) when CONFIG_SMP=y.
    
    arch/arm/kernel/process.c:
    
    void machine_shutdown(void)
    {
     #ifdef CONFIG_SMP
           smp_send_stop();
     #endif
    }
    
    smp_send_stop() calls the function pointer smp_cross_call(), which is set
    on the smp_init_cpus() function for OMAP processors.
    
    arch/arm/mach-omap2/omap-smp.c:
    
    void __init smp_init_cpus(void)
    {
    ...
            set_smp_cross_call(gic_raise_softirq);
    ...
    }
    
    But the ARM setup_arch() function only calls smp_init_cpus()
    if CONFIG_SMP=y && is_smp().
    
    arm/kernel/setup.c:
    
    void __init setup_arch(char **cmdline_p)
    {
    ...
     #ifdef CONFIG_SMP
            if (is_smp())
                    smp_init_cpus();
     #endif
    ...
    }
    
    Newer OMAP CPU's are SMP machines so omap2plus_defconfig sets
    CONFIG_SMP=y. Unfortunately on an OMAP UP machine is_smp()
    returns false and smp_init_cpus() is never called and the
    smp_cross_call() function remains NULL.
    
    If the machine is rebooted or powered off, smp_send_stop() will
    be called (since CONFIG_SMP=y) leading to the following error:
    
    [   42.815551] Restarting system.
    [   42.819030] Unable to handle kernel NULL pointer dereference at virtual address 00000000
    [   42.827667] pgd = d7a74000
    [   42.830566] [00000000] *pgd=96ce7831, *pte=00000000, *ppte=00000000
    [   42.837249] Internal error: Oops: 80000007 [#1] SMP ARM
    [   42.842773] Modules linked in:
    [   42.846008] CPU: 0    Not tainted  (3.5.0-rc3-next-20120622-00002-g62e87ba-dirty #44)
    [   42.854278] PC is at 0x0
    [   42.856994] LR is at smp_send_stop+0x4c/0xe4
    [   42.861511] pc : [<00000000>]    lr : [<c00183a4>]    psr: 60000013
    [   42.861511] sp : d6c85e70  ip : 00000000  fp : 00000000
    [   42.873626] r10: 00000000  r9 : d6c84000  r8 : 00000002
    [   42.879150] r7 : c07235a0  r6 : c06dd2d0  r5 : 000f4241  r4 : d6c85e74
    [   42.886047] r3 : 00000000  r2 : 00000000  r1 : 00000006  r0 : d6c85e74
    [   42.892944] Flags: nZCv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment user
    [   42.900482] Control: 10c5387d  Table: 97a74019  DAC: 00000015
    [   42.906555] Process reboot (pid: 1166, stack limit = 0xd6c842f8)
    [   42.912902] Stack: (0xd6c85e70 to 0xd6c86000)
    [   42.917510] 5e60:                                     c07235a0 00000000 00000000 d6c84000
    [   42.926177] 5e80: 01234567 c00143d0 4321fedc c00511bc d6c85ebc 00000168 00000460 00000000
    [   42.934814] 5ea0: c1017950 a0000013 c1017900 d8014390 d7ec3858 c0498e48 c1017950 00000000
    [   42.943481] 5ec0: d6ddde10 d6c85f78 00000003 00000000 d6ddde10 d6c84000 00000000 00000000
    [   42.952117] 5ee0: 00000002 00000000 00000000 c0088c88 00000002 00000000 00000000 c00f4b90
    [   42.960784] 5f00: 00000000 d6c85ebc d8014390 d7e311c8 60000013 00000103 00000002 d6c84000
    [   42.969421] 5f20: c00f3274 d6e00a00 00000001 60000013 d6c84000 00000000 00000000 c00895d4
    [   42.978057] 5f40: 00000002 d8007c80 d781f000 c00f6150 d8010cc0 c00f3274 d781f000 d6c84000
    [   42.986694] 5f60: c0013020 d6e00a00 00000001 20000010 0001257c ef000000 00000000 c00895d4
    [   42.995361] 5f80: 00000002 00000001 00000003 00000000 00000001 00000003 00000000 00000058
    [   43.003997] 5fa0: c00130c8 c0012f00 00000001 00000003 fee1dead 28121969 01234567 00000002
    [   43.012634] 5fc0: 00000001 00000003 00000000 00000058 00012584 0001257c 00000001 00000000
    [   43.021270] 5fe0: 000124bc bec5cc6c 00008f9c 4a2f7c40 20000010 fee1dead 00000000 00000000
    [   43.029968] [<c00183a4>] (smp_send_stop+0x4c/0xe4) from [<c00143d0>] (machine_restart+0xc/0x4c)
    [   43.039154] [<c00143d0>] (machine_restart+0xc/0x4c) from [<c00511bc>] (sys_reboot+0x144/0x1f0)
    [   43.048278] [<c00511bc>] (sys_reboot+0x144/0x1f0) from [<c0012f00>] (ret_fast_syscall+0x0/0x3c)
    [   43.057464] Code: bad PC value
    [   43.060760] ---[ end trace c3988d1dd0b8f0fb ]---
    
    Add a check so smp_cross_call() is only called when there is more than one CPU on-line.
    
    Signed-off-by: Javier Martinez Canillas <javier at dowhile0.org>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 459a4321c2a29339a00036f2dd3962c262f72242
Author: Will Deacon <will@kernel.org>
Date:   Mon Jul 23 14:18:13 2012 +0100

    ARM: 7479/1: mm: avoid NULL dereference when flushing gate_vma with VIVT caches
    
    commit b74253f78400f9a4b42da84bb1de7540b88ce7c4 upstream.
    
    The vivt_flush_cache_{range,page} functions check that the mm_struct
    of the VMA being flushed has been active on the current CPU before
    performing the cache maintenance.
    
    The gate_vma has a NULL mm_struct pointer and, as such, will cause a
    kernel fault if we try to flush it with the above operations. This
    happens during ELF core dumps, which include the gate_vma as it may be
    useful for debugging purposes.
    
    This patch adds checks to the VIVT cache flushing functions so that VMAs
    with a NULL mm_struct are flushed unconditionally (the vectors page may
    be dirty if we use it to store the current TLS pointer).
    
    Reported-by: Gilles Chanteperdrix <gilles.chanteperdrix@xenomai.org>
    Tested-by: Uros Bizjak <ubizjak@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 14687eb3f69a916dd095f7b7e8611666ec58b55e
Author: Will Deacon <will@kernel.org>
Date:   Fri Jul 20 18:24:55 2012 +0100

    ARM: 7478/1: errata: extend workaround for erratum #720789
    
    commit 5a783cbc48367cfc7b65afc75430953dfe60098f upstream.
    
    Commit cdf357f1 ("ARM: 6299/1: errata: TLBIASIDIS and TLBIMVAIS
    operations can broadcast a faulty ASID") replaced by-ASID TLB flushing
    operations with all-ASID variants to workaround A9 erratum #720789.
    
    This patch extends the workaround to include the tlb_range operations,
    which were overlooked by the original patch.
    
    Tested-by: Steve Capper <steve.capper@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2a105235094eeae46dc0d2386600f4a481a05d84
Author: Colin Cross <ccross@android.com>
Date:   Fri Jul 20 02:03:42 2012 +0100

    ARM: 7477/1: vfp: Always save VFP state in vfp_pm_suspend on UP
    
    commit 24b35521b8ddf088531258f06f681bb7b227bf47 upstream.
    
    vfp_pm_suspend should save the VFP state in suspend after
    any lazy context switch.  If it only saves when the VFP is enabled,
    the state can get lost when, on a UP system:
      Thread 1 uses the VFP
      Context switch occurs to thread 2, VFP is disabled but the
         VFP context is not saved
      Thread 2 initiates suspend
      vfp_pm_suspend is called with the VFP disabled, and the unsaved
         VFP context of Thread 1 in the registers
    
    Modify vfp_pm_suspend to save the VFP context whenever
    vfp_current_hw_state is not NULL.
    
    Includes a fix from Ido Yariv <ido@wizery.com>, who pointed out that on
    SMP systems, the state pointer can be pointing to a freed task struct if
    a task exited on another cpu, fixed by using #ifndef CONFIG_SMP in the
    new if clause.
    
    Signed-off-by: Colin Cross <ccross@android.com>
    Cc: Barry Song <bs14@csr.com>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Ido Yariv <ido@wizery.com>
    Cc: Daniel Drake <dsd@laptop.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fae218a1ff5ebe36893dcc89935df3a9c2681022
Author: Colin Cross <ccross@android.com>
Date:   Fri Jul 20 02:03:43 2012 +0100

    ARM: 7476/1: vfp: only clear vfp state for current cpu in vfp_pm_suspend
    
    commit a84b895a2348f0dbff31b71ddf954f70a6cde368 upstream.
    
    vfp_pm_suspend runs on each cpu, only clear the hardware state
    pointer for the current cpu.  Prevents a possible crash if one
    cpu clears the hw state pointer when another cpu has already
    checked if it is valid.
    
    Signed-off-by: Colin Cross <ccross@android.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 99e2ed123b717b78121cfdf930ed41bf5922fdfc
Author: Shawn Guo <shawn.guo@linaro.org>
Date:   Fri Jul 13 08:19:34 2012 +0100

    ARM: 7466/1: disable interrupt before spinning endlessly
    
    commit 98bd8b96b26db3399a48202318dca4aaa2515355 upstream.
    
    The CPU will endlessly spin at the end of machine_halt and
    machine_restart calls.  However, this will lead to a soft lockup
    warning after about 20 seconds, if CONFIG_LOCKUP_DETECTOR is enabled,
    as system timer is still alive.
    
    Disable interrupt before going to spin endlessly, so that the lockup
    warning will never be seen.
    
    Reported-by: Marek Vasut <marex@denx.de>
    Signed-off-by: Shawn Guo <shawn.guo@linaro.org>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5f5af00012ebd50525e8454cc0d35dabd0a57a89
Author: Joonsoo Kim <js1304@gmail.com>
Date:   Mon Jul 30 14:39:04 2012 -0700

    mm: fix wrong argument of migrate_huge_pages() in soft_offline_huge_page()
    
    commit dc32f63453f56d07a1073a697dcd843dd3098c09 upstream.
    
    Commit a6bc32b89922 ("mm: compaction: introduce sync-light migration for
    use by compaction") changed the declaration of migrate_pages() and
    migrate_huge_pages().
    
    But it missed changing the argument of migrate_huge_pages() in
    soft_offline_huge_page().  In this case, we should call
    migrate_huge_pages() with MIGRATE_SYNC.
    
    Additionally, there is a mismatch between type the of argument and the
    function declaration for migrate_pages().
    
    Signed-off-by: Joonsoo Kim <js1304@gmail.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 952990c86b03578b9d1945307ebce6f116e89574
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jul 31 16:45:59 2012 -0700

    memcg: further prevent OOM with too many dirty pages
    
    commit c3b94f44fcb0725471ecebb701c077a0ed67bd07 upstream.
    
    The may_enter_fs test turns out to be too restrictive: though I saw no
    problem with it when testing on 3.5-rc6, it very soon OOMed when I tested
    on 3.5-rc6-mm1.  I don't know what the difference there is, perhaps I just
    slightly changed the way I started off the testing: dd if=/dev/zero
    of=/mnt/temp bs=1M count=1024; rm -f /mnt/temp; sync repeatedly, in 20M
    memory.limit_in_bytes cgroup to ext4 on USB stick.
    
    ext4 (and gfs2 and xfs) turn out to allocate new pages for writing with
    AOP_FLAG_NOFS: that seems a little worrying, and it's unclear to me why
    the transaction needs to be started even before allocating pagecache
    memory.  But it may not be worth worrying about these days: if direct
    reclaim avoids FS writeback, does __GFP_FS now mean anything?
    
    Anyway, we insisted on the may_enter_fs test to avoid hangs with the loop
    device; but since that also masks off __GFP_IO, we can test for __GFP_IO
    directly, ignoring may_enter_fs and __GFP_FS.
    
    But even so, the test still OOMs sometimes: when originally testing on
    3.5-rc6, it OOMed about one time in five or ten; when testing just now on
    3.5-rc6-mm1, it OOMed on the first iteration.
    
    This residual problem comes from an accumulation of pages under ordinary
    writeback, not marked PageReclaim, so rightly not causing the memcg check
    to wait on their writeback: these too can prevent shrink_page_list() from
    freeing any pages, so many times that memcg reclaim fails and OOMs.
    
    Deal with these in the same way as direct reclaim now deals with dirty FS
    pages: mark them PageReclaim.  It is appropriate to rotate these to tail
    of list when writepage completes, but more importantly, the PageReclaim
    flag makes memcg reclaim wait on them if encountered again.  Increment
    NR_VMSCAN_IMMEDIATE?  That's arguable: I chose not.
    
    Setting PageReclaim here may occasionally race with end_page_writeback()
    clearing it: lru_deactivate_fn() already faced the same race, and
    correctly concluded that the window is small and the issue non-critical.
    
    With these changes, the test runs indefinitely without OOMing on ext4,
    ext3 and ext2: I'll move on to test with other filesystems later.
    
    Trivia: invert conditions for a clearer block without an else, and goto
    keep_locked to do the unlock_page.
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujtisu.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Ying Han <yinghan@google.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Fengguang Wu <fengguang.wu@intel.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 04051e737f8ad4e8d22a7f79b071bc44af9e991b
Author: Michal Hocko <mhocko@suse.cz>
Date:   Tue Jul 31 16:45:55 2012 -0700

    memcg: prevent OOM with too many dirty pages
    
    commit e62e384e9da8d9a0c599795464a7e76fd490931c upstream.
    
    The current implementation of dirty pages throttling is not memcg aware
    which makes it easy to have memcg LRUs full of dirty pages.  Without
    throttling, these LRUs can be scanned faster than the rate of writeback,
    leading to memcg OOM conditions when the hard limit is small.
    
    This patch fixes the problem by throttling the allocating process
    (possibly a writer) during the hard limit reclaim by waiting on
    PageReclaim pages.  We are waiting only for PageReclaim pages because
    those are the pages that made one full round over LRU and that means that
    the writeback is much slower than scanning.
    
    The solution is far from being ideal - long term solution is memcg aware
    dirty throttling - but it is meant to be a band aid until we have a real
    fix.  We are seeing this happening during nightly backups which are placed
    into containers to prevent from eviction of the real working set.
    
    The change affects only memcg reclaim and only when we encounter
    PageReclaim pages which is a signal that the reclaim doesn't catch up on
    with the writers so somebody should be throttled.  This could be
    potentially unfair because it could be somebody else from the group who
    gets throttled on behalf of the writer but as writers need to allocate as
    well and they allocate in higher rate the probability that only innocent
    processes would be penalized is not that high.
    
    I have tested this change by a simple dd copying /dev/zero to tmpfs or
    ext3 running under small memcg (1G copy under 5M, 60M, 300M and 2G
    containers) and dd got killed by OOM killer every time.  With the patch I
    could run the dd with the same size under 5M controller without any OOM.
    The issue is more visible with slower devices for output.
    
    * With the patch
    ================
    * tmpfs size=2G
    ---------------
    $ vim cgroup_cache_oom_test.sh
    $ ./cgroup_cache_oom_test.sh 5M
    using Limit 5M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 30.4049 s, 34.5 MB/s
    $ ./cgroup_cache_oom_test.sh 60M
    using Limit 60M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 31.4561 s, 33.3 MB/s
    $ ./cgroup_cache_oom_test.sh 300M
    using Limit 300M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 20.4618 s, 51.2 MB/s
    $ ./cgroup_cache_oom_test.sh 2G
    using Limit 2G for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 1.42172 s, 738 MB/s
    
    * ext3
    ------
    $ ./cgroup_cache_oom_test.sh 5M
    using Limit 5M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 27.9547 s, 37.5 MB/s
    $ ./cgroup_cache_oom_test.sh 60M
    using Limit 60M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 30.3221 s, 34.6 MB/s
    $ ./cgroup_cache_oom_test.sh 300M
    using Limit 300M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 24.5764 s, 42.7 MB/s
    $ ./cgroup_cache_oom_test.sh 2G
    using Limit 2G for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 3.35828 s, 312 MB/s
    
    * Without the patch
    ===================
    * tmpfs size=2G
    ---------------
    $ ./cgroup_cache_oom_test.sh 5M
    using Limit 5M for group
    ./cgroup_cache_oom_test.sh: line 46:  4668 Killed                  dd if=/dev/zero of=$OUT/zero bs=1M count=$count
    $ ./cgroup_cache_oom_test.sh 60M
    using Limit 60M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 25.4989 s, 41.1 MB/s
    $ ./cgroup_cache_oom_test.sh 300M
    using Limit 300M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 24.3928 s, 43.0 MB/s
    $ ./cgroup_cache_oom_test.sh 2G
    using Limit 2G for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 1.49797 s, 700 MB/s
    
    * ext3
    ------
    $ ./cgroup_cache_oom_test.sh 5M
    using Limit 5M for group
    ./cgroup_cache_oom_test.sh: line 46:  4689 Killed                  dd if=/dev/zero of=$OUT/zero bs=1M count=$count
    $ ./cgroup_cache_oom_test.sh 60M
    using Limit 60M for group
    ./cgroup_cache_oom_test.sh: line 46:  4692 Killed                  dd if=/dev/zero of=$OUT/zero bs=1M count=$count
    $ ./cgroup_cache_oom_test.sh 300M
    using Limit 300M for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 20.248 s, 51.8 MB/s
    $ ./cgroup_cache_oom_test.sh 2G
    using Limit 2G for group
    1000+0 records in
    1000+0 records out
    1048576000 bytes (1.0 GB) copied, 2.85201 s, 368 MB/s
    
    [akpm@linux-foundation.org: tweak changelog, reordered the test to optimize for CONFIG_CGROUP_MEM_RES_CTLR=n]
    [hughd@google.com: fix deadlock with loop driver]
    Reviewed-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujtisu.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Ying Han <yinghan@google.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3c39473e6302d7d468ac63af208dc8f8278b85b1
Author: Greg Pearson <greg.pearson@hp.com>
Date:   Mon Jul 30 14:39:05 2012 -0700

    pcdp: use early_ioremap/early_iounmap to access pcdp table
    
    commit 6c4088ac3a4d82779903433bcd5f048c58fb1aca upstream.
    
    efi_setup_pcdp_console() is called during boot to parse the HCDP/PCDP
    EFI system table and setup an early console for printk output.  The
    routine uses ioremap/iounmap to setup access to the HCDP/PCDP table
    information.
    
    The call to ioremap is happening early in the boot process which leads
    to a panic on x86_64 systems:
    
        panic+0x01ca
        do_exit+0x043c
        oops_end+0x00a7
        no_context+0x0119
        __bad_area_nosemaphore+0x0138
        bad_area_nosemaphore+0x000e
        do_page_fault+0x0321
        page_fault+0x0020
        reserve_memtype+0x02a1
        __ioremap_caller+0x0123
        ioremap_nocache+0x0012
        efi_setup_pcdp_console+0x002b
        setup_arch+0x03a9
        start_kernel+0x00d4
        x86_64_start_reservations+0x012c
        x86_64_start_kernel+0x00fe
    
    This replaces the calls to ioremap/iounmap in efi_setup_pcdp_console()
    with calls to early_ioremap/early_iounmap which can be called during
    early boot.
    
    This patch was tested on an x86_64 prototype system which uses the
    HCDP/PCDP table for early console setup.
    
    Signed-off-by: Greg Pearson <greg.pearson@hp.com>
    Acked-by: Khalid Aziz <khalid.aziz@hp.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d3a162bc815145dfc6b06db301446be7edb7c067
Author: Lad, Prabhakar <prabhakar.lad@ti.com>
Date:   Fri Jun 22 06:19:28 2012 -0300

    media: videobuf-dma-contig: restore buffer mapping for uncached bufers
    
    commit 4099040eaaa4fe543c4e915b8cab51b1d843edee upstream.
    
    from commit a8f3c203e19b702fa5e8e83a9b6fb3c5a6d1cce4
    restore the mapping scheme for uncached buffers,
    which was changed in a common scheme for cached and uncached.
    This apparently was wrong, and was probably intended only for cached buffers.
    the fix fixes the crash observed while mapping uncached buffers.
    
    Signed-off-by: Lad, Prabhakar <prabhakar.lad@ti.com>
    Signed-off-by: Hadli, Manjunath <manjunath.hadli@ti.com>
    Acked-by: Federico Vaga <federico.vaga@gmail.com>
    Acked-by: Hans Verkuil <hans.verkuil@cisco.com>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e14498e734869324747c5c7f039549566885f76f
Author: Sylwester Nawrocki <s.nawrocki@samsung.com>
Date:   Tue Jul 24 12:12:07 2012 -0300

    media: m5mols: Correct reported ISO values
    
    commit 6126b912c84240692e26c1b820a7097610eddf34 upstream.
    
    The V4L2_CID_ISO_SENSITIVITY control menu values should be
    standard ISO values multiplied by 1000. Multiply all menu
    items by 1000 so ISO is properly reported as 50...3200 range.
    
    This applies to kernels 3.5+.
    
    Signed-off-by: Sylwester Nawrocki <s.nawrocki@samsung.com>
    Signed-off-by: Kyungmin Park <kyungmin.park@samsung.com>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bd2c6675ad6c33e2130860ab513466bd9a4069e3
Author: Luis Henriques <luis.henriques@canonical.com>
Date:   Tue Jun 19 11:29:49 2012 -0300

    media: ene_ir: Fix driver initialisation
    
    commit b31b021988fed9e3741a46918f14ba9b063811db upstream.
    
    commit 9ef449c6b31bb6a8e6dedc24de475a3b8c79be20 ("[media] rc: Postpone ISR
    registration") fixed an early ISR registration on several drivers.  It did
    however also introduced a bug by moving the invocation of pnp_port_start()
    to the end of the probe function.
    
    This patch fixes this issue by moving the invocation of pnp_port_start() to
    an earlier stage in the probe function.
    
    Signed-off-by: Luis Henriques <luis.henriques@canonical.com>
    Cc: Jarod Wilson <jarod@redhat.com>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit aca31ab725ec75c502a27f47d1ca18b1e2caad65
Author: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
Date:   Mon Jul 30 14:42:07 2012 -0700

    nilfs2: fix deadlock issue between chcp and thaw ioctls
    
    commit 572d8b3945a31bee7c40d21556803e4807fd9141 upstream.
    
    An fs-thaw ioctl causes deadlock with a chcp or mkcp -s command:
    
     chcp            D ffff88013870f3d0     0  1325   1324 0x00000004
     ...
     Call Trace:
       nilfs_transaction_begin+0x11c/0x1a0 [nilfs2]
       wake_up_bit+0x20/0x20
       copy_from_user+0x18/0x30 [nilfs2]
       nilfs_ioctl_change_cpmode+0x7d/0xcf [nilfs2]
       nilfs_ioctl+0x252/0x61a [nilfs2]
       do_page_fault+0x311/0x34c
       get_unmapped_area+0x132/0x14e
       do_vfs_ioctl+0x44b/0x490
       __set_task_blocked+0x5a/0x61
       vm_mmap_pgoff+0x76/0x87
       __set_current_blocked+0x30/0x4a
       sys_ioctl+0x4b/0x6f
       system_call_fastpath+0x16/0x1b
     thaw            D ffff88013870d890     0  1352   1351 0x00000004
     ...
     Call Trace:
       rwsem_down_failed_common+0xdb/0x10f
       call_rwsem_down_write_failed+0x13/0x20
       down_write+0x25/0x27
       thaw_super+0x13/0x9e
       do_vfs_ioctl+0x1f5/0x490
       vm_mmap_pgoff+0x76/0x87
       sys_ioctl+0x4b/0x6f
       filp_close+0x64/0x6c
       system_call_fastpath+0x16/0x1b
    
    where the thaw ioctl deadlocked at thaw_super() when called while chcp was
    waiting at nilfs_transaction_begin() called from
    nilfs_ioctl_change_cpmode().  This deadlock is 100% reproducible.
    
    This is because nilfs_ioctl_change_cpmode() first locks sb->s_umount in
    read mode and then waits for unfreezing in nilfs_transaction_begin(),
    whereas thaw_super() locks sb->s_umount in write mode.  The locking of
    sb->s_umount here was intended to make snapshot mounts and the downgrade
    of snapshots to checkpoints exclusive.
    
    This fixes the deadlock issue by replacing the sb->s_umount usage in
    nilfs_ioctl_change_cpmode() with a dedicated mutex which protects snapshot
    mounts.
    
    Signed-off-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Cc: Fernando Luis Vazquez Cao <fernando@oss.ntt.co.jp>
    Tested-by: Ryusuke Konishi <konishi.ryusuke@lab.ntt.co.jp>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3145ab3d55ed4f15aca96d4a9be84de253074dfa
Author: Karsten Keil <keil@b1-systems.de>
Date:   Sun Jul 29 07:15:13 2012 +0000

    mISDN: Bugfix only few bytes are transfered on a connection
    
    commit b41a9a66f67817f8acd85bd650e012a14da39faa upstream.
    
    The test for the fillempty condition was wrong in one place.
    Changed the variable to the right boolean type.
    
    Signed-off-by: Karsten Keil <keil@b1-systems.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 988eef525e96e39e6de1118c298cc43276533c6a
Author: Stanislav Kinsbursky <skinsbursky@parallels.com>
Date:   Fri Jul 20 15:57:48 2012 +0400

    SUNRPC: return negative value in case rpcbind client creation error
    
    commit caea33da898e4e14f0ba58173e3b7689981d2c0b upstream.
    
    Without this patch kernel will panic on LockD start, because lockd_up() checks
    lockd_up_net() result for negative value.
    From my pow it's better to return negative value from rpcbind routines instead
    of replacing all such checks like in lockd_up().
    
    Signed-off-by: Stanislav Kinsbursky <skinsbursky@parallels.com>
    Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b0068c95cf455a9761becee7ae16ea9f5e12aec5
Author: Joe Perches <joe@perches.com>
Date:   Wed Jul 18 11:17:11 2012 -0700

    sunrpc: clnt: Add missing braces
    
    commit cac5d07e3ca696dcacfb123553cf6c722111cfd3 upstream.
    
    Add a missing set of braces that commit 4e0038b6b24
    ("SUNRPC: Move clnt->cl_server into struct rpc_xprt")
    forgot.
    
    Signed-off-by: Joe Perches <joe@perches.com>
    Signed-off-by: Trond Myklebust <Trond.Myklebust@netapp.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d14c700fa9fdd3c2cc81d474dd8e340b95291452
Author: Dan Rosenberg <drosenberg@vsecurity.com>
Date:   Mon Jul 30 14:40:26 2012 -0700

    lib/vsprintf.c: kptr_restrict: fix pK-error in SysRq show-all-timers(Q)
    
    commit 3715c5309f6d175c3053672b73fd4f73be16fd07 upstream.
    
    When using ALT+SysRq+Q all the pointers are replaced with "pK-error" like
    this:
    
            [23153.208033]   .base:               pK-error
    
    with echo h > /proc/sysrq-trigger it works:
    
            [23107.776363]   .base:       ffff88023e60d540
    
    The intent behind this behavior was to return "pK-error" in cases where
    the %pK format specifier was used in interrupt context, because the
    CAP_SYSLOG check wouldn't be meaningful.  Clearly this should only apply
    when kptr_restrict is actually enabled though.
    
    Reported-by: Stevie Trujillo <stevie.trujillo@gmail.com>
    Signed-off-by: Dan Rosenberg <dan.j.rosenberg@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03bcc225478c0ec096cf37078ed19a79eee08575
Author: Al Viro <viro@ZenIV.linux.org.uk>
Date:   Sat Jun 9 08:15:16 2012 +0100

    selinux: fix selinux_inode_setxattr oops
    
    commit e3fea3f70fd68af0574a5f24246cdb4ed07f2b74 upstream.
    
    OK, what we have so far is e.g.
            setxattr(path, name, whatever, 0, XATTR_REPLACE)
    with name being good enough to get through xattr_permission().
    Then we reach security_inode_setxattr() with the desired value and size.
    Aha.  name should begin with "security.selinux", or we won't get that
    far in selinux_inode_setxattr().  Suppose we got there and have enough
    permissions to relabel that sucker.  We call security_context_to_sid()
    with value == NULL, size == 0.  OK, we want ss_initialized to be non-zero.
    I.e. after everything had been set up and running.  No problem...
    
    We do 1-byte kmalloc(), zero-length memcpy() (which doesn't oops, even
    thought the source is NULL) and put a NUL there.  I.e. form an empty
    string.  string_to_context_struct() is called and looks for the first
    ':' in there.  Not found, -EINVAL we get.  OK, security_context_to_sid_core()
    has rc == -EINVAL, force == 0, so it silently returns -EINVAL.
    All it takes now is not having CAP_MAC_ADMIN and we are fucked.
    
    All right, it might be a different bug (modulo strange code quoted in the
    report), but it's real.  Easily fixed, AFAICS:
    
    Deal with size == 0, value == NULL case in selinux_inode_setxattr()
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Tested-by: Dave Jones <davej@redhat.com>
    Reported-by: Dave Jones <davej@redhat.com>
    Signed-off-by: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8364f4422511ec6e29c9000496a5971228ef0d42
Author: Alex Hung <alex.hung@canonical.com>
Date:   Wed Jun 20 11:47:35 2012 +0800

    asus-wmi: use ASUS_WMI_METHODID_DSTS2 as default DSTS ID.
    
    commit 63a78bb1051b240417daad3a3fa9c1bb10646dca upstream.
    
    According to responses from the BIOS team, ASUS_WMI_METHODID_DSTS2
    (0x53545344) will be used as future DSTS ID. In addition, calling
    asus_wmi_evaluate_method(ASUS_WMI_METHODID_DSTS2, 0, 0, NULL) returns
    ASUS_WMI_UNSUPPORTED_METHOD in new ASUS laptop PCs. This patch fixes
    no DSTS ID will be assigned in this case.
    
    Signed-off-by: Alex Hung <alex.hung@canonical.com>
    Signed-off-by: Matthew Garrett <mjg@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b9db524c98669822ae5889d1cf10ce8e357b1671
Author: Tony Luck <tony.luck@intel.com>
Date:   Thu Jul 26 10:55:26 2012 -0700

    Redefine ATOMIC_INIT and ATOMIC64_INIT to drop the casts
    
    commit a119365586b0130dfea06457f584953e0ff6481d upstream.
    
    The following build error occured during a ia64 build with
    swap-over-NFS patches applied.
    
    net/core/sock.c:274:36: error: initializer element is not constant
    net/core/sock.c:274:36: error: (near initialization for 'memalloc_socks')
    net/core/sock.c:274:36: error: initializer element is not constant
    
    This is identical to a parisc build error. Fengguang Wu, Mel Gorman
    and James Bottomley did all the legwork to track the root cause of
    the problem. This fix and entire commit log is shamelessly copied
    from them with one extra detail to change a dubious runtime use of
    ATOMIC_INIT() to atomic_set() in drivers/char/mspec.c
    
    Dave Anglin says:
    > Here is the line in sock.i:
    >
    > struct static_key memalloc_socks = ((struct static_key) { .enabled =
    > ((atomic_t) { (0) }) });
    
    The above line contains two compound literals.  It also uses a designated
    initializer to initialize the field enabled.  A compound literal is not a
    constant expression.
    
    The location of the above statement isn't fully clear, but if a compound
    literal occurs outside the body of a function, the initializer list must
    consist of constant expressions.
    
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8058567e89b6f80b754f3edf5324b36f4b199849
Author: Asias He <asias@redhat.com>
Date:   Fri May 25 16:03:27 2012 +0800

    virtio-blk: Use block layer provided spinlock
    
    commit 2c95a3290919541b846bee3e0fbaa75860929f53 upstream.
    
    Block layer will allocate a spinlock for the queue if the driver does
    not provide one in blk_init_queue().
    
    The reason to use the internal spinlock is that blk_cleanup_queue() will
    switch to use the internal spinlock in the cleanup code path.
    
            if (q->queue_lock != &q->__queue_lock)
                    q->queue_lock = &q->__queue_lock;
    
    However, processes which are in D state might have taken the driver
    provided spinlock, when the processes wake up, they would release the
    block provided spinlock.
    
    =====================================
    [ BUG: bad unlock balance detected! ]
    3.4.0-rc7+ #238 Not tainted
    -------------------------------------
    fio/3587 is trying to release lock (&(&q->__queue_lock)->rlock) at:
    [<ffffffff813274d2>] blk_queue_bio+0x2a2/0x380
    but there are no more locks to release!
    
    other info that might help us debug this:
    1 lock held by fio/3587:
     #0:  (&(&vblk->lock)->rlock){......}, at:
    [<ffffffff8132661a>] get_request_wait+0x19a/0x250
    
    Other drivers use block layer provided spinlock as well, e.g. SCSI.
    
    Switching to the block layer provided spinlock saves a bit of memory and
    does not increase lock contention. Performance test shows no real
    difference is observed before and after this patch.
    
    Changes in v2: Improve commit log as Michael suggested.
    
    Signed-off-by: Asias He <asias@redhat.com>
    Cc: virtualization@lists.linux-foundation.org
    Cc: kvm@vger.kernel.org
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c92867fad388d59e325ab439c8c560a3f8dff7ad
Author: Asias He <asias@redhat.com>
Date:   Fri May 25 10:34:48 2012 +0800

    virtio-blk: Reset device after blk_cleanup_queue()
    
    commit 483001c765af6892b3fc3726576cb42f17d1d6b5 upstream.
    
    blk_cleanup_queue() will call blk_drian_queue() to drain all the
    requests before queue DEAD marking. If we reset the device before
    blk_cleanup_queue() the drain would fail.
    
    1) if the queue is stopped in do_virtblk_request() because device is
    full, the q->request_fn() will not be called.
    
    blk_drain_queue() {
       while(true) {
          ...
          if (!list_empty(&q->queue_head))
            __blk_run_queue(q) {
                if (queue is not stoped)
                    q->request_fn()
            }
          ...
       }
    }
    
    Do no reset the device before blk_cleanup_queue() gives the chance to
    start the queue in interrupt handler blk_done().
    
    2) In commit b79d866c8b7014a51f611a64c40546109beaf24a, We abort requests
    dispatched to driver before blk_cleanup_queue(). There is a race if
    requests are dispatched to driver after the abort and before the queue
    DEAD mark. To fix this, instead of aborting the requests explicitly, we
    can just reset the device after after blk_cleanup_queue so that the
    device can complete all the requests before queue DEAD marking in the
    drain process.
    
    Signed-off-by: Asias He <asias@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: virtualization@lists.linux-foundation.org
    Cc: kvm@vger.kernel.org
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9097a6af42d1f0d13908fda5c8933266fd49ae16
Author: Asias He <asias@redhat.com>
Date:   Fri May 25 10:34:47 2012 +0800

    virtio-blk: Call del_gendisk() before disable guest kick
    
    commit 02e2b124943648fba0a2ccee5c3656a5653e0151 upstream.
    
    del_gendisk() might not return due to failing to remove the
    /sys/block/vda/serial sysfs entry when another thread (udev) is
    trying to read it.
    
    virtblk_remove()
      vdev->config->reset() : guest will not kick us through interrupt
        del_gendisk()
          device_del()
            kobject_del(): got stuck, sysfs entry ref count non zero
    
    sysfs_open_file(): user space process read /sys/block/vda/serial
       sysfs_get_active() : got sysfs entry ref count
          dev_attr_show()
            virtblk_serial_show()
               blk_execute_rq() : got stuck, interrupt is disabled
                                  request cannot be finished
    
    This patch fixes it by calling del_gendisk() before we disable guest's
    interrupt so that the request sent in virtblk_serial_show() will be
    finished and del_gendisk() will success.
    
    This fixes another race in hot-unplug process.
    
    It is save to call del_gendisk(vblk->disk) before
    flush_work(&vblk->config_work) which might access vblk->disk, because
    vblk->disk is not freed until put_disk(vblk->disk).
    
    Signed-off-by: Asias He <asias@redhat.com>
    Cc: virtualization@lists.linux-foundation.org
    Cc: kvm@vger.kernel.org
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
