commit fd80923202c6bfd723742fc32426a7aa3632abaa
Author: Sasha Levin <sashal@kernel.org>
Date:   Thu Aug 26 08:55:22 2021 -0400

    Linux 5.4.143
    
    Tested-by: Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
    Tested-by: Hulk Robot <hulkrobot@huawei.com>
    Tested-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Tested-by: Shuah Khan <skhan@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 4bf19415810298bb0562c8923dfadbd3ee29c486
Author: Sergey Marinkevich <sergey.marinkevich@eltex-co.ru>
Date:   Sun Mar 29 19:19:14 2020 +0700

    netfilter: nft_exthdr: fix endianness of tcp option cast
    
    [ Upstream commit 2e34328b396a69b73661ba38d47d92b7cf21c2c4 ]
    
    I got a problem on MIPS with Big-Endian is turned on: every time when
    NF trying to change TCP MSS it returns because of new.v16 was greater
    than old.v16. But real MSS was 1460 and my rule was like this:
    
            add rule table chain tcp option maxseg size set 1400
    
    And 1400 is lesser that 1460, not greater.
    
    Later I founded that main causer is cast from u32 to __be16.
    
    Debugging:
    
    In example MSS = 1400(HEX: 0x578). Here is representation of each byte
    like it is in memory by addresses from left to right(e.g. [0x0 0x1 0x2
    0x3]). LE — Little-Endian system, BE — Big-Endian, left column is type.
    
                 LE               BE
            u32: [78 05 00 00]    [00 00 05 78]
    
    As you can see, u32 representation will be casted to u16 from different
    half of 4-byte address range. But actually nf_tables uses registers and
    store data of various size. Actually TCP MSS stored in 2 bytes. But
    registers are still u32 in definition:
    
            struct nft_regs {
                    union {
                            u32                     data[20];
                            struct nft_verdict      verdict;
                    };
            };
    
    So, access like regs->data[priv->sreg] exactly u32. So, according to
    table presents above, per-byte representation of stored TCP MSS in
    register will be:
    
                                 LE               BE
            (u32)regs->data[]:   [78 05 00 00]    [05 78 00 00]
                                                   ^^ ^^
    
    We see that register uses just half of u32 and other 2 bytes may be
    used for some another data. But in nft_exthdr_tcp_set_eval() it casted
    just like u32 -> __be16:
    
            new.v16 = src
    
    But u32 overfill __be16, so it get 2 low bytes. For clarity draw
    one more table(<xx xx> means that bytes will be used for cast).
    
                                 LE                 BE
            u32:                 [<78 05> 00 00]    [00 00 <05 78>]
            (u32)regs->data[]:   [<78 05> 00 00]    [05 78 <00 00>]
    
    As you can see, for Little-Endian nothing changes, but for Big-endian we
    take the wrong half. In my case there is some other data instead of
    zeros, so new MSS was wrongly greater.
    
    For shooting this bug I used solution for ports ranges. Applying of this
    patch does not affect Little-Endian systems.
    
    Signed-off-by: Sergey Marinkevich <sergey.marinkevich@eltex-co.ru>
    Acked-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e4fd994f02c5c23ef8978d0e631869a0de1e44ff
Author: Jeff Layton <jlayton@kernel.org>
Date:   Fri Aug 20 09:29:50 2021 -0400

    fs: warn about impending deprecation of mandatory locks
    
    [ Upstream commit fdd92b64d15bc4aec973caa25899afd782402e68 ]
    
    We've had CONFIG_MANDATORY_FILE_LOCKING since 2015 and a lot of distros
    have disabled it. Warn the stragglers that still use "-o mand" that
    we'll be dropping support for that mount option.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 41c7f46c89f64a5729d145dedd09c7cba9119972
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Aug 19 19:04:21 2021 -0700

    mm: memcontrol: fix occasional OOMs due to proportional memory.low reclaim
    
    [ Upstream commit f56ce412a59d7d938b81de8878faef128812482c ]
    
    We've noticed occasional OOM killing when memory.low settings are in
    effect for cgroups.  This is unexpected and undesirable as memory.low is
    supposed to express non-OOMing memory priorities between cgroups.
    
    The reason for this is proportional memory.low reclaim.  When cgroups
    are below their memory.low threshold, reclaim passes them over in the
    first round, and then retries if it couldn't find pages anywhere else.
    But when cgroups are slightly above their memory.low setting, page scan
    force is scaled down and diminished in proportion to the overage, to the
    point where it can cause reclaim to fail as well - only in that case we
    currently don't retry, and instead trigger OOM.
    
    To fix this, hook proportional reclaim into the same retry logic we have
    in place for when cgroups are skipped entirely.  This way if reclaim
    fails and some cgroups were scanned with diminished pressure, we'll try
    another full-force cycle before giving up and OOMing.
    
    [akpm@linux-foundation.org: coding-style fixes]
    
    Link: https://lkml.kernel.org/r/20210817180506.220056-1-hannes@cmpxchg.org
    Fixes: 9783aa9917f8 ("mm, memcg: proportional memory.{low,min} reclaim")
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reported-by: Leon Yang <lnyng@fb.com>
    Reviewed-by: Rik van Riel <riel@surriel.com>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Roman Gushchin <guro@fb.com>
    Acked-by: Chris Down <chris@chrisdown.name>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: <stable@vger.kernel.org>            [5.4+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1a3aa81444d3e137fe953daaf9aebe0fac270af8
Author: Yafang Shao <laoar.shao@gmail.com>
Date:   Thu Aug 6 23:22:01 2020 -0700

    mm, memcg: avoid stale protection values when cgroup is above protection
    
    [ Upstream commit 22f7496f0b901249f23c5251eb8a10aae126b909 ]
    
    Patch series "mm, memcg: memory.{low,min} reclaim fix & cleanup", v4.
    
    This series contains a fix for a edge case in my earlier protection
    calculation patches, and a patch to make the area overall a little more
    robust to hopefully help avoid this in future.
    
    This patch (of 2):
    
    A cgroup can have both memory protection and a memory limit to isolate it
    from its siblings in both directions - for example, to prevent it from
    being shrunk below 2G under high pressure from outside, but also from
    growing beyond 4G under low pressure.
    
    Commit 9783aa9917f8 ("mm, memcg: proportional memory.{low,min} reclaim")
    implemented proportional scan pressure so that multiple siblings in excess
    of their protection settings don't get reclaimed equally but instead in
    accordance to their unprotected portion.
    
    During limit reclaim, this proportionality shouldn't apply of course:
    there is no competition, all pressure is from within the cgroup and should
    be applied as such.  Reclaim should operate at full efficiency.
    
    However, mem_cgroup_protected() never expected anybody to look at the
    effective protection values when it indicated that the cgroup is above its
    protection.  As a result, a query during limit reclaim may return stale
    protection values that were calculated by a previous reclaim cycle in
    which the cgroup did have siblings.
    
    When this happens, reclaim is unnecessarily hesitant and potentially slow
    to meet the desired limit.  In theory this could lead to premature OOM
    kills, although it's not obvious this has occurred in practice.
    
    Workaround the problem by special casing reclaim roots in
    mem_cgroup_protection.  These memcgs are never participating in the
    reclaim protection because the reclaim is internal.
    
    We have to ignore effective protection values for reclaim roots because
    mem_cgroup_protected might be called from racing reclaim contexts with
    different roots.  Calculation is relying on root -> leaf tree traversal
    therefore top-down reclaim protection invariants should hold.  The only
    exception is the reclaim root which should have effective protection set
    to 0 but that would be problematic for the following setup:
    
     Let's have global and A's reclaim in parallel:
      |
      A (low=2G, usage = 3G, max = 3G, children_low_usage = 1.5G)
      |\
      | C (low = 1G, usage = 2.5G)
      B (low = 1G, usage = 0.5G)
    
     for A reclaim we have
     B.elow = B.low
     C.elow = C.low
    
     For the global reclaim
     A.elow = A.low
     B.elow = min(B.usage, B.low) because children_low_usage <= A.elow
     C.elow = min(C.usage, C.low)
    
     With the effective values resetting we have A reclaim
     A.elow = 0
     B.elow = B.low
     C.elow = C.low
    
     and global reclaim could see the above and then
     B.elow = C.elow = 0 because children_low_usage > A.elow
    
    Which means that protected memcgs would get reclaimed.
    
    In future we would like to make mem_cgroup_protected more robust against
    racing reclaim contexts but that is likely more complex solution than this
    simple workaround.
    
    [hannes@cmpxchg.org - large part of the changelog]
    [mhocko@suse.com - workaround explanation]
    [chris@chrisdown.name - retitle]
    
    Fixes: 9783aa9917f8 ("mm, memcg: proportional memory.{low,min} reclaim")
    Signed-off-by: Yafang Shao <laoar.shao@gmail.com>
    Signed-off-by: Chris Down <chris@chrisdown.name>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Chris Down <chris@chrisdown.name>
    Acked-by: Roman Gushchin <guro@fb.com>
    Link: http://lkml.kernel.org/r/cover.1594638158.git.chris@chrisdown.name
    Link: http://lkml.kernel.org/r/044fb8ecffd001c7905d27c0c2ad998069fdc396.1594638158.git.chris@chrisdown.name
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9c1c449dcca09274ec5bc6efc53a03ec95746d2e
Author: Takashi Iwai <tiwai@suse.de>
Date:   Thu Aug 19 17:29:45 2021 +0200

    ASoC: intel: atom: Fix breakage for PCM buffer address setup
    
    [ Upstream commit 65ca89c2b12cca0d473f3dd54267568ad3af55cc ]
    
    The commit 2e6b836312a4 ("ASoC: intel: atom: Fix reference to PCM
    buffer address") changed the reference of PCM buffer address to
    substream->runtime->dma_addr as the buffer address may change
    dynamically.  However, I forgot that the dma_addr field is still not
    set up for the CONTINUOUS buffer type (that this driver uses) yet in
    5.14 and earlier kernels, and it resulted in garbage I/O.  The problem
    will be fixed in 5.15, but we need to address it quickly for now.
    
    The fix is to deduce the address again from the DMA pointer with
    virt_to_phys(), but from the right one, substream->runtime->dma_area.
    
    Fixes: 2e6b836312a4 ("ASoC: intel: atom: Fix reference to PCM buffer address")
    Reported-and-tested-by: Hans de Goede <hdegoede@redhat.com>
    Cc: <stable@vger.kernel.org>
    Acked-by: Mark Brown <broonie@kernel.org>
    Link: https://lore.kernel.org/r/2048c6aa-2187-46bd-6772-36a4fb3c5aeb@redhat.com
    Link: https://lore.kernel.org/r/20210819152945.8510-1-tiwai@suse.de
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 846ba58a7c068903b64da3c9800d6be42670aee4
Author: Marcin Bachry <hegel666@gmail.com>
Date:   Wed Jul 21 22:58:58 2021 -0400

    PCI: Increase D3 delay for AMD Renoir/Cezanne XHCI
    
    [ Upstream commit e0bff43220925b7e527f9d3bc9f5c624177c959e ]
    
    The Renoir XHCI controller apparently doesn't resume reliably with the
    standard D3hot-to-D0 delay.  Increase it to 20ms.
    
    [Alex: I talked to the AMD USB hardware team and the AMD Windows team and
    they are not aware of any HW errata or specific issues.  The HW works fine
    in Windows.  I was told Windows uses a rather generous default delay of
    100ms for PCI state transitions.]
    
    Link: https://lore.kernel.org/r/20210722025858.220064-1-alexander.deucher@amd.com
    Signed-off-by: Marcin Bachry <hegel666@gmail.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Cc: stable@vger.kernel.org
    Cc: Mario Limonciello <mario.limonciello@amd.com>
    Cc: Prike Liang <prike.liang@amd.com>
    Cc: Shyam Sundar S K <shyam-sundar.s-k@amd.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 548b75f4905eea41cfa2e9d373236c7cea1a18c5
Author: NeilBrown <neilb@suse.de>
Date:   Fri Aug 6 14:26:24 2021 +1000

    btrfs: prevent rename2 from exchanging a subvol with a directory from different parents
    
    [ Upstream commit 3f79f6f6247c83f448c8026c3ee16d4636ef8d4f ]
    
    Cross-rename lacks a check when that would prevent exchanging a
    directory and subvolume from different parent subvolume. This causes
    data inconsistencies and is caught before commit by tree-checker,
    turning the filesystem to read-only.
    
    Calling the renameat2 with RENAME_EXCHANGE flags like
    
      renameat2(AT_FDCWD, namesrc, AT_FDCWD, namedest, (1 << 1))
    
    on two paths:
    
      namesrc = dir1/subvol1/dir2
     namedest = subvol2/subvol3
    
    will cause key order problem with following write time tree-checker
    report:
    
      [1194842.307890] BTRFS critical (device loop1): corrupt leaf: root=5 block=27574272 slot=10 ino=258, invalid previous key objectid, have 257 expect 258
      [1194842.322221] BTRFS info (device loop1): leaf 27574272 gen 8 total ptrs 11 free space 15444 owner 5
      [1194842.331562] BTRFS info (device loop1): refs 2 lock_owner 0 current 26561
      [1194842.338772]        item 0 key (256 1 0) itemoff 16123 itemsize 160
      [1194842.338793]                inode generation 3 size 16 mode 40755
      [1194842.338801]        item 1 key (256 12 256) itemoff 16111 itemsize 12
      [1194842.338809]        item 2 key (256 84 2248503653) itemoff 16077 itemsize 34
      [1194842.338817]                dir oid 258 type 2
      [1194842.338823]        item 3 key (256 84 2363071922) itemoff 16043 itemsize 34
      [1194842.338830]                dir oid 257 type 2
      [1194842.338836]        item 4 key (256 96 2) itemoff 16009 itemsize 34
      [1194842.338843]        item 5 key (256 96 3) itemoff 15975 itemsize 34
      [1194842.338852]        item 6 key (257 1 0) itemoff 15815 itemsize 160
      [1194842.338863]                inode generation 6 size 8 mode 40755
      [1194842.338869]        item 7 key (257 12 256) itemoff 15801 itemsize 14
      [1194842.338876]        item 8 key (257 84 2505409169) itemoff 15767 itemsize 34
      [1194842.338883]                dir oid 256 type 2
      [1194842.338888]        item 9 key (257 96 2) itemoff 15733 itemsize 34
      [1194842.338895]        item 10 key (258 12 256) itemoff 15719 itemsize 14
      [1194842.339163] BTRFS error (device loop1): block=27574272 write time tree block corruption detected
      [1194842.339245] ------------[ cut here ]------------
      [1194842.443422] WARNING: CPU: 6 PID: 26561 at fs/btrfs/disk-io.c:449 csum_one_extent_buffer+0xed/0x100 [btrfs]
      [1194842.511863] CPU: 6 PID: 26561 Comm: kworker/u17:2 Not tainted 5.14.0-rc3-git+ #793
      [1194842.511870] Hardware name: empty empty/S3993, BIOS PAQEX0-3 02/24/2008
      [1194842.511876] Workqueue: btrfs-worker-high btrfs_work_helper [btrfs]
      [1194842.511976] RIP: 0010:csum_one_extent_buffer+0xed/0x100 [btrfs]
      [1194842.512068] RSP: 0018:ffffa2c284d77da0 EFLAGS: 00010282
      [1194842.512074] RAX: 0000000000000000 RBX: 0000000000001000 RCX: ffff928867bd9978
      [1194842.512078] RDX: 0000000000000000 RSI: 0000000000000027 RDI: ffff928867bd9970
      [1194842.512081] RBP: ffff92876b958000 R08: 0000000000000001 R09: 00000000000c0003
      [1194842.512085] R10: 0000000000000000 R11: 0000000000000001 R12: 0000000000000000
      [1194842.512088] R13: ffff92875f989f98 R14: 0000000000000000 R15: 0000000000000000
      [1194842.512092] FS:  0000000000000000(0000) GS:ffff928867a00000(0000) knlGS:0000000000000000
      [1194842.512095] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [1194842.512099] CR2: 000055f5384da1f0 CR3: 0000000102fe4000 CR4: 00000000000006e0
      [1194842.512103] Call Trace:
      [1194842.512128]  ? run_one_async_free+0x10/0x10 [btrfs]
      [1194842.631729]  btree_csum_one_bio+0x1ac/0x1d0 [btrfs]
      [1194842.631837]  run_one_async_start+0x18/0x30 [btrfs]
      [1194842.631938]  btrfs_work_helper+0xd5/0x1d0 [btrfs]
      [1194842.647482]  process_one_work+0x262/0x5e0
      [1194842.647520]  worker_thread+0x4c/0x320
      [1194842.655935]  ? process_one_work+0x5e0/0x5e0
      [1194842.655946]  kthread+0x135/0x160
      [1194842.655953]  ? set_kthread_struct+0x40/0x40
      [1194842.655965]  ret_from_fork+0x1f/0x30
      [1194842.672465] irq event stamp: 1729
      [1194842.672469] hardirqs last  enabled at (1735): [<ffffffffbd1104f5>] console_trylock_spinning+0x185/0x1a0
      [1194842.672477] hardirqs last disabled at (1740): [<ffffffffbd1104cc>] console_trylock_spinning+0x15c/0x1a0
      [1194842.672482] softirqs last  enabled at (1666): [<ffffffffbdc002e1>] __do_softirq+0x2e1/0x50a
      [1194842.672491] softirqs last disabled at (1651): [<ffffffffbd08aab7>] __irq_exit_rcu+0xa7/0xd0
    
    The corrupted data will not be written, and filesystem can be unmounted
    and mounted again (all changes since the last commit will be lost).
    
    Add the missing check for new_ino so that all non-subvolumes must reside
    under the same parent subvolume. There's an exception allowing to
    exchange two subvolumes from any parents as the directory representing a
    subvolume is only a logical link and does not have any other structures
    related to the parent subvolume, unlike files, directories etc, that
    are always in the inode namespace of the parent subvolume.
    
    Fixes: cdd1fedf8261 ("btrfs: add support for RENAME_EXCHANGE and RENAME_WHITEOUT")
    CC: stable@vger.kernel.org # 4.7+
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Signed-off-by: NeilBrown <neilb@suse.de>
    Reviewed-by: David Sterba <dsterba@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0fc6a9c2025b4238c7a3e86c6931003153483684
Author: Dongliang Mu <mudongliangabcd@gmail.com>
Date:   Tue Aug 10 18:03:19 2021 +0800

    ipack: tpci200: fix memory leak in the tpci200_register
    
    [ Upstream commit 50f05bd114a46a74726e432bf81079d3f13a55b7 ]
    
    The error handling code in tpci200_register does not free interface_regs
    allocated by ioremap and the current version of error handling code is
    problematic.
    
    Fix this by refactoring the error handling code and free interface_regs
    when necessary.
    
    Fixes: 43986798fd50 ("ipack: add error handling for ioremap_nocache")
    Cc: stable@vger.kernel.org
    Reported-by: Dongliang Mu <mudongliangabcd@gmail.com>
    Signed-off-by: Dongliang Mu <mudongliangabcd@gmail.com>
    Link: https://lore.kernel.org/r/20210810100323.3938492-2-mudongliangabcd@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 280d66b317976458cb653725ea522b852805030f
Author: Dongliang Mu <mudongliangabcd@gmail.com>
Date:   Tue Aug 10 18:03:18 2021 +0800

    ipack: tpci200: fix many double free issues in tpci200_pci_probe
    
    [ Upstream commit 57a1681095f912239c7fb4d66683ab0425973838 ]
    
    The function tpci200_register called by tpci200_install and
    tpci200_unregister called by tpci200_uninstall are in pair. However,
    tpci200_unregister has some cleanup operations not in the
    tpci200_register. So the error handling code of tpci200_pci_probe has
    many different double free issues.
    
    Fix this problem by moving those cleanup operations out of
    tpci200_unregister, into tpci200_pci_remove and reverting
    the previous commit 9272e5d0028d ("ipack/carriers/tpci200:
    Fix a double free in tpci200_pci_probe").
    
    Fixes: 9272e5d0028d ("ipack/carriers/tpci200: Fix a double free in tpci200_pci_probe")
    Cc: stable@vger.kernel.org
    Reported-by: Dongliang Mu <mudongliangabcd@gmail.com>
    Signed-off-by: Dongliang Mu <mudongliangabcd@gmail.com>
    Link: https://lore.kernel.org/r/20210810100323.3938492-1-mudongliangabcd@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit cb7aa5103146f88074a09ba9c96bde26d8614def
Author: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
Date:   Mon Aug 9 09:24:28 2021 +0100

    slimbus: ngd: reset dma setup during runtime pm
    
    [ Upstream commit d77772538f00b7265deace6e77e555ee18365ad0 ]
    
    During suspend/resume NGD remote instance is power cycled along
    with remotely controlled bam dma engine.
    So Reset the dma configuration during this suspend resume path
    so that we are not dealing with any stale dma setup.
    
    Without this transactions timeout after first suspend resume path.
    
    Fixes: 917809e2280b ("slimbus: ngd: Add qcom SLIMBus NGD driver")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
    Link: https://lore.kernel.org/r/20210809082428.11236-5-srinivas.kandagatla@linaro.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit abce32d0f7f4f416e2069b76a72cc9962581b2bb
Author: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
Date:   Mon Aug 9 09:24:26 2021 +0100

    slimbus: messaging: check for valid transaction id
    
    [ Upstream commit a263c1ff6abe0e66712f40d595bbddc7a35907f8 ]
    
    In some usecases transaction ids are dynamically allocated inside
    the controller driver after sending the messages which have generic
    acknowledge responses. So check for this before refcounting pm_runtime.
    
    Without this we would end up imbalancing runtime pm count by
    doing pm_runtime_put() in both slim_do_transfer() and slim_msg_response()
    for a single  pm_runtime_get() in slim_do_transfer()
    
    Fixes: d3062a210930 ("slimbus: messaging: add slim_alloc/free_txn_tid()")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
    Link: https://lore.kernel.org/r/20210809082428.11236-3-srinivas.kandagatla@linaro.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0786d315f55c3b5a6cf3e34065360bf1f2e4dada
Author: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
Date:   Mon Aug 9 09:24:25 2021 +0100

    slimbus: messaging: start transaction ids from 1 instead of zero
    
    [ Upstream commit 9659281ce78de0f15a4aa124da8f7450b1399c09 ]
    
    As tid is unsigned its hard to figure out if the tid is valid or
    invalid. So Start the transaction ids from 1 instead of zero
    so that we could differentiate between a valid tid and invalid tids
    
    This is useful in cases where controller would add a tid for controller
    specific transfers.
    
    Fixes: d3062a210930 ("slimbus: messaging: add slim_alloc/free_txn_tid()")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Srinivas Kandagatla <srinivas.kandagatla@linaro.org>
    Link: https://lore.kernel.org/r/20210809082428.11236-2-srinivas.kandagatla@linaro.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 20c2f141b1e58cdc07cd33c84a5a01f2ce5ec3eb
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Sun Aug 8 00:30:11 2021 -0400

    tracing / histogram: Fix NULL pointer dereference on strcmp() on NULL event name
    
    [ Upstream commit 5acce0bff2a0420ce87d4591daeb867f47d552c2 ]
    
    The following commands:
    
     # echo 'read_max u64 size;' > synthetic_events
     # echo 'hist:keys=common_pid:count=count:onmax($count).trace(read_max,count)' > events/syscalls/sys_enter_read/trigger
    
    Causes:
    
     BUG: kernel NULL pointer dereference, address: 0000000000000000
     #PF: supervisor read access in kernel mode
     #PF: error_code(0x0000) - not-present page
     PGD 0 P4D 0
     Oops: 0000 [#1] PREEMPT SMP
     CPU: 4 PID: 1763 Comm: bash Not tainted 5.14.0-rc2-test+ #155
     Hardware name: Hewlett-Packard HP Compaq Pro 6300 SFF/339A, BIOS K01
    v03.03 07/14/2016
     RIP: 0010:strcmp+0xc/0x20
     Code: 75 f7 31 c0 0f b6 0c 06 88 0c 02 48 83 c0 01 84 c9 75 f1 4c 89 c0
    c3 0f 1f 80 00 00 00 00 31 c0 eb 08 48 83 c0 01 84 d2 74 0f <0f> b6 14 07
    3a 14 06 74 ef 19 c0 83 c8 01 c3 31 c0 c3 66 90 48 89
     RSP: 0018:ffffb5fdc0963ca8 EFLAGS: 00010246
     RAX: 0000000000000000 RBX: ffffffffb3a4e040 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: ffff9714c0d0b640 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 00000022986b7cde R09: ffffffffb3a4dff8
     R10: 0000000000000000 R11: 0000000000000000 R12: ffff9714c50603c8
     R13: 0000000000000000 R14: ffff97143fdf9e48 R15: ffff9714c01a2210
     FS:  00007f1fa6785740(0000) GS:ffff9714da400000(0000)
    knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: 0000000000000000 CR3: 000000002d863004 CR4: 00000000001706e0
     Call Trace:
      __find_event_file+0x4e/0x80
      action_create+0x6b7/0xeb0
      ? kstrdup+0x44/0x60
      event_hist_trigger_func+0x1a07/0x2130
      trigger_process_regex+0xbd/0x110
      event_trigger_write+0x71/0xd0
      vfs_write+0xe9/0x310
      ksys_write+0x68/0xe0
      do_syscall_64+0x3b/0x90
      entry_SYSCALL_64_after_hwframe+0x44/0xae
     RIP: 0033:0x7f1fa6879e87
    
    The problem was the "trace(read_max,count)" where the "count" should be
    "$count" as "onmax()" only handles variables (although it really should be
    able to figure out that "count" is a field of sys_enter_read). But there's
    a path that does not find the variable and ends up passing a NULL for the
    event, which ends up getting passed to "strcmp()".
    
    Add a check for NULL to return and error on the command with:
    
     # cat error_log
      hist:syscalls:sys_enter_read: error: Couldn't create or find variable
      Command: hist:keys=common_pid:count=count:onmax($count).trace(read_max,count)
                                    ^
    Link: https://lkml.kernel.org/r/20210808003011.4037f8d0@oasis.local.home
    
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: stable@vger.kernel.org
    Fixes: 50450603ec9cb tracing: Add 'onmax' hist trigger action support
    Reviewed-by: Tom Zanussi <zanussi@kernel.org>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8fbfebe188c020fbcce0c739a5936d025c08b43d
Author: Jaroslav Kysela <perex@perex.cz>
Date:   Wed Aug 11 18:14:41 2021 +0200

    ALSA: hda - fix the 'Capture Switch' value change notifications
    
    [ Upstream commit a2befe9380dd04ee76c871568deca00eedf89134 ]
    
    The original code in the cap_put_caller() function does not
    handle correctly the positive values returned from the passed
    function for multiple iterations. It means that the change
    notifications may be lost.
    
    Fixes: 352f7f914ebb ("ALSA: hda - Merge Realtek parser code to generic parser")
    BugLink: https://bugzilla.kernel.org/show_bug.cgi?id=213851
    Cc: <stable@kernel.org>
    Signed-off-by: Jaroslav Kysela <perex@perex.cz>
    Link: https://lore.kernel.org/r/20210811161441.1325250-1-perex@perex.cz
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 85e60614d1f60ef1de5bae426174452fbe5c617b
Author: Vincent Whitchurch <vincent.whitchurch@axis.com>
Date:   Wed Jun 30 12:22:32 2021 +0200

    mmc: dw_mmc: Fix hang on data CRC error
    
    [ Upstream commit 25f8203b4be1937c4939bb98623e67dcfd7da4d1 ]
    
    When a Data CRC interrupt is received, the driver disables the DMA, then
    sends the stop/abort command and then waits for Data Transfer Over.
    
    However, sometimes, when a data CRC error is received in the middle of a
    multi-block write transfer, the Data Transfer Over interrupt is never
    received, and the driver hangs and never completes the request.
    
    The driver sets the BMOD.SWR bit (SDMMC_IDMAC_SWRESET) when stopping the
    DMA, but according to the manual CMD.STOP_ABORT_CMD should be programmed
    "before assertion of SWR".  Do these operations in the recommended
    order.  With this change the Data Transfer Over is always received
    correctly in my tests.
    
    Signed-off-by: Vincent Whitchurch <vincent.whitchurch@axis.com>
    Reviewed-by: Jaehoon Chung <jh80.chung@samsung.com>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20210630102232.16011-1-vincent.whitchurch@axis.com
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 4f6c9caf7b6c51404bb0cef6480ced31da4ad530
Author: Murphy Zhou <jencce.kernel@gmail.com>
Date:   Fri Jan 17 20:49:29 2020 +0800

    ovl: add splice file read write helper
    
    [ Upstream commit 1a980b8cbf0059a5308eea61522f232fd03002e2 ]
    
    Now overlayfs falls back to use default file splice read
    and write, which is not compatiple with overlayfs, returning
    EFAULT. xfstests generic/591 can reproduce part of this.
    
    Tested this patch with xfstests auto group tests.
    
    Signed-off-by: Murphy Zhou <jencce.kernel@gmail.com>
    Signed-off-by: Miklos Szeredi <mszeredi@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 85813f1f9e86c4a620db7b2f3eedd2679af2c4be
Author: Sylwester Dziedziuch <sylwesterx.dziedziuch@intel.com>
Date:   Wed Aug 18 10:42:17 2021 -0700

    iavf: Fix ping is lost after untrusted VF had tried to change MAC
    
    [ Upstream commit 8da80c9d50220a8e4190a4eaa0dd6aeefcbbb5bf ]
    
    Make changes to MAC address dependent on the response of PF.
    Disallow changes to HW MAC address and MAC filter from untrusted
    VF, thanks to that ping is not lost if VF tries to change MAC.
    Add a new field in iavf_mac_filter, to indicate whether there
    was response from PF for given filter. Based on this field pass
    or discard the filter.
    If untrusted VF tried to change it's address, it's not changed.
    Still filter was changed, because of that ping couldn't go through.
    
    Fixes: c5c922b3e09b ("iavf: fix MAC address setting for VFs when filter is rejected")
    Signed-off-by: Przemyslaw Patynowski <przemyslawx.patynowski@intel.com>
    Signed-off-by: Sylwester Dziedziuch <sylwesterx.dziedziuch@intel.com>
    Signed-off-by: Mateusz Palczewski <mateusz.palczewski@intel.com>
    Tested-by: Gurucharan G <Gurucharanx.g@intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a498115dcd9c3d321379500abe3bc66a04259067
Author: Arkadiusz Kubalewski <arkadiusz.kubalewski@intel.com>
Date:   Wed Aug 18 10:42:16 2021 -0700

    i40e: Fix ATR queue selection
    
    [ Upstream commit a222be597e316389f9f8c26033352c124ce93056 ]
    
    Without this patch, ATR does not work. Receive/transmit uses queue
    selection based on SW DCB hashing method.
    
    If traffic classes are not configured for PF, then use
    netdev_pick_tx function for selecting queue for packet transmission.
    Instead of calling i40e_swdcb_skb_tx_hash, call netdev_pick_tx,
    which ensures that packet is transmitted/received from CPU that is
    running the application.
    
    Reproduction steps:
    1. Load i40e driver
    2. Map each MSI interrupt of i40e port for each CPU
    3. Disable ntuple, enable ATR i.e.:
    ethtool -K $interface ntuple off
    ethtool --set-priv-flags $interface flow-director-atr
    4. Run application that is generating traffic and is bound to a
    single CPU, i.e.:
    taskset -c 9 netperf -H 1.1.1.1 -t TCP_RR -l 10
    5. Observe behavior:
    Application's traffic should be restricted to the CPU provided in
    taskset.
    
    Fixes: 89ec1f0886c1 ("i40e: Fix queue-to-TC mapping on Tx")
    Signed-off-by: Przemyslaw Patynowski <przemyslawx.patynowski@intel.com>
    Signed-off-by: Arkadiusz Kubalewski <arkadiusz.kubalewski@intel.com>
    Tested-by: Dave Switzer <david.switzer@intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1b8a8fba7853905dff29dd7dfe59d1c4e8a33bde
Author: kaixi.fan <fankaixi.li@bytedance.com>
Date:   Wed Aug 18 10:22:15 2021 +0800

    ovs: clear skb->tstamp in forwarding path
    
    [ Upstream commit 01634047bf0d5c2d9b7d8095bb4de1663dbeedeb ]
    
    fq qdisc requires tstamp to be cleared in the forwarding path. Now ovs
    doesn't clear skb->tstamp. We encountered a problem with linux
    version 5.4.56 and ovs version 2.14.1, and packets failed to
    dequeue from qdisc when fq qdisc was attached to ovs port.
    
    Fixes: fb420d5d91c1 ("tcp/fq: move back to CLOCK_MONOTONIC")
    Signed-off-by: kaixi.fan <fankaixi.li@bytedance.com>
    Signed-off-by: xiexiaohui <xiexiaohui.xxh@bytedance.com>
    Reviewed-by: Cong Wang <cong.wang@bytedance.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 84dbbf5482e3e5f5b386d473ce03e999c5d0413b
Author: Saravana Kannan <saravanak@google.com>
Date:   Tue Aug 17 20:38:03 2021 -0700

    net: mdio-mux: Handle -EPROBE_DEFER correctly
    
    [ Upstream commit 7bd0cef5dac685f09ef8b0b2a7748ff42d284dc7 ]
    
    When registering mdiobus children, if we get an -EPROBE_DEFER, we shouldn't
    ignore it and continue registering the rest of the mdiobus children. This
    would permanently prevent the deferring child mdiobus from working instead
    of reattempting it in the future. So, if a child mdiobus needs to be
    reattempted in the future, defer the entire mdio-mux initialization.
    
    This fixes the issue where PHYs sitting under the mdio-mux aren't
    initialized correctly if the PHY's interrupt controller is not yet ready
    when the mdio-mux is being probed. Additional context in the link below.
    
    Fixes: 0ca2997d1452 ("netdev/of/phy: Add MDIO bus multiplexer support.")
    Link: https://lore.kernel.org/lkml/CAGETcx95kHrv8wA-O+-JtfH7H9biJEGJtijuPVN0V5dUKUAB3A@mail.gmail.com/#t
    Signed-off-by: Saravana Kannan <saravanak@google.com>
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Acked-by: Marc Zyngier <maz@kernel.org>
    Tested-by: Marc Zyngier <maz@kernel.org>
    Acked-by: Kevin Hilman <khilman@baylibre.com>
    Tested-by: Kevin Hilman <khilman@baylibre.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 453486e79ed2ecf6aaf82e5802e90917b2f1606d
Author: Saravana Kannan <saravanak@google.com>
Date:   Tue Aug 17 20:38:02 2021 -0700

    net: mdio-mux: Don't ignore memory allocation errors
    
    [ Upstream commit 99d81e942474cc7677d12f673f42a7ea699e2589 ]
    
    If we are seeing memory allocation errors, don't try to continue
    registering child mdiobus devices. It's unlikely they'll succeed.
    
    Fixes: 342fa1964439 ("mdio: mux: make child bus walking more permissive and errors more verbose")
    Signed-off-by: Saravana Kannan <saravanak@google.com>
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Acked-by: Marc Zyngier <maz@kernel.org>
    Tested-by: Marc Zyngier <maz@kernel.org>
    Acked-by: Kevin Hilman <khilman@baylibre.com>
    Tested-by: Kevin Hilman <khilman@baylibre.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6b70c67849bb0b5b7d81d2265d2aa35150a2a72c
Author: Dinghao Liu <dinghao.liu@zju.edu.cn>
Date:   Mon Aug 16 21:14:04 2021 +0800

    net: qlcnic: add missed unlock in qlcnic_83xx_flash_read32
    
    [ Upstream commit 0a298d133893c72c96e2156ed7cb0f0c4a306a3e ]
    
    qlcnic_83xx_unlock_flash() is called on all paths after we call
    qlcnic_83xx_lock_flash(), except for one error path on failure
    of QLCRD32(), which may cause a deadlock. This bug is suggested
    by a static analysis tool, please advise.
    
    Fixes: 81d0aeb0a4fff ("qlcnic: flash template based firmware reset recovery")
    Signed-off-by: Dinghao Liu <dinghao.liu@zju.edu.cn>
    Link: https://lore.kernel.org/r/20210816131405.24024-1-dinghao.liu@zju.edu.cn
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit da92ce364595ba081fb5da052a657dafd5e81c70
Author: Jason Wang <jasowang@redhat.com>
Date:   Tue Aug 17 16:06:59 2021 +0800

    virtio-net: use NETIF_F_GRO_HW instead of NETIF_F_LRO
    
    [ Upstream commit dbcf24d153884439dad30484a0e3f02350692e4c ]
    
    Commit a02e8964eaf92 ("virtio-net: ethtool configurable LRO")
    maps LRO to virtio guest offloading features and allows the
    administrator to enable and disable those features via ethtool.
    
    This leads to several issues:
    
    - For a device that doesn't support control guest offloads, the "LRO"
      can't be disabled triggering WARN in dev_disable_lro() when turning
      off LRO or when enabling forwarding bridging etc.
    
    - For a device that supports control guest offloads, the guest
      offloads are disabled in cases of bridging, forwarding etc slowing
      down the traffic.
    
    Fix this by using NETIF_F_GRO_HW instead. Though the spec does not
    guarantee packets to be re-segmented as the original ones,
    we can add that to the spec, possibly with a flag for devices to
    differentiate between GRO and LRO.
    
    Further, we never advertised LRO historically before a02e8964eaf92
    ("virtio-net: ethtool configurable LRO") and so bridged/forwarded
    configs effectively always relied on virtio receive offloads behaving
    like GRO - thus even if this breaks any configs it is at least not
    a regression.
    
    Fixes: a02e8964eaf92 ("virtio-net: ethtool configurable LRO")
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Reported-by: Ivan <ivan@prestigetransportation.com>
    Tested-by: Ivan <ivan@prestigetransportation.com>
    Signed-off-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9aeadce8e33bf200656013bc6ff2ebac0604752a
Author: Xuan Zhuo <xuanzhuo@linux.alibaba.com>
Date:   Wed Mar 10 10:24:45 2021 +0800

    virtio-net: support XDP when not more queues
    
    [ Upstream commit 97c2c69e1926260c78c7f1c0b2c987934f1dc7a1 ]
    
    The number of queues implemented by many virtio backends is limited,
    especially some machines have a large number of CPUs. In this case, it
    is often impossible to allocate a separate queue for
    XDP_TX/XDP_REDIRECT, then xdp cannot be loaded to work, even xdp does
    not use the XDP_TX/XDP_REDIRECT.
    
    This patch allows XDP_TX/XDP_REDIRECT to run by reuse the existing SQ
    with __netif_tx_lock() hold when there are not enough queues.
    
    Signed-off-by: Xuan Zhuo <xuanzhuo@linux.alibaba.com>
    Reviewed-by: Dust Li <dust.li@linux.alibaba.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3ed7cf8386c9eec0ad8485bc7f6cf28dfbe2a939
Author: Lahav Schlesinger <lschlesinger@drivenets.com>
Date:   Sun Aug 15 12:00:02 2021 +0000

    vrf: Reset skb conntrack connection on VRF rcv
    
    [ Upstream commit 09e856d54bda5f288ef8437a90ab2b9b3eab83d1 ]
    
    To fix the "reverse-NAT" for replies.
    
    When a packet is sent over a VRF, the POST_ROUTING hooks are called
    twice: Once from the VRF interface, and once from the "actual"
    interface the packet will be sent from:
    1) First SNAT: l3mdev_l3_out() -> vrf_l3_out() -> .. -> vrf_output_direct()
         This causes the POST_ROUTING hooks to run.
    2) Second SNAT: 'ip_output()' calls POST_ROUTING hooks again.
    
    Similarly for replies, first ip_rcv() calls PRE_ROUTING hooks, and
    second vrf_l3_rcv() calls them again.
    
    As an example, consider the following SNAT rule:
    > iptables -t nat -A POSTROUTING -p udp -m udp --dport 53 -j SNAT --to-source 2.2.2.2 -o vrf_1
    
    In this case sending over a VRF will create 2 conntrack entries.
    The first is from the VRF interface, which performs the IP SNAT.
    The second will run the SNAT, but since the "expected reply" will remain
    the same, conntrack randomizes the source port of the packet:
    e..g With a socket bound to 1.1.1.1:10000, sending to 3.3.3.3:53, the conntrack
    rules are:
    udp      17 29 src=2.2.2.2 dst=3.3.3.3 sport=10000 dport=53 packets=1 bytes=68 [UNREPLIED] src=3.3.3.3 dst=2.2.2.2 sport=53 dport=61033 packets=0 bytes=0 mark=0 use=1
    udp      17 29 src=1.1.1.1 dst=3.3.3.3 sport=10000 dport=53 packets=1 bytes=68 [UNREPLIED] src=3.3.3.3 dst=2.2.2.2 sport=53 dport=10000 packets=0 bytes=0 mark=0 use=1
    
    i.e. First SNAT IP from 1.1.1.1 --> 2.2.2.2, and second the src port is
    SNAT-ed from 10000 --> 61033.
    
    But when a reply is sent (3.3.3.3:53 -> 2.2.2.2:61033) only the later
    conntrack entry is matched:
    udp      17 29 src=2.2.2.2 dst=3.3.3.3 sport=10000 dport=53 packets=1 bytes=68 src=3.3.3.3 dst=2.2.2.2 sport=53 dport=61033 packets=1 bytes=49 mark=0 use=1
    udp      17 28 src=1.1.1.1 dst=3.3.3.3 sport=10000 dport=53 packets=1 bytes=68 [UNREPLIED] src=3.3.3.3 dst=2.2.2.2 sport=53 dport=10000 packets=0 bytes=0 mark=0 use=1
    
    And a "port 61033 unreachable" ICMP packet is sent back.
    
    The issue is that when PRE_ROUTING hooks are called from vrf_l3_rcv(),
    the skb already has a conntrack flow attached to it, which means
    nf_conntrack_in() will not resolve the flow again.
    
    This means only the dest port is "reverse-NATed" (61033 -> 10000) but
    the dest IP remains 2.2.2.2, and since the socket is bound to 1.1.1.1 it's
    not received.
    This can be verified by logging the 4-tuple of the packet in '__udp4_lib_rcv()'.
    
    The fix is then to reset the flow when skb is received on a VRF, to let
    conntrack resolve the flow again (which now will hit the earlier flow).
    
    To reproduce: (Without the fix "Got pkt_to_nat_port" will not be printed by
      running 'bash ./repro'):
      $ cat run_in_A1.py
      import logging
      logging.getLogger("scapy.runtime").setLevel(logging.ERROR)
      from scapy.all import *
      import argparse
    
      def get_packet_to_send(udp_dst_port, msg_name):
          return Ether(src='11:22:33:44:55:66', dst=iface_mac)/ \
              IP(src='3.3.3.3', dst='2.2.2.2')/ \
              UDP(sport=53, dport=udp_dst_port)/ \
              Raw(f'{msg_name}\x0012345678901234567890')
    
      parser = argparse.ArgumentParser()
      parser.add_argument('-iface_mac', dest="iface_mac", type=str, required=True,
                          help="From run_in_A3.py")
      parser.add_argument('-socket_port', dest="socket_port", type=str,
                          required=True, help="From run_in_A3.py")
      parser.add_argument('-v1_mac', dest="v1_mac", type=str, required=True,
                          help="From script")
    
      args, _ = parser.parse_known_args()
      iface_mac = args.iface_mac
      socket_port = int(args.socket_port)
      v1_mac = args.v1_mac
    
      print(f'Source port before NAT: {socket_port}')
    
      while True:
          pkts = sniff(iface='_v0', store=True, count=1, timeout=10)
          if 0 == len(pkts):
              print('Something failed, rerun the script :(', flush=True)
              break
          pkt = pkts[0]
          if not pkt.haslayer('UDP'):
              continue
    
          pkt_sport = pkt.getlayer('UDP').sport
          print(f'Source port after NAT: {pkt_sport}', flush=True)
    
          pkt_to_send = get_packet_to_send(pkt_sport, 'pkt_to_nat_port')
          sendp(pkt_to_send, '_v0', verbose=False) # Will not be received
    
          pkt_to_send = get_packet_to_send(socket_port, 'pkt_to_socket_port')
          sendp(pkt_to_send, '_v0', verbose=False)
          break
    
      $ cat run_in_A2.py
      import socket
      import netifaces
    
      print(f"{netifaces.ifaddresses('e00000')[netifaces.AF_LINK][0]['addr']}",
            flush=True)
      s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
      s.setsockopt(socket.SOL_SOCKET, socket.SO_BINDTODEVICE,
                   str('vrf_1' + '\0').encode('utf-8'))
      s.connect(('3.3.3.3', 53))
      print(f'{s. getsockname()[1]}', flush=True)
      s.settimeout(5)
    
      while True:
          try:
              # Periodically send in order to keep the conntrack entry alive.
              s.send(b'a'*40)
              resp = s.recvfrom(1024)
              msg_name = resp[0].decode('utf-8').split('\0')[0]
              print(f"Got {msg_name}", flush=True)
          except Exception as e:
              pass
    
      $ cat repro.sh
      ip netns del A1 2> /dev/null
      ip netns del A2 2> /dev/null
      ip netns add A1
      ip netns add A2
    
      ip -n A1 link add _v0 type veth peer name _v1 netns A2
      ip -n A1 link set _v0 up
    
      ip -n A2 link add e00000 type bond
      ip -n A2 link add lo0 type dummy
      ip -n A2 link add vrf_1 type vrf table 10001
      ip -n A2 link set vrf_1 up
      ip -n A2 link set e00000 master vrf_1
    
      ip -n A2 addr add 1.1.1.1/24 dev e00000
      ip -n A2 link set e00000 up
      ip -n A2 link set _v1 master e00000
      ip -n A2 link set _v1 up
      ip -n A2 link set lo0 up
      ip -n A2 addr add 2.2.2.2/32 dev lo0
    
      ip -n A2 neigh add 1.1.1.10 lladdr 77:77:77:77:77:77 dev e00000
      ip -n A2 route add 3.3.3.3/32 via 1.1.1.10 dev e00000 table 10001
    
      ip netns exec A2 iptables -t nat -A POSTROUTING -p udp -m udp --dport 53 -j \
            SNAT --to-source 2.2.2.2 -o vrf_1
    
      sleep 5
      ip netns exec A2 python3 run_in_A2.py > x &
      XPID=$!
      sleep 5
    
      IFACE_MAC=`sed -n 1p x`
      SOCKET_PORT=`sed -n 2p x`
      V1_MAC=`ip -n A2 link show _v1 | sed -n 2p | awk '{print $2'}`
      ip netns exec A1 python3 run_in_A1.py -iface_mac ${IFACE_MAC} -socket_port \
              ${SOCKET_PORT} -v1_mac ${SOCKET_PORT}
      sleep 5
    
      kill -9 $XPID
      wait $XPID 2> /dev/null
      ip netns del A1
      ip netns del A2
      tail x -n 2
      rm x
      set +x
    
    Fixes: 73e20b761acf ("net: vrf: Add support for PREROUTING rules on vrf device")
    Signed-off-by: Lahav Schlesinger <lschlesinger@drivenets.com>
    Reviewed-by: David Ahern <dsahern@kernel.org>
    Link: https://lore.kernel.org/r/20210815120002.2787653-1-lschlesinger@drivenets.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 447b160289560f90e5fe25d040f6a94b82257d6b
Author: Michael Chan <michael.chan@broadcom.com>
Date:   Sun Aug 15 16:15:37 2021 -0400

    bnxt_en: Add missing DMA memory barriers
    
    [ Upstream commit 828affc27ed43441bd1efdaf4e07e96dd43a0362 ]
    
    Each completion ring entry has a valid bit to indicate that the entry
    contains a valid completion event.  The driver's main poll loop
    __bnxt_poll_work() has the proper dma_rmb() to make sure the valid
    bit of the next entry has been checked before proceeding further.
    But when we call bnxt_rx_pkt() to process the RX event, the RX
    completion event consists of two completion entries and only the
    first entry has been checked to be valid.  We need the same barrier
    after checking the next completion entry.  Add missing dma_rmb()
    barriers in bnxt_rx_pkt() and other similar locations.
    
    Fixes: 67a95e2022c7 ("bnxt_en: Need memory barrier when processing the completion ring.")
    Reported-by: Lance Richardson <lance.richardson@broadcom.com>
    Reviewed-by: Andy Gospodarek <gospo@broadcom.com>
    Reviewed-by: Lance Richardson <lance.richardson@broadcom.com>
    Signed-off-by: Michael Chan <michael.chan@broadcom.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c9566df334d0c3356c80b9ba79161ebb433c16c6
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Fri Aug 13 20:33:27 2021 +0300

    ptp_pch: Restore dependency on PCI
    
    [ Upstream commit 55c8fca1dae1fb0d11deaa21b65a647dedb1bc50 ]
    
    During the swap dependency on PCH_GBE to selection PTP_1588_CLOCK_PCH
    incidentally dropped the implicit dependency on the PCI. Restore it.
    
    Fixes: 18d359ceb044 ("pch_gbe, ptp_pch: Fix the dependency direction between these drivers")
    Reported-by: kernel test robot <lkp@intel.com>
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a73b9aa142691c2ae313980a8734997a78f74b22
Author: Pavel Skripkin <paskripkin@gmail.com>
Date:   Fri Aug 13 18:14:33 2021 +0300

    net: 6pack: fix slab-out-of-bounds in decode_data
    
    [ Upstream commit 19d1532a187669ce86d5a2696eb7275310070793 ]
    
    Syzbot reported slab-out-of bounds write in decode_data().
    The problem was in missing validation checks.
    
    Syzbot's reproducer generated malicious input, which caused
    decode_data() to be called a lot in sixpack_decode(). Since
    rx_count_cooked is only 400 bytes and noone reported before,
    that 400 bytes is not enough, let's just check if input is malicious
    and complain about buffer overrun.
    
    Fail log:
    ==================================================================
    BUG: KASAN: slab-out-of-bounds in drivers/net/hamradio/6pack.c:843
    Write of size 1 at addr ffff888087c5544e by task kworker/u4:0/7
    
    CPU: 0 PID: 7 Comm: kworker/u4:0 Not tainted 5.6.0-rc3-syzkaller #0
    ...
    Workqueue: events_unbound flush_to_ldisc
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x197/0x210 lib/dump_stack.c:118
     print_address_description.constprop.0.cold+0xd4/0x30b mm/kasan/report.c:374
     __kasan_report.cold+0x1b/0x32 mm/kasan/report.c:506
     kasan_report+0x12/0x20 mm/kasan/common.c:641
     __asan_report_store1_noabort+0x17/0x20 mm/kasan/generic_report.c:137
     decode_data.part.0+0x23b/0x270 drivers/net/hamradio/6pack.c:843
     decode_data drivers/net/hamradio/6pack.c:965 [inline]
     sixpack_decode drivers/net/hamradio/6pack.c:968 [inline]
    
    Reported-and-tested-by: syzbot+fc8cd9a673d4577fb2e4@syzkaller.appspotmail.com
    Fixes: 1da177e4c3f4 ("Linux-2.6.12-rc2")
    Signed-off-by: Pavel Skripkin <paskripkin@gmail.com>
    Reviewed-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2bc75713434b548dbe84ba3e4c64c053046b31c5
Author: Jakub Kicinski <kuba@kernel.org>
Date:   Thu Aug 12 14:42:40 2021 -0700

    bnxt: disable napi before canceling DIM
    
    [ Upstream commit 01cca6b9330ac7460de44eeeb3a0607f8aae69ff ]
    
    napi schedules DIM, napi has to be disabled first,
    then DIM canceled.
    
    Noticed while reading the code.
    
    Fixes: 0bc0b97fca73 ("bnxt_en: cleanup DIM work on device shutdown")
    Fixes: 6a8788f25625 ("bnxt_en: add support for software dynamic interrupt moderation")
    Reviewed-by: Michael Chan <michael.chan@broadcom.com>
    Reviewed-by: Edwin Peer <edwin.peer@broadcom.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a9fb0f1559804a07b44fc82dae6a9cb3c3b4de08
Author: Jakub Kicinski <kuba@kernel.org>
Date:   Thu Aug 12 14:42:39 2021 -0700

    bnxt: don't lock the tx queue from napi poll
    
    [ Upstream commit 3c603136c9f82833813af77185618de5af67676c ]
    
    We can't take the tx lock from the napi poll routine, because
    netpoll can poll napi at any moment, including with the tx lock
    already held.
    
    The tx lock is protecting against two paths - the disable
    path, and (as Michael points out) the NETDEV_TX_BUSY case
    which may occur if NAPI completions race with start_xmit
    and both decide to re-enable the queue.
    
    For the disable/ifdown path use synchronize_net() to make sure
    closing the device does not race we restarting the queues.
    Annotate accesses to dev_state against data races.
    
    For the NAPI cleanup vs start_xmit path - appropriate barriers
    are already in place in the main spot where Tx queue is stopped
    but we need to do the same careful dance in the TX_BUSY case.
    
    Fixes: c0c050c58d84 ("bnxt_en: New Broadcom ethernet driver.")
    Reviewed-by: Michael Chan <michael.chan@broadcom.com>
    Reviewed-by: Edwin Peer <edwin.peer@broadcom.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1fe038030cc8b38a656514a3e50ae57ba8bfeb63
Author: Ilya Leoshkevich <iii@linux.ibm.com>
Date:   Thu Aug 12 17:18:10 2021 +0200

    bpf: Clear zext_dst of dead insns
    
    [ Upstream commit 45c709f8c71b525b51988e782febe84ce933e7e0 ]
    
    "access skb fields ok" verifier test fails on s390 with the "verifier
    bug. zext_dst is set, but no reg is defined" message. The first insns
    of the test prog are ...
    
       0:   61 01 00 00 00 00 00 00         ldxw %r0,[%r1+0]
       8:   35 00 00 01 00 00 00 00         jge %r0,0,1
      10:   61 01 00 08 00 00 00 00         ldxw %r0,[%r1+8]
    
    ... and the 3rd one is dead (this does not look intentional to me, but
    this is a separate topic).
    
    sanitize_dead_code() converts dead insns into "ja -1", but keeps
    zext_dst. When opt_subreg_zext_lo32_rnd_hi32() tries to parse such
    an insn, it sees this discrepancy and bails. This problem can be seen
    only with JITs whose bpf_jit_needs_zext() returns true.
    
    Fix by clearning dead insns' zext_dst.
    
    The commits that contributed to this problem are:
    
    1. 5aa5bd14c5f8 ("bpf: add initial suite for selftests"), which
       introduced the test with the dead code.
    2. 5327ed3d44b7 ("bpf: verifier: mark verified-insn with
       sub-register zext flag"), which introduced the zext_dst flag.
    3. 83a2881903f3 ("bpf: Account for BPF_FETCH in
       insn_has_def32()"), which introduced the sanity check.
    4. 9183671af6db ("bpf: Fix leakage under speculation on
       mispredicted branches"), which bisect points to.
    
    It's best to fix this on stable branches that contain the second one,
    since that's the point where the inconsistency was introduced.
    
    Fixes: 5327ed3d44b7 ("bpf: verifier: mark verified-insn with sub-register zext flag")
    Signed-off-by: Ilya Leoshkevich <iii@linux.ibm.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/20210812151811.184086-2-iii@linux.ibm.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 73a45f75a07b0abe92079cace5cb3caa185b5caf
Author: Xie Yongji <xieyongji@bytedance.com>
Date:   Wed Jul 28 21:07:56 2021 +0800

    vhost: Fix the calculation in vhost_overflow()
    
    [ Upstream commit f7ad318ea0ad58ebe0e595e59aed270bb643b29b ]
    
    This fixes the incorrect calculation for integer overflow
    when the last address of iova range is 0xffffffff.
    
    Fixes: ec33d031a14b ("vhost: detect 32 bit integer wrap around")
    Reported-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: Xie Yongji <xieyongji@bytedance.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Link: https://lore.kernel.org/r/20210728130756.97-2-xieyongji@bytedance.com
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b9a59636c4bfc5f8324c8580cb46c4430ed2c4a6
Author: Parav Pandit <parav@nvidia.com>
Date:   Wed Jul 21 17:26:47 2021 +0300

    virtio: Protect vqs list access
    
    [ Upstream commit 0e566c8f0f2e8325e35f6f97e13cde5356b41814 ]
    
    VQs may be accessed to mark the device broken while they are
    created/destroyed. Hence protect the access to the vqs list.
    
    Fixes: e2dcdfe95c0b ("virtio: virtio_break_device() to mark all virtqueues broken.")
    Signed-off-by: Parav Pandit <parav@nvidia.com>
    Link: https://lore.kernel.org/r/20210721142648.1525924-4-parav@nvidia.com
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b264e37b3517c64fa52ef6bc789abb98198b5b25
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Aug 8 16:04:40 2021 -0700

    dccp: add do-while-0 stubs for dccp_pr_debug macros
    
    [ Upstream commit 86aab09a4870bb8346c9579864588c3d7f555299 ]
    
    GCC complains about empty macros in an 'if' statement, so convert
    them to 'do {} while (0)' macros.
    
    Fixes these build warnings:
    
    net/dccp/output.c: In function 'dccp_xmit_packet':
    ../net/dccp/output.c:283:71: warning: suggest braces around empty body in an 'if' statement [-Wempty-body]
      283 |                 dccp_pr_debug("transmit_skb() returned err=%d\n", err);
    net/dccp/ackvec.c: In function 'dccp_ackvec_update_old':
    ../net/dccp/ackvec.c:163:80: warning: suggest braces around empty body in an 'else' statement [-Wempty-body]
      163 |                                               (unsigned long long)seqno, state);
    
    Fixes: dc841e30eaea ("dccp: Extend CCID packet dequeueing interface")
    Fixes: 380240864451 ("dccp ccid-2: Update code for the Ack Vector input/registration routine")
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Cc: dccp@vger.kernel.org
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jakub Kicinski <kuba@kernel.org>
    Cc: Gerrit Renker <gerrit@erg.abdn.ac.uk>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9112ebc2990af22ee80c3f8bcd911a2e5e9414f0
Author: Marek Behún <kabel@kernel.org>
Date:   Thu Jul 1 00:56:01 2021 +0200

    cpufreq: armada-37xx: forbid cpufreq for 1.2 GHz variant
    
    [ Upstream commit 484f2b7c61b9ae58cc00c5127bcbcd9177af8dfe ]
    
    The 1.2 GHz variant of the Armada 3720 SOC is unstable with DVFS: when
    the SOC boots, the WTMI firmware sets clocks and AVS values that work
    correctly with 1.2 GHz CPU frequency, but random crashes occur once
    cpufreq driver starts scaling.
    
    We do not know currently what is the reason:
    - it may be that the voltage value for L0 for 1.2 GHz variant provided
      by the vendor in the OTP is simply incorrect when scaling is used,
    - it may be that some delay is needed somewhere,
    - it may be something else.
    
    The most sane solution now seems to be to simply forbid the cpufreq
    driver on 1.2 GHz variant.
    
    Signed-off-by: Marek Behún <kabel@kernel.org>
    Fixes: 92ce45fb875d ("cpufreq: Add DVFS support for Armada 37xx")
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit cb9a9d5fe636492d6b26fc0de267f8ad50724ed6
Author: Frank Wunderlich <frank-w@public-files.de>
Date:   Sat Jul 31 09:47:37 2021 +0200

    iommu: Check if group is NULL before remove device
    
    [ Upstream commit 5aa95d8834e07907e64937d792c12ffef7fb271f ]
    
    If probe_device is failing, iommu_group is not initialized because
    iommu_group_add_device is not reached, so freeing it will result
    in NULL pointer access.
    
    iommu_bus_init
      ->bus_iommu_probe
          ->probe_iommu_group in for each:/* return -22 in fail case */
              ->iommu_probe_device
                  ->__iommu_probe_device       /* return -22 here.*/
                      -> ops->probe_device          /* return -22 here.*/
                      -> iommu_group_get_for_dev
                            -> ops->device_group
                            -> iommu_group_add_device //good case
      ->remove_iommu_group  //in fail case, it will remove group
         ->iommu_release_device
             ->iommu_group_remove_device // here we don't have group
    
    In my case ops->probe_device (mtk_iommu_probe_device from
    mtk_iommu_v1.c) is due to failing fwspec->ops mismatch.
    
    Fixes: d72e31c93746 ("iommu: IOMMU Groups")
    Signed-off-by: Frank Wunderlich <frank-w@public-files.de>
    Link: https://lore.kernel.org/r/20210731074737.4573-1-linux@fw-web.de
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 911a8141efddab3cde50a00d38aa4e1427c2da6f
Author: Ole Bjørn Midtbø <omidtbo@cisco.com>
Date:   Sat Oct 17 13:15:44 2020 +0200

    Bluetooth: hidp: use correct wait queue when removing ctrl_wait
    
    [ Upstream commit cca342d98bef68151a80b024f7bf5f388d1fbdea ]
    
    A different wait queue was used when removing ctrl_wait than when adding
    it. This effectively made the remove operation without locking compared
    to other operations on the wait queue ctrl_wait was part of. This caused
    issues like below where dead000000000100 is LIST_POISON1 and
    dead000000000200 is LIST_POISON2.
    
     list_add corruption. next->prev should be prev (ffffffc1b0a33a08), \
            but was dead000000000200. (next=ffffffc03ac77de0).
     ------------[ cut here ]------------
     CPU: 3 PID: 2138 Comm: bluetoothd Tainted: G           O    4.4.238+ #9
     ...
     ---[ end trace 0adc2158f0646eac ]---
     Call trace:
     [<ffffffc000443f78>] __list_add+0x38/0xb0
     [<ffffffc0000f0d04>] add_wait_queue+0x4c/0x68
     [<ffffffc00020eecc>] __pollwait+0xec/0x100
     [<ffffffc000d1556c>] bt_sock_poll+0x74/0x200
     [<ffffffc000bdb8a8>] sock_poll+0x110/0x128
     [<ffffffc000210378>] do_sys_poll+0x220/0x480
     [<ffffffc0002106f0>] SyS_poll+0x80/0x138
     [<ffffffc00008510c>] __sys_trace_return+0x0/0x4
    
     Unable to handle kernel paging request at virtual address dead000000000100
     ...
     CPU: 4 PID: 5387 Comm: kworker/u15:3 Tainted: G        W  O    4.4.238+ #9
     ...
     Call trace:
      [<ffffffc0000f079c>] __wake_up_common+0x7c/0xa8
      [<ffffffc0000f0818>] __wake_up+0x50/0x70
      [<ffffffc000be11b0>] sock_def_wakeup+0x58/0x60
      [<ffffffc000de5e10>] l2cap_sock_teardown_cb+0x200/0x224
      [<ffffffc000d3f2ac>] l2cap_chan_del+0xa4/0x298
      [<ffffffc000d45ea0>] l2cap_conn_del+0x118/0x198
      [<ffffffc000d45f8c>] l2cap_disconn_cfm+0x6c/0x78
      [<ffffffc000d29934>] hci_event_packet+0x564/0x2e30
      [<ffffffc000d19b0c>] hci_rx_work+0x10c/0x360
      [<ffffffc0000c2218>] process_one_work+0x268/0x460
      [<ffffffc0000c2678>] worker_thread+0x268/0x480
      [<ffffffc0000c94e0>] kthread+0x118/0x128
      [<ffffffc000085070>] ret_from_fork+0x10/0x20
      ---[ end trace 0adc2158f0646ead ]---
    
    Signed-off-by: Ole Bjørn Midtbø <omidtbo@cisco.com>
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5b14c1f16e2d11b093ccc7c74aabed8199d05cda
Author: Bing Guo <bing.guo@amd.com>
Date:   Mon Jul 19 18:24:06 2021 -0400

    drm/amd/display: Fix Dynamic bpp issue with 8K30 with Navi 1X
    
    [ Upstream commit 06050a0f01dbac2ca33145ef19a72041206ea983 ]
    
    Why:
    In DCN2x, HW doesn't automatically divide MASTER_UPDATE_LOCK_DB_X
    by the number of pipes ODM Combined.
    
    How:
    Set MASTER_UPDATE_LOCK_DB_X to the value that is adjusted by the
    number of pipes ODM Combined.
    
    Reviewed-by: Martin Leung <martin.leung@amd.com>
    Acked-by: Aurabindo Pillai <aurabindo.pillai@amd.com>
    Signed-off-by: Bing Guo <bing.guo@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f92dc3a89dd8d7b526c741c3df428cecf568b3a1
Author: Ivan T. Ivanov <iivanov@suse.de>
Date:   Wed Aug 4 11:13:39 2021 +0300

    net: usb: lan78xx: don't modify phy_device state concurrently
    
    [ Upstream commit 6b67d4d63edece1033972214704c04f36c5be89a ]
    
    Currently phy_device state could be left in inconsistent state shown
    by following alert message[1]. This is because phy_read_status could
    be called concurrently from lan78xx_delayedwork, phy_state_machine and
    __ethtool_get_link. Fix this by making sure that phy_device state is
    updated atomically.
    
    [1] lan78xx 1-1.1.1:1.0 eth0: No phy led trigger registered for speed(-1)
    
    Signed-off-by: Ivan T. Ivanov <iivanov@suse.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit be7043679967516f41c576f36f9fafeffd737484
Author: Sudeep Holla <sudeep.holla@arm.com>
Date:   Sat Jun 26 02:01:03 2021 +0200

    ARM: dts: nomadik: Fix up interrupt controller node names
    
    [ Upstream commit 47091f473b364c98207c4def197a0ae386fc9af1 ]
    
    Once the new schema interrupt-controller/arm,vic.yaml is added, we get
    the below warnings:
    
            arch/arm/boot/dts/ste-nomadik-nhk15.dt.yaml:
            intc@10140000: $nodename:0: 'intc@10140000' does not match
            '^interrupt-controller(@[0-9a-f,]+)*$'
    
    Fix the node names for the interrupt controller to conform
    to the standard node name interrupt-controller@..
    
    Signed-off-by: Sudeep Holla <sudeep.holla@arm.com>
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Link: https://lore.kernel.org/r/20210617210825.3064367-2-sudeep.holla@arm.com
    Link: https://lore.kernel.org/r/20210626000103.830184-1-linus.walleij@linaro.org'
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 69aa1a1a569f5c6d554b59352130ef363342ed4c
Author: lijinlin <lijinlin3@huawei.com>
Date:   Tue Jul 27 11:44:55 2021 +0800

    scsi: core: Fix capacity set to zero after offlinining device
    
    [ Upstream commit f0f82e2476f6adb9c7a0135cfab8091456990c99 ]
    
    After adding physical volumes to a volume group through vgextend, the
    kernel will rescan the partitions. This in turn will cause the device
    capacity to be queried.
    
    If the device status is set to offline through sysfs at this time, READ
    CAPACITY command will return a result which the host byte is
    DID_NO_CONNECT, and the capacity of the device will be set to zero in
    read_capacity_error(). After setting device status back to running, the
    capacity of the device will remain stuck at zero.
    
    Fix this issue by rescanning device when the device state changes to
    SDEV_RUNNING.
    
    Link: https://lore.kernel.org/r/20210727034455.1494960-1-lijinlin3@huawei.com
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: lijinlin <lijinlin3@huawei.com>
    Signed-off-by: Wu Bo <wubo40@huawei.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 935de7ec7a4d31cb275083de11d5ef52749524e1
Author: Sreekanth Reddy <sreekanth.reddy@broadcom.com>
Date:   Mon Jul 26 17:24:02 2021 +0530

    scsi: core: Avoid printing an error if target_alloc() returns -ENXIO
    
    [ Upstream commit 70edd2e6f652f67d854981fd67f9ad0f1deaea92 ]
    
    Avoid printing a 'target allocation failed' error if the driver
    target_alloc() callback function returns -ENXIO. This return value
    indicates that the corresponding H:C:T:L entry is empty.
    
    Removing this error reduces the scan time if the user issues SCAN_WILD_CARD
    scan operation through sysfs parameter on a host with a lot of empty
    H:C:T:L entries.
    
    Avoiding the printk on -ENXIO matches the behavior of the other callback
    functions during scanning.
    
    Link: https://lore.kernel.org/r/20210726115402.1936-1-sreekanth.reddy@broadcom.com
    Signed-off-by: Sreekanth Reddy <sreekanth.reddy@broadcom.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7a721a1e18854a0b2ca4335aea1b898abccc7ea5
Author: Ye Bin <yebin10@huawei.com>
Date:   Wed Jan 13 14:31:03 2021 +0800

    scsi: scsi_dh_rdac: Avoid crash during rdac_bus_attach()
    
    [ Upstream commit bc546c0c9abb3bb2fb46866b3d1e6ade9695a5f6 ]
    
    The following BUG_ON() was observed during RDAC scan:
    
    [595952.944297] kernel BUG at drivers/scsi/device_handler/scsi_dh_rdac.c:427!
    [595952.951143] Internal error: Oops - BUG: 0 [#1] SMP
    ......
    [595953.251065] Call trace:
    [595953.259054]  check_ownership+0xb0/0x118
    [595953.269794]  rdac_bus_attach+0x1f0/0x4b0
    [595953.273787]  scsi_dh_handler_attach+0x3c/0xe8
    [595953.278211]  scsi_dh_add_device+0xc4/0xe8
    [595953.282291]  scsi_sysfs_add_sdev+0x8c/0x2a8
    [595953.286544]  scsi_probe_and_add_lun+0x9fc/0xd00
    [595953.291142]  __scsi_scan_target+0x598/0x630
    [595953.295395]  scsi_scan_target+0x120/0x130
    [595953.299481]  fc_user_scan+0x1a0/0x1c0 [scsi_transport_fc]
    [595953.304944]  store_scan+0xb0/0x108
    [595953.308420]  dev_attr_store+0x44/0x60
    [595953.312160]  sysfs_kf_write+0x58/0x80
    [595953.315893]  kernfs_fop_write+0xe8/0x1f0
    [595953.319888]  __vfs_write+0x60/0x190
    [595953.323448]  vfs_write+0xac/0x1c0
    [595953.326836]  ksys_write+0x74/0xf0
    [595953.330221]  __arm64_sys_write+0x24/0x30
    
    Code is in check_ownership:
    
            list_for_each_entry_rcu(tmp, &h->ctlr->dh_list, node) {
                    /* h->sdev should always be valid */
                    BUG_ON(!tmp->sdev);
                    tmp->sdev->access_state = access_state;
            }
    
            rdac_bus_attach
                    initialize_controller
                            list_add_rcu(&h->node, &h->ctlr->dh_list);
                            h->sdev = sdev;
    
            rdac_bus_detach
                    list_del_rcu(&h->node);
                    h->sdev = NULL;
    
    Fix the race between rdac_bus_attach() and rdac_bus_detach() where h->sdev
    is NULL when processing the RDAC attach.
    
    Link: https://lore.kernel.org/r/20210113063103.2698953-1-yebin10@huawei.com
    Reviewed-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Ye Bin <yebin10@huawei.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9900e06ae6e696209f17b4162ed521e3db45e919
Author: Harshvardhan Jha <harshvardhan.jha@oracle.com>
Date:   Thu Jul 8 13:16:42 2021 +0530

    scsi: megaraid_mm: Fix end of loop tests for list_for_each_entry()
    
    [ Upstream commit 77541f78eadfe9fdb018a7b8b69f0f2af2cf4b82 ]
    
    The list_for_each_entry() iterator, "adapter" in this code, can never be
    NULL.  If we exit the loop without finding the correct adapter then
    "adapter" points invalid memory that is an offset from the list head.  This
    will eventually lead to memory corruption and presumably a kernel crash.
    
    Link: https://lore.kernel.org/r/20210708074642.23599-1-harshvardhan.jha@oracle.com
    Acked-by: Sumit Saxena <sumit.saxena@broadcom.com>
    Signed-off-by: Harshvardhan Jha <harshvardhan.jha@oracle.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e37cf26bd56d80f1296db73572af630f1717a538
Author: Peter Ujfalusi <peter.ujfalusi@gmail.com>
Date:   Sat Jul 17 22:00:21 2021 +0300

    dmaengine: of-dma: router_xlate to return -EPROBE_DEFER if controller is not yet available
    
    [ Upstream commit eda97cb095f2958bbad55684a6ca3e7d7af0176a ]
    
    If the router_xlate can not find the controller in the available DMA
    devices then it should return with -EPORBE_DEFER in a same way as the
    of_dma_request_slave_channel() does.
    
    The issue can be reproduced if the event router is registered before the
    DMA controller itself and a driver would request for a channel before the
    controller is registered.
    In of_dma_request_slave_channel():
    1. of_dma_find_controller() would find the dma_router
    2. ofdma->of_dma_xlate() would fail and returned NULL
    3. -ENODEV is returned as error code
    
    with this patch we would return in this case the correct -EPROBE_DEFER and
    the client can try to request the channel later.
    
    Signed-off-by: Peter Ujfalusi <peter.ujfalusi@gmail.com>
    Link: https://lore.kernel.org/r/20210717190021.21897-1-peter.ujfalusi@gmail.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 12d1322d93a6346483f5dbdd4095d0b64fb1313e
Author: Dave Gerlach <d-gerlach@ti.com>
Date:   Fri Jul 16 09:07:30 2021 -0700

    ARM: dts: am43x-epos-evm: Reduce i2c0 bus speed for tps65218
    
    [ Upstream commit 20a6b3fd8e2e2c063b25fbf2ee74d86b898e5087 ]
    
    Based on the latest timing specifications for the TPS65218 from the data
    sheet, http://www.ti.com/lit/ds/symlink/tps65218.pdf, document SLDS206
    from November 2014, we must change the i2c bus speed to better fit within
    the minimum high SCL time required for proper i2c transfer.
    
    When running at 400khz, measurements show that SCL spends
    0.8125 uS/1.666 uS high/low which violates the requirement for minimum
    high period of SCL provided in datasheet Table 7.6 which is 1 uS.
    Switching to 100khz gives us 5 uS/5 uS high/low which both fall above
    the minimum given values for 100 khz, 4.0 uS/4.7 uS high/low.
    
    Without this patch occasionally a voltage set operation from the kernel
    will appear to have worked but the actual voltage reflected on the PMIC
    will not have updated, causing problems especially with cpufreq that may
    update to a higher OPP without actually raising the voltage on DCDC2,
    leading to a hang.
    
    Signed-off-by: Dave Gerlach <d-gerlach@ti.com>
    Signed-off-by: Kevin Hilman <khilman@baylibre.com>
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 11145efd295b0a65fcdadae398f4043300b83567
Author: Yu Kuai <yukuai3@huawei.com>
Date:   Tue Jul 6 20:45:21 2021 +0800

    dmaengine: usb-dmac: Fix PM reference leak in usb_dmac_probe()
    
    [ Upstream commit 1da569fa7ec8cb0591c74aa3050d4ea1397778b4 ]
    
    pm_runtime_get_sync will increment pm usage counter even it failed.
    Forgetting to putting operation will result in reference leak here.
    Fix it by moving the error_pm label above the pm_runtime_put() in
    the error path.
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Yu Kuai <yukuai3@huawei.com>
    Link: https://lore.kernel.org/r/20210706124521.1371901-1-yukuai3@huawei.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9c97a0539288d29be2fc49465fc1f5d782aa318a
Author: Adrian Larumbe <adrian.martinezlarumbe@imgtec.com>
Date:   Wed Jul 7 00:43:38 2021 +0100

    dmaengine: xilinx_dma: Fix read-after-free bug when terminating transfers
    
    [ Upstream commit 7dd2dd4ff9f3abda601f22b9d01441a0869d20d7 ]
    
    When user calls dmaengine_terminate_sync, the driver will clean up any
    remaining descriptors for all the pending or active transfers that had
    previously been submitted. However, this might happen whilst the tasklet is
    invoking the DMA callback for the last finished transfer, so by the time it
    returns and takes over the channel's spinlock, the list of completed
    descriptors it was traversing is no longer valid. This leads to a
    read-after-free situation.
    
    Fix it by signalling whether a user-triggered termination has happened by
    means of a boolean variable.
    
    Signed-off-by: Adrian Larumbe <adrian.martinezlarumbe@imgtec.com>
    Link: https://lore.kernel.org/r/20210706234338.7696-3-adrian.martinezlarumbe@imgtec.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fc566b5a21f5bcdc8355906bd4c43bf45dd4fa52
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Mon Jun 7 11:23:07 2021 -0400

    USB: core: Avoid WARNings for 0-length descriptor requests
    
    [ Upstream commit 60dfe484cef45293e631b3a6e8995f1689818172 ]
    
    The USB core has utility routines to retrieve various types of
    descriptors.  These routines will now provoke a WARN if they are asked
    to retrieve 0 bytes (USB "receive" requests must not have zero
    length), so avert this by checking the size argument at the start.
    
    CC: Johan Hovold <johan@kernel.org>
    Reported-and-tested-by: syzbot+7dbcd9ff34dc4ed45240@syzkaller.appspotmail.com
    Reviewed-by: Johan Hovold <johan@kernel.org>
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Link: https://lore.kernel.org/r/20210607152307.GD1768031@rowland.harvard.edu
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1bd505c814ccca797f291a3f788b4f695ee1b95b
Author: Pavel Skripkin <paskripkin@gmail.com>
Date:   Mon Mar 1 21:38:26 2021 +0100

    media: drivers/media/usb: fix memory leak in zr364xx_probe
    
    [ Upstream commit 9c39be40c0155c43343f53e3a439290c0fec5542 ]
    
    syzbot reported memory leak in zr364xx_probe()[1].
    The problem was in invalid error handling order.
    All error conditions rigth after v4l2_ctrl_handler_init()
    must call v4l2_ctrl_handler_free().
    
    Reported-by: syzbot+efe9aefc31ae1e6f7675@syzkaller.appspotmail.com
    Signed-off-by: Pavel Skripkin <paskripkin@gmail.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    Signed-off-by: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 705660a6d98d22051addf7b849f6a15bec889967
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Jan 21 07:44:00 2021 +0100

    media: zr364xx: fix memory leaks in probe()
    
    [ Upstream commit ea354b6ddd6f09be29424f41fa75a3e637fea234 ]
    
    Syzbot discovered that the probe error handling doesn't clean up the
    resources allocated in zr364xx_board_init().  There are several
    related bugs in this code so I have re-written the error handling.
    
    1)  Introduce a new function zr364xx_board_uninit() which cleans up
        the resources in zr364xx_board_init().
    2)  In zr364xx_board_init() if the call to zr364xx_start_readpipe()
        fails then release the "cam->buffer.frame[i].lpvbits" memory
        before returning.  This way every function either allocates
        everything successfully or it cleans up after itself.
    3)  Re-write the probe function so that each failure path goto frees
        the most recent allocation.  That way we don't free anything
        before it has been allocated and we can also verify that
        everything is freed.
    4)  Originally, in the probe function the "cam->v4l2_dev.release"
        pointer was set to "zr364xx_release" near the start but I moved
        that assignment to the end, after everything had succeeded.  The
        release function was never actually called during the probe cleanup
        process, but with this change I wanted to make it clear that we
        don't want to call zr364xx_release() until everything is
        allocated successfully.
    
    Next I re-wrote the zr364xx_release() function.  Ideally this would
    have been a simple matter of copy and pasting the cleanup code from
    probe and adding an additional call to video_unregister_device().  But
    there are a couple quirks to note.
    
    1)  The probe function does not call videobuf_mmap_free() and I don't
        know where the videobuf_mmap is allocated.  I left the code as-is to
        avoid introducing a bug in code I don't understand.
    2)  The zr364xx_board_uninit() has a call to zr364xx_stop_readpipe()
        which is a change from the original behavior with regards to
        unloading the driver.  Calling zr364xx_stop_readpipe() on a stopped
        pipe is not a problem so this is safe and is potentially a bugfix.
    
    Reported-by: syzbot+b4d54814b339b5c6bbd4@syzkaller.appspotmail.com
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    Signed-off-by: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 79dff2a3f41aa15f31d3307b04049a798f784a1c
Author: Evgeny Novikov <novikov@ispras.ru>
Date:   Tue Oct 6 19:21:22 2020 +0200

    media: zr364xx: propagate errors from zr364xx_start_readpipe()
    
    [ Upstream commit af0321a5be3e5647441eb6b79355beaa592df97a ]
    
    zr364xx_start_readpipe() can fail but callers do not care about that.
    This can result in various negative consequences. The patch adds missed
    error handling.
    
    Found by Linux Driver Verification project (linuxtesting.org).
    
    Signed-off-by: Evgeny Novikov <novikov@ispras.ru>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    Signed-off-by: Mauro Carvalho Chehab <mchehab+huawei@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7305d6d4078f8a74935457bc9fbea71c733261ff
Author: Andreas Persson <andreasp56@outlook.com>
Date:   Mon Jul 12 09:54:52 2021 +0200

    mtd: cfi_cmdset_0002: fix crash when erasing/writing AMD cards
    
    commit 2394e628738933aa014093d93093030f6232946d upstream.
    
    Erasing an AMD linear flash card (AM29F016D) crashes after the first
    sector has been erased. Likewise, writing to it crashes after two bytes
    have been written. The reason is a missing check for a null pointer -
    the cmdset_priv field is not set for this type of card.
    
    Fixes: 4844ef80305d ("mtd: cfi_cmdset_0002: Add support for polling status register")
    Signed-off-by: Andreas Persson <andreasp56@outlook.com>
    Signed-off-by: Miquel Raynal <miquel.raynal@bootlin.com>
    Link: https://lore.kernel.org/linux-mtd/DB6P189MB05830B3530B8087476C5CFE4C1159@DB6P189MB0583.EURP189.PROD.OUTLOOK.COM
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 23f77ad13f8176314b7c51f71b9ac7c5c6d10b7b
Author: Jouni Malinen <jouni@codeaurora.org>
Date:   Mon Dec 14 19:21:18 2020 +0200

    ath9k: Postpone key cache entry deletion for TXQ frames reference it
    
    commit ca2848022c12789685d3fab3227df02b863f9696 upstream.
    
    Do not delete a key cache entry that is still being referenced by
    pending frames in TXQs. This avoids reuse of the key cache entry while a
    frame might still be transmitted using it.
    
    To avoid having to do any additional operations during the main TX path
    operations, track pending key cache entries in a new bitmap and check
    whether any pending entries can be deleted before every new key
    add/remove operation. Also clear any remaining entries when stopping the
    interface.
    
    Signed-off-by: Jouni Malinen <jouni@codeaurora.org>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20201214172118.18100-6-jouni@codeaurora.org
    Cc: Pali Rohár <pali@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c6feaf806da6a0deecc2fe41adb3443cdecba347
Author: Jouni Malinen <jouni@codeaurora.org>
Date:   Mon Dec 14 19:21:17 2020 +0200

    ath: Modify ath_key_delete() to not need full key entry
    
    commit 144cd24dbc36650a51f7fe3bf1424a1432f1f480 upstream.
    
    tkip_keymap can be used internally to avoid the reference to key->cipher
    and with this, only the key index value itself is needed. This allows
    ath_key_delete() call to be postponed to be handled after the upper
    layer STA and key entry have already been removed. This is needed to
    make ath9k key cache management safer.
    
    Signed-off-by: Jouni Malinen <jouni@codeaurora.org>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20201214172118.18100-5-jouni@codeaurora.org
    Cc: Pali Rohár <pali@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b7d593705eb4f0655a70f0207f573fb1edb80bda
Author: Jouni Malinen <jouni@codeaurora.org>
Date:   Mon Dec 14 19:21:16 2020 +0200

    ath: Export ath_hw_keysetmac()
    
    commit d2d3e36498dd8e0c83ea99861fac5cf9e8671226 upstream.
    
    ath9k is going to use this for safer management of key cache entries.
    
    Signed-off-by: Jouni Malinen <jouni@codeaurora.org>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20201214172118.18100-4-jouni@codeaurora.org
    Cc: Pali Rohár <pali@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit add283e2517a90468ce223465e0f4360128bb650
Author: Jouni Malinen <jouni@codeaurora.org>
Date:   Mon Dec 14 19:21:15 2020 +0200

    ath9k: Clear key cache explicitly on disabling hardware
    
    commit 73488cb2fa3bb1ef9f6cf0d757f76958bd4deaca upstream.
    
    Now that ath/key.c may not be explicitly clearing keys from the key
    cache, clear all key cache entries when disabling hardware to make sure
    no keys are left behind beyond this point.
    
    Signed-off-by: Jouni Malinen <jouni@codeaurora.org>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20201214172118.18100-3-jouni@codeaurora.org
    Cc: Pali Rohár <pali@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c049ce432b37a51a0da005314ac32e5d9324ccf
Author: Jouni Malinen <jouni@codeaurora.org>
Date:   Mon Dec 14 19:21:14 2020 +0200

    ath: Use safer key clearing with key cache entries
    
    commit 56c5485c9e444c2e85e11694b6c44f1338fc20fd upstream.
    
    It is possible for there to be pending frames in TXQs with a reference
    to the key cache entry that is being deleted. If such a key cache entry
    is cleared, those pending frame in TXQ might get transmitted without
    proper encryption. It is safer to leave the previously used key into the
    key cache in such cases. Instead, only clear the MAC address to prevent
    RX processing from using this key cache entry.
    
    This is needed in particularly in AP mode where the TXQs cannot be
    flushed on station disconnection. This change alone may not be able to
    address all cases where the key cache entry might get reused for other
    purposes immediately (the key cache entry should be released for reuse
    only once the TXQs do not have any remaining references to them), but
    this makes it less likely to get unprotected frames and the more
    complete changes may end up being significantly more complex.
    
    Signed-off-by: Jouni Malinen <jouni@codeaurora.org>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20201214172118.18100-2-jouni@codeaurora.org
    Cc: Pali Rohár <pali@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 172b91bbbb49f180e60e206eb85a45b8462e0dc0
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 18 16:18:25 2021 +0200

    x86/fpu: Make init_fpstate correct with optimized XSAVE
    
    commit f9dfb5e390fab2df9f7944bb91e7705aba14cd26 upstream.
    
    The XSAVE init code initializes all enabled and supported components with
    XRSTOR(S) to init state. Then it XSAVEs the state of the components back
    into init_fpstate which is used in several places to fill in the init state
    of components.
    
    This works correctly with XSAVE, but not with XSAVEOPT and XSAVES because
    those use the init optimization and skip writing state of components which
    are in init state. So init_fpstate.xsave still contains all zeroes after
    this operation.
    
    There are two ways to solve that:
    
       1) Use XSAVE unconditionally, but that requires to reshuffle the buffer when
          XSAVES is enabled because XSAVES uses compacted format.
    
       2) Save the components which are known to have a non-zero init state by other
          means.
    
    Looking deeper, #2 is the right thing to do because all components the
    kernel supports have all-zeroes init state except the legacy features (FP,
    SSE). Those cannot be hard coded because the states are not identical on all
    CPUs, but they can be saved with FXSAVE which avoids all conditionals.
    
    Use FXSAVE to save the legacy FP/SSE components in init_fpstate along with
    a BUILD_BUG_ON() which reminds developers to validate that a newly added
    component has all zeroes init state. As a bonus remove the now unused
    copy_xregs_to_kernel_booting() crutch.
    
    The XSAVE and reshuffle method can still be implemented in the unlikely
    case that components are added which have a non-zero init state and no
    other means to save them. For now, FXSAVE is just simple and good enough.
    
      [ bp: Fix a typo or two in the text. ]
    
    Fixes: 6bad06b76892 ("x86, xsave: Use xsaveopt in context-switch path when supported")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20210618143444.587311343@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 81d152c8daf835af0cf55b3ce3dd1449b4fcf88e
Author: Ritesh Harjani <riteshh@linux.ibm.com>
Date:   Tue May 5 17:43:14 2020 +0200

    ext4: fix EXT4_MAX_LOGICAL_BLOCK macro
    
    commit 175efa81feb8405676e0136d97b10380179c92e0 upstream.
    
    ext4 supports max number of logical blocks in a file to be 0xffffffff.
    (This is since ext4_extent's ee_block is __le32).
    This means that EXT4_MAX_LOGICAL_BLOCK should be 0xfffffffe (starting
    from 0 logical offset). This patch fixes this.
    
    The issue was seen when ext4 moved to iomap_fiemap API and when
    overlayfs was mounted on top of ext4. Since overlayfs was missing
    filemap_check_ranges(), so it could pass a arbitrary huge length which
    lead to overflow of map.m_len logic.
    
    This patch fixes that.
    
    Fixes: d3b6f23f7167 ("ext4: move ext4_fiemap to use iomap framework")
    Reported-by: syzbot+77fa5bdb65cc39711820@syzkaller.appspotmail.com
    Signed-off-by: Ritesh Harjani <riteshh@linux.ibm.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Link: https://lore.kernel.org/r/20200505154324.3226743-2-hch@lst.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: George Kennedy <george.kennedy@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
