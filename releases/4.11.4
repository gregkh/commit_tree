commit 553c942bef3fb0b70d4e2d20e883343c06455368
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jun 7 12:10:31 2017 +0200

    Linux 4.11.4

commit b5ff97c77487869355fb6eafe79882e6e55ed498
Author: Jan Kara <jack@suse.cz>
Date:   Thu May 18 16:36:23 2017 -0700

    xfs: Fix off-by-in in loop termination in xfs_find_get_desired_pgoff()
    
    commit d7fd24257aa60316bf81093f7f909dc9475ae974 upstream.
    
    There is an off-by-one error in loop termination conditions in
    xfs_find_get_desired_pgoff() since 'end' may index a page beyond end of
    desired range if 'endoff' is page aligned. It doesn't have any visible
    effects but still it is good to fix it.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d514c634a4f267b98463b43bf091fb764afbadf7
Author: Eric Sandeen <sandeen@sandeen.net>
Date:   Mon May 22 19:54:10 2017 -0700

    xfs: fix unaligned access in xfs_btree_visit_blocks
    
    commit a4d768e702de224cc85e0c8eac9311763403b368 upstream.
    
    This structure copy was throwing unaligned access warnings on sparc64:
    
    Kernel unaligned access at TPC[1043c088] xfs_btree_visit_blocks+0x88/0xe0 [xfs]
    
    xfs_btree_copy_ptrs does a memcpy, which avoids it.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fff5729ce2b2e6fb03f66049f06340d17dbb9529
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Mon May 15 19:16:15 2017 -0700

    xfs: avoid mount-time deadlock in CoW extent recovery
    
    commit 3ecb3ac7b950ff8f6c6a61e8b7b0d6e3546429a0 upstream.
    
    If a malicious user corrupts the refcount btree to cause a cycle between
    different levels of the tree, the next mount attempt will deadlock in
    the CoW recovery routine while grabbing buffer locks.  We can use the
    ability to re-grab a buffer that was previous locked to a transaction to
    avoid deadlocks, so do that here.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ecb42615267f2ac94aca35642ee174a0d79eedbf
Author: Christoph Hellwig <hch@lst.de>
Date:   Sat Jun 3 15:18:31 2017 +0200

    xfs: xfs_trans_alloc_empty
    
    This is a partial cherry-pick of commit e89c041338
    ("xfs: implement the GETFSMAP ioctl"), which also adds this helper, and
    a great example of why feature patches should be properly split into
    their parts.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    [hch: split from the larger patch for -stable]
    Signed-off-by: Christoph Hellwig <hch@lst.de>

commit 2e08bd63dc7d7dc5026d546ff3c7fe52394dfc5b
Author: Zorro Lang <zlang@redhat.com>
Date:   Mon May 15 08:40:02 2017 -0700

    xfs: bad assertion for delalloc an extent that start at i_size
    
    commit 892d2a5f705723b2cb488bfb38bcbdcf83273184 upstream.
    
    By run fsstress long enough time enough in RHEL-7, I find an
    assertion failure (harder to reproduce on linux-4.11, but problem
    is still there):
    
      XFS: Assertion failed: (iflags & BMV_IF_DELALLOC) != 0, file: fs/xfs/xfs_bmap_util.c
    
    The assertion is in xfs_getbmap() funciton:
    
      if (map[i].br_startblock == DELAYSTARTBLOCK &&
    -->   map[i].br_startoff <= XFS_B_TO_FSB(mp, XFS_ISIZE(ip)))
              ASSERT((iflags & BMV_IF_DELALLOC) != 0);
    
    When map[i].br_startoff == XFS_B_TO_FSB(mp, XFS_ISIZE(ip)), the
    startoff is just at EOF. But we only need to make sure delalloc
    extents that are within EOF, not include EOF.
    
    Signed-off-by: Zorro Lang <zlang@redhat.com>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2dc6e27120c2fcb3738490fa688e85a19457a2c2
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Fri May 12 10:44:08 2017 -0700

    xfs: BMAPX shouldn't barf on inline-format directories
    
    commit 6eadbf4c8ba816c10d1c97bed9aa861d9fd17809 upstream.
    
    When we're fulfilling a BMAPX request, jump out early if the data fork
    is in local format.  This prevents us from hitting a debugging check in
    bmapi_read and barfing errors back to userspace.  The on-disk extent
    count check later isn't sufficient for IF_DELALLOC mode because da
    extents are in memory and not on disk.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1ae26380c860e76237e2d41bfba3fd01119f21b4
Author: Brian Foster <bfoster@redhat.com>
Date:   Fri May 12 10:44:08 2017 -0700

    xfs: fix indlen accounting error on partial delalloc conversion
    
    commit 0daaecacb83bc6b656a56393ab77a31c28139bc7 upstream.
    
    The delalloc -> real block conversion path uses an incorrect
    calculation in the case where the middle part of a delalloc extent
    is being converted. This is documented as a rare situation because
    XFS generally attempts to maximize contiguity by converting as much
    of a delalloc extent as possible.
    
    If this situation does occur, the indlen reservation for the two new
    delalloc extents left behind by the conversion of the middle range
    is calculated and compared with the original reservation. If more
    blocks are required, the delta is allocated from the global block
    pool. This delta value can be characterized as the difference
    between the new total requirement (temp + temp2) and the currently
    available reservation minus those blocks that have already been
    allocated (startblockval(PREV.br_startblock) - allocated).
    
    The problem is that the current code does not account for previously
    allocated blocks correctly. It subtracts the current allocation
    count from the (new - old) delta rather than the old indlen
    reservation. This means that more indlen blocks than have been
    allocated end up stashed in the remaining extents and free space
    accounting is broken as a result.
    
    Fix up the calculation to subtract the allocated block count from
    the original extent indlen and thus correctly allocate the
    reservation delta based on the difference between the new total
    requirement and the unused blocks from the original reservation.
    Also remove a bogus assert that contradicts the fact that the new
    indlen reservation can be larger than the original indlen
    reservation.
    
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d1a8ae21c3560d8c4b83e71008ec21fbf317bdb9
Author: Eryu Guan <eguan@redhat.com>
Date:   Tue May 2 13:54:47 2017 -0700

    xfs: fix use-after-free in xfs_finish_page_writeback
    
    commit 161f55efba5ddccc690139fae9373cafc3447a97 upstream.
    
    Commit 28b783e47ad7 ("xfs: bufferhead chains are invalid after
    end_page_writeback") fixed one use-after-free issue by
    pre-calculating the loop conditionals before calling bh->b_end_io()
    in the end_io processing loop, but it assigned 'next' pointer before
    checking end offset boundary & breaking the loop, at which point the
    bh might be freed already, and caused use-after-free.
    
    This is caught by KASAN when running fstests generic/127 on sub-page
    block size XFS.
    
    [ 2517.244502] run fstests generic/127 at 2017-04-27 07:30:50
    [ 2747.868840] ==================================================================
    [ 2747.876949] BUG: KASAN: use-after-free in xfs_destroy_ioend+0x3d3/0x4e0 [xfs] at addr ffff8801395ae698
    ...
    [ 2747.918245] Call Trace:
    [ 2747.920975]  dump_stack+0x63/0x84
    [ 2747.924673]  kasan_object_err+0x21/0x70
    [ 2747.928950]  kasan_report+0x271/0x530
    [ 2747.933064]  ? xfs_destroy_ioend+0x3d3/0x4e0 [xfs]
    [ 2747.938409]  ? end_page_writeback+0xce/0x110
    [ 2747.943171]  __asan_report_load8_noabort+0x19/0x20
    [ 2747.948545]  xfs_destroy_ioend+0x3d3/0x4e0 [xfs]
    [ 2747.953724]  xfs_end_io+0x1af/0x2b0 [xfs]
    [ 2747.958197]  process_one_work+0x5ff/0x1000
    [ 2747.962766]  worker_thread+0xe4/0x10e0
    [ 2747.966946]  kthread+0x2d3/0x3d0
    [ 2747.970546]  ? process_one_work+0x1000/0x1000
    [ 2747.975405]  ? kthread_create_on_node+0xc0/0xc0
    [ 2747.980457]  ? syscall_return_slowpath+0xe6/0x140
    [ 2747.985706]  ? do_page_fault+0x30/0x80
    [ 2747.989887]  ret_from_fork+0x2c/0x40
    [ 2747.993874] Object at ffff8801395ae690, in cache buffer_head size: 104
    [ 2748.001155] Allocated:
    [ 2748.003782] PID = 8327
    [ 2748.006411]  save_stack_trace+0x1b/0x20
    [ 2748.010688]  save_stack+0x46/0xd0
    [ 2748.014383]  kasan_kmalloc+0xad/0xe0
    [ 2748.018370]  kasan_slab_alloc+0x12/0x20
    [ 2748.022648]  kmem_cache_alloc+0xb8/0x1b0
    [ 2748.027024]  alloc_buffer_head+0x22/0xc0
    [ 2748.031399]  alloc_page_buffers+0xd1/0x250
    [ 2748.035968]  create_empty_buffers+0x30/0x410
    [ 2748.040730]  create_page_buffers+0x120/0x1b0
    [ 2748.045493]  __block_write_begin_int+0x17a/0x1800
    [ 2748.050740]  iomap_write_begin+0x100/0x2f0
    [ 2748.055308]  iomap_zero_range_actor+0x253/0x5c0
    [ 2748.060362]  iomap_apply+0x157/0x270
    [ 2748.064347]  iomap_zero_range+0x5a/0x80
    [ 2748.068624]  iomap_truncate_page+0x6b/0xa0
    [ 2748.073227]  xfs_setattr_size+0x1f7/0xa10 [xfs]
    [ 2748.078312]  xfs_vn_setattr_size+0x68/0x140 [xfs]
    [ 2748.083589]  xfs_file_fallocate+0x4ac/0x820 [xfs]
    [ 2748.088838]  vfs_fallocate+0x2cf/0x780
    [ 2748.093021]  SyS_fallocate+0x48/0x80
    [ 2748.097006]  do_syscall_64+0x18a/0x430
    [ 2748.101186]  return_from_SYSCALL_64+0x0/0x6a
    [ 2748.105948] Freed:
    [ 2748.108189] PID = 8327
    [ 2748.110816]  save_stack_trace+0x1b/0x20
    [ 2748.115093]  save_stack+0x46/0xd0
    [ 2748.118788]  kasan_slab_free+0x73/0xc0
    [ 2748.122969]  kmem_cache_free+0x7a/0x200
    [ 2748.127247]  free_buffer_head+0x41/0x80
    [ 2748.131524]  try_to_free_buffers+0x178/0x250
    [ 2748.136316]  xfs_vm_releasepage+0x2e9/0x3d0 [xfs]
    [ 2748.141563]  try_to_release_page+0x100/0x180
    [ 2748.146325]  invalidate_inode_pages2_range+0x7da/0xcf0
    [ 2748.152087]  xfs_shift_file_space+0x37d/0x6e0 [xfs]
    [ 2748.157557]  xfs_collapse_file_space+0x49/0x120 [xfs]
    [ 2748.163223]  xfs_file_fallocate+0x2a7/0x820 [xfs]
    [ 2748.168462]  vfs_fallocate+0x2cf/0x780
    [ 2748.172642]  SyS_fallocate+0x48/0x80
    [ 2748.176629]  do_syscall_64+0x18a/0x430
    [ 2748.180810]  return_from_SYSCALL_64+0x0/0x6a
    
    Fixed it by checking on offset against end & breaking out first,
    dereference bh only if there're still bufferheads to process.
    
    Signed-off-by: Eryu Guan <eguan@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 365625a6701bac04e76d6b33eff7203f4d953f1d
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Wed Apr 12 12:26:07 2017 -0700

    xfs: reserve enough blocks to handle btree splits when remapping
    
    commit fe0be23e68200573de027de9b8cc2b27e7fce35e upstream.
    
    In xfs_reflink_end_cow, we erroneously reserve only enough blocks to
    handle adding 1 extent.  This is problematic if we fragment free space,
    have to do CoW, and then have to perform multiple bmap btree expansions.
    Furthermore, the BUI recovery routine doesn't reserve /any/ blocks to
    handle btree splits, so log recovery fails after our first error causes
    the filesystem to go down.
    
    Therefore, refactor the transaction block reservation macros until we
    have a macro that works for our deferred (re)mapping activities, and fix
    both problems by using that macro.
    
    With 1k blocks we can hit this fairly often in g/187 if the scratch fs
    is big enough.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 67e439ccfe51bc393a1fabaa78340d4cd60386d0
Author: Brian Foster <bfoster@redhat.com>
Date:   Wed Apr 26 08:30:40 2017 -0700

    xfs: wait on new inodes during quotaoff dquot release
    
    commit e20c8a517f259cb4d258e10b0cd5d4b30d4167a0 upstream.
    
    The quotaoff operation has a race with inode allocation that results
    in a livelock. An inode allocation that occurs before the quota
    status flags are updated acquires the appropriate dquots for the
    inode via xfs_qm_vop_dqalloc(). It then inserts the XFS_INEW inode
    into the perag radix tree, sometime later attaches the dquots to the
    inode and finally clears the XFS_INEW flag. Quotaoff expects to
    release the dquots from all inodes in the filesystem via
    xfs_qm_dqrele_all_inodes(). This invokes the AG inode iterator,
    which skips inodes in the XFS_INEW state because they are not fully
    constructed. If the scan occurs after dquots have been attached to
    an inode, but before XFS_INEW is cleared, the newly allocated inode
    will continue to hold a reference to the applicable dquots. When
    quotaoff invokes xfs_qm_dqpurge_all(), the reference count of those
    dquot(s) remain elevated and the dqpurge scan spins indefinitely.
    
    To address this problem, update the xfs_qm_dqrele_all_inodes() scan
    to wait on inodes marked on the XFS_INEW state. We wait on the
    inodes explicitly rather than skip and retry to avoid continuous
    retry loops due to a parallel inode allocation workload. Since
    quotaoff updates the quota state flags and uses a synchronous
    transaction before the dqrele scan, and dquots are attached to
    inodes after radix tree insertion iff quota is enabled, one INEW
    waiting pass through the AG guarantees that the scan has processed
    all inodes that could possibly hold dquot references.
    
    Reported-by: Eryu Guan <eguan@redhat.com>
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f8c68633bb9560d04bf62912136b47630686b8d1
Author: Brian Foster <bfoster@redhat.com>
Date:   Wed Apr 26 08:30:39 2017 -0700

    xfs: update ag iterator to support wait on new inodes
    
    commit ae2c4ac2dd39b23a87ddb14ceddc3f2872c6aef5 upstream.
    
    The AG inode iterator currently skips new inodes as such inodes are
    inserted into the inode radix tree before they are fully
    constructed. Certain contexts require the ability to wait on the
    construction of new inodes, however. The fs-wide dquot release from
    the quotaoff sequence is an example of this.
    
    Update the AG inode iterator to support the ability to wait on
    inodes flagged with XFS_INEW upon request. Create a new
    xfs_inode_ag_iterator_flags() interface and support a set of
    iteration flags to modify the iteration behavior. When the
    XFS_AGITER_INEW_WAIT flag is set, include XFS_INEW flags in the
    radix tree inode lookup and wait on them before the callback is
    executed.
    
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 56aab3095b6cb0d40a9b04c316bb9306dc17aff3
Author: Brian Foster <bfoster@redhat.com>
Date:   Wed Apr 26 08:30:39 2017 -0700

    xfs: support ability to wait on new inodes
    
    commit 756baca27fff3ecaeab9dbc7a5ee35a1d7bc0c7f upstream.
    
    Inodes that are inserted into the perag tree but still under
    construction are flagged with the XFS_INEW bit. Most contexts either
    skip such inodes when they are encountered or have the ability to
    handle them.
    
    The runtime quotaoff sequence introduces a context that must wait
    for construction of such inodes to correctly ensure that all dquots
    in the fs are released. In anticipation of this, support the ability
    to wait on new inodes. Wake the appropriate bit when XFS_INEW is
    cleared.
    
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bf16242614e25923597bd8de0fc2d554b85c8330
Author: Brian Foster <bfoster@redhat.com>
Date:   Fri Apr 21 12:40:44 2017 -0700

    xfs: fix up quotacheck buffer list error handling
    
    commit 20e8a063786050083fe05b4f45be338c60b49126 upstream.
    
    The quotacheck error handling of the delwri buffer list assumes the
    resident buffers are locked and doesn't clear the _XBF_DELWRI_Q flag
    on the buffers that are dequeued. This can lead to assert failures
    on buffer release and possibly other locking problems.
    
    Move this code to a delwri queue cancel helper function to
    encapsulate the logic required to properly release buffers from a
    delwri queue. Update the helper to clear the delwri queue flag and
    call it from quotacheck.
    
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 89aab40e1208738ec114d516541c8928a949574f
Author: Brian Foster <bfoster@redhat.com>
Date:   Thu Apr 20 08:06:47 2017 -0700

    xfs: prevent multi-fsb dir readahead from reading random blocks
    
    commit cb52ee334a45ae6c78a3999e4b473c43ddc528f4 upstream.
    
    Directory block readahead uses a complex iteration mechanism to map
    between high-level directory blocks and underlying physical extents.
    This mechanism attempts to traverse the higher-level dir blocks in a
    manner that handles multi-fsb directory blocks and simultaneously
    maintains a reference to the corresponding physical blocks.
    
    This logic doesn't handle certain (discontiguous) physical extent
    layouts correctly with multi-fsb directory blocks. For example,
    consider the case of a 4k FSB filesystem with a 2 FSB (8k) directory
    block size and a directory with the following extent layout:
    
     EXT: FILE-OFFSET      BLOCK-RANGE      AG AG-OFFSET        TOTAL
       0: [0..7]:          88..95            0 (88..95)             8
       1: [8..15]:         80..87            0 (80..87)             8
       2: [16..39]:        168..191          0 (168..191)          24
       3: [40..63]:        5242952..5242975  1 (72..95)            24
    
    Directory block 0 spans physical extents 0 and 1, dirblk 1 lies
    entirely within extent 2 and dirblk 2 spans extents 2 and 3. Because
    extent 2 is larger than the directory block size, the readahead code
    erroneously assumes the block is contiguous and issues a readahead
    based on the physical mapping of the first fsb of the dirblk. This
    results in read verifier failure and a spurious corruption or crc
    failure, depending on the filesystem format.
    
    Further, the subsequent readahead code responsible for walking
    through the physical table doesn't correctly advance the physical
    block reference for dirblk 2. Instead of advancing two physical
    filesystem blocks, the first iteration of the loop advances 1 block
    (correctly), but the subsequent iteration advances 2 more physical
    blocks because the next physical extent (extent 3, above) happens to
    cover more than dirblk 2. At this point, the higher-level directory
    block walking is completely off the rails of the actual physical
    layout of the directory for the respective mapping table.
    
    Update the contiguous dirblock logic to consider the current offset
    in the physical extent to avoid issuing directory readahead to
    unrelated blocks. Also, update the mapping table advancing code to
    consider the current offset within the current dirblock to avoid
    advancing the mapping reference too far beyond the dirblock.
    
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 91bb4f7da5814686e5911941569f93da2e5d8f67
Author: Eric Sandeen <sandeen@redhat.com>
Date:   Thu Apr 13 15:15:47 2017 -0700

    xfs: handle array index overrun in xfs_dir2_leaf_readbuf()
    
    commit 023cc840b40fad95c6fe26fff1d380a8c9d45939 upstream.
    
    Carlos had a case where "find" seemed to start spinning
    forever and never return.
    
    This was on a filesystem with non-default multi-fsb (8k)
    directory blocks, and a fragmented directory with extents
    like this:
    
    0:[0,133646,2,0]
    1:[2,195888,1,0]
    2:[3,195890,1,0]
    3:[4,195892,1,0]
    4:[5,195894,1,0]
    5:[6,195896,1,0]
    6:[7,195898,1,0]
    7:[8,195900,1,0]
    8:[9,195902,1,0]
    9:[10,195908,1,0]
    10:[11,195910,1,0]
    11:[12,195912,1,0]
    12:[13,195914,1,0]
    ...
    
    i.e. the first extent is a contiguous 2-fsb dir block, but
    after that it is fragmented into 1 block extents.
    
    At the top of the readdir path, we allocate a mapping array
    which (for this filesystem geometry) can hold 10 extents; see
    the assignment to map_info->map_size.  During readdir, we are
    therefore able to map extents 0 through 9 above into the array
    for readahead purposes.  If we count by 2, we see that the last
    mapped index (9) is the first block of a 2-fsb directory block.
    
    At the end of xfs_dir2_leaf_readbuf() we have 2 loops to fill
    more readahead; the outer loop assumes one full dir block is
    processed each loop iteration, and an inner loop that ensures
    that this is so by advancing to the next extent until a full
    directory block is mapped.
    
    The problem is that this inner loop may step past the last
    extent in the mapping array as it tries to reach the end of
    the directory block.  This will read garbage for the extent
    length, and as a result the loop control variable 'j' may
    become corrupted and never fail the loop conditional.
    
    The number of valid mappings we have in our array is stored
    in map->map_valid, so stop this inner loop based on that limit.
    
    There is an ASSERT at the top of the outer loop for this
    same condition, but we never made it out of the inner loop,
    so the ASSERT never fired.
    
    Huge appreciation for Carlos for debugging and isolating
    the problem.
    
    Debugged-and-analyzed-by: Carlos Maiolino <cmaiolino@redhat.com>
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Tested-by: Carlos Maiolino <cmaiolino@redhat.com>
    Reviewed-by: Carlos Maiolino <cmaiolino@redhat.com>
    Reviewed-by: Bill O'Donnell <billodo@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 23da04dcc3af73fd69ed4229bf8e095ed524d7c5
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue Apr 11 16:45:52 2017 -0700

    xfs: fix integer truncation in xfs_bmap_remap_alloc
    
    commit 52813fb13ff90bd9c39a93446cbf1103c290b6e9 upstream.
    
    bno should be a xfs_fsblock_t, which is 64-bit wides instead of a
    xfs_aglock_t, which truncates the value to 32 bits.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit eff615a670145310a4b27b9485d7ac98e95c71e1
Author: Brian Foster <bfoster@redhat.com>
Date:   Tue Apr 11 10:50:05 2017 -0700

    xfs: drop iolock from reclaim context to appease lockdep
    
    commit 3b4683c294095b5f777c03307ef8c60f47320e12 upstream.
    
    Lockdep complains about use of the iolock in inode reclaim context
    because it doesn't understand that reclaim has the last reference to
    the inode, and thus an iolock->reclaim->iolock deadlock is not
    possible.
    
    The iolock is technically not necessary in xfs_inactive() and was
    only added to appease an assert in xfs_free_eofblocks(), which can
    be called from other non-reclaim contexts. Therefore, just kill the
    assert and drop the use of the iolock from reclaim context to quiet
    lockdep.
    
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8a1f785887d32c1d5206051a78a22529d61248bf
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Thu Apr 6 16:00:39 2017 -0700

    xfs: actually report xattr extents via iomap
    
    commit 84358536dc355a9c8978ee425f87e116186bed16 upstream.
    
    Apparently FIEMAP for xattrs has been broken since we switched to
    the iomap backend because of an incorrect check for xattr presence.
    Also fix the broken locking.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1c862f5a3e14e3bfbd7af95636cc19bfa6c44b0d
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Mon Apr 3 15:17:57 2017 -0700

    xfs: fix over-copying of getbmap parameters from userspace
    
    commit be6324c00c4d1e0e665f03ed1fc18863a88da119 upstream.
    
    In xfs_ioc_getbmap, we should only copy the fields of struct getbmap
    from userspace, or else we end up copying random stack contents into the
    kernel.  struct getbmap is a strict subset of getbmapx, so a partial
    structure copy should work fine.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2cd6bd867a3016098c5942b65f5410d98f805d80
Author: Brian Foster <bfoster@redhat.com>
Date:   Tue Mar 28 14:51:44 2017 -0700

    xfs: use dedicated log worker wq to avoid deadlock with cil wq
    
    commit 696a562072e3c14bcd13ae5acc19cdf27679e865 upstream.
    
    The log covering background task used to be part of the xfssyncd
    workqueue. That workqueue was removed as of commit 5889608df ("xfs:
    syncd workqueue is no more") and the associated work item scheduled
    to the xfs-log wq. The latter is used for log buffer I/O completion.
    
    Since xfs_log_worker() can invoke a log flush, a deadlock is
    possible between the xfs-log and xfs-cil workqueues. Consider the
    following codepath from xfs_log_worker():
    
    xfs_log_worker()
      xfs_log_force()
        _xfs_log_force()
          xlog_cil_force()
            xlog_cil_force_lsn()
              xlog_cil_push_now()
                flush_work()
    
    The above is in xfs-log wq context and blocked waiting on the
    completion of an xfs-cil work item. Concurrently, the cil push in
    progress can end up blocked here:
    
    xlog_cil_push_work()
      xlog_cil_push()
        xlog_write()
          xlog_state_get_iclog_space()
            xlog_wait(&log->l_flush_wait, ...)
    
    The above is in xfs-cil context waiting on log buffer I/O
    completion, which executes in xfs-log wq context. In this scenario
    both workqueues are deadlocked waiting on eachother.
    
    Add a new workqueue specifically for the high level log covering and
    ail pushing worker, as was the case prior to commit 5889608df.
    
    Diagnosed-by: David Jeffery <djeffery@redhat.com>
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a19348b729e85c1e0e08ec9e82115527d7539a14
Author: Eryu Guan <eguan@redhat.com>
Date:   Tue May 23 08:30:46 2017 -0700

    xfs: fix off-by-one on max nr_pages in xfs_find_get_desired_pgoff()
    
    commit 8affebe16d79ebefb1d9d6d56a46dc89716f9453 upstream.
    
    xfs_find_get_desired_pgoff() is used to search for offset of hole or
    data in page range [index, end] (both inclusive), and the max number
    of pages to search should be at least one, if end == index.
    Otherwise the only page is missed and no hole or data is found,
    which is not correct.
    
    When block size is smaller than page size, this can be demonstrated
    by preallocating a file with size smaller than page size and writing
    data to the last block. E.g. run this xfs_io command on a 1k block
    size XFS on x86_64 host.
    
      # xfs_io -fc "falloc 0 3k" -c "pwrite 2k 1k" \
                -c "seek -d 0" /mnt/xfs/testfile
      wrote 1024/1024 bytes at offset 2048
      1 KiB, 1 ops; 0.0000 sec (33.675 MiB/sec and 34482.7586 ops/sec)
      Whence  Result
      DATA    EOF
    
    Data at offset 2k was missed, and lseek(2) returned ENXIO.
    
    This is uncovered by generic/285 subtest 07 and 08 on ppc64 host,
    where pagesize is 64k. Because a recent change to generic/285
    reduced the preallocated file size to smaller than 64k.
    
    Signed-off-by: Eryu Guan <eguan@redhat.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0364c225a57c7db294c71ca59a5515e5ffcf25da
Author: Brian Foster <bfoster@redhat.com>
Date:   Wed May 31 08:22:52 2017 -0700

    xfs: use ->b_state to fix buffer I/O accounting release race
    
    commit 63db7c815bc0997c29e484d2409684fdd9fcd93b upstream.
    
    We've had user reports of unmount hangs in xfs_wait_buftarg() that
    analysis shows is due to btp->bt_io_count == -1. bt_io_count
    represents the count of in-flight asynchronous buffers and thus
    should always be >= 0. xfs_wait_buftarg() waits for this value to
    stabilize to zero in order to ensure that all untracked (with
    respect to the lru) buffers have completed I/O processing before
    unmount proceeds to tear down in-core data structures.
    
    The value of -1 implies an I/O accounting decrement race. Indeed,
    the fact that xfs_buf_ioacct_dec() is called from xfs_buf_rele()
    (where the buffer lock is no longer held) means that bp->b_flags can
    be updated from an unsafe context. While a user-level reproducer is
    currently not available, some intrusive hacks to run racing buffer
    lookups/ioacct/releases from multiple threads was used to
    successfully manufacture this problem.
    
    Existing callers do not expect to acquire the buffer lock from
    xfs_buf_rele(). Therefore, we can not safely update ->b_flags from
    this context. It turns out that we already have separate buffer
    state bits and associated serialization for dealing with buffer LRU
    state in the form of ->b_state and ->b_lock. Therefore, replace the
    _XBF_IN_FLIGHT flag with a ->b_state variant, update the I/O
    accounting wrappers appropriately and make sure they are used with
    the correct locking. This ensures that buffer in-flight state can be
    modified at buffer release time without racing with modifications
    from a buffer lock holder.
    
    Fixes: 9c7504aa72b6 ("xfs: track and serialize in-flight async buffers against unmount")
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Nikolay Borisov <nborisov@suse.com>
    Tested-by: Libor Pechacek <lpechacek@suse.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 34836549fbc994bf122e6ae180413822e37b8977
Author: Jan Kara <jack@suse.cz>
Date:   Thu May 18 16:36:22 2017 -0700

    xfs: Fix missed holes in SEEK_HOLE implementation
    
    commit 5375023ae1266553a7baa0845e82917d8803f48c upstream.
    
    XFS SEEK_HOLE implementation could miss a hole in an unwritten extent as
    can be seen by the following command:
    
    xfs_io -c "falloc 0 256k" -c "pwrite 0 56k" -c "pwrite 128k 8k"
           -c "seek -h 0" file
    wrote 57344/57344 bytes at offset 0
    56 KiB, 14 ops; 0.0000 sec (49.312 MiB/sec and 12623.9856 ops/sec)
    wrote 8192/8192 bytes at offset 131072
    8 KiB, 2 ops; 0.0000 sec (70.383 MiB/sec and 18018.0180 ops/sec)
    Whence  Result
    HOLE    139264
    
    Where we can see that hole at offset 56k was just ignored by SEEK_HOLE
    implementation. The bug is in xfs_find_get_desired_pgoff() which does
    not properly detect the case when pages are not contiguous.
    
    Fix the problem by properly detecting when found page has larger offset
    than expected.
    
    Fixes: d126d43f631f996daeee5006714fed914be32368
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4ec50822a58a275f09fbb433089eb906ab6d05c7
Author: Patrik Jakobsson <patrik.r.jakobsson@gmail.com>
Date:   Tue Apr 18 13:43:32 2017 +0200

    drm/gma500/psb: Actually use VBT mode when it is found
    
    commit 82bc9a42cf854fdf63155759c0aa790bd1f361b0 upstream.
    
    With LVDS we were incorrectly picking the pre-programmed mode instead of
    the prefered mode provided by VBT. Make sure we pick the VBT mode if
    one is provided. It is likely that the mode read-out code is still wrong
    but this patch fixes the immediate problem on most machines.
    
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=78562
    Signed-off-by: Patrik Jakobsson <patrik.r.jakobsson@gmail.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20170418114332.12183-1-patrik.r.jakobsson@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 74b4db844f3a435cf16eea7e499ca353c415b722
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 2 14:46:25 2017 -0700

    slub/memcg: cure the brainless abuse of sysfs attributes
    
    commit 478fe3037b2278d276d4cd9cd0ab06c4cb2e9b32 upstream.
    
    memcg_propagate_slab_attrs() abuses the sysfs attribute file functions
    to propagate settings from the root kmem_cache to a newly created
    kmem_cache.  It does that with:
    
         attr->show(root, buf);
         attr->store(new, buf, strlen(bug);
    
    Aside of being a lazy and absurd hackery this is broken because it does
    not check the return value of the show() function.
    
    Some of the show() functions return 0 w/o touching the buffer.  That
    means in such a case the store function is called with the stale content
    of the previous show().  That causes nonsense like invoking
    kmem_cache_shrink() on a newly created kmem_cache.  In the worst case it
    would cause handing in an uninitialized buffer.
    
    This should be rewritten proper by adding a propagate() callback to
    those slub_attributes which must be propagated and avoid that insane
    conversion to and from ASCII, but that's too large for a hot fix.
    
    Check at least the return value of the show() function, so calling
    store() with stale content is prevented.
    
    Steven said:
     "It can cause a deadlock with get_online_cpus() that has been uncovered
      by recent cpu hotplug and lockdep changes that Thomas and Peter have
      been doing.
    
         Possible unsafe locking scenario:
    
               CPU0                    CPU1
               ----                    ----
          lock(cpu_hotplug.lock);
                                       lock(slab_mutex);
                                       lock(cpu_hotplug.lock);
          lock(slab_mutex);
    
         *** DEADLOCK ***"
    
    Link: http://lkml.kernel.org/r/alpine.DEB.2.20.1705201244540.2255@nanos
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Acked-by: David Rientjes <rientjes@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Pekka Enberg <penberg@kernel.org>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6caa2db34d34ab0584c4c4f1b57c24c9859bbbb3
Author: Andrea Arcangeli <aarcange@redhat.com>
Date:   Fri Jun 2 14:46:11 2017 -0700

    ksm: prevent crash after write_protect_page fails
    
    commit a7306c3436e9c8e584a4b9fad5f3dc91be2a6076 upstream.
    
    "err" needs to be left set to -EFAULT if split_huge_page succeeds.
    Otherwise if "err" gets clobbered with zero and write_protect_page
    fails, try_to_merge_one_page() will succeed instead of returning -EFAULT
    and then try_to_merge_with_ksm_page() will continue thinking kpage is a
    PageKsm when in fact it's still an anonymous page.  Eventually it'll
    crash in page_add_anon_rmap.
    
    This has been reproduced on Fedora25 kernel but I can reproduce with
    upstream too.
    
    The bug was introduced in commit f765f540598a ("ksm: prepare to new THP
    semantics") introduced in v4.5.
    
        page:fffff67546ce1cc0 count:4 mapcount:2 mapping:ffffa094551e36e1 index:0x7f0f46673
        flags: 0x2ffffc0004007c(referenced|uptodate|dirty|lru|active|swapbacked)
        page dumped because: VM_BUG_ON_PAGE(!PageLocked(page))
        page->mem_cgroup:ffffa09674bf0000
        ------------[ cut here ]------------
        kernel BUG at mm/rmap.c:1222!
        CPU: 1 PID: 76 Comm: ksmd Not tainted 4.9.3-200.fc25.x86_64 #1
        RIP: do_page_add_anon_rmap+0x1c4/0x240
        Call Trace:
          page_add_anon_rmap+0x18/0x20
          try_to_merge_with_ksm_page+0x50b/0x780
          ksm_scan_thread+0x1211/0x1410
          ? prepare_to_wait_event+0x100/0x100
          ? try_to_merge_with_ksm_page+0x780/0x780
          kthread+0xd9/0xf0
          ? kthread_park+0x60/0x60
          ret_from_fork+0x25/0x30
    
    Fixes: f765f54059 ("ksm: prepare to new THP semantics")
    Link: http://lkml.kernel.org/r/20170513131040.21732-1-aarcange@redhat.com
    Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
    Reported-by: Federico Simoncelli <fsimonce@redhat.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6eaf7a4d6230c1d88e1b8afe3179947fbc007b1
Author: Rob Landley <rob@landley.net>
Date:   Sat May 20 15:03:29 2017 -0500

    x86/boot: Use CROSS_COMPILE prefix for readelf
    
    commit 3780578761921f094179c6289072a74b2228c602 upstream.
    
    The boot code Makefile contains a straight 'readelf' invocation. This
    causes build warnings in cross compile environments, when there is no
    unprefixed readelf accessible via $PATH.
    
    Add the missing $(CROSS_COMPILE) prefix.
    
    [ tglx: Rewrote changelog ]
    
    Fixes: 98f78525371b ("x86/boot: Refuse to build with data relocations")
    Signed-off-by: Rob Landley <rob@landley.net>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Paul Bolle <pebolle@tiscali.nl>
    Cc: "H.J. Lu" <hjl.tools@gmail.com>
    Link: http://lkml.kernel.org/r/ced18878-693a-9576-a024-113ef39a22c0@landley.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f7e82ab3b65e075b956a0a41d3a37d21ecdb8b07
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Fri May 12 09:02:00 2017 -0700

    RDMA/qib,hfi1: Fix MR reference count leak on write with immediate
    
    commit 1feb40067cf04ae48d65f728d62ca255c9449178 upstream.
    
    The handling of IB_RDMA_WRITE_ONLY_WITH_IMMEDIATE will leak a memory
    reference when a buffer cannot be allocated for returning the immediate
    data.
    
    The issue is that the rkey validation has already occurred and the RNR
    nak fails to release the reference that was fruitlessly gotten.  The
    the peer will send the identical single packet request when its RNR
    timer pops.
    
    The fix is to release the held reference prior to the rnr nak exit.
    This is the only sequence the requires both rkey validation and the
    buffer allocation on the same packet.
    
    Tested-by: Tadeusz Struk <tadeusz.struk@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 68c98967e7a2f59863770a02ba402b7b5a6bd62a
Author: Israel Rukshin <israelr@mellanox.com>
Date:   Thu May 11 18:52:36 2017 +0300

    RDMA/srp: Fix NULL deref at srp_destroy_qp()
    
    commit 95c2ef50c726a51d580c35ae8dccd383abaa8701 upstream.
    
    If srp_init_qp() fails at srp_create_ch_ib() then ch->send_cq
    may be NULL.
    Calling directly to ib_destroy_qp() is sufficient because
    no work requests were posted on the created qp.
    
    Fixes: 9294000d6d89 ("IB/srp: Drain the send queue before destroying a QP")
    Signed-off-by: Israel Rukshin <israelr@mellanox.com>
    Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
    Reviewed-by: Bart van Assche <bart.vanassche@sandisk.com>--
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dbab02324500a59bafce597f07350462ac5866f2
Author: Michal Hocko <mhocko@suse.com>
Date:   Fri Jun 2 14:46:49 2017 -0700

    mm: consider memblock reservations for deferred memory initialization sizing
    
    commit 864b9a393dcb5aed09b8fd31b9bbda0fdda99374 upstream.
    
    We have seen an early OOM killer invocation on ppc64 systems with
    crashkernel=4096M:
    
            kthreadd invoked oom-killer: gfp_mask=0x16040c0(GFP_KERNEL|__GFP_COMP|__GFP_NOTRACK), nodemask=7, order=0, oom_score_adj=0
            kthreadd cpuset=/ mems_allowed=7
            CPU: 0 PID: 2 Comm: kthreadd Not tainted 4.4.68-1.gd7fe927-default #1
            Call Trace:
              dump_stack+0xb0/0xf0 (unreliable)
              dump_header+0xb0/0x258
              out_of_memory+0x5f0/0x640
              __alloc_pages_nodemask+0xa8c/0xc80
              kmem_getpages+0x84/0x1a0
              fallback_alloc+0x2a4/0x320
              kmem_cache_alloc_node+0xc0/0x2e0
              copy_process.isra.25+0x260/0x1b30
              _do_fork+0x94/0x470
              kernel_thread+0x48/0x60
              kthreadd+0x264/0x330
              ret_from_kernel_thread+0x5c/0xa4
    
            Mem-Info:
            active_anon:0 inactive_anon:0 isolated_anon:0
             active_file:0 inactive_file:0 isolated_file:0
             unevictable:0 dirty:0 writeback:0 unstable:0
             slab_reclaimable:5 slab_unreclaimable:73
             mapped:0 shmem:0 pagetables:0 bounce:0
             free:0 free_pcp:0 free_cma:0
            Node 7 DMA free:0kB min:0kB low:0kB high:0kB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:52428800kB managed:110016kB mlocked:0kB dirty:0kB writeback:0kB mapped:0kB shmem:0kB slab_reclaimable:320kB slab_unreclaimable:4672kB kernel_stack:1152kB pagetables:0kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:0 all_unreclaimable? yes
            lowmem_reserve[]: 0 0 0 0
            Node 7 DMA: 0*64kB 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB 0*8192kB 0*16384kB = 0kB
            0 total pagecache pages
            0 pages in swap cache
            Swap cache stats: add 0, delete 0, find 0/0
            Free swap  = 0kB
            Total swap = 0kB
            819200 pages RAM
            0 pages HighMem/MovableOnly
            817481 pages reserved
            0 pages cma reserved
            0 pages hwpoisoned
    
    the reason is that the managed memory is too low (only 110MB) while the
    rest of the the 50GB is still waiting for the deferred intialization to
    be done.  update_defer_init estimates the initial memoty to initialize
    to 2GB at least but it doesn't consider any memory allocated in that
    range.  In this particular case we've had
    
            Reserving 4096MB of memory at 128MB for crashkernel (System RAM: 51200MB)
    
    so the low 2GB is mostly depleted.
    
    Fix this by considering memblock allocations in the initial static
    initialization estimation.  Move the max_initialise to
    reset_deferred_meminit and implement a simple memblock_reserved_memory
    helper which iterates all reserved blocks and sums the size of all that
    start below the given address.  The cumulative size is than added on top
    of the initial estimation.  This is still not ideal because
    reset_deferred_meminit doesn't consider holes and so reservation might
    be above the initial estimation whihch we ignore but let's make the
    logic simpler until we really need to handle more complicated cases.
    
    Fixes: 3a80a7fa7989 ("mm: meminit: initialise a subset of struct pages if CONFIG_DEFERRED_STRUCT_PAGE_INIT is set")
    Link: http://lkml.kernel.org/r/20170531104010.GI27783@dhcp22.suse.cz
    Signed-off-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Mel Gorman <mgorman@suse.de>
    Tested-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1cc89263447cec61b46b124d706d2a369cfe7f50
Author: James Morse <james.morse@arm.com>
Date:   Fri Jun 2 14:46:46 2017 -0700

    mm/hugetlb: report -EHWPOISON not -EFAULT when FOLL_HWPOISON is specified
    
    commit 9a291a7c9428155e8e623e4a3989f8be47134df5 upstream.
    
    KVM uses get_user_pages() to resolve its stage2 faults.  KVM sets the
    FOLL_HWPOISON flag causing faultin_page() to return -EHWPOISON when it
    finds a VM_FAULT_HWPOISON.  KVM handles these hwpoison pages as a
    special case.  (check_user_page_hwpoison())
    
    When huge pages are involved, this doesn't work so well.
    get_user_pages() calls follow_hugetlb_page(), which stops early if it
    receives VM_FAULT_HWPOISON from hugetlb_fault(), eventually returning
    -EFAULT to the caller.  The step to map this to -EHWPOISON based on the
    FOLL_ flags is missing.  The hwpoison special case is skipped, and
    -EFAULT is returned to user-space, causing Qemu or kvmtool to exit.
    
    Instead, move this VM_FAULT_ to errno mapping code into a header file
    and use it from faultin_page() and follow_hugetlb_page().
    
    With this, KVM works as expected.
    
    This isn't a problem for arm64 today as we haven't enabled
    MEMORY_FAILURE, but I can't see any reason this doesn't happen on x86
    too, so I think this should be a fix.  This doesn't apply earlier than
    stable's v4.11.1 due to all sorts of cleanup.
    
    [james.morse@arm.com: add vm_fault_to_errno() call to faultin_page()]
    suggested.
      Link: http://lkml.kernel.org/r/20170525171035.16359-1-james.morse@arm.com
    [akpm@linux-foundation.org: coding-style fixes]
    Link: http://lkml.kernel.org/r/20170524160900.28786-1-james.morse@arm.com
    Signed-off-by: James Morse <james.morse@arm.com>
    Acked-by: Punit Agrawal <punit.agrawal@arm.com>
    Acked-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Cc: "Kirill A . Shutemov" <kirill.shutemov@linux.intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f814bf465578b4bf2d4ae1329e8f35d89c040d2d
Author: Yisheng Xie <xieyisheng1@huawei.com>
Date:   Fri Jun 2 14:46:43 2017 -0700

    mlock: fix mlock count can not decrease in race condition
    
    commit 70feee0e1ef331b22cc51f383d532a0d043fbdcc upstream.
    
    Kefeng reported that when running the follow test, the mlock count in
    meminfo will increase permanently:
    
     [1] testcase
     linux:~ # cat test_mlockal
     grep Mlocked /proc/meminfo
      for j in `seq 0 10`
      do
            for i in `seq 4 15`
            do
                    ./p_mlockall >> log &
            done
            sleep 0.2
     done
     # wait some time to let mlock counter decrease and 5s may not enough
     sleep 5
     grep Mlocked /proc/meminfo
    
     linux:~ # cat p_mlockall.c
     #include <sys/mman.h>
     #include <stdlib.h>
     #include <stdio.h>
    
     #define SPACE_LEN      4096
    
     int main(int argc, char ** argv)
     {
                    int ret;
                    void *adr = malloc(SPACE_LEN);
                    if (!adr)
                            return -1;
    
                    ret = mlockall(MCL_CURRENT | MCL_FUTURE);
                    printf("mlcokall ret = %d\n", ret);
    
                    ret = munlockall();
                    printf("munlcokall ret = %d\n", ret);
    
                    free(adr);
                    return 0;
             }
    
    In __munlock_pagevec() we should decrement NR_MLOCK for each page where
    we clear the PageMlocked flag.  Commit 1ebb7cc6a583 ("mm: munlock: batch
    NR_MLOCK zone state updates") has introduced a bug where we don't
    decrement NR_MLOCK for pages where we clear the flag, but fail to
    isolate them from the lru list (e.g.  when the pages are on some other
    cpu's percpu pagevec).  Since PageMlocked stays cleared, the NR_MLOCK
    accounting gets permanently disrupted by this.
    
    Fix it by counting the number of page whose PageMlock flag is cleared.
    
    Fixes: 1ebb7cc6a583 (" mm: munlock: batch NR_MLOCK zone state updates")
    Link: http://lkml.kernel.org/r/1495678405-54569-1-git-send-email-xieyisheng1@huawei.com
    Signed-off-by: Yisheng Xie <xieyisheng1@huawei.com>
    Reported-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Tested-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Joern Engel <joern@logfs.org>
    Cc: Mel Gorman <mgorman@suse.de>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Xishi Qiu <qiuxishi@huawei.com>
    Cc: zhongjiang <zhongjiang@huawei.com>
    Cc: Hanjun Guo <guohanjun@huawei.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a0189db30dc0c074236028abe16f9b25794d9975
Author: Punit Agrawal <punitagrawal@gmail.com>
Date:   Fri Jun 2 14:46:40 2017 -0700

    mm/migrate: fix refcount handling when !hugepage_migration_supported()
    
    commit 30809f559a0d348c2dfd7ab05e9a451e2384962e upstream.
    
    On failing to migrate a page, soft_offline_huge_page() performs the
    necessary update to the hugepage ref-count.
    
    But when !hugepage_migration_supported() , unmap_and_move_hugepage()
    also decrements the page ref-count for the hugepage.  The combined
    behaviour leaves the ref-count in an inconsistent state.
    
    This leads to soft lockups when running the overcommitted hugepage test
    from mce-tests suite.
    
      Soft offlining pfn 0x83ed600 at process virtual address 0x400000000000
      soft offline: 0x83ed600: migration failed 1, type 1fffc00000008008 (uptodate|head)
      INFO: rcu_preempt detected stalls on CPUs/tasks:
       Tasks blocked on level-0 rcu_node (CPUs 0-7): P2715
        (detected by 7, t=5254 jiffies, g=963, c=962, q=321)
        thugetlb_overco R  running task        0  2715   2685 0x00000008
        Call trace:
          dump_backtrace+0x0/0x268
          show_stack+0x24/0x30
          sched_show_task+0x134/0x180
          rcu_print_detail_task_stall_rnp+0x54/0x7c
          rcu_check_callbacks+0xa74/0xb08
          update_process_times+0x34/0x60
          tick_sched_handle.isra.7+0x38/0x70
          tick_sched_timer+0x4c/0x98
          __hrtimer_run_queues+0xc0/0x300
          hrtimer_interrupt+0xac/0x228
          arch_timer_handler_phys+0x3c/0x50
          handle_percpu_devid_irq+0x8c/0x290
          generic_handle_irq+0x34/0x50
          __handle_domain_irq+0x68/0xc0
          gic_handle_irq+0x5c/0xb0
    
    Address this by changing the putback_active_hugepage() in
    soft_offline_huge_page() to putback_movable_pages().
    
    This only triggers on systems that enable memory failure handling
    (ARCH_SUPPORTS_MEMORY_FAILURE) but not hugepage migration
    (!ARCH_ENABLE_HUGEPAGE_MIGRATION).
    
    I imagine this wasn't triggered as there aren't many systems running
    this configuration.
    
    [akpm@linux-foundation.org: remove dead comment, per Naoya]
    Link: http://lkml.kernel.org/r/20170525135146.32011-1-punit.agrawal@arm.com
    Reported-by: Manoj Iyer <manoj.iyer@canonical.com>
    Tested-by: Manoj Iyer <manoj.iyer@canonical.com>
    Suggested-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Signed-off-by: Punit Agrawal <punit.agrawal@arm.com>
    Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bdaac1fe714769eae7d6e438fc1b1091a0af4a23
Author: Ross Zwisler <zwisler@kernel.org>
Date:   Fri Jun 2 14:46:37 2017 -0700

    dax: fix race between colliding PMD & PTE entries
    
    commit e2093926a098a8ccf0f1d10f6df8dad452cb28d3 upstream.
    
    We currently have two related PMD vs PTE races in the DAX code.  These
    can both be easily triggered by having two threads reading and writing
    simultaneously to the same private mapping, with the key being that
    private mapping reads can be handled with PMDs but private mapping
    writes are always handled with PTEs so that we can COW.
    
    Here is the first race:
    
      CPU 0                                 CPU 1
    
      (private mapping write)
      __handle_mm_fault()
        create_huge_pmd() - FALLBACK
        handle_pte_fault()
          passes check for pmd_devmap()
    
                                            (private mapping read)
                                            __handle_mm_fault()
                                              create_huge_pmd()
                                                dax_iomap_pmd_fault() inserts PMD
    
          dax_iomap_pte_fault() does a PTE fault, but we already have a DAX PMD
                              installed in our page tables at this spot.
    
    Here's the second race:
    
      CPU 0                                 CPU 1
    
      (private mapping read)
      __handle_mm_fault()
        passes check for pmd_none()
        create_huge_pmd()
          dax_iomap_pmd_fault() inserts PMD
    
      (private mapping write)
      __handle_mm_fault()
        create_huge_pmd() - FALLBACK
                                            (private mapping read)
                                            __handle_mm_fault()
                                              passes check for pmd_none()
                                              create_huge_pmd()
    
        handle_pte_fault()
          dax_iomap_pte_fault() inserts PTE
                                                dax_iomap_pmd_fault() inserts PMD,
                                                   but we already have a PTE at
                                                   this spot.
    
    The core of the issue is that while there is isolation between faults to
    the same range in the DAX fault handlers via our DAX entry locking,
    there is no isolation between faults in the code in mm/memory.c.  This
    means for instance that this code in __handle_mm_fault() can run:
    
            if (pmd_none(*vmf.pmd) && transparent_hugepage_enabled(vma)) {
                    ret = create_huge_pmd(&vmf);
    
    But by the time we actually get to run the fault handler called by
    create_huge_pmd(), the PMD is no longer pmd_none() because a racing PTE
    fault has installed a normal PMD here as a parent.  This is the cause of
    the 2nd race.  The first race is similar - there is the following check
    in handle_pte_fault():
    
            } else {
                    /* See comment in pte_alloc_one_map() */
                    if (pmd_devmap(*vmf->pmd) || pmd_trans_unstable(vmf->pmd))
                            return 0;
    
    So if a pmd_devmap() PMD (a DAX PMD) has been installed at vmf->pmd, we
    will bail and retry the fault.  This is correct, but there is nothing
    preventing the PMD from being installed after this check but before we
    actually get to the DAX PTE fault handlers.
    
    In my testing these races result in the following types of errors:
    
      BUG: Bad rss-counter state mm:ffff8800a817d280 idx:1 val:1
      BUG: non-zero nr_ptes on freeing mm: 15
    
    Fix this issue by having the DAX fault handlers verify that it is safe
    to continue their fault after they have taken an entry lock to block
    other racing faults.
    
    [ross.zwisler@linux.intel.com: improve fix for colliding PMD & PTE entries]
      Link: http://lkml.kernel.org/r/20170526195932.32178-1-ross.zwisler@linux.intel.com
    Link: http://lkml.kernel.org/r/20170522215749.23516-2-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reported-by: Pawel Lebioda <pawel.lebioda@intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: "Darrick J. Wong" <darrick.wong@oracle.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: "Kirill A . Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Pawel Lebioda <pawel.lebioda@intel.com>
    Cc: Dave Jiang <dave.jiang@intel.com>
    Cc: Xiong Zhou <xzhou@redhat.com>
    Cc: Eryu Guan <eguan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b16e6ab5adce667dcbf356c15b30712b9c8fa871
Author: Ross Zwisler <zwisler@kernel.org>
Date:   Fri Jun 2 14:46:34 2017 -0700

    mm: avoid spurious 'bad pmd' warning messages
    
    commit d0f0931de936a0a468d7e59284d39581c16d3a73 upstream.
    
    When the pmd_devmap() checks were added by 5c7fb56e5e3f ("mm, dax:
    dax-pmd vs thp-pmd vs hugetlbfs-pmd") to add better support for DAX huge
    pages, they were all added to the end of if() statements after existing
    pmd_trans_huge() checks.  So, things like:
    
      -       if (pmd_trans_huge(*pmd))
      +       if (pmd_trans_huge(*pmd) || pmd_devmap(*pmd))
    
    When further checks were added after pmd_trans_unstable() checks by
    commit 7267ec008b5c ("mm: postpone page table allocation until we have
    page to map") they were also added at the end of the conditional:
    
      +       if (pmd_trans_unstable(fe->pmd) || pmd_devmap(*fe->pmd))
    
    This ordering is fine for pmd_trans_huge(), but doesn't work for
    pmd_trans_unstable().  This is because DAX huge pages trip the bad_pmd()
    check inside of pmd_none_or_trans_huge_or_clear_bad() (called by
    pmd_trans_unstable()), which prints out a warning and returns 1.  So, we
    do end up doing the right thing, but only after spamming dmesg with
    suspicious looking messages:
    
      mm/pgtable-generic.c:39: bad pmd ffff8808daa49b88(84000001006000a5)
    
    Reorder these checks in a helper so that pmd_devmap() is checked first,
    avoiding the error messages, and add a comment explaining why the
    ordering is important.
    
    Fixes: commit 7267ec008b5c ("mm: postpone page table allocation until we have page to map")
    Link: http://lkml.kernel.org/r/20170522215749.23516-1-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Pawel Lebioda <pawel.lebioda@intel.com>
    Cc: "Darrick J. Wong" <darrick.wong@oracle.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Hansen <dave.hansen@intel.com>
    Cc: Matthew Wilcox <mawilcox@microsoft.com>
    Cc: "Kirill A . Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Dave Jiang <dave.jiang@intel.com>
    Cc: Xiong Zhou <xzhou@redhat.com>
    Cc: Eryu Guan <eguan@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit de12c73fa2de588d9dc532a0238ea98e1ac83121
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Fri Jun 2 14:46:31 2017 -0700

    mm/page_alloc.c: make sure OOM victim can try allocations with no watermarks once
    
    commit c288983dddf714216428774e022ad78f48dd8cb1 upstream.
    
    Roman Gushchin has reported that the OOM killer can trivially selects
    next OOM victim when a thread doing memory allocation from page fault
    path was selected as first OOM victim.
    
        allocate invoked oom-killer: gfp_mask=0x14280ca(GFP_HIGHUSER_MOVABLE|__GFP_ZERO), nodemask=(null),  order=0, oom_score_adj=0
        allocate cpuset=/ mems_allowed=0
        CPU: 1 PID: 492 Comm: allocate Not tainted 4.12.0-rc1-mm1+ #181
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
        Call Trace:
         oom_kill_process+0x219/0x3e0
         out_of_memory+0x11d/0x480
         __alloc_pages_slowpath+0xc84/0xd40
         __alloc_pages_nodemask+0x245/0x260
         alloc_pages_vma+0xa2/0x270
         __handle_mm_fault+0xca9/0x10c0
         handle_mm_fault+0xf3/0x210
         __do_page_fault+0x240/0x4e0
         trace_do_page_fault+0x37/0xe0
         do_async_page_fault+0x19/0x70
         async_page_fault+0x28/0x30
        ...
        Out of memory: Kill process 492 (allocate) score 899 or sacrifice child
        Killed process 492 (allocate) total-vm:2052368kB, anon-rss:1894576kB, file-rss:4kB, shmem-rss:0kB
        allocate: page allocation failure: order:0, mode:0x14280ca(GFP_HIGHUSER_MOVABLE|__GFP_ZERO), nodemask=(null)
        allocate cpuset=/ mems_allowed=0
        CPU: 1 PID: 492 Comm: allocate Not tainted 4.12.0-rc1-mm1+ #181
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
        Call Trace:
         __alloc_pages_slowpath+0xd32/0xd40
         __alloc_pages_nodemask+0x245/0x260
         alloc_pages_vma+0xa2/0x270
         __handle_mm_fault+0xca9/0x10c0
         handle_mm_fault+0xf3/0x210
         __do_page_fault+0x240/0x4e0
         trace_do_page_fault+0x37/0xe0
         do_async_page_fault+0x19/0x70
         async_page_fault+0x28/0x30
        ...
        oom_reaper: reaped process 492 (allocate), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
        ...
        allocate invoked oom-killer: gfp_mask=0x0(), nodemask=(null),  order=0, oom_score_adj=0
        allocate cpuset=/ mems_allowed=0
        CPU: 1 PID: 492 Comm: allocate Not tainted 4.12.0-rc1-mm1+ #181
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
        Call Trace:
         oom_kill_process+0x219/0x3e0
         out_of_memory+0x11d/0x480
         pagefault_out_of_memory+0x68/0x80
         mm_fault_error+0x8f/0x190
         ? handle_mm_fault+0xf3/0x210
         __do_page_fault+0x4b2/0x4e0
         trace_do_page_fault+0x37/0xe0
         do_async_page_fault+0x19/0x70
         async_page_fault+0x28/0x30
        ...
        Out of memory: Kill process 233 (firewalld) score 10 or sacrifice child
        Killed process 233 (firewalld) total-vm:246076kB, anon-rss:20956kB, file-rss:0kB, shmem-rss:0kB
    
    There is a race window that the OOM reaper completes reclaiming the
    first victim's memory while nothing but mutex_trylock() prevents the
    first victim from calling out_of_memory() from pagefault_out_of_memory()
    after memory allocation for page fault path failed due to being selected
    as an OOM victim.
    
    This is a side effect of commit 9a67f6488eca926f ("mm: consolidate
    GFP_NOFAIL checks in the allocator slowpath") because that commit
    silently changed the behavior from
    
        /* Avoid allocations with no watermarks from looping endlessly */
    
    to
    
        /*
         * Give up allocations without trying memory reserves if selected
         * as an OOM victim
         */
    
    in __alloc_pages_slowpath() by moving the location to check TIF_MEMDIE
    flag.  I have noticed this change but I didn't post a patch because I
    thought it is an acceptable change other than noise by warn_alloc()
    because !__GFP_NOFAIL allocations are allowed to fail.  But we
    overlooked that failing memory allocation from page fault path makes
    difference due to the race window explained above.
    
    While it might be possible to add a check to pagefault_out_of_memory()
    that prevents the first victim from calling out_of_memory() or remove
    out_of_memory() from pagefault_out_of_memory(), changing
    pagefault_out_of_memory() does not suppress noise by warn_alloc() when
    allocating thread was selected as an OOM victim.  There is little point
    with printing similar backtraces and memory information from both
    out_of_memory() and warn_alloc().
    
    Instead, if we guarantee that current thread can try allocations with no
    watermarks once when current thread looping inside
    __alloc_pages_slowpath() was selected as an OOM victim, we can follow "who
    can use memory reserves" rules and suppress noise by warn_alloc() and
    prevent memory allocations from page fault path from calling
    pagefault_out_of_memory().
    
    If we take the comment literally, this patch would do
    
      -    if (test_thread_flag(TIF_MEMDIE))
      -        goto nopage;
      +    if (alloc_flags == ALLOC_NO_WATERMARKS || (gfp_mask & __GFP_NOMEMALLOC))
      +        goto nopage;
    
    because gfp_pfmemalloc_allowed() returns false if __GFP_NOMEMALLOC is
    given.  But if I recall correctly (I couldn't find the message), the
    condition is meant to apply to only OOM victims despite the comment.
    Therefore, this patch preserves TIF_MEMDIE check.
    
    Fixes: 9a67f6488eca926f ("mm: consolidate GFP_NOFAIL checks in the allocator slowpath")
    Link: http://lkml.kernel.org/r/201705192112.IAF69238.OQOHSJLFOFFMtV@I-love.SAKURA.ne.jp
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Reported-by: Roman Gushchin <guro@fb.com>
    Tested-by: Roman Gushchin <guro@fb.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit af03bb0cabf4d19b1873da98af124439f2b21094
Author: Takashi Iwai <tiwai@suse.de>
Date:   Tue May 30 23:21:07 2017 +0200

    ALSA: usb: Fix a typo in Tascam US-16x08 mixer element
    
    commit 617163fc2580da3d489b6c1bacb6312e0e2aac02 upstream.
    
    A mixer element created in a quirk for Tascam US-16x08 contains a
    typo: it should be "EQ MidLow Q" instead of "EQ MidQLow Q".
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=195875
    Fixes: d2bb390a2081 ("ALSA: usb-audio: Tascam US-16x08 DSP mixer quirk")
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0be9a9a4229d66e34cc5bdbf1143794c5e48a79a
Author: Takashi Iwai <tiwai@suse.de>
Date:   Tue May 30 09:23:41 2017 +0200

    Revert "ALSA: usb-audio: purge needless variable length array"
    
    commit 64188cfbe5245d412de2139a3864e4e00b4136f0 upstream.
    
    This reverts commit 89b593c30e83 ("ALSA: usb-audio: purge needless
    variable length array").  The patch turned out to cause a severe
    regression, triggering an Oops at snd_usb_ctl_msg().  It was overseen
    that snd_usb_ctl_msg() writes back the response to the given buffer,
    while the patch changed it to a read-only const buffer.  (One should
    always double-check when an extra pointer cast is present...)
    
    As a simple fix, just revert the affected commit.  It was merely a
    cleanup.  Although it brings VLA again, it's clearer as a fix.  We'll
    address the VLA later in another patch.
    
    Fixes: 89b593c30e83 ("ALSA: usb-audio: purge needless variable length array")
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=195875
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ffb97b001b1575a42eded6ebc937a3b1897a60f4
Author: Alexander Tsoy <alexander@tsoy.me>
Date:   Mon May 22 20:58:11 2017 +0300

    ALSA: hda - apply STAC_9200_DELL_M22 quirk for Dell Latitude D430
    
    commit 1fc2e41f7af4572b07190f9dec28396b418e9a36 upstream.
    
    This model is actually called 92XXM2-8 in Windows driver. But since pin
    configs for M22 and M28 are identical, just reuse M22 quirk.
    
    Fixes external microphone (tested) and probably docking station ports
    (not tested).
    
    Signed-off-by: Alexander Tsoy <alexander@tsoy.me>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c4afdc6d82d3790abb4ef0e1b250bbfbc66377f
Author: Takashi Iwai <tiwai@suse.de>
Date:   Tue May 16 09:11:33 2017 +0200

    ALSA: hda - No loopback on ALC299 codec
    
    commit fa16b69f1299004b60b625f181143500a246e5cb upstream.
    
    ALC299 has no loopback mixer, but the driver still tries to add a beep
    control over the mixer NID which leads to the error at accessing it.
    This patch fixes it by properly declaring mixer_nid=0 for this codec.
    
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=195775
    Fixes: 28f1f9b26cee ("ALSA: hda/realtek - Add new codec ID ALC299")
    Signed-off-by: Takashi Iwai <tiwai@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d5bc54d0a373dfb4000b755969e9dbe7524799e0
Author: Nicolas Iooss <nicolas.iooss_linux@m4x.org>
Date:   Fri Jun 2 14:46:28 2017 -0700

    pcmcia: remove left-over %Z format
    
    commit ff5a20169b98d84ad8d7f99f27c5ebbb008204d6 upstream.
    
    Commit 5b5e0928f742 ("lib/vsprintf.c: remove %Z support") removed some
    usages of format %Z but forgot "%.2Zx".  This makes clang 4.0 reports a
    -Wformat-extra-args warning because it does not know about %Z.
    
    Replace %Z with %z.
    
    Link: http://lkml.kernel.org/r/20170520090946.22562-1-nicolas.iooss_linux@m4x.org
    Signed-off-by: Nicolas Iooss <nicolas.iooss_linux@m4x.org>
    Cc: Harald Welte <laforge@gnumonks.org>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2609770993c186efef6f52ca3ed3d8bbb7d41061
Author: Lyude <lyude@redhat.com>
Date:   Thu May 11 19:31:12 2017 -0400

    drm/radeon: Unbreak HPD handling for r600+
    
    commit 3d18e33735a02b1a90aecf14410bf3edbfd4d3dc upstream.
    
    We end up reading the interrupt register for HPD5, and then writing it
    to HPD6 which on systems without anything using HPD5 results in
    permanently disabling hotplug on one of the display outputs after the
    first time we acknowledge a hotplug interrupt from the GPU.
    
    This code is really bad. But for now, let's just fix this. I will
    hopefully have a large patch series to refactor all of this soon.
    
    Reviewed-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Lyude <lyude@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6b693bbf9cd900e0e94b9b11711a15e61f84022f
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu May 11 13:14:14 2017 -0400

    drm/radeon/ci: disable mclk switching for high refresh rates (v2)
    
    commit 58d7e3e427db1bd68f33025519a9468140280a75 upstream.
    
    Even if the vblank period would allow it, it still seems to
    be problematic on some cards.
    
    v2: fix logic inversion (Nils)
    
    bug: https://bugs.freedesktop.org/show_bug.cgi?id=96868
    
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6ba1a4407beb8c82d7b2a31b878ff1673cb4a37
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu May 11 13:57:41 2017 -0400

    drm/amd/powerplay/smu7: disable mclk switching for high refresh rates
    
    commit 2275a3a2fe9914ba6d76c8ea490da3c08342bd19 upstream.
    
    Even if the vblank period would allow it, it still seems to
    be problematic on some cards.
    
    bug: https://bugs.freedesktop.org/show_bug.cgi?id=96868
    
    Acked-by: Christian König <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 662dbfcc66ba8d2d210257f9f1aa737c01fa5858
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Thu May 11 13:46:12 2017 -0400

    drm/amd/powerplay/smu7: add vblank check for mclk switching (v2)
    
    commit 09be4a5219610a6fae3215d4f51f948d6f5d2609 upstream.
    
    Check to make sure the vblank period is long enough to support
    mclk switching.
    
    v2: drop needless initial assignment (Nils)
    
    bug: https://bugs.freedesktop.org/show_bug.cgi?id=96868
    
    Acked-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Rex Zhu <Rex.Zhu@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a8aa8a0c107a7bcf3380ca3633debec2607bb6fb
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon May 22 23:05:04 2017 +0800

    nvme: avoid to use blk_mq_abort_requeue_list()
    
    commit 986f75c876dbafed98eba7cb516c5118f155db23 upstream.
    
    NVMe may add request into requeue list simply and not kick off the
    requeue if hw queues are stopped. Then blk_mq_abort_requeue_list()
    is called in both nvme_kill_queues() and nvme_ns_remove() for
    dealing with this issue.
    
    Unfortunately blk_mq_abort_requeue_list() is absolutely a
    race maker, for example, one request may be requeued during
    the aborting. So this patch just calls blk_mq_kick_requeue_list() in
    nvme_kill_queues() to handle this issue like what nvme_start_queues()
    does. Now all requests in requeue list when queues are stopped will be
    handled by blk_mq_kick_requeue_list() when queues are restarted, either
    in nvme_start_queues() or in nvme_kill_queues().
    
    Reported-by: Zhang Yi <yizhan@redhat.com>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 20c03f455c786c47f64fc402e698e5c6a7878e33
Author: Ming Lei <ming.lei@redhat.com>
Date:   Mon May 22 23:05:03 2017 +0800

    nvme: use blk_mq_start_hw_queues() in nvme_kill_queues()
    
    commit 806f026f9b901eaf1a6baeb48b5da18d6a4f818e upstream.
    
    Inside nvme_kill_queues(), we have to start hw queues for
    draining requests in sw queues, .dispatch list and requeue list,
    so use blk_mq_start_hw_queues() instead of blk_mq_start_stopped_hw_queues()
    which only run queues if queues are stopped, but the queues may have
    been started already, for example nvme_start_queues() is called in reset work
    function.
    
    blk_mq_start_hw_queues() run hw queues in current context, instead
    of running asynchronously like before. Given nvme_kill_queues() is
    run from either remove context or reset worker context, both are fine
    to run hw queue directly. And the mutex of namespaces_mutex isn't a
    problem too becasue nvme_start_freeze() runs hw queue in this way
    already.
    
    Reported-by: Zhang Yi <yizhan@redhat.com>
    Reviewed-by: Keith Busch <keith.busch@intel.com>
    Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0fe9c5519553ee65b1e8ab137d23c07ee4479d05
Author: Marta Rybczynska <mrybczyn@kalray.eu>
Date:   Mon Apr 10 17:12:34 2017 +0200

    nvme-rdma: support devices with queue size < 32
    
    commit 0544f5494a03b8846db74e02be5685d1f32b06c9 upstream.
    
    In the case of small NVMe-oF queue size (<32) we may enter a deadlock
    caused by the fact that the IB completions aren't sent waiting for 32
    and the send queue will fill up.
    
    The error is seen as (using mlx5):
    [ 2048.693355] mlx5_0:mlx5_ib_post_send:3765:(pid 7273):
    [ 2048.693360] nvme nvme1: nvme_rdma_post_send failed with error code -12
    
    This patch changes the way the signaling is done so that it depends on
    the queue depth now. The magic define has been removed completely.
    
    Signed-off-by: Marta Rybczynska <marta.rybczynska@kalray.eu>
    Signed-off-by: Samuel Jones <sjones@kalray.eu>
    Acked-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f88d3d6e4f8407d3a09390eb8db7ffb37e46bb95
Author: Jason Gerecke <killertofu@gmail.com>
Date:   Tue Apr 25 11:29:56 2017 -0700

    HID: wacom: Have wacom_tpc_irq guard against possible NULL dereference
    
    commit 2ac97f0f6654da14312d125005c77a6010e0ea38 upstream.
    
    The following Smatch complaint was generated in response to commit
    2a6cdbd ("HID: wacom: Introduce new 'touch_input' device"):
    
        drivers/hid/wacom_wac.c:1586 wacom_tpc_irq()
                 error: we previously assumed 'wacom->touch_input' could be null (see line 1577)
    
    The 'touch_input' and 'pen_input' variables point to the 'struct input_dev'
    used for relaying touch and pen events to userspace, respectively. If a
    device does not have a touch interface or pen interface, the associated
    input variable is NULL. The 'wacom_tpc_irq()' function is responsible for
    forwarding input reports to a more-specific IRQ handler function. An
    unknown report could theoretically be mistaken as e.g. a touch report
    on a device which does not have a touch interface. This can be prevented
    by only calling the pen/touch functions are called when the pen/touch
    pointers are valid.
    
    Fixes: 2a6cdbd ("HID: wacom: Introduce new 'touch_input' device")
    Signed-off-by: Jason Gerecke <jason.gerecke@wacom.com>
    Reviewed-by: Ping Cheng <ping.cheng@wacom.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8d975ebd0a928b7033ac343a1692b253700391c1
Author: Bryant G. Ly <bryantly@linux.vnet.ibm.com>
Date:   Wed May 10 14:35:47 2017 -0500

    ibmvscsis: Fix the incorrect req_lim_delta
    
    commit 75dbf2d36f6b122ad3c1070fe4bf95f71bbff321 upstream.
    
    The current code is not correctly calculating the req_lim_delta.
    
    We want to make sure vscsi->credit is always incremented when
    we do not send a response for the scsi op. Thus for the case where
    there is a successfully aborted task we need to make sure the
    vscsi->credit is incremented.
    
    v2 - Moves the original location of the vscsi->credit increment
    to a better spot. Since if we increment credit, the next command
    we send back will have increased req_lim_delta. But we probably
    shouldn't be doing that until the aborted cmd is actually released.
    Otherwise the client will think that it can send a new command, and
    we could find ourselves short of command elements. Not likely, but could
    happen.
    
    This patch depends on both:
    commit 25e78531268e ("ibmvscsis: Do not send aborted task response")
    commit 98883f1b5415 ("ibmvscsis: Clear left-over abort_cmd pointers")
    
    Signed-off-by: Bryant G. Ly <bryantly@linux.vnet.ibm.com>
    Reviewed-by: Michael Cyr <mikecyr@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e920be8367e2cbc52d26969450544f993a3e7a5d
Author: Bryant G. Ly <bryantly@linux.vnet.ibm.com>
Date:   Tue May 9 11:50:26 2017 -0500

    ibmvscsis: Clear left-over abort_cmd pointers
    
    commit 98883f1b5415ea9dce60d5178877d15f4faa10b8 upstream.
    
    With the addition of ibmvscsis->abort_cmd pointer within
    commit 25e78531268e ("ibmvscsis: Do not send aborted task response"),
    make sure to explicitly NULL these pointers when clearing
    DELAY_SEND flag.
    
    Do this for two cases, when getting the new new ibmvscsis
    descriptor in ibmvscsis_get_free_cmd() and before posting
    the response completion in ibmvscsis_send_messages().
    
    Signed-off-by: Bryant G. Ly <bryantly@linux.vnet.ibm.com>
    Reviewed-by: Michael Cyr <mikecyr@linux.vnet.ibm.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1fb66c6aad5fe7c5e62cc0cd27cc3c6936ef8601
Author: Artem Savkov <asavkov@redhat.com>
Date:   Sat May 20 09:58:10 2017 +0200

    scsi: scsi_dh_rdac: Use ctlr directly in rdac_failover_get()
    
    commit 0648a07c9b22acc33ead0645cf8f607b0c9c7e32 upstream.
    
    rdac_failover_get references struct rdac_controller as
    ctlr->ms_sdev->handler_data->ctlr for no apparent reason. Besides being
    inefficient this also introduces a null-pointer dereference as
    send_mode_select() sets ctlr->ms_sdev to NULL before calling
    rdac_failover_get():
    
    [   18.432550] device-mapper: multipath service-time: version 0.3.0 loaded
    [   18.436124] BUG: unable to handle kernel NULL pointer dereference at 0000000000000790
    [   18.436129] IP: send_mode_select+0xca/0x560
    [   18.436129] PGD 0
    [   18.436130] P4D 0
    [   18.436130]
    [   18.436132] Oops: 0000 [#1] SMP
    [   18.436133] Modules linked in: dm_service_time sd_mod dm_multipath amdkfd amd_iommu_v2 radeon(+) i2c_algo_bit drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops ttm qla2xxx drm serio_raw scsi_transport_fc bnx2 i2c_core dm_mirror dm_region_hash dm_log dm_mod
    [   18.436143] CPU: 4 PID: 443 Comm: kworker/u16:2 Not tainted 4.12.0-rc1.1.el7.test.x86_64 #1
    [   18.436144] Hardware name: IBM BladeCenter LS22 -[79013SG]-/Server Blade, BIOS -[L8E164AUS-1.07]- 05/25/2011
    [   18.436145] Workqueue: kmpath_rdacd send_mode_select
    [   18.436146] task: ffff880225116a40 task.stack: ffffc90002bd8000
    [   18.436148] RIP: 0010:send_mode_select+0xca/0x560
    [   18.436148] RSP: 0018:ffffc90002bdbda8 EFLAGS: 00010246
    [   18.436149] RAX: 0000000000000000 RBX: ffffc90002bdbe08 RCX: ffff88017ef04a80
    [   18.436150] RDX: ffffc90002bdbe08 RSI: ffff88017ef04a80 RDI: ffff8802248e4388
    [   18.436151] RBP: ffffc90002bdbe48 R08: 0000000000000000 R09: ffffffff81c104c0
    [   18.436151] R10: 00000000000001ff R11: 000000000000035a R12: ffffc90002bdbdd8
    [   18.436152] R13: ffff8802248e4390 R14: ffff880225152800 R15: ffff8802248e4400
    [   18.436153] FS:  0000000000000000(0000) GS:ffff880227d00000(0000) knlGS:0000000000000000
    [   18.436154] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   18.436154] CR2: 0000000000000790 CR3: 000000042535b000 CR4: 00000000000006e0
    [   18.436155] Call Trace:
    [   18.436159]  ? rdac_activate+0x14e/0x150
    [   18.436161]  ? refcount_dec_and_test+0x11/0x20
    [   18.436162]  ? kobject_put+0x1c/0x50
    [   18.436165]  ? scsi_dh_activate+0x6f/0xd0
    [   18.436168]  process_one_work+0x149/0x360
    [   18.436170]  worker_thread+0x4d/0x3c0
    [   18.436172]  kthread+0x109/0x140
    [   18.436173]  ? rescuer_thread+0x380/0x380
    [   18.436174]  ? kthread_park+0x60/0x60
    [   18.436176]  ret_from_fork+0x2c/0x40
    [   18.436177] Code: 49 c7 46 20 00 00 00 00 4c 89 ef c6 07 00 0f 1f 40 00 45 31 ed c7 45 b0 05 00 00 00 44 89 6d b4 4d 89 f5 4c 8b 75 a8 49 8b 45 20 <48> 8b b0 90 07 00 00 48 8b 56 10 8b 42 10 48 8d 7a 28 85 c0 0f
    [   18.436192] RIP: send_mode_select+0xca/0x560 RSP: ffffc90002bdbda8
    [   18.436192] CR2: 0000000000000790
    [   18.436198] ---[ end trace 40f3e4dca1ffabdd ]---
    [   18.436199] Kernel panic - not syncing: Fatal exception
    [   18.436222] Kernel Offset: disabled
    [-- MARK -- Thu May 18 11:45:00 2017]
    
    Fixes: 327825574132 scsi_dh_rdac: switch to scsi_execute_req_flags()
    Signed-off-by: Artem Savkov <asavkov@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 14ba78937e8c3fa1b3d1b75206f884ace830caec
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Wed May 24 21:47:09 2017 -0700

    iscsi-target: Fix initial login PDU asynchronous socket close OOPs
    
    commit 25cdda95fda78d22d44157da15aa7ea34be3c804 upstream.
    
    This patch fixes a OOPs originally introduced by:
    
       commit bb048357dad6d604520c91586334c9c230366a14
       Author: Nicholas Bellinger <nab@linux-iscsi.org>
       Date:   Thu Sep 5 14:54:04 2013 -0700
    
       iscsi-target: Add sk->sk_state_change to cleanup after TCP failure
    
    which would trigger a NULL pointer dereference when a TCP connection
    was closed asynchronously via iscsi_target_sk_state_change(), but only
    when the initial PDU processing in iscsi_target_do_login() from iscsi_np
    process context was blocked waiting for backend I/O to complete.
    
    To address this issue, this patch makes the following changes.
    
    First, it introduces some common helper functions used for checking
    socket closing state, checking login_flags, and atomically checking
    socket closing state + setting login_flags.
    
    Second, it introduces a LOGIN_FLAGS_INITIAL_PDU bit to know when a TCP
    connection has dropped via iscsi_target_sk_state_change(), but the
    initial PDU processing within iscsi_target_do_login() in iscsi_np
    context is still running.  For this case, it sets LOGIN_FLAGS_CLOSED,
    but doesn't invoke schedule_delayed_work().
    
    The original NULL pointer dereference case reported by MNC is now handled
    by iscsi_target_do_login() doing a iscsi_target_sk_check_close() before
    transitioning to FFP to determine when the socket has already closed,
    or iscsi_target_start_negotiation() if the login needs to exchange
    more PDUs (eg: iscsi_target_do_login returned 0) but the socket has
    closed.  For both of these cases, the cleanup up of remaining connection
    resources will occur in iscsi_target_start_negotiation() from iscsi_np
    process context once the failure is detected.
    
    Finally, to handle to case where iscsi_target_sk_state_change() is
    called after the initial PDU procesing is complete, it now invokes
    conn->login_work -> iscsi_target_do_login_rx() to perform cleanup once
    existing iscsi_target_sk_check_close() checks detect connection failure.
    For this case, the cleanup of remaining connection resources will occur
    in iscsi_target_do_login_rx() from delayed workqueue process context
    once the failure is detected.
    
    Reported-by: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Tested-by: Mike Christie <mchristi@redhat.com>
    Cc: Mike Christie <mchristi@redhat.com>
    Reported-by: Hannes Reinecke <hare@suse.com>
    Cc: Hannes Reinecke <hare@suse.com>
    Cc: Sagi Grimberg <sagi@grimberg.me>
    Cc: Varun Prakash <varun@chelsio.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c732f3088710cbde225370473893c5f127fd1aca
Author: Jiang Yi <jiangyilism@gmail.com>
Date:   Tue May 16 17:57:55 2017 +0800

    iscsi-target: Always wait for kthread_should_stop() before kthread exit
    
    commit 5e0cf5e6c43b9e19fc0284f69e5cd2b4a47523b0 upstream.
    
    There are three timing problems in the kthread usages of iscsi_target_mod:
    
     - np_thread of struct iscsi_np
     - rx_thread and tx_thread of struct iscsi_conn
    
    In iscsit_close_connection(), it calls
    
     send_sig(SIGINT, conn->tx_thread, 1);
     kthread_stop(conn->tx_thread);
    
    In conn->tx_thread, which is iscsi_target_tx_thread(), when it receive
    SIGINT the kthread will exit without checking the return value of
    kthread_should_stop().
    
    So if iscsi_target_tx_thread() exit right between send_sig(SIGINT...)
    and kthread_stop(...), the kthread_stop() will try to stop an already
    stopped kthread.
    
    This is invalid according to the documentation of kthread_stop().
    
    (Fix -ECONNRESET logout handling in iscsi_target_tx_thread and
     early iscsi_target_rx_thread failure case - nab)
    
    Signed-off-by: Jiang Yi <jiangyilism@gmail.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a168ac5b24bf7724b2fd49ec5362c4c0ff169d94
Author: Long Li <longli@microsoft.com>
Date:   Thu May 18 15:40:05 2017 -0700

    scsi: zero per-cmd private driver data for each MQ I/O
    
    commit 1bad6c4a57efda0d5f5bf8a2403b21b1ed24875c upstream.
    
    In lower layer driver's (LLD) scsi_host_template, the driver may
    optionally ask SCSI to allocate its private driver memory for each
    command, by specifying cmd_size. This memory is allocated at the end of
    scsi_cmnd by SCSI.  Later when SCSI queues a command, the LLD can use
    scsi_cmd_priv to get to its private data.
    
    Some LLD, e.g. hv_storvsc, doesn't clear its private data before use. In
    this case, the LLD may get to stale or uninitialized data in its private
    driver memory. This may result in unexpected driver and hardware
    behavior.
    
    Fix this problem by also zeroing the private driver memory before
    passing them to LLD.
    
    Signed-off-by: Long Li <longli@microsoft.com>
    Reviewed-by: Bart Van Assche <Bart.VanAssche@sandisk.com>
    Reviewed-by: KY Srinivasan <kys@microsoft.com>
    Reviewed-by: Christoph Hellwig <hch@infradead.org>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 21f8aa4cfc764b64df81247d0c5e59eb7a5c9ead
Author: Srinath Mannam <srinath.mannam@broadcom.com>
Date:   Thu May 18 22:27:40 2017 +0530

    mmc: sdhci-iproc: suppress spurious interrupt with Multiblock read
    
    commit f5f968f2371ccdebb8a365487649673c9af68d09 upstream.
    
    The stingray SDHCI hardware supports ACMD12 and automatically
    issues after multi block transfer completed.
    
    If ACMD12 in SDHCI is disabled, spurious tx done interrupts are seen
    on multi block read command with below error message:
    
    Got data interrupt 0x00000002 even though no data
    operation was in progress.
    
    This patch uses SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12 to enable
    ACM12 support in SDHCI hardware and suppress spurious interrupt.
    
    Signed-off-by: Srinath Mannam <srinath.mannam@broadcom.com>
    Reviewed-by: Ray Jui <ray.jui@broadcom.com>
    Reviewed-by: Scott Branden <scott.branden@broadcom.com>
    Acked-by: Adrian Hunter <adrian.hunter@intel.com>
    Fixes: b580c52d58d9 ("mmc: sdhci-iproc: add IPROC SDHCI driver")
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4c5681afdf984b5eec41b280d43b9934af0f3144
Author: Benjamin Tissoires <benjamin.tissoires@redhat.com>
Date:   Wed May 10 18:12:40 2017 +0200

    Revert "ACPI / button: Change default behavior to lid_init_state=open"
    
    commit 878d8db039daac0938238e9a40a5bd6e50ee3c9b upstream.
    
    Revert commit 77e9a4aa9de1 (ACPI / button: Change default behavior to
    lid_init_state=open) which changed the kernel's behavior on laptops
    that boot with closed lids and expect the lid switch state to be
    reported accurately by the kernel.
    
    If you boot or resume your laptop with the lid closed on a docking
    station while using an external monitor connected to it, both internal
    and external displays will light on, while only the external should.
    
    There is a design choice in gdm to only provide the greeter on the
    internal display when lit on, so users only see a gray area on the
    external monitor. Also, the cursor will not show up as it's by
    default on the internal display too.
    
    To "fix" that, users have to open the laptop once and close it once
    again to sync the state of the switch with the hardware state.
    
    Even if the "method" operation mode implementation can be buggy on
    some platforms, the "open" choice is worse.  It breaks docking
    stations basically and there is no way to have a user-space hwdb to
    fix that.
    
    On the contrary, it's rather easy in user-space to have a hwdb
    with the problematic platforms. Then,  libinput (1.7.0+) can fix
    the state of the lid switch for us: you need to set the udev
    property LIBINPUT_ATTR_LID_SWITCH_RELIABILITY to 'write_open'.
    
    When libinput detects internal keyboard events, it will overwrite the
    state of the switch to open, making it reliable again.  Given that
    logind only checks the lid switch value after a timeout, we can
    assume the user will use the internal keyboard before this timeout
    expires.
    
    For example, such a hwdb entry is:
    
    libinput:name:*Lid Switch*:dmi:*svnMicrosoftCorporation:pnSurface3:*
     LIBINPUT_ATTR_LID_SWITCH_RELIABILITY=write_open
    
    Link: https://bugzilla.gnome.org/show_bug.cgi?id=782380
    Signed-off-by: Benjamin Tissoires <benjamin.tissoires@redhat.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5d0e4205ea6c29a8ed72bf333662e6f3f34162d4
Author: Lv Zheng <lv.zheng@intel.com>
Date:   Tue May 9 13:57:31 2017 +0800

    ACPICA: Tables: Fix regression introduced by a too early mechanism enabling
    
    commit 2ea65321b83539afc1d45c1bea39c55ab42af62b upstream.
    
    In the Linux kernel, acpi_get_table() "clones" haven't been fully
    balanced by acpi_put_table() invocations.  In upstream ACPICA, due to
    the design change, there are also unbalanced acpi_get_table_by_index()
    invocations requiring special care.
    
    acpi_get_table() reference counting mismatches may occor due to that
    and printing error messages related to them is not useful at this
    point.  The strict balanced validation count check should only be
    enabled after confirming that all invocations are safe and aligned
    with their designed purposes.
    
    Thus this patch removes the error value returned by acpi_tb_get_table()
    in that case along with the accompanying error message to fix the
    issue.
    
    Fixes: 174cc7187e6f (ACPICA: Tables: Back port acpi_get_table_with_size() and early_acpi_os_unmap_memory() from Linux kernel)
    Reported-by: Anush Seetharaman <anush.seetharaman@intel.com>
    Reported-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Lv Zheng <lv.zheng@intel.com>
    [ rjw: Changelog ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 34211cbf94b5e9bb5d52fdc7b95389fdcaa01221
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Tue Apr 25 12:58:31 2017 -0700

    ACPI / sysfs: fix acpi_get_table() leak / acpi-sysfs denial of service
    
    commit 0de0e198bc7191a0e46cf71f66fec4d07ca91396 upstream.
    
    Reading an ACPI table through the /sys/firmware/acpi/tables interface
    more than 65,536 times leads to the following log message:
    
     ACPI Error: Table ffff88033595eaa8, Validation count is zero after increment
      (20170119/tbutils-423)
    
    ...and the table being unavailable until the next reboot. Add the
    missing acpi_put_table() so the table ->validation_count is decremented
    after each read.
    
    Reported-by: Anush Seetharaman <anush.seetharaman@intel.com>
    Fixes: 174cc7187e6f "ACPICA: Tables: Back port acpi_get_table_with_size() ..."
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 93da4e6c45f4189ee4b034a0f09e90a4285e6ee1
Author: Vishal Verma <vishal.l.verma@intel.com>
Date:   Fri May 19 11:39:10 2017 +0200

    acpi, nfit: Fix the memory error check in nfit_handle_mce()
    
    commit fc08a4703a418a398bbb575ac311d36d110ac786 upstream.
    
    The check for an MCE being a memory error in the NFIT mce handler was
    bogus. Use the new mce_is_memory_error() helper to detect the error
    properly.
    
    Reported-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Vishal Verma <vishal.l.verma@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: http://lkml.kernel.org/r/20170519093915.15413-3-bp@alien8.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9183980a9e8a8ca4540c8367434dfe3c97177ce0
Author: Borislav Petkov <bp@suse.de>
Date:   Fri May 19 11:39:09 2017 +0200

    x86/MCE: Export memory_error()
    
    commit 2d1f406139ec20320bf38bcd2461aa8e358084b5 upstream.
    
    Export the function which checks whether an MCE is a memory error to
    other users so that we can reuse the logic. Drop the boot_cpu_data use,
    while at it, as mce.cpuvendor already has the CPU vendor in there.
    
    Integrate a piece from a patch from Vishal Verma
    <vishal.l.verma@intel.com> to export it for modules (nfit).
    
    The main reason we're exporting it is that the nfit handler
    nfit_handle_mce() needs to detect a memory error properly before doing
    its recovery actions.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: Vishal Verma <vishal.l.verma@intel.com>
    Link: http://lkml.kernel.org/r/20170519093915.15413-2-bp@alien8.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8f8dca3c86b3b7748968c38ec5b2bc40f85b018b
Author: Lv Zheng <lv.zheng@intel.com>
Date:   Tue May 9 15:02:22 2017 +0800

    Revert "ACPI / button: Remove lid_init_state=method mode"
    
    commit f369fdf4f661322b73f3307e9f3cd55fb3a20123 upstream.
    
    This reverts commit ecb10b694b72ca5ea51b3c90a71ff2a11963425a.
    
    The only expected ACPI control method lid device's usage model is
    
     1. Listen to the lid notification,
     2. Evaluate _LID after being notified by BIOS,
     3. Suspend the system (if users configure to do so) after seeing "close".
    
    It's not ensured that BIOS will notify OS after boot/resume, and
    it's not ensured that BIOS will always generate "open" event upon
    opening the lid.
    
    But there are 2 wrong usage models:
    
     1. When the lid device is responsible for suspend/resume the system,
        userspace requires to see "open" event to be paired with "close" after
        the system is resumed, or it will suspend the system again.
    
     2. When an external monitor connects to the laptop attached docks,
        userspace requires to see "close" event after the system is resumed so
        that it can determine whether the internal display should remain dark
        and the external display should be lit on.
    
    After we made default kernel behavior to be suitable for usage model 1,
    users of usage model 2 start to report regressions for such behavior
    change.
    
    Reversion of button.lid_init_state=method doesn't actually reverts to old
    default behavior as doing so can enter a regression loop, but facilitates
    users to work the reported regressions around with
    button.lid_init_state=method.
    
    Fixes: ecb10b694b72 (ACPI / button: Remove lid_init_state=method mode)
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=195455
    Link: https://bugzilla.redhat.com/show_bug.cgi?id=1430259
    Tested-by: Steffen Weber <steffen.weber@gmail.com>
    Tested-by: Julian Wiedmann <julian.wiedmann@jwi.name>
    Reported-by: Joachim Frieben <jfrieben@hotmail.com>
    Signed-off-by: Lv Zheng <lv.zheng@intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f5eef8d2458bb569ca521b3c2b0a19af62536745
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed May 10 03:48:23 2017 +0800

    crypto: skcipher - Add missing API setkey checks
    
    commit 9933e113c2e87a9f46a40fde8dafbf801dca1ab9 upstream.
    
    The API setkey checks for key sizes and alignment went AWOL during the
    skcipher conversion.  This patch restores them.
    
    Fixes: 4e6c3df4d729 ("crypto: skcipher - Add low-level skcipher...")
    Reported-by: Baozeng <sploving1@gmail.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2da7518890d83a7fc94de41f1bcf7d24b9e13fa9
Author: Sebastian Reichel <sre@kernel.org>
Date:   Fri May 5 11:06:50 2017 +0200

    i2c: i2c-tiny-usb: fix buffer not being DMA capable
    
    commit 5165da5923d6c7df6f2927b0113b2e4d9288661e upstream.
    
    Since v4.9 i2c-tiny-usb generates the below call trace
    and longer works, since it can't communicate with the
    USB device. The reason is, that since v4.9 the USB
    stack checks, that the buffer it should transfer is DMA
    capable. This was a requirement since v2.2 days, but it
    usually worked nevertheless.
    
    [   17.504959] ------------[ cut here ]------------
    [   17.505488] WARNING: CPU: 0 PID: 93 at drivers/usb/core/hcd.c:1587 usb_hcd_map_urb_for_dma+0x37c/0x570
    [   17.506545] transfer buffer not dma capable
    [   17.507022] Modules linked in:
    [   17.507370] CPU: 0 PID: 93 Comm: i2cdetect Not tainted 4.11.0-rc8+ #10
    [   17.508103] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014
    [   17.509039] Call Trace:
    [   17.509320]  ? dump_stack+0x5c/0x78
    [   17.509714]  ? __warn+0xbe/0xe0
    [   17.510073]  ? warn_slowpath_fmt+0x5a/0x80
    [   17.510532]  ? nommu_map_sg+0xb0/0xb0
    [   17.510949]  ? usb_hcd_map_urb_for_dma+0x37c/0x570
    [   17.511482]  ? usb_hcd_submit_urb+0x336/0xab0
    [   17.511976]  ? wait_for_completion_timeout+0x12f/0x1a0
    [   17.512549]  ? wait_for_completion_timeout+0x65/0x1a0
    [   17.513125]  ? usb_start_wait_urb+0x65/0x160
    [   17.513604]  ? usb_control_msg+0xdc/0x130
    [   17.514061]  ? usb_xfer+0xa4/0x2a0
    [   17.514445]  ? __i2c_transfer+0x108/0x3c0
    [   17.514899]  ? i2c_transfer+0x57/0xb0
    [   17.515310]  ? i2c_smbus_xfer_emulated+0x12f/0x590
    [   17.515851]  ? _raw_spin_unlock_irqrestore+0x11/0x20
    [   17.516408]  ? i2c_smbus_xfer+0x125/0x330
    [   17.516876]  ? i2c_smbus_xfer+0x125/0x330
    [   17.517329]  ? i2cdev_ioctl_smbus+0x1c1/0x2b0
    [   17.517824]  ? i2cdev_ioctl+0x75/0x1c0
    [   17.518248]  ? do_vfs_ioctl+0x9f/0x600
    [   17.518671]  ? vfs_write+0x144/0x190
    [   17.519078]  ? SyS_ioctl+0x74/0x80
    [   17.519463]  ? entry_SYSCALL_64_fastpath+0x1e/0xad
    [   17.519959] ---[ end trace d047c04982f5ac50 ]---
    
    Signed-off-by: Sebastian Reichel <sebastian.reichel@collabora.co.uk>
    Reviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Acked-by: Till Harbaum <till@harbaum.org>
    Signed-off-by: Wolfram Sang <wsa@the-dreams.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e4bab31cf957f3b5534e7137ffa6e1267a1e9c00
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Thu May 18 12:29:55 2017 +0100

    drivers/tty: 8250: only call fintek_8250_probe when doing port I/O
    
    commit 4c4fc90964b1cf205a67df566cc82ea1731bcb00 upstream.
    
    Commit fa01e2ca9f53 ("serial: 8250: Integrate Fintek into 8250_base")
    modified the probing logic for PNP0501 devices, to remove a collision
    between the generic 16550A driver and the Fintek driver, which reused
    the same ACPI _HID.
    
    The Fintek device probe is now incorporated into the common 8250 probe
    path, and gets called for all discovered 16550A compatible devices,
    including ones that are MMIO mapped rather than IO mapped. However,
    the Fintek driver assumes the port base is a I/O address, and proceeds
    to probe some arbitrary offsets above it.
    
    This is generally a wrong thing to do, but on ARM systems (having no
    native port I/O), this may result in faulting accesses of completely
    unrelated MMIO regions in the PCI I/O space. Given that this is at
    serial probe time, this results in hard to diagnose crashes at boot.
    
    So let's restrict the Fintek probe to devices that we know are using
    port I/O in the first place.
    
    Fixes: fa01e2ca9f53 ("serial: 8250: Integrate Fintek into 8250_base")
    Suggested-by: Arnd Bergmann <arnd@arndb.de>
    Reviewed-by: Ricardo Ribalda <ricardo.ribalda@gmail.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 84ac7693f46fde81e30387b0bf6d3931df4f5420
Author: Johan Hovold <johan@kernel.org>
Date:   Tue Apr 11 19:07:29 2017 +0200

    serdev: fix tty-port client deregistration
    
    commit aee5da7838787f8ed47f825dbe09e2812acdf97b upstream.
    
    The port client data must be set when registering the serdev controller
    or client deregistration will fail (and the serdev devices are left
    registered and allocated) if the port was never opened in between.
    
    Make sure to clear the port client data on any probe errors to avoid a
    use-after-free when the client is later deregistered unconditionally
    (e.g. in a tty-port deregistration helper).
    
    Also move port client operation initialisation to registration. Note
    that the client ops must be restored on failed probe.
    
    Fixes: bed35c6dfa6a ("serdev: add a tty port controller driver")
    Signed-off-by: Johan Hovold <johan@kernel.org>
    Reviewed-by: Rob Herring <robh@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 427fa8e39177c07d4fbbb2595241a0bef5b6d751
Author: Johan Hovold <johan@kernel.org>
Date:   Tue Apr 11 19:07:28 2017 +0200

    Revert "tty_port: register tty ports with serdev bus"
    
    commit d3ba126a226a6b6da021ebfea444a2a807cde945 upstream.
    
    This reverts commit 8ee3fde047589dc9c201251f07d0ca1dc776feca.
    
    The new serdev bus hooked into the tty layer in
    tty_port_register_device() by registering a serdev controller instead of
    a tty device whenever a serdev client is present, and by deregistering
    the controller in the tty-port destructor. This is broken in several
    ways:
    
    Firstly, it leads to a NULL-pointer dereference whenever a tty driver
    later deregisters its devices as no corresponding character device will
    exist.
    
    Secondly, far from every tty driver uses tty-port refcounting (e.g.
    serial core) so the serdev devices might never be deregistered or
    deallocated.
    
    Thirdly, deregistering at tty-port destruction is too late as the
    underlying device and structures may be long gone by then. A port is not
    released before an open tty device is closed, something which a
    registered serdev client can prevent from ever happening. A driver
    callback while the device is gone typically also leads to crashes.
    
    Many tty drivers even keep their ports around until the driver is
    unloaded (e.g. serial core), something which even if a late callback
    never happens, leads to leaks if a device is unbound from its driver and
    is later rebound.
    
    The right solution here is to add a new tty_port_unregister_device()
    helper and to never call tty_device_unregister() whenever the port has
    been claimed by serdev, but since this requires modifying just about
    every tty driver (and multiple subsystems) it will need to be done
    incrementally.
    
    Reverting the offending patch is the first step in fixing the broken
    lifetime assumptions. A follow-up patch will add a new pair of
    tty-device registration helpers, which a vetted tty driver can use to
    support serdev (initially serial core). When every tty driver uses the
    serdev helpers (at least for deregistration), we can add serdev
    registration to tty_port_register_device() again.
    
    Note that this also fixes another issue with serdev, which currently
    allocates and registers a serdev controller for every tty device
    registered using tty_port_device_register() only to immediately
    deregister and deallocate it when the corresponding OF node or serdev
    child node is missing. This should be addressed before enabling serdev
    for hot-pluggable buses.
    
    Signed-off-by: Johan Hovold <johan@kernel.org>
    Reviewed-by: Rob Herring <robh@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit baa4d4112e6f8f449056b7e32d55a30102976b54
Author: Jeremy Kerr <jk@ozlabs.org>
Date:   Wed May 24 16:49:59 2017 +1000

    powerpc/spufs: Fix hash faults for kernel regions
    
    commit d75e4919cc0b6fbcbc8d6654ef66d87a9dbf1526 upstream.
    
    Commit ac29c64089b7 ("powerpc/mm: Replace _PAGE_USER with
    _PAGE_PRIVILEGED") swapped _PAGE_USER for _PAGE_PRIVILEGED, and
    introduced check_pte_access() which denied kernel access to
    non-_PAGE_PRIVILEGED pages.
    
    However, it didn't add _PAGE_PRIVILEGED to the hash fault handler
    for spufs' kernel accesses, so the DMAs required to establish SPE
    memory no longer work.
    
    This change adds _PAGE_PRIVILEGED to the hash fault handler for
    kernel accesses.
    
    Fixes: ac29c64089b7 ("powerpc/mm: Replace _PAGE_USER with _PAGE_PRIVILEGED")
    Signed-off-by: Jeremy Kerr <jk@ozlabs.org>
    Reported-by: Sombat Tragolgosol <sombat3960@gmail.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 919c7173e08ac070794873decb8ce1335219503f
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed May 24 17:03:26 2017 +1000

    powerpc: Fix booting P9 hash with CONFIG_PPC_RADIX_MMU=N
    
    commit d957fb4d173647640a2b83e7c7e56a580e7fc7e7 upstream.
    
    Currently if you disable CONFIG_PPC_RADIX_MMU you'll crash on boot on
    a P9. This is because we still set MMU_FTR_TYPE_RADIX via
    ibm,pa-features and MMU_FTR_TYPE_RADIX is what's used for code patching
    in much of the asm code (ie. slb_miss_realmode)
    
    This patch fixes the problem by stopping MMU_FTR_TYPE_RADIX from being
    set from ibm.pa-features.
    
    We may eventually end up removing the CONFIG_PPC_RADIX_MMU option
    completely but until then this fixes the issue.
    
    Fixes: 17a3dd2f5fc7 ("powerpc/mm/radix: Use firmware feature to enable Radix MMU")
    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 72351ac5cdcb09186469f2a27e5aaccda044c61f
Author: Richard Narron <comet.berkeley@gmail.com>
Date:   Sun Jun 4 16:23:18 2017 -0700

    fs/ufs: Set UFS default maximum bytes per file
    
    commit 239e250e4acbc0104d514307029c0839e834a51a upstream.
    
    This fixes a problem with reading files larger than 2GB from a UFS-2
    file system:
    
        https://bugzilla.kernel.org/show_bug.cgi?id=195721
    
    The incorrect UFS s_maxsize limit became a problem as of commit
    c2a9737f45e2 ("vfs,mm: fix a dead loop in truncate_inode_pages_range()")
    which started using s_maxbytes to avoid a page index overflow in
    do_generic_file_read().
    
    That caused files to be truncated on UFS-2 file systems because the
    default maximum file size is 2GB (MAX_NON_LFS) and UFS didn't update it.
    
    Here I simply increase the default to a common value used by other file
    systems.
    
    Signed-off-by: Richard Narron <comet.berkeley@gmail.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Will B <will.brokenbourgh2877@gmail.com>
    Cc: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f351b1226d10b7e2b924016287aaa10c1e6af789
Author: Liam R. Howlett <Liam.Howlett@Oracle.com>
Date:   Wed May 17 11:47:00 2017 -0400

    sparc/ftrace: Fix ftrace graph time measurement
    
    
    [ Upstream commit 48078d2dac0a26f84f5f3ec704f24f7c832cce14 ]
    
    The ftrace function_graph time measurements of a given function is not
    accurate according to those recorded by ftrace using the function
    filters.  This change pulls the x86_64 fix from 'commit 722b3c746953
    ("ftrace/graph: Trace function entry before updating index")' into the
    sparc specific prepare_ftrace_return which stops ftrace from
    counting interrupted tasks in the time measurement.
    
    Example measurements for select_task_rq_fair running "hackbench 100
    process 1000":
    
                  |  tracing/trace_stat/function0  |  function_graph
     Before patch |  2.802 us                      |  4.255 us
     After patch  |  2.749 us                      |  3.094 us
    
    Signed-off-by: Liam R. Howlett <Liam.Howlett@Oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 76037bf9e12e1ed1885d3f552a16fadcdaa370f0
Author: Orlando Arias <oarias@knights.ucf.edu>
Date:   Tue May 16 15:34:00 2017 -0400

    sparc: Fix -Wstringop-overflow warning
    
    
    [ Upstream commit deba804c90642c8ed0f15ac1083663976d578f54 ]
    
    Greetings,
    
    GCC 7 introduced the -Wstringop-overflow flag to detect buffer overflows
    in calls to string handling functions [1][2]. Due to the way
    ``empty_zero_page'' is declared in arch/sparc/include/setup.h, this
    causes a warning to trigger at compile time in the function mem_init(),
    which is subsequently converted to an error. The ensuing patch fixes
    this issue and aligns the declaration of empty_zero_page to that of
    other architectures. Thank you.
    
    Cheers,
    Orlando.
    
    [1] https://gcc.gnu.org/ml/gcc-patches/2016-10/msg02308.html
    [2] https://gcc.gnu.org/gcc-7/changes.html
    
    Signed-off-by: Orlando Arias <oarias@knights.ucf.edu>
    
    --------------------------------------------------------------------------------
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e346489fac4cf0dfc947ebc295292e2444a7cb8f
Author: Nitin Gupta <nitin.m.gupta@oracle.com>
Date:   Mon May 15 16:28:17 2017 -0700

    sparc64: Fix mapping of 64k pages with MAP_FIXED
    
    
    [ Upstream commit b6c41cb050d5debc7e4eaa0a81cbdbad72588891 ]
    
    An incorrect huge page alignment check caused
    mmap failure for 64K pages when MAP_FIXED is used
    with address not aligned to HPAGE_SIZE.
    
    Orabug: 25885991
    
    Fixes: dcd1912d21a0 ("sparc64: Add 64K page size support")
    Signed-off-by: Nitin Gupta <nitin.m.gupta@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 21dccb0f7cb4915845ac41fd39772c287e9b8777
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu May 18 03:00:06 2017 +0200

    bpf: adjust verifier heuristics
    
    
    [ Upstream commit 3c2ce60bdd3d57051bf85615deec04a694473840 ]
    
    Current limits with regards to processing program paths do not
    really reflect today's needs anymore due to programs becoming
    more complex and verifier smarter, keeping track of more data
    such as const ALU operations, alignment tracking, spilling of
    PTR_TO_MAP_VALUE_ADJ registers, and other features allowing for
    smarter matching of what LLVM generates.
    
    This also comes with the side-effect that we result in fewer
    opportunities to prune search states and thus often need to do
    more work to prove safety than in the past due to different
    register states and stack layout where we mismatch. Generally,
    it's quite hard to determine what caused a sudden increase in
    complexity, it could be caused by something as trivial as a
    single branch somewhere at the beginning of the program where
    LLVM assigned a stack slot that is marked differently throughout
    other branches and thus causing a mismatch, where verifier
    then needs to prove safety for the whole rest of the program.
    Subsequently, programs with even less than half the insn size
    limit can get rejected. We noticed that while some programs
    load fine under pre 4.11, they get rejected due to hitting
    limits on more recent kernels. We saw that in the vast majority
    of cases (90+%) pruning failed due to register mismatches. In
    case of stack mismatches, majority of cases failed due to
    different stack slot types (invalid, spill, misc) rather than
    differences in spilled registers.
    
    This patch makes pruning more aggressive by also adding markers
    that sit at conditional jumps as well. Currently, we only mark
    jump targets for pruning. For example in direct packet access,
    these are usually error paths where we bail out. We found that
    adding these markers, it can reduce number of processed insns
    by up to 30%. Another option is to ignore reg->id in probing
    PTR_TO_MAP_VALUE_OR_NULL registers, which can help pruning
    slightly as well by up to 7% observed complexity reduction as
    stand-alone. Meaning, if a previous path with register type
    PTR_TO_MAP_VALUE_OR_NULL for map X was found to be safe, then
    in the current state a PTR_TO_MAP_VALUE_OR_NULL register for
    the same map X must be safe as well. Last but not least the
    patch also adds a scheduling point and bumps the current limit
    for instructions to be processed to a more adequate value.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 87cebd0f198b3f1153e5aa8d63acf18c4d61af87
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu May 25 01:05:08 2017 +0200

    bpf: fix wrong exposure of map_flags into fdinfo for lpm
    
    
    [ Upstream commit a316338cb71a3260201490e615f2f6d5c0d8fb2c ]
    
    trie_alloc() always needs to have BPF_F_NO_PREALLOC passed in via
    attr->map_flags, since it does not support preallocation yet. We
    check the flag, but we never copy the flag into trie->map.map_flags,
    which is later on exposed into fdinfo and used by loaders such as
    iproute2. Latter uses this in bpf_map_selfcheck_pinned() to test
    whether a pinned map has the same spec as the one from the BPF obj
    file and if not, bails out, which is currently the case for lpm
    since it exposes always 0 as flags.
    
    Also copy over flags in array_map_alloc() and stack_map_alloc().
    They always have to be 0 right now, but we should make sure to not
    miss to copy them over at a later point in time when we add actual
    flags for them to use.
    
    Fixes: b95a5c4db09b ("bpf: add a longest prefix match trie map implementation")
    Reported-by: Jarno Rajahalme <jarno@covalent.io>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6d2860eeefbbf574288b556bb3b17df3ad2f824
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu May 25 01:05:07 2017 +0200

    bpf: add bpf_clone_redirect to bpf_helper_changes_pkt_data
    
    
    [ Upstream commit 41703a731066fde79c3e5ccf3391cf77a98aeda5 ]
    
    The bpf_clone_redirect() still needs to be listed in
    bpf_helper_changes_pkt_data() since we call into
    bpf_try_make_head_writable() from there, thus we need
    to invalidate prior pkt regs as well.
    
    Fixes: 36bbef52c7eb ("bpf: direct packet write and access for helpers for clsact progs")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3b69d6516e1c2aac93fb1f24826ac6a8760156e7
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu May 25 14:27:35 2017 -0700

    ipv4: add reference counting to metrics
    
    
    [ Upstream commit 3fb07daff8e99243366a081e5129560734de4ada ]
    
    Andrey Konovalov reported crashes in ipv4_mtu()
    
    I could reproduce the issue with KASAN kernels, between
    10.246.7.151 and 10.246.7.152 :
    
    1) 20 concurrent netperf -t TCP_RR -H 10.246.7.152 -l 1000 &
    
    2) At the same time run following loop :
    while :
    do
     ip ro add 10.246.7.152 dev eth0 src 10.246.7.151 mtu 1500
     ip ro del 10.246.7.152 dev eth0 src 10.246.7.151 mtu 1500
    done
    
    Cong Wang attempted to add back rt->fi in commit
    82486aa6f1b9 ("ipv4: restore rt->fi for reference counting")
    but this proved to add some issues that were complex to solve.
    
    Instead, I suggested to add a refcount to the metrics themselves,
    being a standalone object (in particular, no reference to other objects)
    
    I tried to make this patch as small as possible to ease its backport,
    instead of being super clean. Note that we believe that only ipv4 dst
    need to take care of the metric refcount. But if this is wrong,
    this patch adds the basic infrastructure to extend this to other
    families.
    
    Many thanks to Julian Anastasov for reviewing this patch, and Cong Wang
    for his efforts on this problem.
    
    Fixes: 2860583fe840 ("ipv4: Kill rt->fi")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Reviewed-by: Julian Anastasov <ja@ssi.bg>
    Acked-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d3edf403e279401947de9b274537ffbfe5310c28
Author: Peter Dawson <petedaws@gmail.com>
Date:   Fri May 26 06:35:18 2017 +1000

    ip6_tunnel, ip6_gre: fix setting of DSCP on encapsulated packets
    
    
    [ Upstream commit 0e9a709560dbcfbace8bf4019dc5298619235891 ]
    
    This fix addresses two problems in the way the DSCP field is formulated
     on the encapsulating header of IPv6 tunnels.
    Bugzilla: https://bugzilla.kernel.org/show_bug.cgi?id=195661
    
    1) The IPv6 tunneling code was manipulating the DSCP field of the
     encapsulating packet using the 32b flowlabel. Since the flowlabel is
     only the lower 20b it was incorrect to assume that the upper 12b
     containing the DSCP and ECN fields would remain intact when formulating
     the encapsulating header. This fix handles the 'inherit' and
     'fixed-value' DSCP cases explicitly using the extant dsfield u8 variable.
    
    2) The use of INET_ECN_encapsulate(0, dsfield) in ip6_tnl_xmit was
     incorrect and resulted in the DSCP value always being set to 0.
    
    Commit 90427ef5d2a4 ("ipv6: fix flow labels when the traffic class
     is non-0") caused the regression by masking out the flowlabel
     which exposed the incorrect handling of the DSCP portion of the
     flowlabel in ip6_tunnel and ip6_gre.
    
    Fixes: 90427ef5d2a4 ("ipv6: fix flow labels when the traffic class is non-0")
    Signed-off-by: Peter Dawson <peter.a.dawson@boeing.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 90e7c3322d0cd536b29c7ea70af906283317dc42
Author: Davide Caratti <dcaratti@redhat.com>
Date:   Thu May 25 19:14:56 2017 +0200

    sctp: fix ICMP processing if skb is non-linear
    
    
    [ Upstream commit 804ec7ebe8ea003999ca8d1bfc499edc6a9e07df ]
    
    sometimes ICMP replies to INIT chunks are ignored by the client, even if
    the encapsulated SCTP headers match an open socket. This happens when the
    ICMP packet is carried by a paged skb: use skb_header_pointer() to read
    packet contents beyond the SCTP header, so that chunk header and initiate
    tag are validated correctly.
    
    v2:
    - don't use skb_header_pointer() to read the transport header, since
      icmp_socket_deliver() already puts these 8 bytes in the linear area.
    - change commit message to make specific reference to INIT chunks.
    
    Signed-off-by: Davide Caratti <dcaratti@redhat.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Reviewed-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0236d8c44eb8961365f6d9ed98b8aac06b2c23b1
Author: Wei Wang <weiwan@google.com>
Date:   Wed May 24 09:59:31 2017 -0700

    tcp: avoid fastopen API to be used on AF_UNSPEC
    
    
    [ Upstream commit ba615f675281d76fd19aa03558777f81fb6b6084 ]
    
    Fastopen API should be used to perform fastopen operations on the TCP
    socket. It does not make sense to use fastopen API to perform disconnect
    by calling it with AF_UNSPEC. The fastopen data path is also prone to
    race conditions and bugs when using with AF_UNSPEC.
    
    One issue reported and analyzed by Vegard Nossum is as follows:
    +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    Thread A:                            Thread B:
    ------------------------------------------------------------------------
    sendto()
     - tcp_sendmsg()
         - sk_stream_memory_free() = 0
             - goto wait_for_sndbuf
                 - sk_stream_wait_memory()
                    - sk_wait_event() // sleep
              |                          sendto(flags=MSG_FASTOPEN, dest_addr=AF_UNSPEC)
              |                           - tcp_sendmsg()
              |                              - tcp_sendmsg_fastopen()
              |                                 - __inet_stream_connect()
              |                                    - tcp_disconnect() //because of AF_UNSPEC
              |                                       - tcp_transmit_skb()// send RST
              |                                    - return 0; // no reconnect!
              |                           - sk_stream_wait_connect()
              |                                 - sock_error()
              |                                    - xchg(&sk->sk_err, 0)
              |                                    - return -ECONNRESET
            - ... // wake up, see sk->sk_err == 0
        - skb_entail() on TCP_CLOSE socket
    
    If the connection is reopened then we will send a brand new SYN packet
    after thread A has already queued a buffer. At this point I think the
    socket internal state (sequence numbers etc.) becomes messed up.
    
    When the new connection is closed, the FIN-ACK is rejected because the
    sequence number is outside the window. The other side tries to
    retransmit,
    but __tcp_retransmit_skb() calls tcp_trim_head() on an empty skb which
    corrupts the skb data length and hits a BUG() in copy_and_csum_bits().
    +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    
    Hence, this patch adds a check for AF_UNSPEC in the fastopen data path
    and return EOPNOTSUPP to user if such case happens.
    
    Fixes: cf60af03ca4e7 ("tcp: Fast Open client - sendmsg(MSG_FASTOPEN)")
    Reported-by: Vegard Nossum <vegard.nossum@oracle.com>
    Signed-off-by: Wei Wang <weiwan@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1642394fffd5cbcaef65b166708aa4a0443b5e8a
Author: Eric Garver <e@erig.me>
Date:   Tue May 23 18:37:27 2017 -0400

    geneve: fix fill_info when using collect_metadata
    
    
    [ Upstream commit 11387fe4a98f75d1f4cdb3efe3b42b19205c9df5 ]
    
    Since 9b4437a5b870 ("geneve: Unify LWT and netdev handling.") fill_info
    does not return UDP_ZERO_CSUM6_RX when using COLLECT_METADATA. This is
    because it uses ip_tunnel_info_af() with the device level info, which is
    not valid for COLLECT_METADATA.
    
    Fix by checking for the presence of the actual sockets.
    
    Fixes: 9b4437a5b870 ("geneve: Unify LWT and netdev handling.")
    Signed-off-by: Eric Garver <e@erig.me>
    Acked-by: Pravin B Shelar <pshelar@ovn.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4dbbbaad64c5189cd3177bb4adcbe80fcc63b4c0
Author: Vlad Yasevich <vyasevich@gmail.com>
Date:   Tue May 23 13:38:43 2017 -0400

    virtio-net: enable TSO/checksum offloads for Q-in-Q vlans
    
    
    [ Upstream commit 2836b4f224d4fd7d1a2b23c3eecaf0f0ae199a74 ]
    
    Since virtio does not provide it's own ndo_features_check handler,
    TSO, and now checksum offload, are disabled for stacked vlans.
    Re-enable the support and let the host take care of it.  This
    restores/improves Guest-to-Guest performance over Q-in-Q vlans.
    
    Acked-by: Jason Wang <jasowang@redhat.com>
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Vladislav Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit acc866e9b53eb04a397750d1461c34c3c9622490
Author: Vlad Yasevich <vyasevich@gmail.com>
Date:   Tue May 23 13:38:42 2017 -0400

    be2net: Fix offload features for Q-in-Q packets
    
    
    [ Upstream commit cc6e9de62a7f84c9293a2ea41bc412b55bb46e85 ]
    
    At least some of the be2net cards do not seem to be capabled
    of performing checksum offload computions on Q-in-Q packets.
    In these case, the recevied checksum on the remote is invalid
    and TCP syn packets are dropped.
    
    This patch adds a call to check disbled acceleration features
    on Q-in-Q tagged traffic.
    
    CC: Sathya Perla <sathya.perla@broadcom.com>
    CC: Ajit Khaparde <ajit.khaparde@broadcom.com>
    CC: Sriharsha Basavapatna <sriharsha.basavapatna@broadcom.com>
    CC: Somnath Kotur <somnath.kotur@broadcom.com>
    Signed-off-by: Vladislav Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 423c1b43240d7369c0e06650bedb181d51cd8961
Author: Vlad Yasevich <vyasevich@gmail.com>
Date:   Tue May 23 13:38:41 2017 -0400

    vlan: Fix tcp checksum offloads in Q-in-Q vlans
    
    
    [ Upstream commit 35d2f80b07bbe03fb358afb0bdeff7437a7d67ff ]
    
    It appears that TCP checksum offloading has been broken for
    Q-in-Q vlans.  The behavior was execerbated by the
    series
        commit afb0bc972b52 ("Merge branch 'stacked_vlan_tso'")
    that that enabled accleleration features on stacked vlans.
    
    However, event without that series, it is possible to trigger
    this issue.  It just requires a lot more specialized configuration.
    
    The root cause is the interaction between how
    netdev_intersect_features() works, the features actually set on
    the vlan devices and HW having the ability to run checksum with
    longer headers.
    
    The issue starts when netdev_interesect_features() replaces
    NETIF_F_HW_CSUM with a combination of NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM,
    if the HW advertises IP|IPV6 specific checksums.  This happens
    for tagged and multi-tagged packets.   However, HW that enables
    IP|IPV6 checksum offloading doesn't gurantee that packets with
    arbitrarily long headers can be checksummed.
    
    This patch disables IP|IPV6 checksums on the packet for multi-tagged
    packets.
    
    CC: Toshiaki Makita <makita.toshiaki@lab.ntt.co.jp>
    CC: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: Vladislav Yasevich <vyasevic@redhat.com>
    Acked-by: Toshiaki Makita <makita.toshiaki@lab.ntt.co.jp>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f1cd4c6331e303f193604c095c71c4f391ea1219
Author: Andrew Lunn <andrew@lunn.ch>
Date:   Tue May 23 17:49:13 2017 +0200

    net: phy: marvell: Limit errata to 88m1101
    
    
    [ Upstream commit f2899788353c13891412b273fdff5f02d49aa40f ]
    
    The 88m1101 has an errata when configuring autoneg. However, it was
    being applied to many other Marvell PHYs as well. Limit its scope to
    just the 88m1101.
    
    Fixes: 76884679c644 ("phylib: Add support for Marvell 88e1111S and 88e1145")
    Reported-by: Daniel Walker <danielwa@cisco.com>
    Signed-off-by: Andrew Lunn <andrew@lunn.ch>
    Acked-by: Harini Katakam <harinik@xilinx.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bea278025cbc41556fd8e7edd22a64d84a60ca2f
Author: Mohamad Haj Yahia <mohamad@mellanox.com>
Date:   Thu Feb 23 11:19:36 2017 +0200

    net/mlx5: Avoid using pending command interface slots
    
    
    [ Upstream commit 73dd3a4839c1d27c36d4dcc92e1ff44225ecbeb7 ]
    
    Currently when firmware command gets stuck or it takes long time to
    complete, the driver command will get timeout and the command slot is
    freed and can be used for new commands, and if the firmware receive new
    command on the old busy slot its behavior is unexpected and this could
    be harmful.
    To fix this when the driver command gets timeout we return failure,
    but we don't free the command slot and we wait for the firmware to
    explicitly respond to that command.
    Once all the entries are busy we will stop processing new firmware
    commands.
    
    Fixes: 9cba4ebcf374 ('net/mlx5: Fix potential deadlock in command mode change')
    Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
    Cc: kernel-team@fb.com
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1cdcbe7c706a6f6bee2d844bf8e7d5fc7c270fb7
Author: Jarod Wilson <jarod@redhat.com>
Date:   Fri May 19 19:43:45 2017 -0400

    bonding: fix accounting of active ports in 3ad
    
    
    [ Upstream commit 751da2a69b7cc82d83dc310ed7606225f2d6e014 ]
    
    As of 7bb11dc9f59d and 0622cab0341c, bond slaves in a 3ad bond are not
    removed from the aggregator when they are down, and the active slave count
    is NOT equal to number of ports in the aggregator, but rather the number
    of ports in the aggregator that are still enabled. The sysfs spew for
    bonding_show_ad_num_ports() has a comment that says "Show number of active
    802.3ad ports.", but it's currently showing total number of ports, both
    active and inactive. Remedy it by using the same logic introduced in
    0622cab0341c in __bond_3ad_get_active_agg_info(), so sysfs, procfs and
    netlink all report the number of active ports. Note that this means that
    IFLA_BOND_AD_INFO_NUM_PORTS really means NUM_ACTIVE_PORTS instead of
    NUM_PORTS, and thus perhaps should be renamed for clarity.
    
    Lightly tested on a dual i40e lacp bond, simulating link downs with an ip
    link set dev <slave2> down, was able to produce the state where I could
    see both in the same aggregator, but a number of ports count of 1.
    
    MII Status: up
    Active Aggregator Info:
            Aggregator ID: 1
            Number of ports: 2 <---
    Slave Interface: ens10
    MII Status: up <---
    Aggregator ID: 1
    Slave Interface: ens11
    MII Status: up
    Aggregator ID: 1
    
    MII Status: up
    Active Aggregator Info:
            Aggregator ID: 1
            Number of ports: 1 <---
    Slave Interface: ens10
    MII Status: down <---
    Aggregator ID: 1
    Slave Interface: ens11
    MII Status: up
    Aggregator ID: 1
    
    CC: Jay Vosburgh <j.vosburgh@gmail.com>
    CC: Veaceslav Falico <vfalico@gmail.com>
    CC: Andy Gospodarek <andy@greyhouse.net>
    CC: netdev@vger.kernel.org
    Signed-off-by: Jarod Wilson <jarod@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 827624c3d1cfd1b569ec2c6593a6a50ab65c72bb
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri May 19 14:17:48 2017 -0700

    ipv6: fix out of bound writes in __ip6_append_data()
    
    
    [ Upstream commit 232cd35d0804cc241eb887bb8d4d9b3b9881c64a ]
    
    Andrey Konovalov and idaifish@gmail.com reported crashes caused by
    one skb shared_info being overwritten from __ip6_append_data()
    
    Andrey program lead to following state :
    
    copy -4200 datalen 2000 fraglen 2040
    maxfraglen 2040 alloclen 2048 transhdrlen 0 offset 0 fraggap 6200
    
    The skb_copy_and_csum_bits(skb_prev, maxfraglen, data + transhdrlen,
    fraggap, 0); is overwriting skb->head and skb_shared_info
    
    Since we apparently detect this rare condition too late, move the
    code earlier to even avoid allocating skb and risking crashes.
    
    Once again, many thanks to Andrey and syzkaller team.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Tested-by: Andrey Konovalov <andreyknvl@google.com>
    Reported-by: <idaifish@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 99c971a56d764f6f3bb7c6a2581b2d33cacc702a
Author: Xin Long <lucien.xin@gmail.com>
Date:   Fri May 19 22:20:29 2017 +0800

    bridge: start hello_timer when enabling KERNEL_STP in br_stp_start
    
    
    [ Upstream commit 6d18c732b95c0a9d35e9f978b4438bba15412284 ]
    
    Since commit 76b91c32dd86 ("bridge: stp: when using userspace stp stop
    kernel hello and hold timers"), bridge would not start hello_timer if
    stp_enabled is not KERNEL_STP when br_dev_open.
    
    The problem is even if users set stp_enabled with KERNEL_STP later,
    the timer will still not be started. It causes that KERNEL_STP can
    not really work. Users have to re-ifup the bridge to avoid this.
    
    This patch is to fix it by starting br->hello_timer when enabling
    KERNEL_STP in br_stp_start.
    
    As an improvement, it's also to start hello_timer again only when
    br->stp_enabled is KERNEL_STP in br_hello_timer_expired, there is
    no reason to start the timer again when it's NO_STP.
    
    Fixes: 76b91c32dd86 ("bridge: stp: when using userspace stp stop kernel hello and hold timers")
    Reported-by: Haidong Li <haili@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Reviewed-by: Ivan Vecera <cera@cera.cz>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bf97c6bf24f83f8a2141ff22856aa4a1ca6e0dd3
Author: Bjørn Mork <bjorn@mork.no>
Date:   Wed May 17 16:31:41 2017 +0200

    qmi_wwan: add another Lenovo EM74xx device ID
    
    
    [ Upstream commit 486181bcb3248e2f1977f4e69387a898234a4e1e ]
    
    In their infinite wisdom, and never ending quest for end user frustration,
    Lenovo has decided to use a new USB device ID for the wwan modules in
    their 2017 laptops.  The actual hardware is still the Sierra Wireless
    EM7455 or EM7430, depending on region.
    
    Signed-off-by: Bjørn Mork <bjorn@mork.no>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7b570175b3da6cb7f6e99e46eb04b1f8eb1ad220
Author: Tobias Jungel <tobias.jungel@bisdn.de>
Date:   Wed May 17 09:29:12 2017 +0200

    bridge: netlink: check vlan_default_pvid range
    
    
    [ Upstream commit a285860211bf257b0e6d522dac6006794be348af ]
    
    Currently it is allowed to set the default pvid of a bridge to a value
    above VLAN_VID_MASK (0xfff). This patch adds a check to br_validate and
    returns -EINVAL in case the pvid is out of bounds.
    
    Reproduce by calling:
    
    [root@test ~]# ip l a type bridge
    [root@test ~]# ip l a type dummy
    [root@test ~]# ip l s bridge0 type bridge vlan_filtering 1
    [root@test ~]# ip l s bridge0 type bridge vlan_default_pvid 9999
    [root@test ~]# ip l s dummy0 master bridge0
    [root@test ~]# bridge vlan
    port    vlan ids
    bridge0  9999 PVID Egress Untagged
    
    dummy0   9999 PVID Egress Untagged
    
    Fixes: 0f963b7592ef ("bridge: netlink: add support for default_pvid")
    Acked-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: Tobias Jungel <tobias.jungel@bisdn.de>
    Acked-by: Sabrina Dubroca <sd@queasysnail.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4b3a6fa35eed466bf6396427463bc8ae58e16b15
Author: David S. Miller <davem@davemloft.net>
Date:   Wed May 17 22:54:11 2017 -0400

    ipv6: Check ip6_find_1stfragopt() return value properly.
    
    
    [ Upstream commit 7dd7eb9513bd02184d45f000ab69d78cb1fa1531 ]
    
    Do not use unsigned variables to see if it returns a negative
    error or not.
    
    Fixes: 2423496af35d ("ipv6: Prevent overrun when parsing v6 header options")
    Reported-by: Julia Lawall <julia.lawall@lip6.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9909e4e4ff16e3f66b4e33e118621d7fe92fc6d4
Author: Craig Gallek <kraig@google.com>
Date:   Tue May 16 14:36:23 2017 -0400

    ipv6: Prevent overrun when parsing v6 header options
    
    
    [ Upstream commit 2423496af35d94a87156b063ea5cedffc10a70a1 ]
    
    The KASAN warning repoted below was discovered with a syzkaller
    program.  The reproducer is basically:
      int s = socket(AF_INET6, SOCK_RAW, NEXTHDR_HOP);
      send(s, &one_byte_of_data, 1, MSG_MORE);
      send(s, &more_than_mtu_bytes_data, 2000, 0);
    
    The socket() call sets the nexthdr field of the v6 header to
    NEXTHDR_HOP, the first send call primes the payload with a non zero
    byte of data, and the second send call triggers the fragmentation path.
    
    The fragmentation code tries to parse the header options in order
    to figure out where to insert the fragment option.  Since nexthdr points
    to an invalid option, the calculation of the size of the network header
    can made to be much larger than the linear section of the skb and data
    is read outside of it.
    
    This fix makes ip6_find_1stfrag return an error if it detects
    running out-of-bounds.
    
    [   42.361487] ==================================================================
    [   42.364412] BUG: KASAN: slab-out-of-bounds in ip6_fragment+0x11c8/0x3730
    [   42.365471] Read of size 840 at addr ffff88000969e798 by task ip6_fragment-oo/3789
    [   42.366469]
    [   42.366696] CPU: 1 PID: 3789 Comm: ip6_fragment-oo Not tainted 4.11.0+ #41
    [   42.367628] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1ubuntu1 04/01/2014
    [   42.368824] Call Trace:
    [   42.369183]  dump_stack+0xb3/0x10b
    [   42.369664]  print_address_description+0x73/0x290
    [   42.370325]  kasan_report+0x252/0x370
    [   42.370839]  ? ip6_fragment+0x11c8/0x3730
    [   42.371396]  check_memory_region+0x13c/0x1a0
    [   42.371978]  memcpy+0x23/0x50
    [   42.372395]  ip6_fragment+0x11c8/0x3730
    [   42.372920]  ? nf_ct_expect_unregister_notifier+0x110/0x110
    [   42.373681]  ? ip6_copy_metadata+0x7f0/0x7f0
    [   42.374263]  ? ip6_forward+0x2e30/0x2e30
    [   42.374803]  ip6_finish_output+0x584/0x990
    [   42.375350]  ip6_output+0x1b7/0x690
    [   42.375836]  ? ip6_finish_output+0x990/0x990
    [   42.376411]  ? ip6_fragment+0x3730/0x3730
    [   42.376968]  ip6_local_out+0x95/0x160
    [   42.377471]  ip6_send_skb+0xa1/0x330
    [   42.377969]  ip6_push_pending_frames+0xb3/0xe0
    [   42.378589]  rawv6_sendmsg+0x2051/0x2db0
    [   42.379129]  ? rawv6_bind+0x8b0/0x8b0
    [   42.379633]  ? _copy_from_user+0x84/0xe0
    [   42.380193]  ? debug_check_no_locks_freed+0x290/0x290
    [   42.380878]  ? ___sys_sendmsg+0x162/0x930
    [   42.381427]  ? rcu_read_lock_sched_held+0xa3/0x120
    [   42.382074]  ? sock_has_perm+0x1f6/0x290
    [   42.382614]  ? ___sys_sendmsg+0x167/0x930
    [   42.383173]  ? lock_downgrade+0x660/0x660
    [   42.383727]  inet_sendmsg+0x123/0x500
    [   42.384226]  ? inet_sendmsg+0x123/0x500
    [   42.384748]  ? inet_recvmsg+0x540/0x540
    [   42.385263]  sock_sendmsg+0xca/0x110
    [   42.385758]  SYSC_sendto+0x217/0x380
    [   42.386249]  ? SYSC_connect+0x310/0x310
    [   42.386783]  ? __might_fault+0x110/0x1d0
    [   42.387324]  ? lock_downgrade+0x660/0x660
    [   42.387880]  ? __fget_light+0xa1/0x1f0
    [   42.388403]  ? __fdget+0x18/0x20
    [   42.388851]  ? sock_common_setsockopt+0x95/0xd0
    [   42.389472]  ? SyS_setsockopt+0x17f/0x260
    [   42.390021]  ? entry_SYSCALL_64_fastpath+0x5/0xbe
    [   42.390650]  SyS_sendto+0x40/0x50
    [   42.391103]  entry_SYSCALL_64_fastpath+0x1f/0xbe
    [   42.391731] RIP: 0033:0x7fbbb711e383
    [   42.392217] RSP: 002b:00007ffff4d34f28 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    [   42.393235] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007fbbb711e383
    [   42.394195] RDX: 0000000000001000 RSI: 00007ffff4d34f60 RDI: 0000000000000003
    [   42.395145] RBP: 0000000000000046 R08: 00007ffff4d34f40 R09: 0000000000000018
    [   42.396056] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000400aad
    [   42.396598] R13: 0000000000000066 R14: 00007ffff4d34ee0 R15: 00007fbbb717af00
    [   42.397257]
    [   42.397411] Allocated by task 3789:
    [   42.397702]  save_stack_trace+0x16/0x20
    [   42.398005]  save_stack+0x46/0xd0
    [   42.398267]  kasan_kmalloc+0xad/0xe0
    [   42.398548]  kasan_slab_alloc+0x12/0x20
    [   42.398848]  __kmalloc_node_track_caller+0xcb/0x380
    [   42.399224]  __kmalloc_reserve.isra.32+0x41/0xe0
    [   42.399654]  __alloc_skb+0xf8/0x580
    [   42.400003]  sock_wmalloc+0xab/0xf0
    [   42.400346]  __ip6_append_data.isra.41+0x2472/0x33d0
    [   42.400813]  ip6_append_data+0x1a8/0x2f0
    [   42.401122]  rawv6_sendmsg+0x11ee/0x2db0
    [   42.401505]  inet_sendmsg+0x123/0x500
    [   42.401860]  sock_sendmsg+0xca/0x110
    [   42.402209]  ___sys_sendmsg+0x7cb/0x930
    [   42.402582]  __sys_sendmsg+0xd9/0x190
    [   42.402941]  SyS_sendmsg+0x2d/0x50
    [   42.403273]  entry_SYSCALL_64_fastpath+0x1f/0xbe
    [   42.403718]
    [   42.403871] Freed by task 1794:
    [   42.404146]  save_stack_trace+0x16/0x20
    [   42.404515]  save_stack+0x46/0xd0
    [   42.404827]  kasan_slab_free+0x72/0xc0
    [   42.405167]  kfree+0xe8/0x2b0
    [   42.405462]  skb_free_head+0x74/0xb0
    [   42.405806]  skb_release_data+0x30e/0x3a0
    [   42.406198]  skb_release_all+0x4a/0x60
    [   42.406563]  consume_skb+0x113/0x2e0
    [   42.406910]  skb_free_datagram+0x1a/0xe0
    [   42.407288]  netlink_recvmsg+0x60d/0xe40
    [   42.407667]  sock_recvmsg+0xd7/0x110
    [   42.408022]  ___sys_recvmsg+0x25c/0x580
    [   42.408395]  __sys_recvmsg+0xd6/0x190
    [   42.408753]  SyS_recvmsg+0x2d/0x50
    [   42.409086]  entry_SYSCALL_64_fastpath+0x1f/0xbe
    [   42.409513]
    [   42.409665] The buggy address belongs to the object at ffff88000969e780
    [   42.409665]  which belongs to the cache kmalloc-512 of size 512
    [   42.410846] The buggy address is located 24 bytes inside of
    [   42.410846]  512-byte region [ffff88000969e780, ffff88000969e980)
    [   42.411941] The buggy address belongs to the page:
    [   42.412405] page:ffffea000025a780 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
    [   42.413298] flags: 0x100000000008100(slab|head)
    [   42.413729] raw: 0100000000008100 0000000000000000 0000000000000000 00000001800c000c
    [   42.414387] raw: ffffea00002a9500 0000000900000007 ffff88000c401280 0000000000000000
    [   42.415074] page dumped because: kasan: bad access detected
    [   42.415604]
    [   42.415757] Memory state around the buggy address:
    [   42.416222]  ffff88000969e880: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   42.416904]  ffff88000969e900: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   42.417591] >ffff88000969e980: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   42.418273]                    ^
    [   42.418588]  ffff88000969ea00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   42.419273]  ffff88000969ea80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   42.419882] ==================================================================
    
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: Craig Gallek <kraig@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit df6342be40ff97a8dc35fa8713c90d21fb4f2f67
Author: David Ahern <dsahern@gmail.com>
Date:   Mon May 15 23:19:17 2017 -0700

    net: Improve handling of failures on link and route dumps
    
    
    [ Upstream commit f6c5775ff0bfa62b072face6bf1d40f659f194b2 ]
    
    In general, rtnetlink dumps do not anticipate failure to dump a single
    object (e.g., link or route) on a single pass. As both route and link
    objects have grown via more attributes, that is no longer a given.
    
    netlink dumps can handle a failure if the dump function returns an
    error; specifically, netlink_dump adds the return code to the response
    if it is <= 0 so userspace is notified of the failure. The missing
    piece is the rtnetlink dump functions returning the error.
    
    Fix route and link dump functions to return the errors if no object is
    added to an skb (detected by skb->len != 0). IPv6 route dumps
    (rt6_dump_route) already return the error; this patch updates IPv4 and
    link dumps. Other dump functions may need to be ajusted as well.
    
    Reported-by: Jan Moskyto Matejka <mq@ucw.cz>
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a19f55f9bb374b24f3bca3bfd7e75752b9e6d372
Author: Christoph Hellwig <hch@lst.de>
Date:   Tue May 16 09:51:38 2017 +0300

    net/smc: Add warning about remote memory exposure
    
    
    [ Upstream commit 19a0f7e37c0761a0a1cbf550705a6063c9675223 ]
    
    The driver explicitly bypasses APIs to register all memory once a
    connection is made, and thus allows remote access to memory.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Leon Romanovsky <leon@kernel.org>
    Acked-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 516b3ed999efddfec7c49f06b9630ec55ebc9631
Author: Ursula Braun <ubraun@linux.vnet.ibm.com>
Date:   Mon May 15 17:33:37 2017 +0200

    smc: switch to usage of IB_PD_UNSAFE_GLOBAL_RKEY
    
    
    [ Upstream commit 263eec9b2a82e8697d064709414914b5b10ac538 ]
    
    Currently, SMC enables remote access to physical memory when a user
    has successfully configured and established an SMC-connection until ten
    minutes after the last SMC connection is closed. Because this is considered
    a security risk, drivers are supposed to use IB_PD_UNSAFE_GLOBAL_RKEY in
    such a case.
    
    This patch changes the current SMC code to use IB_PD_UNSAFE_GLOBAL_RKEY.
    This improves user awareness, but does not remove the security risk itself.
    
    Signed-off-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6cb41cf3023ac2026f149ce77864ea49cbb470b
Author: Soheil Hassas Yeganeh <soheil@google.com>
Date:   Mon May 15 17:05:47 2017 -0400

    tcp: eliminate negative reordering in tcp_clean_rtx_queue
    
    
    [ Upstream commit bafbb9c73241760023d8981191ddd30bb1c6dbac ]
    
    tcp_ack() can call tcp_fragment() which may dededuct the
    value tp->fackets_out when MSS changes. When prior_fackets
    is larger than tp->fackets_out, tcp_clean_rtx_queue() can
    invoke tcp_update_reordering() with negative values. This
    results in absurd tp->reodering values higher than
    sysctl_tcp_max_reordering.
    
    Note that tcp_update_reordering indeeds sets tp->reordering
    to min(sysctl_tcp_max_reordering, metric), but because
    the comparison is signed, a negative metric always wins.
    
    Fixes: c7caf8d3ed7a ("[TCP]: Fix reord detection due to snd_una covered holes")
    Reported-by: Rebecca Isaacs <risaacs@google.com>
    Signed-off-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cc1d2a620dd0aeb55e641f5a406bab631aa6842c
Author: Gal Pressman <galp@mellanox.com>
Date:   Wed Apr 19 14:35:15 2017 +0300

    net/mlx5e: Fix ethtool pause support and advertise reporting
    
    
    [ Upstream commit e3c19503712d6360239b19c14cded56dd63c40d7 ]
    
    Pause bit should set when RX pause is on, not TX pause.
    Also, setting Asym_Pause is incorrect, and should be turned off.
    
    Fixes: 665bc53969d7 ("net/mlx5e: Use new ethtool get/set link ksettings API")
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Cc: kernel-team@fb.com
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c8a52aa79a4b44a50cf4f213f6dfe3e3cfda5368
Author: Gal Pressman <galp@mellanox.com>
Date:   Mon Apr 3 15:11:22 2017 +0300

    net/mlx5e: Use the correct pause values for ethtool advertising
    
    
    [ Upstream commit b383b544f2666d67446b951a9a97af239dafed5d ]
    
    Query the operational pause from firmware (PFCC register) instead of
    always passing zeros.
    
    Fixes: 665bc53969d7 ("net/mlx5e: Use new ethtool get/set link ksettings API")
    Signed-off-by: Gal Pressman <galp@mellanox.com>
    Cc: kernel-team@fb.com
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03c10a87f16fb27f65cb3eb54dc4a84753177720
Author: Douglas Caetano dos Santos <douglascs@taghos.com.br>
Date:   Fri May 12 15:19:15 2017 -0300

    net/packet: fix missing net_device reference release
    
    
    [ Upstream commit d19b183cdc1fa3d70d6abe2a4c369e748cd7ebb8 ]
    
    When using a TX ring buffer, if an error occurs processing a control
    message (e.g. invalid message), the net_device reference is not
    released.
    
    Fixes c14ac9451c348 ("sock: enable timestamping using control messages")
    Signed-off-by: Douglas Caetano dos Santos <douglascs@taghos.com.br>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 703a20827411c3906b644713bc4462d4b3fb6a5f
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 17 07:16:40 2017 -0700

    sctp: do not inherit ipv6_{mc|ac|fl}_list from parent
    
    
    [ Upstream commit fdcee2cbb8438702ea1b328fb6e0ac5e9a40c7f8 ]
    
    SCTP needs fixes similar to 83eaddab4378 ("ipv6/dccp: do not inherit
    ipv6_mc_list from parent"), otherwise bad things can happen.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Tested-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dc9bf5513e0ffa01e5f0c7b8a183d24610e6cdaa
Author: Xin Long <lucien.xin@gmail.com>
Date:   Fri May 12 14:39:52 2017 +0800

    sctp: fix src address selection if using secondary addresses for ipv6
    
    
    [ Upstream commit dbc2b5e9a09e9a6664679a667ff81cff6e5f2641 ]
    
    Commit 0ca50d12fe46 ("sctp: fix src address selection if using secondary
    addresses") has fixed a src address selection issue when using secondary
    addresses for ipv4.
    
    Now sctp ipv6 also has the similar issue. When using a secondary address,
    sctp_v6_get_dst tries to choose the saddr which has the most same bits
    with the daddr by sctp_v6_addr_match_len. It may make some cases not work
    as expected.
    
    hostA:
      [1] fd21:356b:459a:cf10::11 (eth1)
      [2] fd21:356b:459a:cf20::11 (eth2)
    
    hostB:
      [a] fd21:356b:459a:cf30::2  (eth1)
      [b] fd21:356b:459a:cf40::2  (eth2)
    
    route from hostA to hostB:
      fd21:356b:459a:cf30::/64 dev eth1  metric 1024  mtu 1500
    
    The expected path should be:
      fd21:356b:459a:cf10::11 <-> fd21:356b:459a:cf30::2
    But addr[2] matches addr[a] more bits than addr[1] does, according to
    sctp_v6_addr_match_len. It causes the path to be:
      fd21:356b:459a:cf20::11 <-> fd21:356b:459a:cf30::2
    
    This patch is to fix it with the same way as Marcelo's fix for sctp ipv4.
    As no ip_dev_find for ipv6, this patch is to use ipv6_chk_addr to check
    if the saddr is in a dev instead.
    
    Note that for backwards compatibility, it will still do the addr_match_len
    check here when no optimal is found.
    
    Reported-by: Patrick Talbert <ptalbert@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d9cb26d6a39f4d75dddf699033d5963b6633b98b
Author: Jon Paul Maloy <jon.maloy@ericsson.com>
Date:   Thu May 11 20:28:15 2017 +0200

    tipc: make macro tipc_wait_for_cond() smp safe
    
    
    [ Upstream commit 844cf763fba654436d3a4279b6a672c196cf1901 ]
    
    The macro tipc_wait_for_cond() is embedding the macro sk_wait_event()
    to fulfil its task. The latter, in turn, is evaluating the stated
    condition outside the socket lock context. This is problematic if
    the condition is accessing non-trivial data structures which may be
    altered by incoming interrupts, as is the case with the cong_links()
    linked list, used by socket to keep track of the current set of
    congested links. We sometimes see crashes when this list is accessed
    by a condition function at the same time as a SOCK_WAKEUP interrupt
    is removing an element from the list.
    
    We fix this by expanding selected parts of sk_wait_event() into the
    outer macro, while ensuring that all evaluations of a given condition
    are performed under socket lock protection.
    
    Fixes: commit 365ad353c256 ("tipc: reduce risk of user starvation during link congestion")
    Reviewed-by: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c91cd74b32ecbfa1a796e9f789e229024f9902f1
Author: Yuchung Cheng <ycheng@google.com>
Date:   Wed May 10 17:01:27 2017 -0700

    tcp: avoid fragmenting peculiar skbs in SACK
    
    
    [ Upstream commit b451e5d24ba6687c6f0e7319c727a709a1846c06 ]
    
    This patch fixes a bug in splitting an SKB during SACK
    processing. Specifically if an skb contains multiple
    packets and is only partially sacked in the higher sequences,
    tcp_match_sack_to_skb() splits the skb and marks the second fragment
    as SACKed.
    
    The current code further attempts rounding up the first fragment
    to MSS boundaries. But it misses a boundary condition when the
    rounded-up fragment size (pkt_len) is exactly skb size.  Spliting
    such an skb is pointless and causses a kernel warning and aborts
    the SACK processing. This patch universally checks such over-split
    before calling tcp_fragment to prevent these unnecessary warnings.
    
    Fixes: adb92db857ee ("tcp: Make SACK code to split only at mss boundaries")
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Soheil Hassas Yeganeh <soheil@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 20d699e0ca98c9708aab910937c3f7235527036d
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue May 16 13:27:53 2017 -0700

    net: fix compile error in skb_orphan_partial()
    
    
    [ Upstream commit 9142e9007f2d7ab58a587a1e1d921b0064a339aa ]
    
    If CONFIG_INET is not set, net/core/sock.c can not compile :
    
    net/core/sock.c: In function ‘skb_orphan_partial’:
    net/core/sock.c:1810:2: error: implicit declaration of function
    ‘skb_is_tcp_pure_ack’ [-Werror=implicit-function-declaration]
      if (skb_is_tcp_pure_ack(skb))
      ^
    
    Fix this by always including <net/tcp.h>
    
    Fixes: f6ba8d33cfbb ("netem: fix skb_orphan_partial()")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Paul Gortmaker <paul.gortmaker@windriver.com>
    Reported-by: Randy Dunlap <rdunlap@infradead.org>
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e13cb6c25b555f75cef9eb44d348b361da1291d5
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu May 11 15:24:41 2017 -0700

    netem: fix skb_orphan_partial()
    
    
    [ Upstream commit f6ba8d33cfbb46df569972e64dbb5bb7e929bfd9 ]
    
    I should have known that lowering skb->truesize was dangerous :/
    
    In case packets are not leaving the host via a standard Ethernet device,
    but looped back to local sockets, bad things can happen, as reported
    by Michael Madsen ( https://bugzilla.kernel.org/show_bug.cgi?id=195713 )
    
    So instead of tweaking skb->truesize, lets change skb->destructor
    and keep a reference on the owner socket via its sk_refcnt.
    
    Fixes: f2f872f9272a ("netem: Introduce skb_orphan_partial() helper")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Michael Madsen <mkm@nabto.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3bfb04d10247c111acee0ed785600a837afadf9d
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Thu May 11 01:53:15 2017 +0200

    bpf, arm64: fix faulty emission of map access in tail calls
    
    
    [ Upstream commit d8b54110ee944de522ccd3531191f39986ec20f9 ]
    
    Shubham was recently asking on netdev why in arm64 JIT we don't multiply
    the index for accessing the tail call map by 8. That led me into testing
    out arm64 JIT wrt tail calls and it turned out I got a NULL pointer
    dereference on the tail call.
    
    The buggy access is at:
    
      prog = array->ptrs[index];
      if (prog == NULL)
          goto out;
    
      [...]
      00000060:  d2800e0a  mov x10, #0x70 // #112
      00000064:  f86a682a  ldr x10, [x1,x10]
      00000068:  f862694b  ldr x11, [x10,x2]
      0000006c:  b40000ab  cbz x11, 0x00000080
      [...]
    
    The code triggering the crash is f862694b. x1 at the time contains the
    address of the bpf array, x10 offsetof(struct bpf_array, ptrs). Meaning,
    above we load the pointer to the program at map slot 0 into x10. x10
    can then be NULL if the slot is not occupied, which we later on try to
    access with a user given offset in x2 that is the map index.
    
    Fix this by emitting the following instead:
    
      [...]
      00000060:  d2800e0a  mov x10, #0x70 // #112
      00000064:  8b0a002a  add x10, x1, x10
      00000068:  d37df04b  lsl x11, x2, #3
      0000006c:  f86b694b  ldr x11, [x10,x11]
      00000070:  b40000ab  cbz x11, 0x00000084
      [...]
    
    This basically adds the offset to ptrs to the base address of the bpf
    array we got and we later on access the map with an index * 8 offset
    relative to that. The tail call map itself is basically one large area
    with meta data at the head followed by the array of prog pointers.
    This makes tail calls working again, tested on Cavium ThunderX ARMv8.
    
    Fixes: ddb55992b04d ("arm64: bpf: implement bpf_tail_call() helper")
    Reported-by: Shubham Bansal <illusionist.neo@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 617461cac6523a03fcac1d64962753d844dd23bb
Author: Ursula Braun <ubraun@linux.vnet.ibm.com>
Date:   Wed May 10 19:07:54 2017 +0200

    s390/qeth: add missing hash table initializations
    
    
    [ Upstream commit ebccc7397e4a49ff64c8f44a54895de9d32fe742 ]
    
    commit 5f78e29ceebf ("qeth: optimize IP handling in rx_mode callback")
    added new hash tables, but missed to initialize them.
    
    Fixes: 5f78e29ceebf ("qeth: optimize IP handling in rx_mode callback")
    Signed-off-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Reviewed-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b8a9a79c8913046ff2477c948ee8e69648afe81d
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Wed May 10 19:07:53 2017 +0200

    s390/qeth: avoid null pointer dereference on OSN
    
    
    [ Upstream commit 25e2c341e7818a394da9abc403716278ee646014 ]
    
    Access card->dev only after checking whether's its valid.
    
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Reviewed-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9b1042aa59c46a0cc8c5aceb5c8c4441e4e3b0f5
Author: Julian Wiedmann <jwi@linux.vnet.ibm.com>
Date:   Wed May 10 19:07:52 2017 +0200

    s390/qeth: unbreak OSM and OSN support
    
    
    [ Upstream commit 2d2ebb3ed0c6acfb014f98e427298673a5d07b82 ]
    
    commit b4d72c08b358 ("qeth: bridgeport support - basic control")
    broke the support for OSM and OSN devices as follows:
    
    As OSM and OSN are L2 only, qeth_core_probe_device() does an early
    setup by loading the l2 discipline and calling qeth_l2_probe_device().
    In this context, adding the l2-specific bridgeport sysfs attributes
    via qeth_l2_create_device_attributes() hits a BUG_ON in fs/sysfs/group.c,
    since the basic sysfs infrastructure for the device hasn't been
    established yet.
    
    Note that OSN actually has its own unique sysfs attributes
    (qeth_osn_devtype), so the additional attributes shouldn't be created
    at all.
    For OSM, add a new qeth_l2_devtype that contains all the common
    and l2-specific sysfs attributes.
    When qeth_core_probe_device() does early setup for OSM or OSN, assign
    the corresponding devtype so that the ccwgroup probe code creates the
    full set of sysfs attributes.
    This allows us to skip qeth_l2_create_device_attributes() in case
    of an early setup.
    
    Any device that can't do early setup will initially have only the
    generic sysfs attributes, and when it's probed later
    qeth_l2_probe_device() adds the l2-specific attributes.
    
    If an early-setup device is removed (by calling ccwgroup_ungroup()),
    device_unregister() will - using the devtype - delete the
    l2-specific attributes before qeth_l2_remove_device() is called.
    So make sure to not remove them twice.
    
    What complicates the issue is that qeth_l2_probe_device() and
    qeth_l2_remove_device() is also called on a device when its
    layer2 attribute changes (ie. its layer mode is switched).
    For early-setup devices this wouldn't work properly - we wouldn't
    remove the l2-specific attributes when switching to L3.
    But switching the layer mode doesn't actually make any sense;
    we already decided that the device can only operate in L2!
    So just refuse to switch the layer mode on such devices. Note that
    OSN doesn't have a layer2 attribute, so we only need to special-case
    OSM.
    
    Based on an initial patch by Ursula Braun.
    
    Fixes: b4d72c08b358 ("qeth: bridgeport support - basic control")
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 41b81ff056a486cfc4ff9abc10085a17917dd102
Author: Ursula Braun <ubraun@linux.vnet.ibm.com>
Date:   Wed May 10 19:07:51 2017 +0200

    s390/qeth: handle sysfs error during initialization
    
    
    [ Upstream commit 9111e7880ccf419548c7b0887df020b08eadb075 ]
    
    When setting up the device from within the layer discipline's
    probe routine, creating the layer-specific sysfs attributes can fail.
    Report this error back to the caller, and handle it by
    releasing the layer discipline.
    
    Signed-off-by: Ursula Braun <ubraun@linux.vnet.ibm.com>
    [jwi: updated commit msg, moved an OSN change to a subsequent patch]
    Signed-off-by: Julian Wiedmann <jwi@linux.vnet.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8e929937f8813fb209a2d733ee1367db80b6f622
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Tue May 9 16:59:54 2017 -0700

    ipv6/dccp: do not inherit ipv6_mc_list from parent
    
    
    [ Upstream commit 83eaddab4378db256d00d295bda6ca997cd13a52 ]
    
    Like commit 657831ffc38e ("dccp/tcp: do not inherit mc_list from parent")
    we should clear ipv6_mc_list etc. for IPv6 sockets too.
    
    Cc: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03a275f5aa819b8824a94572ac1c18cf69cae3ca
Author: Gao Feng <gfree.wind@vip.163.com>
Date:   Tue May 9 18:27:33 2017 +0800

    driver: vrf: Fix one possible use-after-free issue
    
    
    [ Upstream commit 1a4a5bf52a4adb477adb075e5afce925824ad132 ]
    
    The current codes only deal with the case that the skb is dropped, it
    may meet one use-after-free issue when NF_HOOK returns 0 that means
    the skb is stolen by one netfilter rule or hook.
    
    When one netfilter rule or hook stoles the skb and return NF_STOLEN,
    it means the skb is taken by the rule, and other modules should not
    touch this skb ever. Maybe the skb is queued or freed directly by the
    rule.
    
    Now uses the nf_hook instead of NF_HOOK to get the result of netfilter,
    and check the return value of nf_hook. Only when its value equals 1, it
    means the skb could go ahead. Or reset the skb as NULL.
    
    BTW, because vrf_rcv_finish is empty function, so needn't invoke it
    even though nf_hook returns 1. But we need to modify vrf_rcv_finish
    to deal with the NF_STOLEN case.
    
    There are two cases when skb is stolen.
    1. The skb is stolen and freed directly.
       There is nothing we need to do, and vrf_rcv_finish isn't invoked.
    2. The skb is queued and reinjected again.
       The vrf_rcv_finish would be invoked as okfn, so need to free the
       skb in it.
    
    Signed-off-by: Gao Feng <gfree.wind@vip.163.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit db8ebc6da8cfd1057dc94e69fbd7a8c5ff34cef6
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue May 9 06:29:19 2017 -0700

    dccp/tcp: do not inherit mc_list from parent
    
    
    [ Upstream commit 657831ffc38e30092a2d5f03d385d710eb88b09a ]
    
    syzkaller found a way to trigger double frees from ip_mc_drop_socket()
    
    It turns out that leave a copy of parent mc_list at accept() time,
    which is very bad.
    
    Very similar to commit 8b485ce69876 ("tcp: do not inherit
    fastopen_req from parent")
    
    Initial report from Pray3r, completed by Andrey one.
    Thanks a lot to them !
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Pray3r <pray3r.z@gmail.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Tested-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
