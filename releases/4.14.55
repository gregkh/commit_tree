commit 1e92e813554a93741666e9f378a83d70405b9076
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jul 11 16:29:25 2018 +0200

    Linux 4.14.55

commit b3ef356a096e218244b24e701abca72fc08e0e07
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Jun 27 23:26:05 2018 -0700

    Revert mm/vmstat.c: fix vmstat_update() preemption BUG
    
    commit 28557cc106e6d2aa8b8c5c7687ea9f8055ff3911 upstream.
    
    Revert commit c7f26ccfb2c3 ("mm/vmstat.c: fix vmstat_update() preemption
    BUG").  Steven saw a "using smp_processor_id() in preemptible" message
    and added a preempt_disable() section around it to keep it quiet.  This
    is not the right thing to do it does not fix the real problem.
    
    vmstat_update() is invoked by a kworker on a specific CPU.  This worker
    it bound to this CPU.  The name of the worker was "kworker/1:1" so it
    should have been a worker which was bound to CPU1.  A worker which can
    run on any CPU would have a `u' before the first digit.
    
    smp_processor_id() can be used in a preempt-enabled region as long as
    the task is bound to a single CPU which is the case here.  If it could
    run on an arbitrary CPU then this is the problem we have an should seek
    to resolve.
    
    Not only this smp_processor_id() must not be migrated to another CPU but
    also refresh_cpu_vm_stats() which might access wrong per-CPU variables.
    Not to mention that other code relies on the fact that such a worker
    runs on one specific CPU only.
    
    Therefore revert that commit and we should look instead what broke the
    affinity mask of the kworker.
    
    Link: http://lkml.kernel.org/r/20180504104451.20278-1-bigeasy@linutronix.de
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Steven J. Hill <steven.hill@cavium.com>
    Cc: Tejun Heo <htejun@gmail.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7cf346dfdea552f5ca71b85cf7389d347269b40c
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Thu May 24 15:26:48 2018 +0200

    sched, tracing: Fix trace_sched_pi_setprio() for deboosting
    
    commit 4ff648decf4712d39f184fc2df3163f43975575a upstream.
    
    Since the following commit:
    
      b91473ff6e97 ("sched,tracing: Update trace_sched_pi_setprio()")
    
    the sched_pi_setprio trace point shows the "newprio" during a deboost:
    
      |futex sched_pi_setprio: comm=futex_requeue_p pid"34 oldprio newprio=3D98
      |futex sched_switch: prev_comm=futex_requeue_p prev_pid"34 prev_prio=120
    
    This patch open codes __rt_effective_prio() in the tracepoint as the
    'newprio' to get the old behaviour back / the correct priority:
    
      |futex sched_pi_setprio: comm=futex_requeue_p pid"20 oldprio newprio=3D120
      |futex sched_switch: prev_comm=futex_requeue_p prev_pid"20 prev_prio=120
    
    Peter suggested to open code the new priority so people using tracehook
    could get the deadline data out.
    
    Reported-by: Mansky Christian <man@keba.com>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: b91473ff6e97 ("sched,tracing: Update trace_sched_pi_setprio()")
    Link: http://lkml.kernel.org/r/20180524132647.gg6ziuogczdmjjzu@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 32199c810655f5251e388abdd63e2313c71ad4d8
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Tue Jun 5 12:36:30 2018 +0300

    staging: comedi: quatech_daqp_cs: fix no-op loop daqp_ao_insn_write()
    
    commit 1376b0a2160319125c3a2822e8c09bd283cd8141 upstream.
    
    There is a '>' vs '<' typo so this loop is a no-op.
    
    Fixes: d35dcc89fc93 ("staging: comedi: quatech_daqp_cs: fix daqp_ao_insn_write()")
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Ian Abbott <abbotti@mev.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6d2b458d3d140bf75899aa1ef4349d7921bb7bf5
Author: Jann Horn <jannh@google.com>
Date:   Mon Jun 25 17:22:00 2018 +0200

    netfilter: nf_log: don't hold nf_log_mutex during user access
    
    commit ce00bf07cc95a57cd20b208e02b3c2604e532ae8 upstream.
    
    The old code would indefinitely block other users of nf_log_mutex if
    a userspace access in proc_dostring() blocked e.g. due to a userfaultfd
    region. Fix it by moving proc_dostring() out of the locked region.
    
    This is a followup to commit 266d07cb1c9a ("netfilter: nf_log: fix
    sleeping function called from invalid context"), which changed this code
    from using rcu_read_lock() to taking nf_log_mutex.
    
    Fixes: 266d07cb1c9a ("netfilter: nf_log: fix sleeping function calle[...]")
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ac6bfe418e043e20f3805e95b46194d8956f3357
Author: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
Date:   Wed May 30 18:32:29 2018 +0900

    mtd: cfi_cmdset_0002: Change erase functions to check chip good only
    
    commit 79ca484b613041ca223f74b34608bb6f5221724b upstream.
    
    Currently the functions use to check both chip ready and good.
    But the chip ready is not enough to check the operation status.
    So change this to check the chip good instead of this.
    About the retry functions to make sure the error handling remain it.
    
    Signed-off-by: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
    Reviewed-by: Joakim Tjernlund <Joakim.Tjernlund@infinera.com>
    Cc: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Cyrille Pitchen <cyrille.pitchen@wedev4u.fr>
    Cc: linux-mtd@lists.infradead.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b76d8aa04240a07b1bc55759a3aa75556c106eed
Author: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
Date:   Wed May 30 18:32:28 2018 +0900

    mtd: cfi_cmdset_0002: Change erase functions to retry for error
    
    commit 45f75b8a919a4255f52df454f1ffdee0e42443b2 upstream.
    
    For the word write functions it is retried for error.
    But it is not implemented to retry for the erase functions.
    To make sure for the erase functions change to retry as same.
    
    This is needed to prevent the flash erase error caused only once.
    It was caused by the error case of chip_good() in the do_erase_oneblock().
    Also it was confirmed on the MACRONIX flash device MX29GL512FHT2I-11G.
    But the error issue behavior is not able to reproduce at this moment.
    The flash controller is parallel Flash interface integrated on BCM53003.
    
    Signed-off-by: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
    Reviewed-by: Joakim Tjernlund <Joakim.Tjernlund@infinera.com>
    Cc: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Cyrille Pitchen <cyrille.pitchen@wedev4u.fr>
    Cc: linux-mtd@lists.infradead.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit eb638a002274b5a73b2be94e1553ac96e0b4f3fd
Author: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
Date:   Wed May 30 18:32:27 2018 +0900

    mtd: cfi_cmdset_0002: Change definition naming to retry write operation
    
    commit 85a82e28b023de9b259a86824afbd6ba07bd6475 upstream.
    
    The definition can be used for other program and erase operations also.
    So change the naming to MAX_RETRIES from MAX_WORD_RETRIES.
    
    Signed-off-by: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
    Reviewed-by: Joakim Tjernlund <Joakim.Tjernlund@infinera.com>
    Cc: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Cyrille Pitchen <cyrille.pitchen@wedev4u.fr>
    Cc: linux-mtd@lists.infradead.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 74ec37d03a12b001120c81fecfcb878e5e9d4382
Author: Ross Zwisler <zwisler@kernel.org>
Date:   Tue Jun 26 16:30:41 2018 -0600

    dm: prevent DAX mounts if not supported
    
    commit dbc626597c39b24cefce09fbd8e9dea85869a801 upstream.
    
    Currently device_supports_dax() just checks to see if the QUEUE_FLAG_DAX
    flag is set on the device's request queue to decide whether or not the
    device supports filesystem DAX.  Really we should be using
    bdev_dax_supported() like filesystems do at mount time.  This performs
    other tests like checking to make sure the dax_direct_access() path works.
    
    We also explicitly clear QUEUE_FLAG_DAX on the DM device's request queue if
    any of the underlying devices do not support DAX.  This makes the handling
    of QUEUE_FLAG_DAX consistent with the setting/clearing of most other flags
    in dm_table_set_restrictions().
    
    Now that bdev_dax_supported() explicitly checks for QUEUE_FLAG_DAX, this
    will ensure that filesystems built upon DM devices will only be able to
    mount with DAX if all underlying devices also support DAX.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Fixes: commit 545ed20e6df6 ("dm: add infrastructure for DAX support")
    Cc: stable@vger.kernel.org
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0605fa6daa6642c276ef037b3246595e4de53491
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Mon Dec 4 23:28:32 2017 -0500

    dm: set QUEUE_FLAG_DAX accordingly in dm_table_set_restrictions()
    
    commit ad3793fc3945173f64d82d05d3ecde41f6c0435c upstream.
    
    Rather than having DAX support be unique by setting it based on table
    type in dm_setup_md_queue().
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3729e5561e1e4a0319a2c794d8ae78b8baea4a36
Author: Ross Zwisler <zwisler@kernel.org>
Date:   Tue Jun 26 16:30:40 2018 -0600

    dax: check for QUEUE_FLAG_DAX in bdev_dax_supported()
    
    commit 15256f6cc4b44f2e70503758150267fd2a53c0d6 upstream.
    
    Add an explicit check for QUEUE_FLAG_DAX to __bdev_dax_supported().  This
    is needed for DM configurations where the first element in the dm-linear or
    dm-stripe target supports DAX, but other elements do not.  Without this
    check __bdev_dax_supported() will pass for such devices, letting a
    filesystem on that device mount with the DAX option.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Suggested-by: Mike Snitzer <snitzer@redhat.com>
    Fixes: commit 545ed20e6df6 ("dm: add infrastructure for DAX support")
    Cc: stable@vger.kernel.org
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8214347c260b0839c007ec4882e180fca1b6a077
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed May 30 13:03:46 2018 -0700

    dax: change bdev_dax_supported() to support boolean returns
    
    commit 80660f20252d6f76c9f203874ad7c7a4a8508cf8 upstream.
    
    The function return values are confusing with the way the function is
    named. We expect a true or false return value but it actually returns
    0/-errno.  This makes the code very confusing. Changing the return values
    to return a bool where if DAX is supported then return true and no DAX
    support returns false.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a19385766b4faa1e27aff8b677e2be6a0f03afe4
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Wed May 30 13:03:45 2018 -0700

    fs: allow per-device dax status checking for filesystems
    
    commit ba23cba9b3bdc967aabdc6ff1e3e9b11ce05bb4f upstream.
    
    Change bdev_dax_supported so it takes a bdev parameter.  This enables
    multi-device filesystems like xfs to check that a dax device can work for
    the particular filesystem.  Once that's in place, actually fix all the
    parts of XFS where we need to be able to distinguish between datadev and
    rtdev.
    
    This patch fixes the problem where we screw up the dax support checking
    in xfs if the datadev and rtdev have different dax capabilities.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    [rez: Re-added __bdev_dax_supported() for !CONFIG_FS_DAX cases]
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5941026fc7a540b9d60824a9fb77ccdbe2238c0c
Author: Martin Kaiser <martin@kaiser.cx>
Date:   Mon Jun 18 22:41:03 2018 +0200

    mtd: rawnand: mxc: set spare area size register explicitly
    
    commit 3f77f244d8ec28e3a0a81240ffac7d626390060c upstream.
    
    The v21 version of the NAND flash controller contains a Spare Area Size
    Register (SPAS) at offset 0x10. Its setting defaults to the maximum
    spare area size of 218 bytes. The size that is set in this register is
    used by the controller when it calculates the ECC bytes internally in
    hardware.
    
    Usually, this register is updated from settings in the IIM fuses when
    the system is booting from NAND flash. For other boot media, however,
    the SPAS register remains at the default setting, which may not work for
    the particular flash chip on the board. The same goes for flash chips
    whose configuration cannot be set in the IIM fuses (e.g. chips with 2k
    sector size and 128 bytes spare area size can't be configured in the IIM
    fuses on imx25 systems).
    
    Set the SPAS register explicitly during the preset operation. Derive the
    register value from mtd->oobsize that was detected during probe by
    decoding the flash chip's ID bytes.
    
    While at it, rename the define for the spare area register's offset to
    NFC_V21_RSLTSPARE_AREA. The register at offset 0x10 on v1 controllers is
    different from the register on v21 controllers.
    
    Fixes: d484018 ("mtd: mxc_nand: set NFC registers after reset")
    Cc: stable@vger.kernel.org
    Signed-off-by: Martin Kaiser <martin@kaiser.cx>
    Reviewed-by: Sascha Hauer <s.hauer@pengutronix.de>
    Reviewed-by: Miquel Raynal <miquel.raynal@bootlin.com>
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c4097c64d03afaf1212a76729b6758f662e901b1
Author: Brad Love <brad@nextdimension.cc>
Date:   Tue Mar 6 14:15:34 2018 -0500

    media: cx25840: Use subdev host data for PLL override
    
    commit 3ee9bc12342cf546313d300808ff47d7dbb8e7db upstream.
    
    The cx25840 driver currently configures 885, 887, and 888 using
    default divisors for each chip. This check to see if the cx23885
    driver has passed the cx25840 a non-default clock rate for a
    specific chip. If a cx23885 board has left clk_freq at 0, the
    clock default values will be used to configure the PLLs.
    
    This patch only has effect on 888 boards who set clk_freq to 25M.
    
    Signed-off-by: Brad Love <brad@nextdimension.cc>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@s-opensource.com>
    Cc: Ben Hutchings <ben.hutchings@codethink.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e82885490a611f2b75a6c27cd7bb09665c1740be
Author: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Date:   Sun Apr 8 23:35:28 2018 +0200

    Kbuild: fix # escaping in .cmd files for future Make
    
    commit 9564a8cf422d7b58f6e857e3546d346fa970191e upstream.
    
    I tried building using a freshly built Make (4.2.1-69-g8a731d1), but
    already the objtool build broke with
    
    orc_dump.c: In function ‘orc_dump’:
    orc_dump.c:106:2: error: ‘elf_getshnum’ is deprecated [-Werror=deprecated-declarations]
      if (elf_getshdrnum(elf, &nr_sections)) {
    
    Turns out that with that new Make, the backslash was not removed, so cpp
    didn't see a #include directive, grep found nothing, and
    -DLIBELF_USE_DEPRECATED was wrongly put in CFLAGS.
    
    Now, that new Make behaviour is documented in their NEWS file:
    
      * WARNING: Backward-incompatibility!
        Number signs (#) appearing inside a macro reference or function invocation
        no longer introduce comments and should not be escaped with backslashes:
        thus a call such as:
          foo := $(shell echo '#')
        is legal.  Previously the number sign needed to be escaped, for example:
          foo := $(shell echo '\#')
        Now this latter will resolve to "\#".  If you want to write makefiles
        portable to both versions, assign the number sign to a variable:
          C := \#
          foo := $(shell echo '$C')
        This was claimed to be fixed in 3.81, but wasn't, for some reason.
        To detect this change search for 'nocomment' in the .FEATURES variable.
    
    This also fixes up the two make-cmd instances to replace # with $(pound)
    rather than with \#. There might very well be other places that need
    similar fixup in preparation for whatever future Make release contains
    the above change, but at least this builds an x86_64 defconfig with the
    new make.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=197847
    Cc: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3bb6397ba643d20a6bc0f9a729a6e6e7c83e420a
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Jul 10 16:01:30 2018 +0200

    Revert "dpaa_eth: fix error in dpaa_remove()"
    
    This reverts commit 5bbb99d2fde047df596379be6c58e265e2ddbe1f which is
    commit 88075256ee817041d68c2387f29065b5cb2b342a upstream.
    
    Jiri writes that this was an incorrect fix, and Madalin-cristian says it
    was fixed differently in a later patch.  So just revert this from
    4.14.y.
    
    Reported-by: Jiri Slaby <jslaby@suse.cz>
    Cc: Madalin Bucur <madalin.bucur@nxp.com>
    Cc: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 42dc2a7bb72ed376ccfe8b8f49187a00f893c53f
Author: Jaegeuk Kim <jaegeuk@kernel.org>
Date:   Fri Mar 30 17:58:13 2018 -0700

    f2fs: truncate preallocated blocks in error case
    
    commit dc7a10ddee0c56c6d891dd18de5c4ee9869545e0 upstream.
    
    If write is failed, we must deallocate the blocks that we couldn't write.
    
    Cc: stable@vger.kernel.org
    Reviewed-by: Chao Yu <yuchao0@huawei.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>
    Signed-off-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a2c7493c7f31c0e4d1dede9a179f853484f7dd1d
Author: Sakari Ailus <sakari.ailus@linux.intel.com>
Date:   Fri Feb 2 05:08:59 2018 -0500

    media: vb2: core: Finish buffers at the end of the stream
    
    commit 03703ed1debf777ea845aa9b50ba2e80a5e7dd3c upstream.
    
    If buffers were prepared or queued and the buffers were released without
    starting the queue, the finish mem op (corresponding to the prepare mem
    op) was never called to the buffers.
    
    Before commit a136f59c0a1f there was no need to do this as in such a case
    the prepare mem op had not been called yet. Address the problem by
    explicitly calling finish mem op when the queue is stopped if the buffer
    is in either prepared or queued state.
    
    Fixes: a136f59c0a1f ("[media] vb2: Move buffer cache synchronisation to prepare from queue")
    
    Cc: stable@vger.kernel.org # for v4.13 and up
    Signed-off-by: Sakari Ailus <sakari.ailus@linux.intel.com>
    Tested-by: Devin Heitmueller <dheitmueller@kernellabs.com>
    Signed-off-by: Hans Verkuil <hans.verkuil@cisco.com>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@s-opensource.com>
    Signed-off-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b16a6af97461f6d296422887502331b33c729b48
Author: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Date:   Thu Apr 5 16:23:05 2018 -0700

    mm: hwpoison: disable memory error handling on 1GB hugepage
    
    commit 31286a8484a85e8b4e91ddb0f5415aee8a416827 upstream.
    
    Recently the following BUG was reported:
    
        Injecting memory failure for pfn 0x3c0000 at process virtual address 0x7fe300000000
        Memory failure: 0x3c0000: recovery action for huge page: Recovered
        BUG: unable to handle kernel paging request at ffff8dfcc0003000
        IP: gup_pgd_range+0x1f0/0xc20
        PGD 17ae72067 P4D 17ae72067 PUD 0
        Oops: 0000 [#1] SMP PTI
        ...
        CPU: 3 PID: 5467 Comm: hugetlb_1gb Not tainted 4.15.0-rc8-mm1-abc+ #3
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.9.3-1.fc25 04/01/2014
    
    You can easily reproduce this by calling madvise(MADV_HWPOISON) twice on
    a 1GB hugepage.  This happens because get_user_pages_fast() is not aware
    of a migration entry on pud that was created in the 1st madvise() event.
    
    I think that conversion to pud-aligned migration entry is working, but
    other MM code walking over page table isn't prepared for it.  We need
    some time and effort to make all this work properly, so this patch
    avoids the reported bug by just disabling error handling for 1GB
    hugepage.
    
    [n-horiguchi@ah.jp.nec.com: v2]
      Link: http://lkml.kernel.org/r/1517284444-18149-1-git-send-email-n-horiguchi@ah.jp.nec.com
    Link: http://lkml.kernel.org/r/1517207283-15769-1-git-send-email-n-horiguchi@ah.jp.nec.com
    Signed-off-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Acked-by: Punit Agrawal <punit.agrawal@arm.com>
    Tested-by: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07a1c2d1131b2675776480118d0855845cfffaef
Author: Rakib Mullick <rakib.mullick@gmail.com>
Date:   Wed Nov 1 10:14:51 2017 +0600

    irq/core: Fix boot crash when the irqaffinity= boot parameter is passed on CPUMASK_OFFSTACK=y kernels(v1)
    
    commit 10d94ff4d558b96bfc4f55bb0051ae4d938246fe upstream.
    
    When the irqaffinity= kernel parameter is passed in a CPUMASK_OFFSTACK=y
    kernel, it fails to boot, because zalloc_cpumask_var() cannot be used before
    initializing the slab allocator to allocate a cpumask.
    
    So, use alloc_bootmem_cpumask_var() instead.
    
    Also do some cleanups while at it: in init_irq_default_affinity() remove
    an #ifdef via using cpumask_available().
    
    Signed-off-by: Rakib Mullick <rakib.mullick@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20171026045800.27087-1-rakib.mullick@gmail.com
    Link: http://lkml.kernel.org/r/20171101041451.12581-1-rakib.mullick@gmail.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: Janne Huttunen <janne.huttunen@nokia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 50b4d984f55e7e8d75f75da6803505ca3c122cef
Author: Daniel Rosenberg <drosen@google.com>
Date:   Mon Jul 2 16:59:37 2018 -0700

    HID: debug: check length before copy_to_user()
    
    commit 717adfdaf14704fd3ec7fa2c04520c0723247eac upstream.
    
    If our length is greater than the size of the buffer, we
    overflow the buffer
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Daniel Rosenberg <drosen@google.com>
    Reviewed-by: Benjamin Tissoires <benjamin.tissoires@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c1d21fe74c2554f5031f6ceb354ee3ce2ccf475f
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Fri Jun 29 17:08:44 2018 -0500

    HID: hiddev: fix potential Spectre v1
    
    commit 4f65245f2d178b9cba48350620d76faa4a098841 upstream.
    
    uref->field_index, uref->usage_index, finfo.field_index and cinfo.index can be
    indirectly controlled by user-space, hence leading to a potential exploitation
    of the Spectre variant 1 vulnerability.
    
    This issue was detected with the help of Smatch:
    
    drivers/hid/usbhid/hiddev.c:473 hiddev_ioctl_usage() warn: potential spectre issue 'report->field' (local cap)
    drivers/hid/usbhid/hiddev.c:477 hiddev_ioctl_usage() warn: potential spectre issue 'field->usage' (local cap)
    drivers/hid/usbhid/hiddev.c:757 hiddev_ioctl() warn: potential spectre issue 'report->field' (local cap)
    drivers/hid/usbhid/hiddev.c:801 hiddev_ioctl() warn: potential spectre issue 'hid->collection' (local cap)
    
    Fix this by sanitizing such structure fields before using them to index
    report->field, field->usage and hid->collection
    
    Notice that given that speculation windows are large, the policy is
    to kill the speculation on the first load and not worry if it can be
    completed with a dependent load/store [1].
    
    [1] https://marc.info/?l=linux-kernel&m=152449131114778&w=2
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 702027291bf5b6a0d70eca15adff0a68bfcd8430
Author: Jason Andryuk <jandryuk@gmail.com>
Date:   Fri Jun 22 12:25:49 2018 -0400

    HID: i2c-hid: Fix "incomplete report" noise
    
    commit ef6eaf27274c0351f7059163918f3795da13199c upstream.
    
    Commit ac75a041048b ("HID: i2c-hid: fix size check and type usage") started
    writing messages when the ret_size is <= 2 from i2c_master_recv.  However, my
    device i2c-DLL07D1 returns 2 for a short period of time (~0.5s) after I stop
    moving the pointing stick or touchpad.  It varies, but you get ~50 messages
    each time which spams the log hard.
    
    [  95.925055] i2c_hid i2c-DLL07D1:01: i2c_hid_get_input: incomplete report (83/2)
    
    This has also been observed with a i2c-ALP0017.
    
    [ 1781.266353] i2c_hid i2c-ALP0017:00: i2c_hid_get_input: incomplete report (30/2)
    
    Only print the message when ret_size is totally invalid and less than 2 to cut
    down on the log spam.
    
    Fixes: ac75a041048b ("HID: i2c-hid: fix size check and type usage")
    Reported-by: John Smith <john-s-84@gmx.net>
    Cc: stable@vger.kernel.org
    Signed-off-by: Jason Andryuk <jandryuk@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c894755d1bc8beaff5dec0dc493178209118630f
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Oct 16 15:59:10 2017 +0200

    block: cope with WRITE ZEROES failing in blkdev_issue_zeroout()
    
    commit d5ce4c31d6df518dd8f63bbae20d7423c5018a6c upstream.
    
    sd_config_write_same() ignores ->max_ws_blocks == 0 and resets it to
    permit trying WRITE SAME on older SCSI devices, unless ->no_write_same
    is set.  Because REQ_OP_WRITE_ZEROES is implemented in terms of WRITE
    SAME, blkdev_issue_zeroout() may fail with -EREMOTEIO:
    
      $ fallocate -zn -l 1k /dev/sdg
      fallocate: fallocate failed: Remote I/O error
      $ fallocate -zn -l 1k /dev/sdg  # OK
      $ fallocate -zn -l 1k /dev/sdg  # OK
    
    The following calls succeed because sd_done() sets ->no_write_same in
    response to a sense that would become BLK_STS_TARGET/-EREMOTEIO, causing
    __blkdev_issue_zeroout() to fall back to generating ZERO_PAGE bios.
    
    This means blkdev_issue_zeroout() must cope with WRITE ZEROES failing
    and fall back to manually zeroing, unless BLKDEV_ZERO_NOFALLBACK is
    specified.  For BLKDEV_ZERO_NOFALLBACK case, return -EOPNOTSUPP if
    sd_done() has just set ->no_write_same thus indicating lack of offload
    support.
    
    Fixes: c20cfc27a473 ("block: stop using blkdev_issue_write_same for zeroing")
    Cc: Hannes Reinecke <hare@suse.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Cc: Janne Huttunen <janne.huttunen@nokia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e3f1310c6065f38538ee5b64a2610212110e148
Author: Ilya Dryomov <idryomov@gmail.com>
Date:   Mon Oct 16 15:59:09 2017 +0200

    block: factor out __blkdev_issue_zero_pages()
    
    commit 425a4dba7953e35ffd096771973add6d2f40d2ed upstream.
    
    blkdev_issue_zeroout() will use this in !BLKDEV_ZERO_NOFALLBACK case.
    
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Cc: Janne Huttunen <janne.huttunen@nokia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fba3230595cb7c27ba27a4e100cdf9e4b4b273b9
Author: Jon Derrick <jonathan.derrick@intel.com>
Date:   Mon Jul 2 18:45:18 2018 -0400

    ext4: check superblock mapped prior to committing
    
    commit a17712c8e4be4fa5404d20e9cd3b2b21eae7bc56 upstream.
    
    This patch attempts to close a hole leading to a BUG seen with hot
    removals during writes [1].
    
    A block device (NVME namespace in this test case) is formatted to EXT4
    without partitions. It's mounted and write I/O is run to a file, then
    the device is hot removed from the slot. The superblock attempts to be
    written to the drive which is no longer present.
    
    The typical chain of events leading to the BUG:
    ext4_commit_super()
      __sync_dirty_buffer()
        submit_bh()
          submit_bh_wbc()
            BUG_ON(!buffer_mapped(bh));
    
    This fix checks for the superblock's buffer head being mapped prior to
    syncing.
    
    [1] https://www.spinics.net/lists/linux-ext4/msg56527.html
    
    Signed-off-by: Jon Derrick <jonathan.derrick@intel.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 54bf664ae4fa0b27d8fefc64514509e63dd89929
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sun Jun 17 18:11:20 2018 -0400

    ext4: add more mount time checks of the superblock
    
    commit bfe0a5f47ada40d7984de67e59a7d3390b9b9ecc upstream.
    
    The kernel's ext4 mount-time checks were more permissive than
    e2fsprogs's libext2fs checks when opening a file system.  The
    superblock is considered too insane for debugfs or e2fsck to operate
    on it, the kernel has no business trying to mount it.
    
    This will make file system fuzzing tools work harder, but the failure
    cases that they find will be more useful and be easier to evaluate.
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c24aab6d86640ccf321b87be6096319f55b16274
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sun Jun 17 00:41:14 2018 -0400

    ext4: add more inode number paranoia checks
    
    commit c37e9e013469521d9adb932d17a1795c139b36db upstream.
    
    If there is a directory entry pointing to a system inode (such as a
    journal inode), complain and declare the file system to be corrupted.
    
    Also, if the superblock's first inode number field is too small,
    refuse to mount the file system.
    
    This addresses CVE-2018-10882.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200069
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 02945e49dc2026459e069467ec64e3fbecda844f
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jun 16 23:41:59 2018 -0400

    ext4: avoid running out of journal credits when appending to an inline file
    
    commit 8bc1379b82b8e809eef77a9fedbb75c6c297be19 upstream.
    
    Use a separate journal transaction if it turns out that we need to
    convert an inline file to use an data block.  Otherwise we could end
    up failing due to not having journal credits.
    
    This addresses CVE-2018-10883.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200071
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8a9ef17c0dc93def47e17b227ada95c682592a1d
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jun 16 15:40:48 2018 -0400

    ext4: never move the system.data xattr out of the inode body
    
    commit 8cdb5240ec5928b20490a2bb34cb87e9a5f40226 upstream.
    
    When expanding the extra isize space, we must never move the
    system.data xattr out of the inode body.  For performance reasons, it
    doesn't make any sense, and the inline data implementation assumes
    that system.data xattr is never in the external xattr block.
    
    This addresses CVE-2018-10880
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200005
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit deb465ec750b80776cc4ac5b92b72c0a71fd4f0b
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Fri Jun 15 12:28:16 2018 -0400

    ext4: clear i_data in ext4_inode_info when removing inline data
    
    commit 6e8ab72a812396996035a37e5ca4b3b99b5d214b upstream.
    
    When converting from an inode from storing the data in-line to a data
    block, ext4_destroy_inline_data_nolock() was only clearing the on-disk
    copy of the i_blocks[] array.  It was not clearing copy of the
    i_blocks[] in ext4_inode_info, in i_data[], which is the copy actually
    used by ext4_map_blocks().
    
    This didn't matter much if we are using extents, since the extents
    header would be invalid and thus the extents could would re-initialize
    the extents tree.  But if we are using indirect blocks, the previous
    contents of the i_blocks array will be treated as block numbers, with
    potentially catastrophic results to the file system integrity and/or
    user data.
    
    This gets worse if the file system is using a 1k block size and
    s_first_data is zero, but even without this, the file system can get
    quite badly corrupted.
    
    This addresses CVE-2018-10881.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200015
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 64804502d0e957bc594de35872381a808bb986cb
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Fri Jun 15 12:27:16 2018 -0400

    ext4: include the illegal physical block in the bad map ext4_error msg
    
    commit bdbd6ce01a70f02e9373a584d0ae9538dcf0a121 upstream.
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d69a9df614fc68741efcb0fcc020f05caa99d668
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Thu Jun 14 12:55:10 2018 -0400

    ext4: verify the depth of extent tree in ext4_find_extent()
    
    commit bc890a60247171294acc0bd67d211fa4b88d40ba upstream.
    
    If there is a corupted file system where the claimed depth of the
    extent tree is -1, this can cause a massive buffer overrun leading to
    sadness.
    
    This addresses CVE-2018-10877.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199417
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 44a4bc970bfae625d0ec9ecdfefc88c9d93dfe6c
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Thu Jun 14 00:58:00 2018 -0400

    ext4: only look at the bg_flags field if it is valid
    
    commit 8844618d8aa7a9973e7b527d038a2a589665002c upstream.
    
    The bg_flags field in the block group descripts is only valid if the
    uninit_bg or metadata_csum feature is enabled.  We were not
    consistently looking at this field; fix this.
    
    Also block group #0 must never have uninitialized allocation bitmaps,
    or need to be zeroed, since that's where the root inode, and other
    special inodes are set up.  Check for these conditions and mark the
    file system as corrupted if they are detected.
    
    This addresses CVE-2018-10876.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199403
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ac48bb9bc0a32f5a4432be1645b57607f8c46aa7
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 23:00:48 2018 -0400

    ext4: always check block group bounds in ext4_init_block_bitmap()
    
    commit 819b23f1c501b17b9694325471789e6b5cc2d0d2 upstream.
    
    Regardless of whether the flex_bg feature is set, we should always
    check to make sure the bits we are setting in the block bitmap are
    within the block group bounds.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199865
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ac93c718365ac6ea9d7631641c8dec867d623491
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 23:08:26 2018 -0400

    ext4: make sure bitmaps and the inode table don't overlap with bg descriptors
    
    commit 77260807d1170a8cf35dbb06e07461a655f67eee upstream.
    
    It's really bad when the allocation bitmaps and the inode table
    overlap with the block group descriptors, since it causes random
    corruption of the bg descriptors.  So we really want to head those off
    at the pass.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199865
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3150e8913b957d71398511a0580606e181153d10
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 00:51:28 2018 -0400

    ext4: always verify the magic number in xattr blocks
    
    commit 513f86d73855ce556ea9522b6bfd79f87356dc3a upstream.
    
    If there an inode points to a block which is also some other type of
    metadata block (such as a block allocation bitmap), the
    buffer_verified flag can be set when it was validated as that other
    metadata block type; however, it would make a really terrible external
    attribute block.  The reason why we use the verified flag is to avoid
    constantly reverifying the block.  However, it doesn't take much
    overhead to make sure the magic number of the xattr block is correct,
    and this will avoid potential crashes.
    
    This addresses CVE-2018-10879.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200001
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0dc148230f3827f49b1e2a72d14cbad0c5c63e86
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 00:23:11 2018 -0400

    ext4: add corruption check in ext4_xattr_set_entry()
    
    commit 5369a762c882c0b6e9599e4ebbb3a9ba9eee7e2d upstream.
    
    In theory this should have been caught earlier when the xattr list was
    verified, but in case it got missed, it's simple enough to add check
    to make sure we don't overrun the xattr buffer.
    
    This addresses CVE-2018-10879.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200001
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0321e68838d7ba2528b367b879b2fcf9d96a2099
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jun 16 20:21:45 2018 -0400

    jbd2: don't mark block as modified if the handle is out of credits
    
    commit e09463f220ca9a1a1ecfda84fcda658f99a1f12a upstream.
    
    Do not set the b_modified flag in block's journal head should not
    until after we're sure that jbd2_journal_dirty_metadat() will not
    abort with an error due to there not being enough space reserved in
    the jbd2 handle.
    
    Otherwise, future attempts to modify the buffer may lead a large
    number of spurious errors and warnings.
    
    This addresses CVE-2018-10883.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200071
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b541f470d4bda051356e8169d6b309bdd37437db
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Sun Jun 3 16:40:54 2018 +0200

    drm/udl: fix display corruption of the last line
    
    commit 99ec9e77511dea55d81729fc80b6c63a61bfa8e0 upstream.
    
    The displaylink hardware has such a peculiarity that it doesn't render a
    command until next command is received. This produces occasional
    corruption, such as when setting 22x11 font on the console, only the first
    line of the cursor will be blinking if the cursor is located at some
    specific columns.
    
    When we end up with a repeating pixel, the driver has a bug that it leaves
    one uninitialized byte after the command (and this byte is enough to flush
    the command and render it - thus it fixes the screen corruption), however
    whe we end up with a non-repeating pixel, there is no byte appended and
    this results in temporary screen corruption.
    
    This patch fixes the screen corruption by always appending a byte 0xAF at
    the end of URB. It also removes the uninitialized byte.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3cb81bce2191df8701cc85fd7d360df4321cf566
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Fri Jun 29 16:27:10 2018 +0200

    drm: Use kvzalloc for allocating blob property memory
    
    commit 718b5406cd76f1aa6434311241b7febf0e8571ff upstream.
    
    The property size may be controlled by userspace, can be large (I've
    seen failure with order 4, i.e. 16 pages / 64 KB) and doesn't need to be
    physically contiguous.
    
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180629142710.2069-1-michel@daenzer.net
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 748144f35514aef14c4fdef5bcaa0db99cb9367a
Author: Stefano Brivio <sbrivio@redhat.com>
Date:   Thu Jul 5 11:46:42 2018 +0200

    cifs: Fix slab-out-of-bounds in send_set_info() on SMB2 ACE setting
    
    commit f46ecbd97f508e68a7806291a139499794874f3d upstream.
    
    A "small" CIFS buffer is not big enough in general to hold a
    setacl request for SMB2, and we end up overflowing the buffer in
    send_set_info(). For instance:
    
     # mount.cifs //127.0.0.1/test /mnt/test -o username=test,password=test,nounix,cifsacl
     # touch /mnt/test/acltest
     # getcifsacl /mnt/test/acltest
     REVISION:0x1
     CONTROL:0x9004
     OWNER:S-1-5-21-2926364953-924364008-418108241-1000
     GROUP:S-1-22-2-1001
     ACL:S-1-5-21-2926364953-924364008-418108241-1000:ALLOWED/0x0/0x1e01ff
     ACL:S-1-22-2-1001:ALLOWED/0x0/R
     ACL:S-1-22-2-1001:ALLOWED/0x0/R
     ACL:S-1-5-21-2926364953-924364008-418108241-1000:ALLOWED/0x0/0x1e01ff
     ACL:S-1-1-0:ALLOWED/0x0/R
     # setcifsacl -a "ACL:S-1-22-2-1004:ALLOWED/0x0/R" /mnt/test/acltest
    
    this setacl will cause the following KASAN splat:
    
    [  330.777927] BUG: KASAN: slab-out-of-bounds in send_set_info+0x4dd/0xc20 [cifs]
    [  330.779696] Write of size 696 at addr ffff88010d5e2860 by task setcifsacl/1012
    
    [  330.781882] CPU: 1 PID: 1012 Comm: setcifsacl Not tainted 4.18.0-rc2+ #2
    [  330.783140] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014
    [  330.784395] Call Trace:
    [  330.784789]  dump_stack+0xc2/0x16b
    [  330.786777]  print_address_description+0x6a/0x270
    [  330.787520]  kasan_report+0x258/0x380
    [  330.788845]  memcpy+0x34/0x50
    [  330.789369]  send_set_info+0x4dd/0xc20 [cifs]
    [  330.799511]  SMB2_set_acl+0x76/0xa0 [cifs]
    [  330.801395]  set_smb2_acl+0x7ac/0xf30 [cifs]
    [  330.830888]  cifs_xattr_set+0x963/0xe40 [cifs]
    [  330.840367]  __vfs_setxattr+0x84/0xb0
    [  330.842060]  __vfs_setxattr_noperm+0xe6/0x370
    [  330.843848]  vfs_setxattr+0xc2/0xd0
    [  330.845519]  setxattr+0x258/0x320
    [  330.859211]  path_setxattr+0x15b/0x1b0
    [  330.864392]  __x64_sys_setxattr+0xc0/0x160
    [  330.866133]  do_syscall_64+0x14e/0x4b0
    [  330.876631]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [  330.878503] RIP: 0033:0x7ff2e507db0a
    [  330.880151] Code: 48 8b 0d 89 93 2c 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 49 89 ca b8 bc 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 56 93 2c 00 f7 d8 64 89 01 48
    [  330.885358] RSP: 002b:00007ffdc4903c18 EFLAGS: 00000246 ORIG_RAX: 00000000000000bc
    [  330.887733] RAX: ffffffffffffffda RBX: 000055d1170de140 RCX: 00007ff2e507db0a
    [  330.890067] RDX: 000055d1170de7d0 RSI: 000055d115b39184 RDI: 00007ffdc4904818
    [  330.892410] RBP: 0000000000000001 R08: 0000000000000000 R09: 000055d1170de7e4
    [  330.894785] R10: 00000000000002b8 R11: 0000000000000246 R12: 0000000000000007
    [  330.897148] R13: 000055d1170de0c0 R14: 0000000000000008 R15: 000055d1170de550
    
    [  330.901057] Allocated by task 1012:
    [  330.902888]  kasan_kmalloc+0xa0/0xd0
    [  330.904714]  kmem_cache_alloc+0xc8/0x1d0
    [  330.906615]  mempool_alloc+0x11e/0x380
    [  330.908496]  cifs_small_buf_get+0x35/0x60 [cifs]
    [  330.910510]  smb2_plain_req_init+0x4a/0xd60 [cifs]
    [  330.912551]  send_set_info+0x198/0xc20 [cifs]
    [  330.914535]  SMB2_set_acl+0x76/0xa0 [cifs]
    [  330.916465]  set_smb2_acl+0x7ac/0xf30 [cifs]
    [  330.918453]  cifs_xattr_set+0x963/0xe40 [cifs]
    [  330.920426]  __vfs_setxattr+0x84/0xb0
    [  330.922284]  __vfs_setxattr_noperm+0xe6/0x370
    [  330.924213]  vfs_setxattr+0xc2/0xd0
    [  330.926008]  setxattr+0x258/0x320
    [  330.927762]  path_setxattr+0x15b/0x1b0
    [  330.929592]  __x64_sys_setxattr+0xc0/0x160
    [  330.931459]  do_syscall_64+0x14e/0x4b0
    [  330.933314]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [  330.936843] Freed by task 0:
    [  330.938588] (stack is not available)
    
    [  330.941886] The buggy address belongs to the object at ffff88010d5e2800
     which belongs to the cache cifs_small_rq of size 448
    [  330.946362] The buggy address is located 96 bytes inside of
     448-byte region [ffff88010d5e2800, ffff88010d5e29c0)
    [  330.950722] The buggy address belongs to the page:
    [  330.952789] page:ffffea0004357880 count:1 mapcount:0 mapping:ffff880108fdca80 index:0x0 compound_mapcount: 0
    [  330.955665] flags: 0x17ffffc0008100(slab|head)
    [  330.957760] raw: 0017ffffc0008100 dead000000000100 dead000000000200 ffff880108fdca80
    [  330.960356] raw: 0000000000000000 0000000080100010 00000001ffffffff 0000000000000000
    [  330.963005] page dumped because: kasan: bad access detected
    
    [  330.967039] Memory state around the buggy address:
    [  330.969255]  ffff88010d5e2880: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  330.971833]  ffff88010d5e2900: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  330.974397] >ffff88010d5e2980: 00 00 00 00 00 00 00 00 fc fc fc fc fc fc fc fc
    [  330.976956]                                            ^
    [  330.979226]  ffff88010d5e2a00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  330.981755]  ffff88010d5e2a80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  330.984225] ==================================================================
    
    Fix this by allocating a regular CIFS buffer in
    smb2_plain_req_init() if the request command is SMB2_SET_INFO.
    
    Reported-by: Jianhong Yin <jiyin@redhat.com>
    Fixes: 366ed846df60 ("cifs: Use smb 2 - 3 and cifsacl mount options setacl function")
    CC: Stable <stable@vger.kernel.org>
    Signed-off-by: Stefano Brivio <sbrivio@redhat.com>
    Reviewed-and-tested-by: Aurelien Aptel <aaptel@suse.com>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28cada984c0e940d8419e6b3955d1f513f989e3a
Author: Paulo Alcantara <paulo@paulo.ac>
Date:   Thu Jul 5 13:46:34 2018 -0300

    cifs: Fix infinite loop when using hard mount option
    
    commit 7ffbe65578b44fafdef577a360eb0583929f7c6e upstream.
    
    For every request we send, whether it is SMB1 or SMB2+, we attempt to
    reconnect tcon (cifs_reconnect_tcon or smb2_reconnect) before carrying
    out the request.
    
    So, while server->tcpStatus != CifsNeedReconnect, we wait for the
    reconnection to succeed on wait_event_interruptible_timeout(). If it
    returns, that means that either the condition was evaluated to true, or
    timeout elapsed, or it was interrupted by a signal.
    
    Since we're not handling the case where the process woke up due to a
    received signal (-ERESTARTSYS), the next call to
    wait_event_interruptible_timeout() will _always_ fail and we end up
    looping forever inside either cifs_reconnect_tcon() or smb2_reconnect().
    
    Here's an example of how to trigger that:
    
    $ mount.cifs //foo/share /mnt/test -o
    username=foo,password=foo,vers=1.0,hard
    
    (break connection to server before executing bellow cmd)
    $ stat -f /mnt/test & sleep 140
    [1] 2511
    
    $ ps -aux -q 2511
    USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
    root      2511  0.0  0.0  12892  1008 pts/0    S    12:24   0:00 stat -f
    /mnt/test
    
    $ kill -9 2511
    
    (wait for a while; process is stuck in the kernel)
    $ ps -aux -q 2511
    USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
    root      2511 83.2  0.0  12892  1008 pts/0    R    12:24  30:01 stat -f
    /mnt/test
    
    By using 'hard' mount point means that cifs.ko will keep retrying
    indefinitely, however we must allow the process to be killed otherwise
    it would hang the system.
    
    Signed-off-by: Paulo Alcantara <palcantara@suse.de>
    Cc: stable@vger.kernel.org
    Reviewed-by: Aurelien Aptel <aaptel@suse.com>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f5f485d888d541431ce40aa1e6bc3ae95bd5ae91
Author: Paulo Alcantara <paulo@paulo.ac>
Date:   Wed Jul 4 14:16:16 2018 -0300

    cifs: Fix memory leak in smb2_set_ea()
    
    commit 6aa0c114eceec8cc61715f74a4ce91b048d7561c upstream.
    
    This patch fixes a memory leak when doing a setxattr(2) in SMB2+.
    
    Signed-off-by: Paulo Alcantara <palcantara@suse.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Reviewed-by: Aurelien Aptel <aaptel@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ff533735af1d31c621d1f4297cd3f6f01673b74b
Author: Lars Persson <lars.persson@axis.com>
Date:   Mon Jun 25 14:05:25 2018 +0200

    cifs: Fix use after free of a mid_q_entry
    
    commit 696e420bb2a6624478105651d5368d45b502b324 upstream.
    
    With protocol version 2.0 mounts we have seen crashes with corrupt mid
    entries. Either the server->pending_mid_q list becomes corrupt with a
    cyclic reference in one element or a mid object fetched by the
    demultiplexer thread becomes overwritten during use.
    
    Code review identified a race between the demultiplexer thread and the
    request issuing thread. The demultiplexer thread seems to be written
    with the assumption that it is the sole user of the mid object until
    it calls the mid callback which either wakes the issuer task or
    deletes the mid.
    
    This assumption is not true because the issuer task can be woken up
    earlier by a signal. If the demultiplexer thread has proceeded as far
    as setting the mid_state to MID_RESPONSE_RECEIVED then the issuer
    thread will happily end up calling cifs_delete_mid while the
    demultiplexer thread still is using the mid object.
    
    Inserting a delay in the cifs demultiplexer thread widens the race
    window and makes reproduction of the race very easy:
    
                    if (server->large_buf)
                            buf = server->bigbuf;
    
    +               usleep_range(500, 4000);
    
                    server->lstrp = jiffies;
    
    To resolve this I think the proper solution involves putting a
    reference count on the mid object. This patch makes sure that the
    demultiplexer thread holds a reference until it has finished
    processing the transaction.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Lars Persson <larper@axis.com>
    Acked-by: Paulo Alcantara <palcantara@suse.de>
    Reviewed-by: Ronnie Sahlberg <lsahlber@redhat.com>
    Reviewed-by: Pavel Shilovsky <pshilov@microsoft.com>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5d8ddc819c848a6009aed5a560e8d53f7cbafa08
Author: Jason Gunthorpe <jgg@ziepe.ca>
Date:   Fri Jun 29 11:31:50 2018 -0600

    vfio: Use get_user_pages_longterm correctly
    
    commit bb94b55af3461e26b32f0e23d455abeae0cfca5d upstream.
    
    The patch noted in the fixes below converted get_user_pages_fast() to
    get_user_pages_longterm(), however the two calls differ in a few ways.
    
    First _fast() is documented to not require the mmap_sem, while _longterm()
    is documented to need it. Hold the mmap sem as required.
    
    Second, _fast accepts an 'int write' while _longterm uses 'unsigned int
    gup_flags', so the expression '!!(prot & IOMMU_WRITE)' is only working by
    luck as FOLL_WRITE is currently == 0x1. Use the expected FOLL_WRITE
    constant instead.
    
    Fixes: 94db151dc892 ("vfio: disable filesystem-dax page pinning")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0ce6c46463715cecf78e6b92381f05dd47724f65
Author: Lars Ellenberg <lars.ellenberg@linbit.com>
Date:   Mon Jun 25 11:39:52 2018 +0200

    drbd: fix access after free
    
    commit 64dafbc9530c10300acffc57fae3269d95fa8f93 upstream.
    
    We have
      struct drbd_requests { ... struct bio *private_bio;  ... }
    to hold a bio clone for local submission.
    
    On local IO completion, we put that bio, and in case we want to use the
    result later, we overload that member to hold the ERR_PTR() of the
    completion result,
    
    Which, before v4.3, used to be the passed in "int error",
    so we could first bio_put(), then assign.
    
    v4.3-rc1~100^2~21 4246a0b63bd8 block: add a bi_error field to struct bio
    changed that:
            bio_put(req->private_bio);
     -      req->private_bio = ERR_PTR(error);
     +      req->private_bio = ERR_PTR(bio->bi_error);
    
    Which introduces an access after free,
    because it was non obvious that req->private_bio == bio.
    
    Impact of that was mostly unnoticable, because we only use that value
    in a multiple-failure case, and even then map any "unexpected" error
    code to EIO, so worst case we could potentially mask a more specific
    error with EIO in a multiple failure case.
    
    Unless the pointed to memory region was unmapped, as is the case with
    CONFIG_DEBUG_PAGEALLOC, in which case this results in
    
      BUG: unable to handle kernel paging request
    
    v4.13-rc1~70^2~75 4e4cbee93d56 block: switch bios to blk_status_t
    changes it further to
            bio_put(req->private_bio);
            req->private_bio = ERR_PTR(blk_status_to_errno(bio->bi_status));
    
    And blk_status_to_errno() now contains a WARN_ON_ONCE() for unexpected
    values, which catches this "sometimes", if the memory has been reused
    quickly enough for other things.
    
    Should also go into stable since 4.3, with the trivial change around 4.13.
    
    Cc: stable@vger.kernel.org
    Fixes: 4246a0b63bd8 block: add a bi_error field to struct bio
    Reported-by: Sarah Newman <srn@prgmr.com>
    Signed-off-by: Lars Ellenberg <lars.ellenberg@linbit.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2b6eff5923ce501d69e58807a1f81d910c029c8f
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Thu Jun 21 14:49:38 2018 +0200

    s390: Correct register corruption in critical section cleanup
    
    commit 891f6a726cacbb87e5b06076693ffab53bd378d7 upstream.
    
    In the critical section cleanup we must not mess with r1.  For march=z9
    or older, larl + ex (instead of exrl) are used with r1 as a temporary
    register. This can clobber r1 in several interrupt handlers. Fix this by
    using r11 as a temp register.  r11 is being saved by all callers of
    cleanup_critical.
    
    Fixes: 6dd85fbb87 ("s390: move expoline assembler macros to a header")
    Cc: stable@vger.kernel.org #v4.16
    Reported-by: Oliver Kurz <okurz@suse.com>
    Reported-by: Petr Tesařík <ptesarik@suse.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: Hendrik Brueckner <brueckner@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e6cf7e68728560f1466046a85c4ae5c685c7b651
Author: David Disseldorp <ddiss@suse.de>
Date:   Tue Jun 19 17:58:24 2018 +0200

    scsi: target: Fix truncated PR-in ReadKeys response
    
    commit 63ce3c384db26494615e3c8972bcd419ed71f4c4 upstream.
    
    SPC5r17 states that the contents of the ADDITIONAL LENGTH field are not
    altered based on the allocation length, so always calculate and pack the
    full key list length even if the list itself is truncated.
    
    According to Maged:
    
      Yes it fixes the "Storage Spaces Persistent Reservation" test in the
      Windows 2016 Server Failover Cluster validation suites when having
      many connections that result in more than 8 registrations. I tested
      your patch on 4.17 with iblock.
    
    This behaviour can be tested using the libiscsi PrinReadKeys.Truncate test.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: David Disseldorp <ddiss@suse.de>
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Tested-by: Maged Mokhtar <mmokhtar@petasan.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6e51bfa950864343cfe210a75268e826a2b4b2e8
Author: Jann Horn <jannh@google.com>
Date:   Mon Jun 25 16:25:44 2018 +0200

    scsi: sg: mitigate read/write abuse
    
    commit 26b5b874aff5659a7e26e5b1997e3df2c41fa7fd upstream.
    
    As Al Viro noted in commit 128394eff343 ("sg_write()/bsg_write() is not fit
    to be called under KERNEL_DS"), sg improperly accesses userspace memory
    outside the provided buffer, permitting kernel memory corruption via
    splice().  But it doesn't just do it on ->write(), also on ->read().
    
    As a band-aid, make sure that the ->read() and ->write() handlers can not
    be called in weird contexts (kernel context or credentials different from
    file opener), like for ib_safe_file_access().
    
    If someone needs to use these interfaces from different security contexts,
    a new interface should be written that goes through the ->ioctl() handler.
    
    I've mostly copypasted ib_safe_file_access() over as sg_safe_file_access()
    because I couldn't find a good common header - please tell me if you know a
    better way.
    
    [mkp: s/_safe_/_check_/]
    
    Fixes: 1da177e4c3f4 ("Linux-2.6.12-rc2")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jann Horn <jannh@google.com>
    Acked-by: Douglas Gilbert <dgilbert@interlog.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 54f1da1ff0347182ca58c6d1f64551afb36ecb90
Author: Changbin Du <changbin.du@intel.com>
Date:   Wed Jan 31 23:48:49 2018 +0800

    tracing: Fix missing return symbol in function_graph output
    
    commit 1fe4293f4b8de75824935f8d8e9a99c7fc6873da upstream.
    
    The function_graph tracer does not show the interrupt return marker for the
    leaf entry. On leaf entries, we see an unbalanced interrupt marker (the
    interrupt was entered, but nevern left).
    
    Before:
     1)               |  SyS_write() {
     1)               |    __fdget_pos() {
     1)   0.061 us    |      __fget_light();
     1)   0.289 us    |    }
     1)               |    vfs_write() {
     1)   0.049 us    |      rw_verify_area();
     1) + 15.424 us   |      __vfs_write();
     1)   ==========> |
     1)   6.003 us    |      smp_apic_timer_interrupt();
     1)   0.055 us    |      __fsnotify_parent();
     1)   0.073 us    |      fsnotify();
     1) + 23.665 us   |    }
     1) + 24.501 us   |  }
    
    After:
     0)               |  SyS_write() {
     0)               |    __fdget_pos() {
     0)   0.052 us    |      __fget_light();
     0)   0.328 us    |    }
     0)               |    vfs_write() {
     0)   0.057 us    |      rw_verify_area();
     0)               |      __vfs_write() {
     0)   ==========> |
     0)   8.548 us    |      smp_apic_timer_interrupt();
     0)   <========== |
     0) + 36.507 us   |      } /* __vfs_write */
     0)   0.049 us    |      __fsnotify_parent();
     0)   0.066 us    |      fsnotify();
     0) + 50.064 us   |    }
     0) + 50.952 us   |  }
    
    Link: http://lkml.kernel.org/r/1517413729-20411-1-git-send-email-changbin.du@intel.com
    
    Cc: stable@vger.kernel.org
    Fixes: f8b755ac8e0cc ("tracing/function-graph-tracer: Output arrows signal on hardirq call/return")
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 48b019a51ab8836dcea2d5e68e07fa129b604c3a
Author: Cannon Matthews <cannonmatthews@google.com>
Date:   Tue Jul 3 17:02:43 2018 -0700

    mm: hugetlb: yield when prepping struct pages
    
    commit 520495fe96d74e05db585fc748351e0504d8f40d upstream.
    
    When booting with very large numbers of gigantic (i.e.  1G) pages, the
    operations in the loop of gather_bootmem_prealloc, and specifically
    prep_compound_gigantic_page, takes a very long time, and can cause a
    softlockup if enough pages are requested at boot.
    
    For example booting with 3844 1G pages requires prepping
    (set_compound_head, init the count) over 1 billion 4K tail pages, which
    takes considerable time.
    
    Add a cond_resched() to the outer loop in gather_bootmem_prealloc() to
    prevent this lockup.
    
    Tested: Booted with softlockup_panic=1 hugepagesz=1G hugepages=3844 and
    no softlockup is reported, and the hugepages are reported as
    successfully setup.
    
    Link: http://lkml.kernel.org/r/20180627214447.260804-1-cannonmatthews@google.com
    Signed-off-by: Cannon Matthews <cannonmatthews@google.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Andres Lagar-Cavilla <andreslc@google.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6fe74fb8af8949e91b67fc3fc244c8db0e2e276d
Author: Janosch Frank <frankja@linux.ibm.com>
Date:   Tue Jul 3 17:02:39 2018 -0700

    userfaultfd: hugetlbfs: fix userfaultfd_huge_must_wait() pte access
    
    commit 1e2c043628c7736dd56536d16c0ce009bc834ae7 upstream.
    
    Use huge_ptep_get() to translate huge ptes to normal ptes so we can
    check them with the huge_pte_* functions.  Otherwise some architectures
    will check the wrong values and will not wait for userspace to bring in
    the memory.
    
    Link: http://lkml.kernel.org/r/20180626132421.78084-1-frankja@linux.ibm.com
    Fixes: 369cd2121be4 ("userfaultfd: hugetlbfs: userfaultfd_huge_must_wait for hugepmd ranges")
    Signed-off-by: Janosch Frank <frankja@linux.ibm.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
