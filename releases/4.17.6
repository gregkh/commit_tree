commit b36cc73101fa785ba47f3092fb7517dde0c27da3
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jul 11 16:31:35 2018 +0200

    Linux 4.17.6

commit 22f5d0a83a40e8a3367b44349951a81bcee7c3f1
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Jun 27 23:26:05 2018 -0700

    Revert mm/vmstat.c: fix vmstat_update() preemption BUG
    
    commit 28557cc106e6d2aa8b8c5c7687ea9f8055ff3911 upstream.
    
    Revert commit c7f26ccfb2c3 ("mm/vmstat.c: fix vmstat_update() preemption
    BUG").  Steven saw a "using smp_processor_id() in preemptible" message
    and added a preempt_disable() section around it to keep it quiet.  This
    is not the right thing to do it does not fix the real problem.
    
    vmstat_update() is invoked by a kworker on a specific CPU.  This worker
    it bound to this CPU.  The name of the worker was "kworker/1:1" so it
    should have been a worker which was bound to CPU1.  A worker which can
    run on any CPU would have a `u' before the first digit.
    
    smp_processor_id() can be used in a preempt-enabled region as long as
    the task is bound to a single CPU which is the case here.  If it could
    run on an arbitrary CPU then this is the problem we have an should seek
    to resolve.
    
    Not only this smp_processor_id() must not be migrated to another CPU but
    also refresh_cpu_vm_stats() which might access wrong per-CPU variables.
    Not to mention that other code relies on the fact that such a worker
    runs on one specific CPU only.
    
    Therefore revert that commit and we should look instead what broke the
    affinity mask of the kworker.
    
    Link: http://lkml.kernel.org/r/20180504104451.20278-1-bigeasy@linutronix.de
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Steven J. Hill <steven.hill@cavium.com>
    Cc: Tejun Heo <htejun@gmail.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2aeef3fb8063003ba42428d34b5359759d1fef28
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Tue Jun 5 12:36:30 2018 +0300

    staging: comedi: quatech_daqp_cs: fix no-op loop daqp_ao_insn_write()
    
    commit 1376b0a2160319125c3a2822e8c09bd283cd8141 upstream.
    
    There is a '>' vs '<' typo so this loop is a no-op.
    
    Fixes: d35dcc89fc93 ("staging: comedi: quatech_daqp_cs: fix daqp_ao_insn_write()")
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Ian Abbott <abbotti@mev.co.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 362aa587f6129c27153de857e0c039ed81c968fb
Author: Jann Horn <jannh@google.com>
Date:   Mon Jun 25 17:22:00 2018 +0200

    netfilter: nf_log: don't hold nf_log_mutex during user access
    
    commit ce00bf07cc95a57cd20b208e02b3c2604e532ae8 upstream.
    
    The old code would indefinitely block other users of nf_log_mutex if
    a userspace access in proc_dostring() blocked e.g. due to a userfaultfd
    region. Fix it by moving proc_dostring() out of the locked region.
    
    This is a followup to commit 266d07cb1c9a ("netfilter: nf_log: fix
    sleeping function called from invalid context"), which changed this code
    from using rcu_read_lock() to taking nf_log_mutex.
    
    Fixes: 266d07cb1c9a ("netfilter: nf_log: fix sleeping function calle[...]")
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 10929ce0fe818f1ad34712bf09295a277e91a726
Author: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
Date:   Wed May 30 18:32:29 2018 +0900

    mtd: cfi_cmdset_0002: Change erase functions to check chip good only
    
    commit 79ca484b613041ca223f74b34608bb6f5221724b upstream.
    
    Currently the functions use to check both chip ready and good.
    But the chip ready is not enough to check the operation status.
    So change this to check the chip good instead of this.
    About the retry functions to make sure the error handling remain it.
    
    Signed-off-by: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
    Reviewed-by: Joakim Tjernlund <Joakim.Tjernlund@infinera.com>
    Cc: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Cyrille Pitchen <cyrille.pitchen@wedev4u.fr>
    Cc: linux-mtd@lists.infradead.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e642f13e4aa856d51d21810c7252c59992460ecb
Author: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
Date:   Wed May 30 18:32:28 2018 +0900

    mtd: cfi_cmdset_0002: Change erase functions to retry for error
    
    commit 45f75b8a919a4255f52df454f1ffdee0e42443b2 upstream.
    
    For the word write functions it is retried for error.
    But it is not implemented to retry for the erase functions.
    To make sure for the erase functions change to retry as same.
    
    This is needed to prevent the flash erase error caused only once.
    It was caused by the error case of chip_good() in the do_erase_oneblock().
    Also it was confirmed on the MACRONIX flash device MX29GL512FHT2I-11G.
    But the error issue behavior is not able to reproduce at this moment.
    The flash controller is parallel Flash interface integrated on BCM53003.
    
    Signed-off-by: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
    Reviewed-by: Joakim Tjernlund <Joakim.Tjernlund@infinera.com>
    Cc: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Cyrille Pitchen <cyrille.pitchen@wedev4u.fr>
    Cc: linux-mtd@lists.infradead.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1cc9491775d4d6cbe6ceb6a8cb71814df26fda00
Author: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
Date:   Wed May 30 18:32:27 2018 +0900

    mtd: cfi_cmdset_0002: Change definition naming to retry write operation
    
    commit 85a82e28b023de9b259a86824afbd6ba07bd6475 upstream.
    
    The definition can be used for other program and erase operations also.
    So change the naming to MAX_RETRIES from MAX_WORD_RETRIES.
    
    Signed-off-by: Tokunori Ikegami <ikegami@allied-telesis.co.jp>
    Reviewed-by: Joakim Tjernlund <Joakim.Tjernlund@infinera.com>
    Cc: Chris Packham <chris.packham@alliedtelesis.co.nz>
    Cc: Brian Norris <computersforpeace@gmail.com>
    Cc: David Woodhouse <dwmw2@infradead.org>
    Cc: Boris Brezillon <boris.brezillon@free-electrons.com>
    Cc: Marek Vasut <marek.vasut@gmail.com>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Cyrille Pitchen <cyrille.pitchen@wedev4u.fr>
    Cc: linux-mtd@lists.infradead.org
    Cc: stable@vger.kernel.org
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1ac28f09976b172931dfe7bf28eed303589b9502
Author: Ross Zwisler <zwisler@kernel.org>
Date:   Tue Jun 26 16:30:41 2018 -0600

    dm: prevent DAX mounts if not supported
    
    commit dbc626597c39b24cefce09fbd8e9dea85869a801 upstream.
    
    Currently device_supports_dax() just checks to see if the QUEUE_FLAG_DAX
    flag is set on the device's request queue to decide whether or not the
    device supports filesystem DAX.  Really we should be using
    bdev_dax_supported() like filesystems do at mount time.  This performs
    other tests like checking to make sure the dax_direct_access() path works.
    
    We also explicitly clear QUEUE_FLAG_DAX on the DM device's request queue if
    any of the underlying devices do not support DAX.  This makes the handling
    of QUEUE_FLAG_DAX consistent with the setting/clearing of most other flags
    in dm_table_set_restrictions().
    
    Now that bdev_dax_supported() explicitly checks for QUEUE_FLAG_DAX, this
    will ensure that filesystems built upon DM devices will only be able to
    mount with DAX if all underlying devices also support DAX.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Fixes: commit 545ed20e6df6 ("dm: add infrastructure for DAX support")
    Cc: stable@vger.kernel.org
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e9aaac43ff96065db11b373177528d802ca3a928
Author: Ross Zwisler <zwisler@kernel.org>
Date:   Tue Jun 26 16:30:40 2018 -0600

    dax: check for QUEUE_FLAG_DAX in bdev_dax_supported()
    
    commit 15256f6cc4b44f2e70503758150267fd2a53c0d6 upstream.
    
    Add an explicit check for QUEUE_FLAG_DAX to __bdev_dax_supported().  This
    is needed for DM configurations where the first element in the dm-linear or
    dm-stripe target supports DAX, but other elements do not.  Without this
    check __bdev_dax_supported() will pass for such devices, letting a
    filesystem on that device mount with the DAX option.
    
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Suggested-by: Mike Snitzer <snitzer@redhat.com>
    Fixes: commit 545ed20e6df6 ("dm: add infrastructure for DAX support")
    Cc: stable@vger.kernel.org
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Reviewed-by: Toshi Kani <toshi.kani@hpe.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f266082e1b0fdfe4d2a19eac1f439a4a9e704f3a
Author: Dave Jiang <dave.jiang@intel.com>
Date:   Wed May 30 13:03:46 2018 -0700

    dax: change bdev_dax_supported() to support boolean returns
    
    commit 80660f20252d6f76c9f203874ad7c7a4a8508cf8 upstream.
    
    The function return values are confusing with the way the function is
    named. We expect a true or false return value but it actually returns
    0/-errno.  This makes the code very confusing. Changing the return values
    to return a bool where if DAX is supported then return true and no DAX
    support returns false.
    
    Signed-off-by: Dave Jiang <dave.jiang@intel.com>
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2384edbfa7ff6d4122bb6554a5cf94d67ee88b9e
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Wed May 30 13:03:45 2018 -0700

    fs: allow per-device dax status checking for filesystems
    
    commit ba23cba9b3bdc967aabdc6ff1e3e9b11ce05bb4f upstream.
    
    Change bdev_dax_supported so it takes a bdev parameter.  This enables
    multi-device filesystems like xfs to check that a dax device can work for
    the particular filesystem.  Once that's in place, actually fix all the
    parts of XFS where we need to be able to distinguish between datadev and
    rtdev.
    
    This patch fixes the problem where we screw up the dax support checking
    in xfs if the datadev and rtdev have different dax capabilities.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    [rez: Re-added __bdev_dax_supported() for !CONFIG_FS_DAX cases]
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reviewed-by: Eric Sandeen <sandeen@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5f0a93e12376ac29d353c628eb2a75c4bda59887
Author: Peter Rosin <peda@axentia.se>
Date:   Wed Jun 20 11:43:23 2018 +0200

    i2c: smbus: kill memory leak on emulated and failed DMA SMBus xfers
    
    commit 9aa613674f89d01248ae2e4afe691b515ff8fbb6 upstream.
    
    If DMA safe memory was allocated, but the subsequent I2C transfer
    fails the memory is leaked. Plug this leak.
    
    Fixes: 8a77821e74d6 ("i2c: smbus: use DMA safe buffers for emulated SMBus transactions")
    Signed-off-by: Peter Rosin <peda@axentia.se>
    Signed-off-by: Wolfram Sang <wsa@the-dreams.de>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 328349288e77e9b5df4717af534c05670f47192f
Author: Wenwen Wang <wang6495@umn.edu>
Date:   Sat May 5 08:02:21 2018 -0500

    i2c: core: smbus: fix a potential missing-check bug
    
    commit 8e03477cb709b73a2c1e1f4349ee3b7b33c50416 upstream.
    
    In i2c_smbus_xfer_emulated(), the function i2c_transfer() is invoked to
    transfer i2c messages. The number of actual transferred messages is
    returned and saved to 'status'. If 'status' is negative, that means an
    error occurred during the transfer process. In that case, the value of
    'status' is an error code to indicate the reason of the transfer failure.
    In most cases, i2c_transfer() can transfer 'num' messages with no error.
    And so 'status' == 'num'. However, due to unexpected errors, it is probable
    that only partial messages are transferred by i2c_transfer(). As a result,
    'status' != 'num'. This special case is not checked after the invocation of
    i2c_transfer() and can potentially lead to unexpected issues in the
    following execution since it is expected that 'status' == 'num'.
    
    This patch checks the return value of i2c_transfer() and returns an error
    code -EIO if the number of actual transferred messages 'status' is not
    equal to 'num'.
    
    Signed-off-by: Wenwen Wang <wang6495@umn.edu>
    Signed-off-by: Wolfram Sang <wsa@the-dreams.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 091b5e3f593a8d34919b6226d58c00e18fb47305
Author: Benjamin Tissoires <benjamin.tissoires@redhat.com>
Date:   Thu May 31 13:49:29 2018 +0200

    HID: core: allow concurrent registration of drivers
    
    commit 8f732850df1b2b4d8d719f7e606dfb3050e7ea11 upstream.
    
    Detected on the Dell XPS 9365.
    
    The laptop has 2 devices that benefit from the hid-generic auto-unbinding.
    When those 2 devices are presented to the userspace, udev loads both wacom and
    hid-multitouch. When this happens, the code in __hid_bus_reprobe_drivers() is
    called concurrently and the second device gets reprobed twice.
    
    An other bug in the power_supply subsystem prevent to remove the wacom driver
    if it just finished its initialization, which basically kills the wacom node.
    
    [jkosina@suse.cz: reformat changelog a bit]
    Fixes c17a7476e4c4 ("HID: core: rewrite the hid-generic automatic unbind")
    Cc: stable@vger.kernel.org # v4.17
    Tested-by: Mario Limonciello <mario.limonciello@dell.com>
    Signed-off-by: Benjamin Tissoires <benjamin.tissoires@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 787b882d9178c35eb2e06e974f3c37fc14829e53
Author: Daniel Rosenberg <drosen@google.com>
Date:   Mon Jul 2 16:59:37 2018 -0700

    HID: debug: check length before copy_to_user()
    
    commit 717adfdaf14704fd3ec7fa2c04520c0723247eac upstream.
    
    If our length is greater than the size of the buffer, we
    overflow the buffer
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Daniel Rosenberg <drosen@google.com>
    Reviewed-by: Benjamin Tissoires <benjamin.tissoires@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9be3ce793708c0b2324b632e22a9214586f7757c
Author: Gustavo A. R. Silva <gustavo@embeddedor.com>
Date:   Fri Jun 29 17:08:44 2018 -0500

    HID: hiddev: fix potential Spectre v1
    
    commit 4f65245f2d178b9cba48350620d76faa4a098841 upstream.
    
    uref->field_index, uref->usage_index, finfo.field_index and cinfo.index can be
    indirectly controlled by user-space, hence leading to a potential exploitation
    of the Spectre variant 1 vulnerability.
    
    This issue was detected with the help of Smatch:
    
    drivers/hid/usbhid/hiddev.c:473 hiddev_ioctl_usage() warn: potential spectre issue 'report->field' (local cap)
    drivers/hid/usbhid/hiddev.c:477 hiddev_ioctl_usage() warn: potential spectre issue 'field->usage' (local cap)
    drivers/hid/usbhid/hiddev.c:757 hiddev_ioctl() warn: potential spectre issue 'report->field' (local cap)
    drivers/hid/usbhid/hiddev.c:801 hiddev_ioctl() warn: potential spectre issue 'hid->collection' (local cap)
    
    Fix this by sanitizing such structure fields before using them to index
    report->field, field->usage and hid->collection
    
    Notice that given that speculation windows are large, the policy is
    to kill the speculation on the first load and not worry if it can be
    completed with a dependent load/store [1].
    
    [1] https://marc.info/?l=linux-kernel&m=152449131114778&w=2
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Gustavo A. R. Silva <gustavo@embeddedor.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 79ef9243e7febb086542373780d49da1bd32ca6b
Author: Jason Andryuk <jandryuk@gmail.com>
Date:   Fri Jun 22 12:25:49 2018 -0400

    HID: i2c-hid: Fix "incomplete report" noise
    
    commit ef6eaf27274c0351f7059163918f3795da13199c upstream.
    
    Commit ac75a041048b ("HID: i2c-hid: fix size check and type usage") started
    writing messages when the ret_size is <= 2 from i2c_master_recv.  However, my
    device i2c-DLL07D1 returns 2 for a short period of time (~0.5s) after I stop
    moving the pointing stick or touchpad.  It varies, but you get ~50 messages
    each time which spams the log hard.
    
    [  95.925055] i2c_hid i2c-DLL07D1:01: i2c_hid_get_input: incomplete report (83/2)
    
    This has also been observed with a i2c-ALP0017.
    
    [ 1781.266353] i2c_hid i2c-ALP0017:00: i2c_hid_get_input: incomplete report (30/2)
    
    Only print the message when ret_size is totally invalid and less than 2 to cut
    down on the log spam.
    
    Fixes: ac75a041048b ("HID: i2c-hid: fix size check and type usage")
    Reported-by: John Smith <john-s-84@gmx.net>
    Cc: stable@vger.kernel.org
    Signed-off-by: Jason Andryuk <jandryuk@gmail.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c2b9dc3f6e9402026bc0e2cd122ef02673153d50
Author: Jon Derrick <jonathan.derrick@intel.com>
Date:   Mon Jul 2 18:45:18 2018 -0400

    ext4: check superblock mapped prior to committing
    
    commit a17712c8e4be4fa5404d20e9cd3b2b21eae7bc56 upstream.
    
    This patch attempts to close a hole leading to a BUG seen with hot
    removals during writes [1].
    
    A block device (NVME namespace in this test case) is formatted to EXT4
    without partitions. It's mounted and write I/O is run to a file, then
    the device is hot removed from the slot. The superblock attempts to be
    written to the drive which is no longer present.
    
    The typical chain of events leading to the BUG:
    ext4_commit_super()
      __sync_dirty_buffer()
        submit_bh()
          submit_bh_wbc()
            BUG_ON(!buffer_mapped(bh));
    
    This fix checks for the superblock's buffer head being mapped prior to
    syncing.
    
    [1] https://www.spinics.net/lists/linux-ext4/msg56527.html
    
    Signed-off-by: Jon Derrick <jonathan.derrick@intel.com>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a5f8b0a70e3967ec2e5b91dfc865d10fb995f37d
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sun Jun 17 18:11:20 2018 -0400

    ext4: add more mount time checks of the superblock
    
    commit bfe0a5f47ada40d7984de67e59a7d3390b9b9ecc upstream.
    
    The kernel's ext4 mount-time checks were more permissive than
    e2fsprogs's libext2fs checks when opening a file system.  The
    superblock is considered too insane for debugfs or e2fsck to operate
    on it, the kernel has no business trying to mount it.
    
    This will make file system fuzzing tools work harder, but the failure
    cases that they find will be more useful and be easier to evaluate.
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 77d4024c10f3271dc7e799890e15df8fcadebcda
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sun Jun 17 00:41:14 2018 -0400

    ext4: add more inode number paranoia checks
    
    commit c37e9e013469521d9adb932d17a1795c139b36db upstream.
    
    If there is a directory entry pointing to a system inode (such as a
    journal inode), complain and declare the file system to be corrupted.
    
    Also, if the superblock's first inode number field is too small,
    refuse to mount the file system.
    
    This addresses CVE-2018-10882.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200069
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 44cb38f45625d8cc1d565407243e5e02e08f2f10
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jun 16 23:41:59 2018 -0400

    ext4: avoid running out of journal credits when appending to an inline file
    
    commit 8bc1379b82b8e809eef77a9fedbb75c6c297be19 upstream.
    
    Use a separate journal transaction if it turns out that we need to
    convert an inline file to use an data block.  Otherwise we could end
    up failing due to not having journal credits.
    
    This addresses CVE-2018-10883.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200071
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1f18321d31d0971a5e9a02a9e67a6d94b638fca3
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jun 16 15:40:48 2018 -0400

    ext4: never move the system.data xattr out of the inode body
    
    commit 8cdb5240ec5928b20490a2bb34cb87e9a5f40226 upstream.
    
    When expanding the extra isize space, we must never move the
    system.data xattr out of the inode body.  For performance reasons, it
    doesn't make any sense, and the inline data implementation assumes
    that system.data xattr is never in the external xattr block.
    
    This addresses CVE-2018-10880
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200005
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0abaed0c74f4dbd3f5a9dcb9fb6b472735874b5e
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Fri Jun 15 12:28:16 2018 -0400

    ext4: clear i_data in ext4_inode_info when removing inline data
    
    commit 6e8ab72a812396996035a37e5ca4b3b99b5d214b upstream.
    
    When converting from an inode from storing the data in-line to a data
    block, ext4_destroy_inline_data_nolock() was only clearing the on-disk
    copy of the i_blocks[] array.  It was not clearing copy of the
    i_blocks[] in ext4_inode_info, in i_data[], which is the copy actually
    used by ext4_map_blocks().
    
    This didn't matter much if we are using extents, since the extents
    header would be invalid and thus the extents could would re-initialize
    the extents tree.  But if we are using indirect blocks, the previous
    contents of the i_blocks array will be treated as block numbers, with
    potentially catastrophic results to the file system integrity and/or
    user data.
    
    This gets worse if the file system is using a 1k block size and
    s_first_data is zero, but even without this, the file system can get
    quite badly corrupted.
    
    This addresses CVE-2018-10881.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200015
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6af469f553b5c3e5fe10449ad38bbadc11fb1d31
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Fri Jun 15 12:27:16 2018 -0400

    ext4: include the illegal physical block in the bad map ext4_error msg
    
    commit bdbd6ce01a70f02e9373a584d0ae9538dcf0a121 upstream.
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a266689c463cc6057400d1cfdf85b8e3ef7b6efd
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Thu Jun 14 12:55:10 2018 -0400

    ext4: verify the depth of extent tree in ext4_find_extent()
    
    commit bc890a60247171294acc0bd67d211fa4b88d40ba upstream.
    
    If there is a corupted file system where the claimed depth of the
    extent tree is -1, this can cause a massive buffer overrun leading to
    sadness.
    
    This addresses CVE-2018-10877.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199417
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b94094f668a9bf7837c275cd6e49bf29def3c77f
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Thu Jun 14 00:58:00 2018 -0400

    ext4: only look at the bg_flags field if it is valid
    
    commit 8844618d8aa7a9973e7b527d038a2a589665002c upstream.
    
    The bg_flags field in the block group descripts is only valid if the
    uninit_bg or metadata_csum feature is enabled.  We were not
    consistently looking at this field; fix this.
    
    Also block group #0 must never have uninitialized allocation bitmaps,
    or need to be zeroed, since that's where the root inode, and other
    special inodes are set up.  Check for these conditions and mark the
    file system as corrupted if they are detected.
    
    This addresses CVE-2018-10876.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199403
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 425a51f7b055ccc66ea7fd0415eb905ede66622d
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 23:00:48 2018 -0400

    ext4: always check block group bounds in ext4_init_block_bitmap()
    
    commit 819b23f1c501b17b9694325471789e6b5cc2d0d2 upstream.
    
    Regardless of whether the flex_bg feature is set, we should always
    check to make sure the bits we are setting in the block bitmap are
    within the block group bounds.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199865
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0f2e7fe6d2cc8903765dac6eea7d7aa96e9ad823
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 23:08:26 2018 -0400

    ext4: make sure bitmaps and the inode table don't overlap with bg descriptors
    
    commit 77260807d1170a8cf35dbb06e07461a655f67eee upstream.
    
    It's really bad when the allocation bitmaps and the inode table
    overlap with the block group descriptors, since it causes random
    corruption of the bg descriptors.  So we really want to head those off
    at the pass.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=199865
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 11f6b0e426aa5d85df5e9cad74a55b407b5be007
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 00:51:28 2018 -0400

    ext4: always verify the magic number in xattr blocks
    
    commit 513f86d73855ce556ea9522b6bfd79f87356dc3a upstream.
    
    If there an inode points to a block which is also some other type of
    metadata block (such as a block allocation bitmap), the
    buffer_verified flag can be set when it was validated as that other
    metadata block type; however, it would make a really terrible external
    attribute block.  The reason why we use the verified flag is to avoid
    constantly reverifying the block.  However, it doesn't take much
    overhead to make sure the magic number of the xattr block is correct,
    and this will avoid potential crashes.
    
    This addresses CVE-2018-10879.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200001
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e4130b9612095a6db9bafb90634fbd579b77d893
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jun 13 00:23:11 2018 -0400

    ext4: add corruption check in ext4_xattr_set_entry()
    
    commit 5369a762c882c0b6e9599e4ebbb3a9ba9eee7e2d upstream.
    
    In theory this should have been caught earlier when the xattr list was
    verified, but in case it got missed, it's simple enough to add check
    to make sure we don't overrun the xattr buffer.
    
    This addresses CVE-2018-10879.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200001
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Reviewed-by: Andreas Dilger <adilger@dilger.ca>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f869e0b631a6a7befe595dbad0b2e3662c6d1a99
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Sat Jun 16 20:21:45 2018 -0400

    jbd2: don't mark block as modified if the handle is out of credits
    
    commit e09463f220ca9a1a1ecfda84fcda658f99a1f12a upstream.
    
    Do not set the b_modified flag in block's journal head should not
    until after we're sure that jbd2_journal_dirty_metadat() will not
    abort with an error due to there not being enough space reserved in
    the jbd2 handle.
    
    Otherwise, future attempts to modify the buffer may lead a large
    number of spurious errors and warnings.
    
    This addresses CVE-2018-10883.
    
    https://bugzilla.kernel.org/show_bug.cgi?id=200071
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: stable@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 802de58a57746661d1389ef732bcafaccf3c4426
Author: Lyude Paul <lyude@redhat.com>
Date:   Mon Jun 25 21:09:07 2018 -0400

    drm/amdgpu: Dynamically probe for ATIF handle (v2)
    
    commit f9ff68521a5541e1fdaeb0ef11871c035b30e409 upstream.
    
    The other day I was testing one of the HP laptops at my office with an
    i915/amdgpu hybrid setup and noticed that hotplugging was non-functional
    on almost all of the display outputs. I eventually discovered that all
    of the external outputs were connected to the amdgpu device instead of
    i915, and that the hotplugs weren't being detected so long as the GPU
    was in runtime suspend. After some talking with folks at AMD, I learned
    that amdgpu is actually supposed to support hotplug detection in runtime
    suspend so long as the OEM has implemented it properly in the firmware.
    
    On this HP ZBook 15 G4 (the machine in question), amdgpu wasn't managing
    to find the ATIF handle at all despite the fact that I could see acpi
    events being sent in response to any hotplugging. After going through
    dumps of the firmware, I discovered that this machine did in fact
    support ATIF, but that it's ATIF method lived in an entirely different
    namespace than this device's handle (the device handle was
    \_SB_.PCI0.PEG0.PEGP, but ATIF lives in ATPX's handle at
    \_SB_.PCI0.GFX0).
    
    So, fix this by probing ATPX's ACPI parent's namespace if we can't find
    ATIF elsewhere, along with storing a pointer to the proper handle to use
    for ATIF and using that instead of the device's handle.
    
    This fixes HPD detection while in runtime suspend for this ZBook!
    
    v2: Update the comment to reflect how the namespaces are arranged
    based on the system configuration. (Alex)
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 95576e9e2d0cb06cf1df496331a9ed040c2cf15b
Author: Lyude Paul <lyude@redhat.com>
Date:   Mon Jun 25 21:09:06 2018 -0400

    drm/amdgpu: Add amdgpu_atpx_get_dhandle()
    
    commit 4aa5d5eb82bb237d0bb3a38b2a7555054d018081 upstream.
    
    Since it seems that some vendors are storing the ATIF ACPI methods under
    the same handle that ATPX lives under instead of the device's own
    handle, we're going to need to be able to retrieve this handle later so
    we can probe for ATIF there.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 039ae7c9cbfc84ec070d8ea344abee50a6a55521
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Sun Jun 3 16:40:54 2018 +0200

    drm/udl: fix display corruption of the last line
    
    commit 99ec9e77511dea55d81729fc80b6c63a61bfa8e0 upstream.
    
    The displaylink hardware has such a peculiarity that it doesn't render a
    command until next command is received. This produces occasional
    corruption, such as when setting 22x11 font on the console, only the first
    line of the cursor will be blinking if the cursor is located at some
    specific columns.
    
    When we end up with a repeating pixel, the driver has a bug that it leaves
    one uninitialized byte after the command (and this byte is enough to flush
    the command and render it - thus it fixes the screen corruption), however
    whe we end up with a non-repeating pixel, there is no byte appended and
    this results in temporary screen corruption.
    
    This patch fixes the screen corruption by always appending a byte 0xAF at
    the end of URB. It also removes the uninitialized byte.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 50f6300d73c58ebb1695121962c1e5431f5b684e
Author: Michel Dänzer <michel.daenzer@amd.com>
Date:   Fri Jun 29 16:27:10 2018 +0200

    drm: Use kvzalloc for allocating blob property memory
    
    commit 718b5406cd76f1aa6434311241b7febf0e8571ff upstream.
    
    The property size may be controlled by userspace, can be large (I've
    seen failure with order 4, i.e. 16 pages / 64 KB) and doesn't need to be
    physically contiguous.
    
    Signed-off-by: Michel Dänzer <michel.daenzer@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180629142710.2069-1-michel@daenzer.net
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9f0003b7d67983c6a3472b7ae5954d8f6ff7e922
Author: Paulo Alcantara <paulo@paulo.ac>
Date:   Thu Jul 5 13:46:34 2018 -0300

    cifs: Fix infinite loop when using hard mount option
    
    commit 7ffbe65578b44fafdef577a360eb0583929f7c6e upstream.
    
    For every request we send, whether it is SMB1 or SMB2+, we attempt to
    reconnect tcon (cifs_reconnect_tcon or smb2_reconnect) before carrying
    out the request.
    
    So, while server->tcpStatus != CifsNeedReconnect, we wait for the
    reconnection to succeed on wait_event_interruptible_timeout(). If it
    returns, that means that either the condition was evaluated to true, or
    timeout elapsed, or it was interrupted by a signal.
    
    Since we're not handling the case where the process woke up due to a
    received signal (-ERESTARTSYS), the next call to
    wait_event_interruptible_timeout() will _always_ fail and we end up
    looping forever inside either cifs_reconnect_tcon() or smb2_reconnect().
    
    Here's an example of how to trigger that:
    
    $ mount.cifs //foo/share /mnt/test -o
    username=foo,password=foo,vers=1.0,hard
    
    (break connection to server before executing bellow cmd)
    $ stat -f /mnt/test & sleep 140
    [1] 2511
    
    $ ps -aux -q 2511
    USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
    root      2511  0.0  0.0  12892  1008 pts/0    S    12:24   0:00 stat -f
    /mnt/test
    
    $ kill -9 2511
    
    (wait for a while; process is stuck in the kernel)
    $ ps -aux -q 2511
    USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
    root      2511 83.2  0.0  12892  1008 pts/0    R    12:24  30:01 stat -f
    /mnt/test
    
    By using 'hard' mount point means that cifs.ko will keep retrying
    indefinitely, however we must allow the process to be killed otherwise
    it would hang the system.
    
    Signed-off-by: Paulo Alcantara <palcantara@suse.de>
    Cc: stable@vger.kernel.org
    Reviewed-by: Aurelien Aptel <aaptel@suse.com>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dbe71f37e7ae2cf7d9bd03a64ce5d829c76cd404
Author: Stefano Brivio <sbrivio@redhat.com>
Date:   Thu Jul 5 11:46:42 2018 +0200

    cifs: Fix slab-out-of-bounds in send_set_info() on SMB2 ACE setting
    
    commit f46ecbd97f508e68a7806291a139499794874f3d upstream.
    
    A "small" CIFS buffer is not big enough in general to hold a
    setacl request for SMB2, and we end up overflowing the buffer in
    send_set_info(). For instance:
    
     # mount.cifs //127.0.0.1/test /mnt/test -o username=test,password=test,nounix,cifsacl
     # touch /mnt/test/acltest
     # getcifsacl /mnt/test/acltest
     REVISION:0x1
     CONTROL:0x9004
     OWNER:S-1-5-21-2926364953-924364008-418108241-1000
     GROUP:S-1-22-2-1001
     ACL:S-1-5-21-2926364953-924364008-418108241-1000:ALLOWED/0x0/0x1e01ff
     ACL:S-1-22-2-1001:ALLOWED/0x0/R
     ACL:S-1-22-2-1001:ALLOWED/0x0/R
     ACL:S-1-5-21-2926364953-924364008-418108241-1000:ALLOWED/0x0/0x1e01ff
     ACL:S-1-1-0:ALLOWED/0x0/R
     # setcifsacl -a "ACL:S-1-22-2-1004:ALLOWED/0x0/R" /mnt/test/acltest
    
    this setacl will cause the following KASAN splat:
    
    [  330.777927] BUG: KASAN: slab-out-of-bounds in send_set_info+0x4dd/0xc20 [cifs]
    [  330.779696] Write of size 696 at addr ffff88010d5e2860 by task setcifsacl/1012
    
    [  330.781882] CPU: 1 PID: 1012 Comm: setcifsacl Not tainted 4.18.0-rc2+ #2
    [  330.783140] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1 04/01/2014
    [  330.784395] Call Trace:
    [  330.784789]  dump_stack+0xc2/0x16b
    [  330.786777]  print_address_description+0x6a/0x270
    [  330.787520]  kasan_report+0x258/0x380
    [  330.788845]  memcpy+0x34/0x50
    [  330.789369]  send_set_info+0x4dd/0xc20 [cifs]
    [  330.799511]  SMB2_set_acl+0x76/0xa0 [cifs]
    [  330.801395]  set_smb2_acl+0x7ac/0xf30 [cifs]
    [  330.830888]  cifs_xattr_set+0x963/0xe40 [cifs]
    [  330.840367]  __vfs_setxattr+0x84/0xb0
    [  330.842060]  __vfs_setxattr_noperm+0xe6/0x370
    [  330.843848]  vfs_setxattr+0xc2/0xd0
    [  330.845519]  setxattr+0x258/0x320
    [  330.859211]  path_setxattr+0x15b/0x1b0
    [  330.864392]  __x64_sys_setxattr+0xc0/0x160
    [  330.866133]  do_syscall_64+0x14e/0x4b0
    [  330.876631]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [  330.878503] RIP: 0033:0x7ff2e507db0a
    [  330.880151] Code: 48 8b 0d 89 93 2c 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 49 89 ca b8 bc 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 56 93 2c 00 f7 d8 64 89 01 48
    [  330.885358] RSP: 002b:00007ffdc4903c18 EFLAGS: 00000246 ORIG_RAX: 00000000000000bc
    [  330.887733] RAX: ffffffffffffffda RBX: 000055d1170de140 RCX: 00007ff2e507db0a
    [  330.890067] RDX: 000055d1170de7d0 RSI: 000055d115b39184 RDI: 00007ffdc4904818
    [  330.892410] RBP: 0000000000000001 R08: 0000000000000000 R09: 000055d1170de7e4
    [  330.894785] R10: 00000000000002b8 R11: 0000000000000246 R12: 0000000000000007
    [  330.897148] R13: 000055d1170de0c0 R14: 0000000000000008 R15: 000055d1170de550
    
    [  330.901057] Allocated by task 1012:
    [  330.902888]  kasan_kmalloc+0xa0/0xd0
    [  330.904714]  kmem_cache_alloc+0xc8/0x1d0
    [  330.906615]  mempool_alloc+0x11e/0x380
    [  330.908496]  cifs_small_buf_get+0x35/0x60 [cifs]
    [  330.910510]  smb2_plain_req_init+0x4a/0xd60 [cifs]
    [  330.912551]  send_set_info+0x198/0xc20 [cifs]
    [  330.914535]  SMB2_set_acl+0x76/0xa0 [cifs]
    [  330.916465]  set_smb2_acl+0x7ac/0xf30 [cifs]
    [  330.918453]  cifs_xattr_set+0x963/0xe40 [cifs]
    [  330.920426]  __vfs_setxattr+0x84/0xb0
    [  330.922284]  __vfs_setxattr_noperm+0xe6/0x370
    [  330.924213]  vfs_setxattr+0xc2/0xd0
    [  330.926008]  setxattr+0x258/0x320
    [  330.927762]  path_setxattr+0x15b/0x1b0
    [  330.929592]  __x64_sys_setxattr+0xc0/0x160
    [  330.931459]  do_syscall_64+0x14e/0x4b0
    [  330.933314]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [  330.936843] Freed by task 0:
    [  330.938588] (stack is not available)
    
    [  330.941886] The buggy address belongs to the object at ffff88010d5e2800
     which belongs to the cache cifs_small_rq of size 448
    [  330.946362] The buggy address is located 96 bytes inside of
     448-byte region [ffff88010d5e2800, ffff88010d5e29c0)
    [  330.950722] The buggy address belongs to the page:
    [  330.952789] page:ffffea0004357880 count:1 mapcount:0 mapping:ffff880108fdca80 index:0x0 compound_mapcount: 0
    [  330.955665] flags: 0x17ffffc0008100(slab|head)
    [  330.957760] raw: 0017ffffc0008100 dead000000000100 dead000000000200 ffff880108fdca80
    [  330.960356] raw: 0000000000000000 0000000080100010 00000001ffffffff 0000000000000000
    [  330.963005] page dumped because: kasan: bad access detected
    
    [  330.967039] Memory state around the buggy address:
    [  330.969255]  ffff88010d5e2880: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  330.971833]  ffff88010d5e2900: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  330.974397] >ffff88010d5e2980: 00 00 00 00 00 00 00 00 fc fc fc fc fc fc fc fc
    [  330.976956]                                            ^
    [  330.979226]  ffff88010d5e2a00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  330.981755]  ffff88010d5e2a80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  330.984225] ==================================================================
    
    Fix this by allocating a regular CIFS buffer in
    smb2_plain_req_init() if the request command is SMB2_SET_INFO.
    
    Reported-by: Jianhong Yin <jiyin@redhat.com>
    Fixes: 366ed846df60 ("cifs: Use smb 2 - 3 and cifsacl mount options setacl function")
    CC: Stable <stable@vger.kernel.org>
    Signed-off-by: Stefano Brivio <sbrivio@redhat.com>
    Reviewed-and-tested-by: Aurelien Aptel <aaptel@suse.com>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ef5bf57178139bb66c14b8d76f9a8b7e85b63687
Author: Paulo Alcantara <paulo@paulo.ac>
Date:   Wed Jul 4 14:16:16 2018 -0300

    cifs: Fix memory leak in smb2_set_ea()
    
    commit 6aa0c114eceec8cc61715f74a4ce91b048d7561c upstream.
    
    This patch fixes a memory leak when doing a setxattr(2) in SMB2+.
    
    Signed-off-by: Paulo Alcantara <palcantara@suse.de>
    Cc: stable@vger.kernel.org
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Reviewed-by: Aurelien Aptel <aaptel@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9f4cf98ddfd9dcf35ece9c38e0ef4b167fa8fca
Author: Lars Persson <lars.persson@axis.com>
Date:   Mon Jun 25 14:05:25 2018 +0200

    cifs: Fix use after free of a mid_q_entry
    
    commit 696e420bb2a6624478105651d5368d45b502b324 upstream.
    
    With protocol version 2.0 mounts we have seen crashes with corrupt mid
    entries. Either the server->pending_mid_q list becomes corrupt with a
    cyclic reference in one element or a mid object fetched by the
    demultiplexer thread becomes overwritten during use.
    
    Code review identified a race between the demultiplexer thread and the
    request issuing thread. The demultiplexer thread seems to be written
    with the assumption that it is the sole user of the mid object until
    it calls the mid callback which either wakes the issuer task or
    deletes the mid.
    
    This assumption is not true because the issuer task can be woken up
    earlier by a signal. If the demultiplexer thread has proceeded as far
    as setting the mid_state to MID_RESPONSE_RECEIVED then the issuer
    thread will happily end up calling cifs_delete_mid while the
    demultiplexer thread still is using the mid object.
    
    Inserting a delay in the cifs demultiplexer thread widens the race
    window and makes reproduction of the race very easy:
    
                    if (server->large_buf)
                            buf = server->bigbuf;
    
    +               usleep_range(500, 4000);
    
                    server->lstrp = jiffies;
    
    To resolve this I think the proper solution involves putting a
    reference count on the mid object. This patch makes sure that the
    demultiplexer thread holds a reference until it has finished
    processing the transaction.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Lars Persson <larper@axis.com>
    Acked-by: Paulo Alcantara <palcantara@suse.de>
    Reviewed-by: Ronnie Sahlberg <lsahlber@redhat.com>
    Reviewed-by: Pavel Shilovsky <pshilov@microsoft.com>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 38d3690f7a4d29b5931f3ef427880e8db4f6e5aa
Author: Roger Quadros <rogerq@ti.com>
Date:   Tue May 29 12:00:54 2018 +0300

    ARM: dts: dra7: Disable metastability workaround for USB2
    
    commit 07eaa43e66f505980d00e0f5fe697f3da7c6a730 upstream.
    
    Disable the metastability workaround for USB2. The original
    patch disabled the workaround on the wrong USB port.
    
    Fixes: b8c9c6fa2002 ("ARM: dts: dra7: Disable USB metastability workaround for USB2")
    Cc: <stable@vger.kernel.org>        [4.16+]
    Signed-off-by: Roger Quadros <rogerq@ti.com>
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c25bd5bf23017c5e3655c0ddd93cb883707853f7
Author: Adam Ford <aford173@gmail.com>
Date:   Mon Jun 25 07:41:33 2018 -0500

    ARM: dts: omap3: Fix am3517 mdio and emac clock references
    
    commit 0144eb204cdcdf09a76794b4a294291388e739bc upstream.
    
    A previous patch removed OMAP clock aliases that were perceived
    to be unnecessary.  Unfortunately, it broke the ethernet on the
    am3517-evm.  This patch enables the MDIO clock and EMAC clock.
    
    Fixes: 0ed266d7ae5e ("clk: ti: omap3: cleanup unnecessary clock aliases")
    Cc: stable@vger.kernel.org #4.16+
    
    Signed-off-by: Adam Ford <aford173@gmail.com>
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dbecaae4bfcb1551ca483a6c4d3b5e3c68f06675
Author: Nick Dyer <nick@shmanahar.org>
Date:   Thu Jun 21 19:10:00 2018 +0100

    ARM: dts: imx51-zii-rdu1: fix touchscreen pinctrl
    
    commit 06d793b114e9d922c03aa077ac6c5c51fdda2722 upstream.
    
    The pinctrl settings were incorrect for the touchscreen interrupt line, causing
    an interrupt storm. This change has been tested with both the atmel_mxt_ts and
    RMI4 drivers on the RDU1 units.
    
    The value 0x4 comes from the value of register IOMUXC_SW_PAD_CTL_PAD_CSI1_D8
    from the old vendor kernel.
    
    Signed-off-by: Nick Dyer <nick@shmanahar.org>
    Fixes: ceef0396f367 ("ARM: dts: imx: add ZII RDU1 board")
    Cc: <stable@vger.kernel.org> # 4.15+
    Reviewed-by: Fabio Estevam <fabio.estevam@nxp.com>
    Tested-by: Chris Healy <cphealy@gmail.com>
    Signed-off-by: Shawn Guo <shawnguo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5cdc9e29ffb074a4062100825d4d049e202818a7
Author: Jason Gunthorpe <jgg@ziepe.ca>
Date:   Fri Jun 29 11:31:50 2018 -0600

    vfio: Use get_user_pages_longterm correctly
    
    commit bb94b55af3461e26b32f0e23d455abeae0cfca5d upstream.
    
    The patch noted in the fixes below converted get_user_pages_fast() to
    get_user_pages_longterm(), however the two calls differ in a few ways.
    
    First _fast() is documented to not require the mmap_sem, while _longterm()
    is documented to need it. Hold the mmap sem as required.
    
    Second, _fast accepts an 'int write' while _longterm uses 'unsigned int
    gup_flags', so the expression '!!(prot & IOMMU_WRITE)' is only working by
    luck as FOLL_WRITE is currently == 0x1. Use the expected FOLL_WRITE
    constant instead.
    
    Fixes: 94db151dc892 ("vfio: disable filesystem-dax page pinning")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a3be6357ded22c64ba4836cd744d8b2038c8edc4
Author: Lars Ellenberg <lars.ellenberg@linbit.com>
Date:   Mon Jun 25 11:39:52 2018 +0200

    drbd: fix access after free
    
    commit 64dafbc9530c10300acffc57fae3269d95fa8f93 upstream.
    
    We have
      struct drbd_requests { ... struct bio *private_bio;  ... }
    to hold a bio clone for local submission.
    
    On local IO completion, we put that bio, and in case we want to use the
    result later, we overload that member to hold the ERR_PTR() of the
    completion result,
    
    Which, before v4.3, used to be the passed in "int error",
    so we could first bio_put(), then assign.
    
    v4.3-rc1~100^2~21 4246a0b63bd8 block: add a bi_error field to struct bio
    changed that:
            bio_put(req->private_bio);
     -      req->private_bio = ERR_PTR(error);
     +      req->private_bio = ERR_PTR(bio->bi_error);
    
    Which introduces an access after free,
    because it was non obvious that req->private_bio == bio.
    
    Impact of that was mostly unnoticable, because we only use that value
    in a multiple-failure case, and even then map any "unexpected" error
    code to EIO, so worst case we could potentially mask a more specific
    error with EIO in a multiple failure case.
    
    Unless the pointed to memory region was unmapped, as is the case with
    CONFIG_DEBUG_PAGEALLOC, in which case this results in
    
      BUG: unable to handle kernel paging request
    
    v4.13-rc1~70^2~75 4e4cbee93d56 block: switch bios to blk_status_t
    changes it further to
            bio_put(req->private_bio);
            req->private_bio = ERR_PTR(blk_status_to_errno(bio->bi_status));
    
    And blk_status_to_errno() now contains a WARN_ON_ONCE() for unexpected
    values, which catches this "sometimes", if the memory has been reused
    quickly enough for other things.
    
    Should also go into stable since 4.3, with the trivial change around 4.13.
    
    Cc: stable@vger.kernel.org
    Fixes: 4246a0b63bd8 block: add a bi_error field to struct bio
    Reported-by: Sarah Newman <srn@prgmr.com>
    Signed-off-by: Lars Ellenberg <lars.ellenberg@linbit.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3d590170fb5c71cb29db38ac03eeb9ef03c4e362
Author: Christian Borntraeger <borntraeger@de.ibm.com>
Date:   Thu Jun 21 14:49:38 2018 +0200

    s390: Correct register corruption in critical section cleanup
    
    commit 891f6a726cacbb87e5b06076693ffab53bd378d7 upstream.
    
    In the critical section cleanup we must not mess with r1.  For march=z9
    or older, larl + ex (instead of exrl) are used with r1 as a temporary
    register. This can clobber r1 in several interrupt handlers. Fix this by
    using r11 as a temp register.  r11 is being saved by all callers of
    cleanup_critical.
    
    Fixes: 6dd85fbb87 ("s390: move expoline assembler macros to a header")
    Cc: stable@vger.kernel.org #v4.16
    Reported-by: Oliver Kurz <okurz@suse.com>
    Reported-by: Petr Tesařík <ptesarik@suse.com>
    Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
    Reviewed-by: Hendrik Brueckner <brueckner@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 04dbce2f5d77eba47369ccd349dae55f9be7f598
Author: David Disseldorp <ddiss@suse.de>
Date:   Tue Jun 19 17:58:24 2018 +0200

    scsi: target: Fix truncated PR-in ReadKeys response
    
    commit 63ce3c384db26494615e3c8972bcd419ed71f4c4 upstream.
    
    SPC5r17 states that the contents of the ADDITIONAL LENGTH field are not
    altered based on the allocation length, so always calculate and pack the
    full key list length even if the list itself is truncated.
    
    According to Maged:
    
      Yes it fixes the "Storage Spaces Persistent Reservation" test in the
      Windows 2016 Server Failover Cluster validation suites when having
      many connections that result in more than 8 registrations. I tested
      your patch on 4.17 with iblock.
    
    This behaviour can be tested using the libiscsi PrinReadKeys.Truncate test.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: David Disseldorp <ddiss@suse.de>
    Reviewed-by: Mike Christie <mchristi@redhat.com>
    Tested-by: Maged Mokhtar <mmokhtar@petasan.org>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 620f480fd8322d7c01dba037540cab243193ca46
Author: Raghava Aditya Renukunta <RaghavaAditya.Renukunta@microsemi.com>
Date:   Fri Jun 22 06:55:47 2018 -0700

    scsi: aacraid: Fix PD performance regression over incorrect qd being set
    
    commit 59b433c825569ce251371485f0e29fca888b549d upstream.
    
    The driver fails to set the correct queue depth for native devices, due to
    failing to set the device type prior to calling aac_set_safw_target_qd().
    This results in slave configure setting the queue depth to 1.
    
    This causes around 30% performance degradation. Fixed by setting the dev
    type before trying to set queue depth.
    
    Reported-by: Steve Best <sbest@redhat.com>
    Fixes: 0bcb45fb20c21 ("scsi: aacraid: Add helper function to set queue depth")
    cc: stable@vger.kernel.org
    Signed-off-by: Raghava Aditya Renukunta <RaghavaAditya.Renukunta@microsemi.com>
    Reviewed-by: David Carroll <David.Carroll@microsemi.com>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ae78cf6c0c2e2ea05f9d2d6bd59f702fd1e8220c
Author: Jann Horn <jannh@google.com>
Date:   Mon Jun 25 16:25:44 2018 +0200

    scsi: sg: mitigate read/write abuse
    
    commit 26b5b874aff5659a7e26e5b1997e3df2c41fa7fd upstream.
    
    As Al Viro noted in commit 128394eff343 ("sg_write()/bsg_write() is not fit
    to be called under KERNEL_DS"), sg improperly accesses userspace memory
    outside the provided buffer, permitting kernel memory corruption via
    splice().  But it doesn't just do it on ->write(), also on ->read().
    
    As a band-aid, make sure that the ->read() and ->write() handlers can not
    be called in weird contexts (kernel context or credentials different from
    file opener), like for ib_safe_file_access().
    
    If someone needs to use these interfaces from different security contexts,
    a new interface should be written that goes through the ->ioctl() handler.
    
    I've mostly copypasted ib_safe_file_access() over as sg_safe_file_access()
    because I couldn't find a good common header - please tell me if you know a
    better way.
    
    [mkp: s/_safe_/_check_/]
    
    Fixes: 1da177e4c3f4 ("Linux-2.6.12-rc2")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jann Horn <jannh@google.com>
    Acked-by: Douglas Gilbert <dgilbert@interlog.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ac126896d4df90ad417d09930cf52f43a5a090e0
Author: Changbin Du <changbin.du@intel.com>
Date:   Wed Jan 31 23:48:49 2018 +0800

    tracing: Fix missing return symbol in function_graph output
    
    commit 1fe4293f4b8de75824935f8d8e9a99c7fc6873da upstream.
    
    The function_graph tracer does not show the interrupt return marker for the
    leaf entry. On leaf entries, we see an unbalanced interrupt marker (the
    interrupt was entered, but nevern left).
    
    Before:
     1)               |  SyS_write() {
     1)               |    __fdget_pos() {
     1)   0.061 us    |      __fget_light();
     1)   0.289 us    |    }
     1)               |    vfs_write() {
     1)   0.049 us    |      rw_verify_area();
     1) + 15.424 us   |      __vfs_write();
     1)   ==========> |
     1)   6.003 us    |      smp_apic_timer_interrupt();
     1)   0.055 us    |      __fsnotify_parent();
     1)   0.073 us    |      fsnotify();
     1) + 23.665 us   |    }
     1) + 24.501 us   |  }
    
    After:
     0)               |  SyS_write() {
     0)               |    __fdget_pos() {
     0)   0.052 us    |      __fget_light();
     0)   0.328 us    |    }
     0)               |    vfs_write() {
     0)   0.057 us    |      rw_verify_area();
     0)               |      __vfs_write() {
     0)   ==========> |
     0)   8.548 us    |      smp_apic_timer_interrupt();
     0)   <========== |
     0) + 36.507 us   |      } /* __vfs_write */
     0)   0.049 us    |      __fsnotify_parent();
     0)   0.066 us    |      fsnotify();
     0) + 50.064 us   |    }
     0) + 50.952 us   |  }
    
    Link: http://lkml.kernel.org/r/1517413729-20411-1-git-send-email-changbin.du@intel.com
    
    Cc: stable@vger.kernel.org
    Fixes: f8b755ac8e0cc ("tracing/function-graph-tracer: Output arrows signal on hardirq call/return")
    Signed-off-by: Changbin Du <changbin.du@intel.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 89cc5f854c68ff861ce5ce18f091a20bf40e9a09
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Mar 28 16:09:10 2018 +0200

    tracing: Avoid string overflow
    
    commit cf4d418e653afc84c9c873236033e06be5d58f1c upstream.
    
    'err' is used as a NUL-terminated string, but using strncpy() with the length
    equal to the buffer size may result in lack of the termination:
    
    kernel/trace/trace_events_hist.c: In function 'hist_err_event':
    kernel/trace/trace_events_hist.c:396:3: error: 'strncpy' specified bound 256 equals destination size [-Werror=stringop-truncation]
       strncpy(err, var, MAX_FILTER_STR_VAL);
    
    This changes it to use the safer strscpy() instead.
    
    Link: http://lkml.kernel.org/r/20180328140920.2842153-1-arnd@arndb.de
    
    Cc: stable@vger.kernel.org
    Fixes: f404da6e1d46 ("tracing: Add 'last error' error facility for hist triggers")
    Acked-by: Tom Zanussi <tom.zanussi@linux.intel.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit af23e901a6c04055da853d2f8aa942746eb02df6
Author: Lyude Paul <lyude@redhat.com>
Date:   Mon Jun 25 21:09:04 2018 -0400

    drm/amdgpu: Make struct amdgpu_atif private to amdgpu_acpi.c
    
    commit 2cd5fe22d9a45cdf11c62bbe8db3ce9101207510 upstream.
    
    Currently, there is nothing in amdgpu that actually uses these structs
    other than amdgpu_acpi.c. Additionally, since we're about to start
    saving the correct ACPI handle to use for calling ATIF in this struct
    this saves us from having to handle making sure that the acpi_handle
    (and by proxy, the type definition for acpi_handle and all of the other
    acpi headers) doesn't need to be included within the amdgpu_drv struct
    itself. This follows the example set by amdgpu_atpx_handler.c.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8505f57ce378f986032714040adab2fe1b719b97
Author: Jouke Witteveen <j.witteveen@gmail.com>
Date:   Wed Jul 4 12:27:15 2018 +0200

    ACPI / battery: Safe unregistering of hooks
    
    commit 673b4271665a12fa839a12abb50e6f6e9953c081 upstream.
    
    A hooking API was implemented for 4.17 in fa93854f7a7ed63d followed
    by hooks for Thinkpad laptops in 2801b9683f740012. The Thinkpad
    drivers did not support the Thinkpad 13 and the hooking API crashes
    on unsupported batteries by altering a list of hooks during unsafe
    iteration. Thus, Thinkpad 13 laptops could no longer boot.
    
    Additionally, a lock was kept in place and debugging information was
    printed out of order.
    
    Fixes: fa93854f7a7e (battery: Add the battery hooking API)
    Cc: 4.17+ <stable@vger.kernel.org> # 4.17+
    Signed-off-by: Jouke Witteveen <j.witteveen@gmail.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a5b79b8f55f780bfdf379549e46041e0bdb9bc84
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sat Jun 30 23:24:04 2018 +0200

    ACPICA: Drop leading newlines from error messages
    
    commit a0d5f3b69af7733f3173a8e19d51f68a08017c76 upstream.
    
    Commit 5088814a6e93 (ACPICA: AML parser: attempt to continue loading
    table after error) unintentionally added leading newlines to error
    messages emitted by ACPICA which caused unexpected things to be
    printed to the kernel log.  Drop these newlines (which effectively
    reverts the part of commit 5088814a6e93 adding them).
    
    Fixes: 5088814a6e93 (ACPICA: AML parser: attempt to continue loading table after error)
    Reported-by: Toralf Förster <toralf.foerster@gmx.de>
    Reported-by: Guenter Roeck <linux@roeck-us.net>
    Cc: 4.17+ <stable@vger.kernel.org> # 4.17+
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bff8d39af67e0ad7eb73738cd37db3a1806f1b3b
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Sat Jun 30 23:19:33 2018 +0200

    PCI / ACPI / PM: Resume bridges w/o drivers on suspend-to-RAM
    
    commit 26112ddc254c98681b224aa9ededefc01b6e02d2 upstream.
    
    It is reported that commit c62ec4610c40 (PM / core: Fix direct_complete
    handling for devices with no callbacks) introduced a system suspend
    regression on Samsung 305V4A by allowing a PCI bridge (not a PCIe
    port) to stay in D3 over suspend-to-RAM, which is a side effect of
    setting power.direct_complete for the children of that bridge that
    have no PM callbacks.
    
    On the majority of systems PCI bridges are not allowed to be
    runtime-suspended (the power/control sysfs attribute is set to "on"
    for them by default), but user space can change that setting and if
    it does so and a given bridge has no children with PM callbacks, the
    direct_complete optimization will be applied to it and it will stay
    in suspend over system suspend.  Apparently, that confuses the
    platform firmware on the affected machine and that may very well
    happen elsewhere, so avoid the direct_complete optimization for
    PCI bridges with no drivers (if there is a driver, it should take
    care of the PM handling) on suspend-to-RAM altogether (that should
    not matter for suspend-to-idle as platform firmware is not involved
    in it).
    
    Fixes: c62ec4610c40 (PM / core: Fix direct_complete handling for devices with no callbacks)
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=199941
    Reported-by: n0000b.n000b@gmail.com
    Tested-by: n0000b.n000b@gmail.com
    Reviewed-by: Mika Westerberg <mika.westerberg@linux.intel.com>
    Acked-by: Bjorn Helgaas <bhelgaas@google.com>
    Cc: 4.15+ <stable@vger.kernel.org> # 4.15+
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b34e1148f29e16f02c61f2fc5a4ad89ec329f31c
Author: Pavel Tatashin <pasha.tatashin@oracle.com>
Date:   Tue Jul 3 17:02:53 2018 -0700

    mm: teach dump_page() to correctly output poisoned struct pages
    
    commit fc36def997cfd6cbff3eda4f82853a5c311c5466 upstream.
    
    If struct page is poisoned, and uninitialized access is detected via
    PF_POISONED_CHECK(page) dump_page() is called to output the page.  But,
    the dump_page() itself accesses struct page to determine how to print
    it, and therefore gets into a recursive loop.
    
    For example:
    
      dump_page()
       __dump_page()
        PageSlab(page)
         PF_POISONED_CHECK(page)
          VM_BUG_ON_PGFLAGS(PagePoisoned(page), page)
           dump_page() recursion loop.
    
    Link: http://lkml.kernel.org/r/20180702180536.2552-1-pasha.tatashin@oracle.com
    Fixes: f165b378bbdf ("mm: uninitialized struct page poisoning sanity checking")
    Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8b083096463697143e1343ce05072ad89919b35b
Author: Cannon Matthews <cannonmatthews@google.com>
Date:   Tue Jul 3 17:02:43 2018 -0700

    mm: hugetlb: yield when prepping struct pages
    
    commit 520495fe96d74e05db585fc748351e0504d8f40d upstream.
    
    When booting with very large numbers of gigantic (i.e.  1G) pages, the
    operations in the loop of gather_bootmem_prealloc, and specifically
    prep_compound_gigantic_page, takes a very long time, and can cause a
    softlockup if enough pages are requested at boot.
    
    For example booting with 3844 1G pages requires prepping
    (set_compound_head, init the count) over 1 billion 4K tail pages, which
    takes considerable time.
    
    Add a cond_resched() to the outer loop in gather_bootmem_prealloc() to
    prevent this lockup.
    
    Tested: Booted with softlockup_panic=1 hugepagesz=1G hugepages=3844 and
    no softlockup is reported, and the hugepages are reported as
    successfully setup.
    
    Link: http://lkml.kernel.org/r/20180627214447.260804-1-cannonmatthews@google.com
    Signed-off-by: Cannon Matthews <cannonmatthews@google.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Andres Lagar-Cavilla <andreslc@google.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: Greg Thelen <gthelen@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8712b87adbb2f06c48a5453a4d08e828e71222da
Author: Janosch Frank <frankja@linux.ibm.com>
Date:   Tue Jul 3 17:02:39 2018 -0700

    userfaultfd: hugetlbfs: fix userfaultfd_huge_must_wait() pte access
    
    commit 1e2c043628c7736dd56536d16c0ce009bc834ae7 upstream.
    
    Use huge_ptep_get() to translate huge ptes to normal ptes so we can
    check them with the huge_pte_* functions.  Otherwise some architectures
    will check the wrong values and will not wait for userspace to bring in
    the memory.
    
    Link: http://lkml.kernel.org/r/20180626132421.78084-1-frankja@linux.ibm.com
    Fixes: 369cd2121be4 ("userfaultfd: hugetlbfs: userfaultfd_huge_must_wait for hugepmd ranges")
    Signed-off-by: Janosch Frank <frankja@linux.ibm.com>
    Reviewed-by: David Hildenbrand <david@redhat.com>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
