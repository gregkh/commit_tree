commit afe5d2361cfac43e2eb53d547e78386bd9fb9483
Author: Sasha Levin <sashal@kernel.org>
Date:   Wed Jun 30 09:03:25 2021 -0400

    Linux 5.12.14
    
    Tested-by: Fox Chen <foxhlchen@gmail.com>
    Tested-by: Justin M. Forbes <jforbes@fedoraproject.org>
    Tested-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c59019dfed03d43dab79ca325fc83cb2b49a08c1
Author: Eric Snowberg <eric.snowberg@oracle.com>
Date:   Fri Jan 22 13:10:54 2021 -0500

    integrity: Load mokx variables into the blacklist keyring
    
    [ Upstream commit ebd9c2ae369a45bdd9f8615484db09be58fc242b ]
    
    During boot the Secure Boot Forbidden Signature Database, dbx,
    is loaded into the blacklist keyring.  Systems booted with shim
    have an equivalent Forbidden Signature Database called mokx.
    Currently mokx is only used by shim and grub, the contents are
    ignored by the kernel.
    
    Add the ability to load mokx into the blacklist keyring during boot.
    
    Signed-off-by: Eric Snowberg <eric.snowberg@oracle.com>
    Suggested-by: James Bottomley <James.Bottomley@HansenPartnership.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Jarkko Sakkinen <jarkko@kernel.org>
    cc: keyrings@vger.kernel.org
    Link: https://lore.kernel.org/r/c33c8e3839a41e9654f41cc92c7231104931b1d7.camel@HansenPartnership.com/
    Link: https://lore.kernel.org/r/20210122181054.32635-5-eric.snowberg@oracle.com/ # v5
    Link: https://lore.kernel.org/r/161428674320.677100.12637282414018170743.stgit@warthog.procyon.org.uk/
    Link: https://lore.kernel.org/r/161433313205.902181.2502803393898221637.stgit@warthog.procyon.org.uk/ # v2
    Link: https://lore.kernel.org/r/161529607422.163428.13530426573612578854.stgit@warthog.procyon.org.uk/ # v3
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b3ca1077e1c4fb260d2c0a3a9dc9d267e81e6685
Author: Eric Snowberg <eric.snowberg@oracle.com>
Date:   Fri Jan 22 13:10:53 2021 -0500

    certs: Add ability to preload revocation certs
    
    [ Upstream commit d1f044103dad70c1cec0a8f3abdf00834fec8b98 ]
    
    Add a new Kconfig option called SYSTEM_REVOCATION_KEYS. If set,
    this option should be the filename of a PEM-formated file containing
    X.509 certificates to be included in the default blacklist keyring.
    
    DH Changes:
     - Make the new Kconfig option depend on SYSTEM_REVOCATION_LIST.
     - Fix SYSTEM_REVOCATION_KEYS=n, but CONFIG_SYSTEM_REVOCATION_LIST=y[1][2].
     - Use CONFIG_SYSTEM_REVOCATION_LIST for extract-cert[3].
     - Use CONFIG_SYSTEM_REVOCATION_LIST for revocation_certificates.o[3].
    
    Signed-off-by: Eric Snowberg <eric.snowberg@oracle.com>
    Acked-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Randy Dunlap <rdunlap@infradead.org>
    cc: keyrings@vger.kernel.org
    Link: https://lore.kernel.org/r/e1c15c74-82ce-3a69-44de-a33af9b320ea@infradead.org/ [1]
    Link: https://lore.kernel.org/r/20210303034418.106762-1-eric.snowberg@oracle.com/ [2]
    Link: https://lore.kernel.org/r/20210304175030.184131-1-eric.snowberg@oracle.com/ [3]
    Link: https://lore.kernel.org/r/20200930201508.35113-3-eric.snowberg@oracle.com/
    Link: https://lore.kernel.org/r/20210122181054.32635-4-eric.snowberg@oracle.com/ # v5
    Link: https://lore.kernel.org/r/161428673564.677100.4112098280028451629.stgit@warthog.procyon.org.uk/
    Link: https://lore.kernel.org/r/161433312452.902181.4146169951896577982.stgit@warthog.procyon.org.uk/ # v2
    Link: https://lore.kernel.org/r/161529606657.163428.3340689182456495390.stgit@warthog.procyon.org.uk/ # v3
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8365f9a6c81535112e7ff7fdd1c88ec2782e1abc
Author: Eric Snowberg <eric.snowberg@oracle.com>
Date:   Fri Jan 22 13:10:52 2021 -0500

    certs: Move load_system_certificate_list to a common function
    
    [ Upstream commit 2565ca7f5ec1a98d51eea8860c4ab923f1ca2c85 ]
    
    Move functionality within load_system_certificate_list to a common
    function, so it can be reused in the future.
    
    DH Changes:
     - Added inclusion of common.h to common.c (Eric [1]).
    
    Signed-off-by: Eric Snowberg <eric.snowberg@oracle.com>
    Acked-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: keyrings@vger.kernel.org
    Link: https://lore.kernel.org/r/EDA280F9-F72D-4181-93C7-CDBE95976FF7@oracle.com/ [1]
    Link: https://lore.kernel.org/r/20200930201508.35113-2-eric.snowberg@oracle.com/
    Link: https://lore.kernel.org/r/20210122181054.32635-3-eric.snowberg@oracle.com/ # v5
    Link: https://lore.kernel.org/r/161428672825.677100.7545516389752262918.stgit@warthog.procyon.org.uk/
    Link: https://lore.kernel.org/r/161433311696.902181.3599366124784670368.stgit@warthog.procyon.org.uk/ # v2
    Link: https://lore.kernel.org/r/161529605850.163428.7786675680201528556.stgit@warthog.procyon.org.uk/ # v3
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7be8fb1494c65f57bb6a95743cfbd3312fe9bf52
Author: Eric Snowberg <eric.snowberg@oracle.com>
Date:   Fri Jan 22 13:10:51 2021 -0500

    certs: Add EFI_CERT_X509_GUID support for dbx entries
    
    [ Upstream commit 56c5812623f95313f6a46fbf0beee7fa17c68bbf ]
    
    This fixes CVE-2020-26541.
    
    The Secure Boot Forbidden Signature Database, dbx, contains a list of now
    revoked signatures and keys previously approved to boot with UEFI Secure
    Boot enabled.  The dbx is capable of containing any number of
    EFI_CERT_X509_SHA256_GUID, EFI_CERT_SHA256_GUID, and EFI_CERT_X509_GUID
    entries.
    
    Currently when EFI_CERT_X509_GUID are contained in the dbx, the entries are
    skipped.
    
    Add support for EFI_CERT_X509_GUID dbx entries. When a EFI_CERT_X509_GUID
    is found, it is added as an asymmetrical key to the .blacklist keyring.
    Anytime the .platform keyring is used, the keys in the .blacklist keyring
    are referenced, if a matching key is found, the key will be rejected.
    
    [DH: Made the following changes:
     - Added to have a config option to enable the facility.  This allows a
       Kconfig solution to make sure that pkcs7_validate_trust() is
       enabled.[1][2]
     - Moved the functions out from the middle of the blacklist functions.
     - Added kerneldoc comments.]
    
    Signed-off-by: Eric Snowberg <eric.snowberg@oracle.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Jarkko Sakkinen <jarkko@kernel.org>
    cc: Randy Dunlap <rdunlap@infradead.org>
    cc: Mickaël Salaün <mic@digikod.net>
    cc: Arnd Bergmann <arnd@kernel.org>
    cc: keyrings@vger.kernel.org
    Link: https://lore.kernel.org/r/20200901165143.10295-1-eric.snowberg@oracle.com/ # rfc
    Link: https://lore.kernel.org/r/20200909172736.73003-1-eric.snowberg@oracle.com/ # v2
    Link: https://lore.kernel.org/r/20200911182230.62266-1-eric.snowberg@oracle.com/ # v3
    Link: https://lore.kernel.org/r/20200916004927.64276-1-eric.snowberg@oracle.com/ # v4
    Link: https://lore.kernel.org/r/20210122181054.32635-2-eric.snowberg@oracle.com/ # v5
    Link: https://lore.kernel.org/r/161428672051.677100.11064981943343605138.stgit@warthog.procyon.org.uk/
    Link: https://lore.kernel.org/r/161433310942.902181.4901864302675874242.stgit@warthog.procyon.org.uk/ # v2
    Link: https://lore.kernel.org/r/161529605075.163428.14625520893961300757.stgit@warthog.procyon.org.uk/ # v3
    Link: https://lore.kernel.org/r/bc2c24e3-ed68-2521-0bf4-a1f6be4a895d@infradead.org/ [1]
    Link: https://lore.kernel.org/r/20210225125638.1841436-1-arnd@kernel.org/ [2]
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2b2e592096b5b06706c099f6d2f7c5748b6adccd
Author: Daniel Vetter <daniel.vetter@ffwll.ch>
Date:   Tue Jun 22 09:54:09 2021 +0200

    Revert "drm: add a locked version of drm_is_current_master"
    
    commit f54b3ca7ea1e5e02f481cf4ca54568e57bd66086 upstream.
    
    This reverts commit 1815d9c86e3090477fbde066ff314a7e9721ee0f.
    
    Unfortunately this inverts the locking hierarchy, so back to the
    drawing board. Full lockdep splat below:
    
    ======================================================
    WARNING: possible circular locking dependency detected
    5.13.0-rc7-CI-CI_DRM_10254+ #1 Not tainted
    ------------------------------------------------------
    kms_frontbuffer/1087 is trying to acquire lock:
    ffff88810dcd01a8 (&dev->master_mutex){+.+.}-{3:3}, at: drm_is_current_master+0x1b/0x40
    but task is already holding lock:
    ffff88810dcd0488 (&dev->mode_config.mutex){+.+.}-{3:3}, at: drm_mode_getconnector+0x1c6/0x4a0
    which lock already depends on the new lock.
    the existing dependency chain (in reverse order) is:
    -> #2 (&dev->mode_config.mutex){+.+.}-{3:3}:
           __mutex_lock+0xab/0x970
           drm_client_modeset_probe+0x22e/0xca0
           __drm_fb_helper_initial_config_and_unlock+0x42/0x540
           intel_fbdev_initial_config+0xf/0x20 [i915]
           async_run_entry_fn+0x28/0x130
           process_one_work+0x26d/0x5c0
           worker_thread+0x37/0x380
           kthread+0x144/0x170
           ret_from_fork+0x1f/0x30
    -> #1 (&client->modeset_mutex){+.+.}-{3:3}:
           __mutex_lock+0xab/0x970
           drm_client_modeset_commit_locked+0x1c/0x180
           drm_client_modeset_commit+0x1c/0x40
           __drm_fb_helper_restore_fbdev_mode_unlocked+0x88/0xb0
           drm_fb_helper_set_par+0x34/0x40
           intel_fbdev_set_par+0x11/0x40 [i915]
           fbcon_init+0x270/0x4f0
           visual_init+0xc6/0x130
           do_bind_con_driver+0x1e5/0x2d0
           do_take_over_console+0x10e/0x180
           do_fbcon_takeover+0x53/0xb0
           register_framebuffer+0x22d/0x310
           __drm_fb_helper_initial_config_and_unlock+0x36c/0x540
           intel_fbdev_initial_config+0xf/0x20 [i915]
           async_run_entry_fn+0x28/0x130
           process_one_work+0x26d/0x5c0
           worker_thread+0x37/0x380
           kthread+0x144/0x170
           ret_from_fork+0x1f/0x30
    -> #0 (&dev->master_mutex){+.+.}-{3:3}:
           __lock_acquire+0x151e/0x2590
           lock_acquire+0xd1/0x3d0
           __mutex_lock+0xab/0x970
           drm_is_current_master+0x1b/0x40
           drm_mode_getconnector+0x37e/0x4a0
           drm_ioctl_kernel+0xa8/0xf0
           drm_ioctl+0x1e8/0x390
           __x64_sys_ioctl+0x6a/0xa0
           do_syscall_64+0x39/0xb0
           entry_SYSCALL_64_after_hwframe+0x44/0xae
    other info that might help us debug this:
    Chain exists of: &dev->master_mutex --> &client->modeset_mutex --> &dev->mode_config.mutex
     Possible unsafe locking scenario:
           CPU0                    CPU1
           ----                    ----
      lock(&dev->mode_config.mutex);
                                   lock(&client->modeset_mutex);
                                   lock(&dev->mode_config.mutex);
      lock(&dev->master_mutex);

commit 54ab8b082d0a9120ea9676e5b93de9eac24afcd2
Author: Naoya Horiguchi <naoya.horiguchi@nec.com>
Date:   Thu Jun 24 18:40:01 2021 -0700

    mm/hwpoison: do not lock page again when me_huge_page() successfully recovers
    
    commit ea6d0630100b285f059d0a8d8e86f38a46407536 upstream.
    
    Currently me_huge_page() temporary unlocks page to perform some actions
    then locks it again later.  My testcase (which calls hard-offline on
    some tail page in a hugetlb, then accesses the address of the hugetlb
    range) showed that page allocation code detects this page lock on buddy
    page and printed out "BUG: Bad page state" message.
    
    check_new_page_bad() does not consider a page with __PG_HWPOISON as bad
    page, so this flag works as kind of filter, but this filtering doesn't
    work in this case because the "bad page" is not the actual hwpoisoned
    page.  So stop locking page again.  Actions to be taken depend on the
    page type of the error, so page unlocking should be done in ->action()
    callbacks.  So let's make it assumed and change all existing callbacks
    that way.
    
    Link: https://lkml.kernel.org/r/20210609072029.74645-1-nao.horiguchi@gmail.com
    Fixes: commit 78bb920344b8 ("mm: hwpoison: dissolve in-use hugepage in unrecoverable memory error")
    Signed-off-by: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.vnet.ibm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ee98cb6f22dc0e664fed8180360077dceaf437ed
Author: Jeff Layton <jlayton@kernel.org>
Date:   Sun Jun 13 19:33:45 2021 -0400

    netfs: fix test for whether we can skip read when writing beyond EOF
    
    commit 827a746f405d25f79560c7868474aec5aee174e1 upstream.
    
    It's not sufficient to skip reading when the pos is beyond the EOF.
    There may be data at the head of the page that we need to fill in
    before the write.
    
    Add a new helper function that corrects and clarifies the logic of
    when we can skip reads, and have it only zero out the part of the page
    that won't have data copied in for the write.
    
    Finally, don't set the page Uptodate after zeroing. It's not up to date
    since the write data won't have been copied in yet.
    
    [DH made the following changes:
    
     - Prefixed the new function with "netfs_".
    
     - Don't call zero_user_segments() for a full-page write.
    
     - Altered the beyond-last-page check to avoid a DIV instruction and got
       rid of then-redundant zero-length file check.
    ]
    
    [ Note: this fix is commit 827a746f405d in mainline kernels. The
            original bug was in ceph, but got lifted into the fs/netfs
            library for v5.13. This backport should apply to stable
            kernels v5.10 though v5.12. ]
    
    Fixes: e1b1240c1ff5f ("netfs: Add write_begin helper")
    Reported-by: Andrew W Elble <aweits@rit.edu>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    cc: ceph-devel@vger.kernel.org
    Link: https://lore.kernel.org/r/20210613233345.113565-1-jlayton@kernel.org/
    Link: https://lore.kernel.org/r/162367683365.460125.4467036947364047314.stgit@warthog.procyon.org.uk/ # v1
    Link: https://lore.kernel.org/r/162391826758.1173366.11794946719301590013.stgit@warthog.procyon.org.uk/ # v2
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e77b796eb9b7ca3c1c0d574d0c155f55b59ca8d5
Author: Bumyong Lee <bumyong.lee@samsung.com>
Date:   Mon May 10 18:10:04 2021 +0900

    swiotlb: manipulate orig_addr when tlb_addr has offset
    
    commit 5f89468e2f060031cd89fd4287298e0eaf246bf6 upstream.
    
    in case of driver wants to sync part of ranges with offset,
    swiotlb_tbl_sync_single() copies from orig_addr base to tlb_addr with
    offset and ends up with data mismatch.
    
    It was removed from
    "swiotlb: don't modify orig_addr in swiotlb_tbl_sync_single",
    but said logic has to be added back in.
    
    From Linus's email:
    "That commit which the removed the offset calculation entirely, because the old
    
            (unsigned long)tlb_addr & (IO_TLB_SIZE - 1)
    
    was wrong, but instead of removing it, I think it should have just
    fixed it to be
    
            (tlb_addr - mem->start) & (IO_TLB_SIZE - 1);
    
    instead. That way the slot offset always matches the slot index calculation."
    
    (Unfortunatly that broke NVMe).
    
    The use-case that drivers are hitting is as follow:
    
    1. Get dma_addr_t from dma_map_single()
    
    dma_addr_t tlb_addr = dma_map_single(dev, vaddr, vsize, DMA_TO_DEVICE);
    
        |<---------------vsize------------->|
        +-----------------------------------+
        |                                   | original buffer
        +-----------------------------------+
      vaddr
    
     swiotlb_align_offset
         |<----->|<---------------vsize------------->|
         +-------+-----------------------------------+
         |       |                                   | swiotlb buffer
         +-------+-----------------------------------+
              tlb_addr
    
    2. Do something
    3. Sync dma_addr_t through dma_sync_single_for_device(..)
    
    dma_sync_single_for_device(dev, tlb_addr + offset, size, DMA_TO_DEVICE);
    
      Error case.
        Copy data to original buffer but it is from base addr (instead of
      base addr + offset) in original buffer:
    
     swiotlb_align_offset
         |<----->|<- offset ->|<- size ->|
         +-------+-----------------------------------+
         |       |            |##########|           | swiotlb buffer
         +-------+-----------------------------------+
              tlb_addr
    
        |<- size ->|
        +-----------------------------------+
        |##########|                        | original buffer
        +-----------------------------------+
      vaddr
    
    The fix is to copy the data to the original buffer and take into
    account the offset, like so:
    
     swiotlb_align_offset
         |<----->|<- offset ->|<- size ->|
         +-------+-----------------------------------+
         |       |            |##########|           | swiotlb buffer
         +-------+-----------------------------------+
              tlb_addr
    
        |<- offset ->|<- size ->|
        +-----------------------------------+
        |            |##########|           | original buffer
        +-----------------------------------+
      vaddr
    
    [One fix which was Linus's that made more sense to as it created a
    symmetry would break NVMe. The reason for that is the:
     unsigned int offset = (tlb_addr - mem->start) & (IO_TLB_SIZE - 1);
    
    would come up with the proper offset, but it would lose the
    alignment (which this patch contains).]
    
    Fixes: 16fc3cef33a0 ("swiotlb: don't modify orig_addr in swiotlb_tbl_sync_single")
    Signed-off-by: Bumyong Lee <bumyong.lee@samsung.com>
    Signed-off-by: Chanho Park <chanho61.park@samsung.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Reported-by: Dominique MARTINET <dominique.martinet@atmark-techno.com>
    Reported-by: Horia Geantă <horia.geanta@nxp.com>
    Tested-by: Horia Geantă <horia.geanta@nxp.com>
    CC: stable@vger.kernel.org
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d94b8af42e532cd80da2fbea207cfedce7467690
Author: Alper Gun <alpergun@google.com>
Date:   Thu Jun 10 17:46:04 2021 +0000

    KVM: SVM: Call SEV Guest Decommission if ASID binding fails
    
    commit 934002cd660b035b926438244b4294e647507e13 upstream.
    
    Send SEV_CMD_DECOMMISSION command to PSP firmware if ASID binding
    fails. If a failure happens after  a successful LAUNCH_START command,
    a decommission command should be executed. Otherwise, guest context
    will be unfreed inside the AMD SP. After the firmware will not have
    memory to allocate more SEV guest context, LAUNCH_START command will
    begin to fail with SEV_RET_RESOURCE_LIMIT error.
    
    The existing code calls decommission inside sev_unbind_asid, but it is
    not called if a failure happens before guest activation succeeds. If
    sev_bind_asid fails, decommission is never called. PSP firmware has a
    limit for the number of guests. If sev_asid_binding fails many times,
    PSP firmware will not have resources to create another guest context.
    
    Cc: stable@vger.kernel.org
    Fixes: 59414c989220 ("KVM: SVM: Add support for KVM_SEV_LAUNCH_START command")
    Reported-by: Peter Gonda <pgonda@google.com>
    Signed-off-by: Alper Gun <alpergun@google.com>
    Reviewed-by: Marc Orr <marcorr@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Message-Id: <20210610174604.2554090-1-alpergun@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 11b5f1bdadb6ed6ba8694a94805af248c9170dae
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:52 2021 -0700

    mm, futex: fix shared futex pgoff on shmem huge page
    
    commit fe19bd3dae3d15d2fbfdb3de8839a6ea0fe94264 upstream.
    
    If more than one futex is placed on a shmem huge page, it can happen
    that waking the second wakes the first instead, and leaves the second
    waiting: the key's shared.pgoff is wrong.
    
    When 3.11 commit 13d60f4b6ab5 ("futex: Take hugepages into account when
    generating futex_key"), the only shared huge pages came from hugetlbfs,
    and the code added to deal with its exceptional page->index was put into
    hugetlb source.  Then that was missed when 4.8 added shmem huge pages.
    
    page_to_pgoff() is what others use for this nowadays: except that, as
    currently written, it gives the right answer on hugetlbfs head, but
    nonsense on hugetlbfs tails.  Fix that by calling hugetlbfs-specific
    hugetlb_basepage_index() on PageHuge tails as well as on head.
    
    Yes, it's unconventional to declare hugetlb_basepage_index() there in
    pagemap.h, rather than in hugetlb.h; but I do not expect anything but
    page_to_pgoff() ever to need it.
    
    [akpm@linux-foundation.org: give hugetlb_basepage_index() prototype the correct scope]
    
    Link: https://lkml.kernel.org/r/b17d946b-d09-326e-b42a-52884c36df32@google.com
    Fixes: 800d8c63b2e9 ("shmem: add huge pages support")
    Reported-by: Neel Natu <neelnatu@google.com>
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Zhang Yi <wetpzy@gmail.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Mike Kravetz <mike.kravetz@oracle.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Darren Hart <dvhart@infradead.org>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a8f60caa646b4d9c75f9cb23a1d619c43938b8d4
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:30 2021 -0700

    mm/thp: another PVMW_SYNC fix in page_vma_mapped_walk()
    
    commit a7a69d8ba88d8dcee7ef00e91d413a4bd003a814 upstream.
    
    Aha! Shouldn't that quick scan over pte_none()s make sure that it holds
    ptlock in the PVMW_SYNC case? That too might have been responsible for
    BUGs or WARNs in split_huge_page_to_list() or its unmap_page(), though
    I've never seen any.
    
    Link: https://lkml.kernel.org/r/1bdf384c-8137-a149-2a1e-475a4791c3c@google.com
    Link: https://lore.kernel.org/linux-mm/20210412180659.B9E3.409509F4@e16-tech.com/
    Fixes: ace71a19cec5 ("mm: introduce page_vma_mapped_walk()")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Tested-by: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8ab4361cb4fd37799302d9e00cddc510b2d3de4e
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:26 2021 -0700

    mm/thp: fix page_vma_mapped_walk() if THP mapped by ptes
    
    commit a9a7504d9beaf395481faa91e70e2fd08f7a3dde upstream.
    
    Running certain tests with a DEBUG_VM kernel would crash within hours,
    on the total_mapcount BUG() in split_huge_page_to_list(), while trying
    to free up some memory by punching a hole in a shmem huge page: split's
    try_to_unmap() was unable to find all the mappings of the page (which,
    on a !DEBUG_VM kernel, would then keep the huge page pinned in memory).
    
    Crash dumps showed two tail pages of a shmem huge page remained mapped
    by pte: ptes in a non-huge-aligned vma of a gVisor process, at the end
    of a long unmapped range; and no page table had yet been allocated for
    the head of the huge page to be mapped into.
    
    Although designed to handle these odd misaligned huge-page-mapped-by-pte
    cases, page_vma_mapped_walk() falls short by returning false prematurely
    when !pmd_present or !pud_present or !p4d_present or !pgd_present: there
    are cases when a huge page may span the boundary, with ptes present in
    the next.
    
    Restructure page_vma_mapped_walk() as a loop to continue in these cases,
    while keeping its layout much as before.  Add a step_forward() helper to
    advance pvmw->address across those boundaries: originally I tried to use
    mm's standard p?d_addr_end() macros, but hit the same crash 512 times
    less often: because of the way redundant levels are folded together, but
    folded differently in different configurations, it was just too
    difficult to use them correctly; and step_forward() is simpler anyway.
    
    Link: https://lkml.kernel.org/r/fedb8632-1798-de42-f39e-873551d5bc81@google.com
    Fixes: ace71a19cec5 ("mm: introduce page_vma_mapped_walk()")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6701cbcf02b5d9e7779e3e7864dba7a27b034a4c
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:23 2021 -0700

    mm: page_vma_mapped_walk(): get vma_address_end() earlier
    
    commit a765c417d876cc635f628365ec9aa6f09470069a upstream.
    
    page_vma_mapped_walk() cleanup: get THP's vma_address_end() at the
    start, rather than later at next_pte.
    
    It's a little unnecessary overhead on the first call, but makes for a
    simpler loop in the following commit.
    
    Link: https://lkml.kernel.org/r/4542b34d-862f-7cb4-bb22-e0df6ce830a2@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec7c3f2831225a223d7c802b7174d81aa87807c0
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:20 2021 -0700

    mm: page_vma_mapped_walk(): use goto instead of while (1)
    
    commit 474466301dfd8b39a10c01db740645f3f7ae9a28 upstream.
    
    page_vma_mapped_walk() cleanup: add a label this_pte, matching next_pte,
    and use "goto this_pte", in place of the "while (1)" loop at the end.
    
    Link: https://lkml.kernel.org/r/a52b234a-851-3616-2525-f42736e8934@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c1a4f969895f6658124259b3f1bed0edf68567c
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:17 2021 -0700

    mm: page_vma_mapped_walk(): add a level of indentation
    
    commit b3807a91aca7d21c05d5790612e49969117a72b9 upstream.
    
    page_vma_mapped_walk() cleanup: add a level of indentation to much of
    the body, making no functional change in this commit, but reducing the
    later diff when this is all converted to a loop.
    
    [hughd@google.com: : page_vma_mapped_walk(): add a level of indentation fix]
      Link: https://lkml.kernel.org/r/7f817555-3ce1-c785-e438-87d8efdcaf26@google.com
    
    Link: https://lkml.kernel.org/r/efde211-f3e2-fe54-977-ef481419e7f3@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 063ef7dd44eaf1b71f049ef063dd3a50b72ea624
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:14 2021 -0700

    mm: page_vma_mapped_walk(): crossing page table boundary
    
    commit 448282487483d6fa5b2eeeafaa0acc681e544a9c upstream.
    
    page_vma_mapped_walk() cleanup: adjust the test for crossing page table
    boundary - I believe pvmw->address is always page-aligned, but nothing
    else here assumed that; and remember to reset pvmw->pte to NULL after
    unmapping the page table, though I never saw any bug from that.
    
    Link: https://lkml.kernel.org/r/799b3f9c-2a9e-dfef-5d89-26e9f76fd97@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bcd41f6b0f1a91659a374b403e6063ae33181fb6
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:10 2021 -0700

    mm: page_vma_mapped_walk(): prettify PVMW_MIGRATION block
    
    commit e2e1d4076c77b3671cf8ce702535ae7dee3acf89 upstream.
    
    page_vma_mapped_walk() cleanup: rearrange the !pmd_present() block to
    follow the same "return not_found, return not_found, return true"
    pattern as the block above it (note: returning not_found there is never
    premature, since existence or prior existence of huge pmd guarantees
    good alignment).
    
    Link: https://lkml.kernel.org/r/378c8650-1488-2edf-9647-32a53cf2e21@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0d212ac10de58feda3e4d1695e9c01c2651c46f5
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:07 2021 -0700

    mm: page_vma_mapped_walk(): use pmde for *pvmw->pmd
    
    commit 3306d3119ceacc43ea8b141a73e21fea68eec30c upstream.
    
    page_vma_mapped_walk() cleanup: re-evaluate pmde after taking lock, then
    use it in subsequent tests, instead of repeatedly dereferencing pointer.
    
    Link: https://lkml.kernel.org/r/53fbc9d-891e-46b2-cb4b-468c3b19238e@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dc7010b49a9955c7384d8301bd9fcb095c61130d
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:04 2021 -0700

    mm: page_vma_mapped_walk(): settle PageHuge on entry
    
    commit 6d0fd5987657cb0c9756ce684e3a74c0f6351728 upstream.
    
    page_vma_mapped_walk() cleanup: get the hugetlbfs PageHuge case out of
    the way at the start, so no need to worry about it later.
    
    Link: https://lkml.kernel.org/r/e31a483c-6d73-a6bb-26c5-43c3b880a2@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2d8d4f42ec200daefab64f531822c2b91990d0f7
Author: Hugh Dickins <hughd@google.com>
Date:   Thu Jun 24 18:39:01 2021 -0700

    mm: page_vma_mapped_walk(): use page for pvmw->page
    
    commit f003c03bd29e6f46fef1b9a8e8d636ac732286d5 upstream.
    
    Patch series "mm: page_vma_mapped_walk() cleanup and THP fixes".
    
    I've marked all of these for stable: many are merely cleanups, but I
    think they are much better before the main fix than after.
    
    This patch (of 11):
    
    page_vma_mapped_walk() cleanup: sometimes the local copy of pvwm->page
    was used, sometimes pvmw->page itself: use the local copy "page"
    throughout.
    
    Link: https://lkml.kernel.org/r/589b358c-febc-c88e-d4c2-7834b37fa7bf@google.com
    Link: https://lkml.kernel.org/r/88e67645-f467-c279-bf5e-af4b5c6b13eb@google.com
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: Alistair Popple <apopple@nvidia.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Peter Xu <peterx@redhat.com>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: Will Deacon <will@kernel.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2ceb1f903fa0bbb7bd3c81f4733232e27a28d621
Author: Yang Shi <shy828301@gmail.com>
Date:   Tue Jun 15 18:24:07 2021 -0700

    mm: thp: replace DEBUG_VM BUG with VM_WARN when unmap fails for split
    
    commit 504e070dc08f757bccaed6d05c0f53ecbfac8a23 upstream.
    
    When debugging the bug reported by Wang Yugui [1], try_to_unmap() may
    fail, but the first VM_BUG_ON_PAGE() just checks page_mapcount() however
    it may miss the failure when head page is unmapped but other subpage is
    mapped.  Then the second DEBUG_VM BUG() that check total mapcount would
    catch it.  This may incur some confusion.
    
    As this is not a fatal issue, so consolidate the two DEBUG_VM checks
    into one VM_WARN_ON_ONCE_PAGE().
    
    [1] https://lore.kernel.org/linux-mm/20210412180659.B9E3.409509F4@e16-tech.com/
    
    Link: https://lkml.kernel.org/r/d0f0db68-98b8-ebfb-16dc-f29df24cf012@google.com
    Signed-off-by: Yang Shi <shy828301@gmail.com>
    Reviewed-by: Zi Yan <ziy@nvidia.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jue Wang <juew@google.com>
    Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d1367516c1d6e632e9dcb99818b54d9dab8117dc
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jun 15 18:24:03 2021 -0700

    mm/thp: unmap_mapping_page() to fix THP truncate_cleanup_page()
    
    commit 22061a1ffabdb9c3385de159c5db7aac3a4df1cc upstream.
    
    There is a race between THP unmapping and truncation, when truncate sees
    pmd_none() and skips the entry, after munmap's zap_huge_pmd() cleared
    it, but before its page_remove_rmap() gets to decrement
    compound_mapcount: generating false "BUG: Bad page cache" reports that
    the page is still mapped when deleted.  This commit fixes that, but not
    in the way I hoped.
    
    The first attempt used try_to_unmap(page, TTU_SYNC|TTU_IGNORE_MLOCK)
    instead of unmap_mapping_range() in truncate_cleanup_page(): it has
    often been an annoyance that we usually call unmap_mapping_range() with
    no pages locked, but there apply it to a single locked page.
    try_to_unmap() looks more suitable for a single locked page.
    
    However, try_to_unmap_one() contains a VM_BUG_ON_PAGE(!pvmw.pte,page):
    it is used to insert THP migration entries, but not used to unmap THPs.
    Copy zap_huge_pmd() and add THP handling now? Perhaps, but their TLB
    needs are different, I'm too ignorant of the DAX cases, and couldn't
    decide how far to go for anon+swap.  Set that aside.
    
    The second attempt took a different tack: make no change in truncate.c,
    but modify zap_huge_pmd() to insert an invalidated huge pmd instead of
    clearing it initially, then pmd_clear() between page_remove_rmap() and
    unlocking at the end.  Nice.  But powerpc blows that approach out of the
    water, with its serialize_against_pte_lookup(), and interesting pgtable
    usage.  It would need serious help to get working on powerpc (with a
    minor optimization issue on s390 too).  Set that aside.
    
    Just add an "if (page_mapped(page)) synchronize_rcu();" or other such
    delay, after unmapping in truncate_cleanup_page()? Perhaps, but though
    that's likely to reduce or eliminate the number of incidents, it would
    give less assurance of whether we had identified the problem correctly.
    
    This successful iteration introduces "unmap_mapping_page(page)" instead
    of try_to_unmap(), and goes the usual unmap_mapping_range_tree() route,
    with an addition to details.  Then zap_pmd_range() watches for this
    case, and does spin_unlock(pmd_lock) if so - just like
    page_vma_mapped_walk() now does in the PVMW_SYNC case.  Not pretty, but
    safe.
    
    Note that unmap_mapping_page() is doing a VM_BUG_ON(!PageLocked) to
    assert its interface; but currently that's only used to make sure that
    page->mapping is stable, and zap_pmd_range() doesn't care if the page is
    locked or not.  Along these lines, in invalidate_inode_pages2_range()
    move the initial unmap_mapping_range() out from under page lock, before
    then calling unmap_mapping_page() under page lock if still mapped.
    
    Link: https://lkml.kernel.org/r/a2a4a148-cdd8-942c-4ef8-51b77f643dbe@google.com
    Fixes: fc127da085c2 ("truncate: handle file thp")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Yang Shi <shy828301@gmail.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jue Wang <juew@google.com>
    Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9dbb5ac4291f3c70c9169addc11eb25b6529c97b
Author: Jue Wang <juew@google.com>
Date:   Tue Jun 15 18:24:00 2021 -0700

    mm/thp: fix page_address_in_vma() on file THP tails
    
    commit 31657170deaf1d8d2f6a1955fbc6fa9d228be036 upstream.
    
    Anon THP tails were already supported, but memory-failure may need to
    use page_address_in_vma() on file THP tails, which its page->mapping
    check did not permit: fix it.
    
    hughd adds: no current usage is known to hit the issue, but this does
    fix a subtle trap in a general helper: best fixed in stable sooner than
    later.
    
    Link: https://lkml.kernel.org/r/a0d9b53-bf5d-8bab-ac5-759dc61819c1@google.com
    Fixes: 800d8c63b2e9 ("shmem: add huge pages support")
    Signed-off-by: Jue Wang <juew@google.com>
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Reviewed-by: Yang Shi <shy828301@gmail.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b2a4c9a9d2da3be1dacaebb0b50a61aaa11361c8
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jun 15 18:23:56 2021 -0700

    mm/thp: fix vma_address() if virtual address below file offset
    
    commit 494334e43c16d63b878536a26505397fce6ff3a2 upstream.
    
    Running certain tests with a DEBUG_VM kernel would crash within hours,
    on the total_mapcount BUG() in split_huge_page_to_list(), while trying
    to free up some memory by punching a hole in a shmem huge page: split's
    try_to_unmap() was unable to find all the mappings of the page (which,
    on a !DEBUG_VM kernel, would then keep the huge page pinned in memory).
    
    When that BUG() was changed to a WARN(), it would later crash on the
    VM_BUG_ON_VMA(end < vma->vm_start || start >= vma->vm_end, vma) in
    mm/internal.h:vma_address(), used by rmap_walk_file() for
    try_to_unmap().
    
    vma_address() is usually correct, but there's a wraparound case when the
    vm_start address is unusually low, but vm_pgoff not so low:
    vma_address() chooses max(start, vma->vm_start), but that decides on the
    wrong address, because start has become almost ULONG_MAX.
    
    Rewrite vma_address() to be more careful about vm_pgoff; move the
    VM_BUG_ON_VMA() out of it, returning -EFAULT for errors, so that it can
    be safely used from page_mapped_in_vma() and page_address_in_vma() too.
    
    Add vma_address_end() to apply similar care to end address calculation,
    in page_vma_mapped_walk() and page_mkclean_one() and try_to_unmap_one();
    though it raises a question of whether callers would do better to supply
    pvmw->end to page_vma_mapped_walk() - I chose not, for a smaller patch.
    
    An irritation is that their apparent generality breaks down on KSM
    pages, which cannot be located by the page->index that page_to_pgoff()
    uses: as commit 4b0ece6fa016 ("mm: migrate: fix remove_migration_pte()
    for ksm pages") once discovered.  I dithered over the best thing to do
    about that, and have ended up with a VM_BUG_ON_PAGE(PageKsm) in both
    vma_address() and vma_address_end(); though the only place in danger of
    using it on them was try_to_unmap_one().
    
    Sidenote: vma_address() and vma_address_end() now use compound_nr() on a
    head page, instead of thp_size(): to make the right calculation on a
    hugetlbfs page, whether or not THPs are configured.  try_to_unmap() is
    used on hugetlbfs pages, but perhaps the wrong calculation never
    mattered.
    
    Link: https://lkml.kernel.org/r/caf1c1a3-7cfb-7f8f-1beb-ba816e932825@google.com
    Fixes: a8fa41ad2f6f ("mm, rmap: check all VMAs that PTE-mapped THP can be part of")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jue Wang <juew@google.com>
    Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 926b3364f87b12bac5742f090f1150d3ead5d353
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jun 15 18:23:53 2021 -0700

    mm/thp: try_to_unmap() use TTU_SYNC for safe splitting
    
    commit 732ed55823fc3ad998d43b86bf771887bcc5ec67 upstream.
    
    Stressing huge tmpfs often crashed on unmap_page()'s VM_BUG_ON_PAGE
    (!unmap_success): with dump_page() showing mapcount:1, but then its raw
    struct page output showing _mapcount ffffffff i.e.  mapcount 0.
    
    And even if that particular VM_BUG_ON_PAGE(!unmap_success) is removed,
    it is immediately followed by a VM_BUG_ON_PAGE(compound_mapcount(head)),
    and further down an IS_ENABLED(CONFIG_DEBUG_VM) total_mapcount BUG():
    all indicative of some mapcount difficulty in development here perhaps.
    But the !CONFIG_DEBUG_VM path handles the failures correctly and
    silently.
    
    I believe the problem is that once a racing unmap has cleared pte or
    pmd, try_to_unmap_one() may skip taking the page table lock, and emerge
    from try_to_unmap() before the racing task has reached decrementing
    mapcount.
    
    Instead of abandoning the unsafe VM_BUG_ON_PAGE(), and the ones that
    follow, use PVMW_SYNC in try_to_unmap_one() in this case: adding
    TTU_SYNC to the options, and passing that from unmap_page().
    
    When CONFIG_DEBUG_VM, or for non-debug too? Consensus is to do the same
    for both: the slight overhead added should rarely matter, except perhaps
    if splitting sparsely-populated multiply-mapped shmem.  Once confident
    that bugs are fixed, TTU_SYNC here can be removed, and the race
    tolerated.
    
    Link: https://lkml.kernel.org/r/c1e95853-8bcd-d8fd-55fa-e7f2488e78f@google.com
    Fixes: fec89c109f3a ("thp: rewrite freeze_page()/unfreeze_page() with generic rmap walkers")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jue Wang <juew@google.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b1daf8f862136894a4595770a44e4508808fb806
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jun 15 18:23:49 2021 -0700

    mm/thp: make is_huge_zero_pmd() safe and quicker
    
    commit 3b77e8c8cde581dadab9a0f1543a347e24315f11 upstream.
    
    Most callers of is_huge_zero_pmd() supply a pmd already verified
    present; but a few (notably zap_huge_pmd()) do not - it might be a pmd
    migration entry, in which the pfn is encoded differently from a present
    pmd: which might pass the is_huge_zero_pmd() test (though not on x86,
    since L1TF forced us to protect against that); or perhaps even crash in
    pmd_page() applied to a swap-like entry.
    
    Make it safe by adding pmd_present() check into is_huge_zero_pmd()
    itself; and make it quicker by saving huge_zero_pfn, so that
    is_huge_zero_pmd() will not need to do that pmd_page() lookup each time.
    
    __split_huge_pmd_locked() checked pmd_trans_huge() before: that worked,
    but is unnecessary now that is_huge_zero_pmd() checks present.
    
    Link: https://lkml.kernel.org/r/21ea9ca-a1f5-8b90-5e88-95fb1c49bbfa@google.com
    Fixes: e71769ae5260 ("mm: enable thp migration for shmem thp")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Reviewed-by: Yang Shi <shy828301@gmail.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jue Wang <juew@google.com>
    Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9e2230731476114c4152027788f303d0ec743af
Author: Hugh Dickins <hughd@google.com>
Date:   Tue Jun 15 18:23:45 2021 -0700

    mm/thp: fix __split_huge_pmd_locked() on shmem migration entry
    
    commit 99fa8a48203d62b3743d866fc48ef6abaee682be upstream.
    
    Patch series "mm/thp: fix THP splitting unmap BUGs and related", v10.
    
    Here is v2 batch of long-standing THP bug fixes that I had not got
    around to sending before, but prompted now by Wang Yugui's report
    https://lore.kernel.org/linux-mm/20210412180659.B9E3.409509F4@e16-tech.com/
    
    Wang Yugui has tested a rollup of these fixes applied to 5.10.39, and
    they have done no harm, but have *not* fixed that issue: something more
    is needed and I have no idea of what.
    
    This patch (of 7):
    
    Stressing huge tmpfs page migration racing hole punch often crashed on
    the VM_BUG_ON(!pmd_present) in pmdp_huge_clear_flush(), with DEBUG_VM=y
    kernel; or shortly afterwards, on a bad dereference in
    __split_huge_pmd_locked() when DEBUG_VM=n.  They forgot to allow for pmd
    migration entries in the non-anonymous case.
    
    Full disclosure: those particular experiments were on a kernel with more
    relaxed mmap_lock and i_mmap_rwsem locking, and were not repeated on the
    vanilla kernel: it is conceivable that stricter locking happens to avoid
    those cases, or makes them less likely; but __split_huge_pmd_locked()
    already allowed for pmd migration entries when handling anonymous THPs,
    so this commit brings the shmem and file THP handling into line.
    
    And while there: use old_pmd rather than _pmd, as in the following
    blocks; and make it clearer to the eye that the !vma_is_anonymous()
    block is self-contained, making an early return after accounting for
    unmapping.
    
    Link: https://lkml.kernel.org/r/af88612-1473-2eaa-903-8d1a448b26@google.com
    Link: https://lkml.kernel.org/r/dd221a99-efb3-cd1d-6256-7e646af29314@google.com
    Fixes: e71769ae5260 ("mm: enable thp migration for shmem thp")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Yang Shi <shy828301@gmail.com>
    Cc: Wang Yugui <wangyugui@e16-tech.com>
    Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
    Cc: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Cc: Alistair Popple <apopple@nvidia.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: Zi Yan <ziy@nvidia.com>
    Cc: Miaohe Lin <linmiaohe@huawei.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Jue Wang <juew@google.com>
    Cc: Peter Xu <peterx@redhat.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Shakeel Butt <shakeelb@google.com>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 46adfc2870949c6f8cf6141f78499f0c08fc611a
Author: Xu Yu <xuyu@linux.alibaba.com>
Date:   Tue Jun 15 18:23:42 2021 -0700

    mm, thp: use head page in __migration_entry_wait()
    
    commit ffc90cbb2970ab88b66ea51dd580469eede57b67 upstream.
    
    We notice that hung task happens in a corner but practical scenario when
    CONFIG_PREEMPT_NONE is enabled, as follows.
    
    Process 0                       Process 1                     Process 2..Inf
    split_huge_page_to_list
        unmap_page
            split_huge_pmd_address
                                    __migration_entry_wait(head)
                                                                  __migration_entry_wait(tail)
        remap_page (roll back)
            remove_migration_ptes
                rmap_walk_anon
                    cond_resched
    
    Where __migration_entry_wait(tail) is occurred in kernel space, e.g.,
    copy_to_user in fstat, which will immediately fault again without
    rescheduling, and thus occupy the cpu fully.
    
    When there are too many processes performing __migration_entry_wait on
    tail page, remap_page will never be done after cond_resched.
    
    This makes __migration_entry_wait operate on the compound head page,
    thus waits for remap_page to complete, whether the THP is split
    successfully or roll back.
    
    Note that put_and_wait_on_page_locked helps to drop the page reference
    acquired with get_page_unless_zero, as soon as the page is on the wait
    queue, before actually waiting.  So splitting the THP is only prevented
    for a brief interval.
    
    Link: https://lkml.kernel.org/r/b9836c1dd522e903891760af9f0c86a2cce987eb.1623144009.git.xuyu@linux.alibaba.com
    Fixes: ba98828088ad ("thp: add option to setup migration entries during PMD split")
    Suggested-by: Hugh Dickins <hughd@google.com>
    Signed-off-by: Gang Deng <gavin.dg@linux.alibaba.com>
    Signed-off-by: Xu Yu <xuyu@linux.alibaba.com>
    Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Acked-by: Hugh Dickins <hughd@google.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7867cc42fc9d64e9d0041579c0b859f208ea7b35
Author: Tony Luck <tony.luck@intel.com>
Date:   Thu Jun 24 18:39:55 2021 -0700

    mm/memory-failure: use a mutex to avoid memory_failure() races
    
    commit 171936ddaf97e6f4e1264f4128bb5cf15691339c upstream.
    
    Patch series "mm,hwpoison: fix sending SIGBUS for Action Required MCE", v5.
    
    I wrote this patchset to materialize what I think is the current
    allowable solution mentioned by the previous discussion [1].  I simply
    borrowed Tony's mutex patch and Aili's return code patch, then I queued
    another one to find error virtual address in the best effort manner.  I
    know that this is not a perfect solution, but should work for some
    typical case.
    
    [1]: https://lore.kernel.org/linux-mm/20210331192540.2141052f@alex-virtual-machine/
    
    This patch (of 2):
    
    There can be races when multiple CPUs consume poison from the same page.
    The first into memory_failure() atomically sets the HWPoison page flag
    and begins hunting for tasks that map this page.  Eventually it
    invalidates those mappings and may send a SIGBUS to the affected tasks.
    
    But while all that work is going on, other CPUs see a "success" return
    code from memory_failure() and so they believe the error has been
    handled and continue executing.
    
    Fix by wrapping most of the internal parts of memory_failure() in a
    mutex.
    
    [akpm@linux-foundation.org: make mf_mutex local to memory_failure()]
    
    Link: https://lkml.kernel.org/r/20210521030156.2612074-1-nao.horiguchi@gmail.com
    Link: https://lkml.kernel.org/r/20210521030156.2612074-2-nao.horiguchi@gmail.com
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Signed-off-by: Naoya Horiguchi <naoya.horiguchi@nec.com>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Oscar Salvador <osalvador@suse.de>
    Cc: Aili Yao <yaoaili@kingsoft.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: David Hildenbrand <david@redhat.com>
    Cc: Jue Wang <juew@google.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e40e787d89b360cf7ff7810cf699bf88896f057
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 18 16:18:25 2021 +0200

    x86/fpu: Make init_fpstate correct with optimized XSAVE
    
    commit f9dfb5e390fab2df9f7944bb91e7705aba14cd26 upstream.
    
    The XSAVE init code initializes all enabled and supported components with
    XRSTOR(S) to init state. Then it XSAVEs the state of the components back
    into init_fpstate which is used in several places to fill in the init state
    of components.
    
    This works correctly with XSAVE, but not with XSAVEOPT and XSAVES because
    those use the init optimization and skip writing state of components which
    are in init state. So init_fpstate.xsave still contains all zeroes after
    this operation.
    
    There are two ways to solve that:
    
       1) Use XSAVE unconditionally, but that requires to reshuffle the buffer when
          XSAVES is enabled because XSAVES uses compacted format.
    
       2) Save the components which are known to have a non-zero init state by other
          means.
    
    Looking deeper, #2 is the right thing to do because all components the
    kernel supports have all-zeroes init state except the legacy features (FP,
    SSE). Those cannot be hard coded because the states are not identical on all
    CPUs, but they can be saved with FXSAVE which avoids all conditionals.
    
    Use FXSAVE to save the legacy FP/SSE components in init_fpstate along with
    a BUILD_BUG_ON() which reminds developers to validate that a newly added
    component has all zeroes init state. As a bonus remove the now unused
    copy_xregs_to_kernel_booting() crutch.
    
    The XSAVE and reshuffle method can still be implemented in the unlikely
    case that components are added which have a non-zero init state and no
    other means to save them. For now, FXSAVE is just simple and good enough.
    
      [ bp: Fix a typo or two in the text. ]
    
    Fixes: 6bad06b76892 ("x86, xsave: Use xsaveopt in context-switch path when supported")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20210618143444.587311343@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit be2b52c651ed85ce40d2263d1b27c124021e03b8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 18 16:18:24 2021 +0200

    x86/fpu: Preserve supervisor states in sanitize_restored_user_xstate()
    
    commit 9301982c424a003c0095bf157154a85bf5322bd0 upstream.
    
    sanitize_restored_user_xstate() preserves the supervisor states only
    when the fx_only argument is zero, which allows unprivileged user space
    to put supervisor states back into init state.
    
    Preserve them unconditionally.
    
     [ bp: Fix a typo or two in the text. ]
    
    Fixes: 5d6b6a6f9b5c ("x86/fpu/xstate: Update sanitize_restored_xstate() for supervisor xstates")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20210618143444.438635017@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit eb674f16f19498b21d43a1283c3fe424d0b65f2c
Author: Petr Mladek <pmladek@suse.com>
Date:   Thu Jun 24 18:39:48 2021 -0700

    kthread: prevent deadlock when kthread_mod_delayed_work() races with kthread_cancel_delayed_work_sync()
    
    commit 5fa54346caf67b4b1b10b1f390316ae466da4d53 upstream.
    
    The system might hang with the following backtrace:
    
            schedule+0x80/0x100
            schedule_timeout+0x48/0x138
            wait_for_common+0xa4/0x134
            wait_for_completion+0x1c/0x2c
            kthread_flush_work+0x114/0x1cc
            kthread_cancel_work_sync.llvm.16514401384283632983+0xe8/0x144
            kthread_cancel_delayed_work_sync+0x18/0x2c
            xxxx_pm_notify+0xb0/0xd8
            blocking_notifier_call_chain_robust+0x80/0x194
            pm_notifier_call_chain_robust+0x28/0x4c
            suspend_prepare+0x40/0x260
            enter_state+0x80/0x3f4
            pm_suspend+0x60/0xdc
            state_store+0x108/0x144
            kobj_attr_store+0x38/0x88
            sysfs_kf_write+0x64/0xc0
            kernfs_fop_write_iter+0x108/0x1d0
            vfs_write+0x2f4/0x368
            ksys_write+0x7c/0xec
    
    It is caused by the following race between kthread_mod_delayed_work()
    and kthread_cancel_delayed_work_sync():
    
    CPU0                            CPU1
    
    Context: Thread A               Context: Thread B
    
    kthread_mod_delayed_work()
      spin_lock()
      __kthread_cancel_work()
         spin_unlock()
         del_timer_sync()
                                    kthread_cancel_delayed_work_sync()
                                      spin_lock()
                                      __kthread_cancel_work()
                                        spin_unlock()
                                        del_timer_sync()
                                        spin_lock()
    
                                      work->canceling++
                                      spin_unlock
         spin_lock()
       queue_delayed_work()
         // dwork is put into the worker->delayed_work_list
    
       spin_unlock()
    
                                      kthread_flush_work()
         // flush_work is put at the tail of the dwork
    
                                        wait_for_completion()
    
    Context: IRQ
    
      kthread_delayed_work_timer_fn()
        spin_lock()
        list_del_init(&work->node);
        spin_unlock()
    
    BANG: flush_work is not longer linked and will never get proceed.
    
    The problem is that kthread_mod_delayed_work() checks work->canceling
    flag before canceling the timer.
    
    A simple solution is to (re)check work->canceling after
    __kthread_cancel_work().  But then it is not clear what should be
    returned when __kthread_cancel_work() removed the work from the queue
    (list) and it can't queue it again with the new @delay.
    
    The return value might be used for reference counting.  The caller has
    to know whether a new work has been queued or an existing one was
    replaced.
    
    The proper solution is that kthread_mod_delayed_work() will remove the
    work from the queue (list) _only_ when work->canceling is not set.  The
    flag must be checked after the timer is stopped and the remaining
    operations can be done under worker->lock.
    
    Note that kthread_mod_delayed_work() could remove the timer and then
    bail out.  It is fine.  The other canceling caller needs to cancel the
    timer as well.  The important thing is that the queue (list)
    manipulation is done atomically under worker->lock.
    
    Link: https://lkml.kernel.org/r/20210610133051.15337-3-pmladek@suse.com
    Fixes: 9a6b06c8d9a220860468a ("kthread: allow to modify delayed kthread work")
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Reported-by: Martin Liu <liumartin@google.com>
    Cc: <jenhaochen@google.com>
    Cc: Minchan Kim <minchan@google.com>
    Cc: Nathan Chancellor <nathan@kernel.org>
    Cc: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 998f7b27e9c31caff4a7452006f4ffe230a30931
Author: Petr Mladek <pmladek@suse.com>
Date:   Thu Jun 24 18:39:45 2021 -0700

    kthread_worker: split code for canceling the delayed work timer
    
    commit 34b3d5344719d14fd2185b2d9459b3abcb8cf9d8 upstream.
    
    Patch series "kthread_worker: Fix race between kthread_mod_delayed_work()
    and kthread_cancel_delayed_work_sync()".
    
    This patchset fixes the race between kthread_mod_delayed_work() and
    kthread_cancel_delayed_work_sync() including proper return value
    handling.
    
    This patch (of 2):
    
    Simple code refactoring as a preparation step for fixing a race between
    kthread_mod_delayed_work() and kthread_cancel_delayed_work_sync().
    
    It does not modify the existing behavior.
    
    Link: https://lkml.kernel.org/r/20210610133051.15337-2-pmladek@suse.com
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Cc: <jenhaochen@google.com>
    Cc: Martin Liu <liumartin@google.com>
    Cc: Minchan Kim <minchan@google.com>
    Cc: Nathan Chancellor <nathan@kernel.org>
    Cc: Nick Desaulniers <ndesaulniers@google.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9d294f749c41ca0608a92e6d33f92b951456824
Author: Juergen Gross <jgross@suse.com>
Date:   Wed Jun 23 15:09:13 2021 +0200

    xen/events: reset active flag for lateeoi events later
    
    commit 3de218ff39b9e3f0d453fe3154f12a174de44b25 upstream.
    
    In order to avoid a race condition for user events when changing
    cpu affinity reset the active flag only when EOI-ing the event.
    
    This is working fine as all user events are lateeoi events. Note that
    lateeoi_ack_mask_dynirq() is not modified as there is no explicit call
    to xen_irq_lateeoi() expected later.
    
    Cc: stable@vger.kernel.org
    Reported-by: Julien Grall <julien@xen.org>
    Fixes: b6622798bc50b62 ("xen/events: avoid handling the same event on two cpus at the same time")
    Tested-by: Julien Grall <julien@xen.org>
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrvsky@oracle.com>
    Link: https://lore.kernel.org/r/20210623130913.9405-1-jgross@suse.com
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f810a6ac02bc3cebec5a800f6adfb8fcdabb3af3
Author: Jeff Layton <jlayton@kernel.org>
Date:   Tue Jun 1 09:40:25 2021 -0400

    ceph: must hold snap_rwsem when filling inode for async create
    
    commit 27171ae6a0fdc75571e5bf3d0961631a1e4fb765 upstream.
    
    ...and add a lockdep assertion for it to ceph_fill_inode().
    
    Cc: stable@vger.kernel.org # v5.7+
    Fixes: 9a8d03ca2e2c3 ("ceph: attempt to do async create when possible")
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Reviewed-by: Ilya Dryomov <idryomov@gmail.com>
    Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cdc9ae6b3bd46e71cd07a8a97f21ebd0207d36c2
Author: Johan Hovold <johan@kernel.org>
Date:   Mon May 24 11:09:12 2021 +0200

    i2c: robotfuzz-osif: fix control-request directions
    
    commit 4ca070ef0dd885616ef294d269a9bf8e3b258e1a upstream.
    
    The direction of the pipe argument must match the request-type direction
    bit or control requests may fail depending on the host-controller-driver
    implementation.
    
    Control transfers without a data stage are treated as OUT requests by
    the USB stack and should be using usb_sndctrlpipe(). Failing to do so
    will now trigger a warning.
    
    Fix the OSIFI2C_SET_BIT_RATE and OSIFI2C_STOP requests which erroneously
    used the osif_usb_read() helper and set the IN direction bit.
    
    Reported-by: syzbot+9d7dadd15b8819d73f41@syzkaller.appspotmail.com
    Fixes: 83e53a8f120f ("i2c: Add bus driver for for OSIF USB i2c device.")
    Cc: stable@vger.kernel.org      # 3.14
    Signed-off-by: Johan Hovold <johan@kernel.org>
    Signed-off-by: Wolfram Sang <wsa@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c36fbd888dcc27d365c865e6c959d7f7802a207c
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Thu Jun 24 08:29:04 2021 -0400

    KVM: do not allow mapping valid but non-reference-counted pages
    
    commit f8be156be163a052a067306417cd0ff679068c97 upstream.
    
    It's possible to create a region which maps valid but non-refcounted
    pages (e.g., tail pages of non-compound higher order allocations). These
    host pages can then be returned by gfn_to_page, gfn_to_pfn, etc., family
    of APIs, which take a reference to the page, which takes it from 0 to 1.
    When the reference is dropped, this will free the page incorrectly.
    
    Fix this by only taking a reference on valid pages if it was non-zero,
    which indicates it is participating in normal refcounting (and can be
    released with put_page).
    
    This addresses CVE-2021-22543.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Tested-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cf9fdfe7ac67776416edce83bc02c5836e137919
Author: Sven Schnelle <svens@linux.ibm.com>
Date:   Fri Jun 11 16:08:18 2021 +0200

    s390: clear pt_regs::flags on irq entry
    
    commit ca1f4d702d534387aa1f16379edb3b03cdb6ceda upstream.
    
    The current irq entry code doesn't initialize pt_regs::flags. On exit to
    user mode arch_do_signal_or_restart() tests whether PIF_SYSCALL is set,
    which might yield wrong results.
    
    Fix this by clearing pt_regs::flags in the entry.S irq handler
    code.
    
    Reported-by: Heiko Carstens <hca@linux.ibm.com>
    Signed-off-by: Sven Schnelle <svens@linux.ibm.com>
    Reviewed-by: Heiko Carstens <hca@linux.ibm.com>
    Fixes: 56e62a737028 ("s390: convert to generic entry")
    Cc: <stable@vger.kernel.org> # 5.12
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c37ba4086c805c8309cd6a431a0c426de05bcf51
Author: Sven Schnelle <svens@linux.ibm.com>
Date:   Fri Jun 11 10:27:51 2021 +0200

    s390: fix system call restart with multiple signals
    
    commit fc66127dc3396338f287c3b494dfbf102547e770 upstream.
    
    glibc complained with "The futex facility returned an unexpected error
    code.". It turned out that the futex syscall returned -ERESTARTSYS because
    a signal is pending. arch_do_signal_or_restart() restored the syscall
    parameters (nameley regs->gprs[2]) and set PIF_SYSCALL_RESTART. When
    another signal is made pending later in the exit loop
    arch_do_signal_or_restart() is called again. This function clears
    PIF_SYSCALL_RESTART and checks the return code which is set in
    regs->gprs[2]. However, regs->gprs[2] was restored in the previous run
    and no longer contains -ERESTARTSYS, so PIF_SYSCALL_RESTART isn't set
    again and the syscall is skipped.
    
    Fix this by not clearing PIF_SYSCALL_RESTART - it is already cleared in
    __do_syscall() when the syscall is restarted.
    
    Reported-by: Bjoern Walk <bwalk@linux.ibm.com>
    Signed-off-by: Sven Schnelle <svens@linux.ibm.com>
    Reviewed-by: Heiko Carstens <hca@linux.ibm.com>
    Fixes: 56e62a737028 ("s390: convert to generic entry")
    Cc: <stable@vger.kernel.org> # 5.12
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 24b8aa8c90a86d95600549f2dbdd2fc7381e48d9
Author: Heiko Carstens <hca@linux.ibm.com>
Date:   Fri Jun 18 16:58:47 2021 +0200

    s390/stack: fix possible register corruption with stack switch helper
    
    commit 67147e96a332b56c7206238162771d82467f86c0 upstream.
    
    The CALL_ON_STACK macro is used to call a C function from inline
    assembly, and therefore must consider the C ABI, which says that only
    registers 6-13, and 15 are non-volatile (restored by the called
    function).
    
    The inline assembly incorrectly marks all registers used to pass
    parameters to the called function as read-only input operands, instead
    of operands that are read and written to. This might result in
    register corruption depending on usage, compiler, and compile options.
    
    Fix this by marking all operands used to pass parameters as read/write
    operands. To keep the code simple even register 6, if used, is marked
    as read-write operand.
    
    Fixes: ff340d2472ec ("s390: add stack switch helper")
    Cc: <stable@kernel.org> # 4.20
    Reviewed-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Heiko Carstens <hca@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 57378c52f158a7e6d82d5d6f960e608005deea84
Author: Sven Schnelle <svens@linux.ibm.com>
Date:   Tue Jun 15 15:05:22 2021 +0200

    s390/topology: clear thread/group maps for offline cpus
    
    commit 9e3d62d55bf455d4f9fdf2ede5c8756410c64102 upstream.
    
    The current code doesn't clear the thread/group maps for offline
    CPUs. This may cause kernel crashes like the one bewlow in common
    code that assumes if a CPU has sibblings it is online.
    
    Unable to handle kernel pointer dereference in virtual kernel address space
    
    Call Trace:
     [<000000013a4b8c3c>] blk_mq_map_swqueue+0x10c/0x388
    ([<000000013a4b8bcc>] blk_mq_map_swqueue+0x9c/0x388)
     [<000000013a4b9300>] blk_mq_init_allocated_queue+0x448/0x478
     [<000000013a4b9416>] blk_mq_init_queue+0x4e/0x90
     [<000003ff8019d3e6>] loop_add+0x106/0x278 [loop]
     [<000003ff801b8148>] loop_init+0x148/0x1000 [loop]
     [<0000000139de4924>] do_one_initcall+0x3c/0x1e0
     [<0000000139ef449a>] do_init_module+0x6a/0x2a0
     [<0000000139ef61bc>] __do_sys_finit_module+0xa4/0xc0
     [<0000000139de9e6e>] do_syscall+0x7e/0xd0
     [<000000013a8e0aec>] __do_syscall+0xbc/0x110
     [<000000013a8ee2e8>] system_call+0x78/0xa0
    
    Fixes: 52aeda7accb6 ("s390/topology: remove offline CPUs from CPU topology masks")
    Cc: <stable@kernel.org> # 5.7+
    Reported-by: Marius Hillenbrand <mhillen@linux.ibm.com>
    Signed-off-by: Sven Schnelle <svens@linux.ibm.com>
    Reviewed-by: Heiko Carstens <hca@linux.ibm.com>
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2eb327bf4de3d1713496f231ea7ede5e4df06458
Author: Pavel Skripkin <paskripkin@gmail.com>
Date:   Thu Jun 24 18:39:33 2021 -0700

    nilfs2: fix memory leak in nilfs_sysfs_delete_device_group
    
    [ Upstream commit 8fd0c1b0647a6bda4067ee0cd61e8395954b6f28 ]
    
    My local syzbot instance hit memory leak in nilfs2.  The problem was in
    missing kobject_put() in nilfs_sysfs_delete_device_group().
    
    kobject_del() does not call kobject_cleanup() for passed kobject and it
    leads to leaking duped kobject name if kobject_put() was not called.
    
    Fail log:
    
      BUG: memory leak
      unreferenced object 0xffff8880596171e0 (size 8):
      comm "syz-executor379", pid 8381, jiffies 4294980258 (age 21.100s)
      hex dump (first 8 bytes):
        6c 6f 6f 70 30 00 00 00                          loop0...
      backtrace:
         kstrdup+0x36/0x70 mm/util.c:60
         kstrdup_const+0x53/0x80 mm/util.c:83
         kvasprintf_const+0x108/0x190 lib/kasprintf.c:48
         kobject_set_name_vargs+0x56/0x150 lib/kobject.c:289
         kobject_add_varg lib/kobject.c:384 [inline]
         kobject_init_and_add+0xc9/0x160 lib/kobject.c:473
         nilfs_sysfs_create_device_group+0x150/0x800 fs/nilfs2/sysfs.c:999
         init_nilfs+0xe26/0x12b0 fs/nilfs2/the_nilfs.c:637
    
    Link: https://lkml.kernel.org/r/20210612140559.20022-1-paskripkin@gmail.com
    Fixes: da7141fb78db ("nilfs2: add /sys/fs/nilfs2/<device> group")
    Signed-off-by: Pavel Skripkin <paskripkin@gmail.com>
    Acked-by: Ryusuke Konishi <konishi.ryusuke@gmail.com>
    Cc: Michael L. Semon <mlsemon35@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 48e33193a26993e48a6069b8a1178506a0470820
Author: Heikki Krogerus <heikki.krogerus@linux.intel.com>
Date:   Wed Jun 23 16:14:21 2021 +0300

    software node: Handle software node injection to an existing device properly
    
    [ Upstream commit 5dca69e26fe97f17d4a6cbd6872103c868577b14 ]
    
    The function software_node_notify() - the function that creates
    and removes the symlinks between the node and the device - was
    called unconditionally in device_add_software_node() and
    device_remove_software_node(), but it needs to be called in
    those functions only in the special case where the node is
    added to a device that has already been registered.
    
    This fixes NULL pointer dereference that happens if
    device_remove_software_node() is used with device that was
    never registered.
    
    Fixes: b622b24519f5 ("software node: Allow node addition to already existing device")
    Reported-and-tested-by: Dominik Brodowski <linux@dominikbrodowski.net>
    Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Heikki Krogerus <heikki.krogerus@linux.intel.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0ffdf36db924085fd803c013ba0091470189fa9d
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Jun 17 13:55:04 2021 +0200

    scsi: sd: Call sd_revalidate_disk() for ioctl(BLKRRPART)
    
    [ Upstream commit d1b7f92035c6fb42529ada531e2cbf3534544c82 ]
    
    While the disk state has nothing to do with partitions, BLKRRPART is used
    to force a full revalidate after things like a disk format for historical
    reasons. Restore that behavior.
    
    Link: https://lore.kernel.org/r/20210617115504.1732350-1-hch@lst.de
    Fixes: 471bd0af544b ("sd: use bdev_check_media_change")
    Reported-by: Xiang Chen <chenxiang66@hisilicon.com>
    Tested-by: Xiang Chen <chenxiang66@hisilicon.com>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 79e0dbd5aa904ebf1805c1f0ed8b43a9abf3168a
Author: Gabriel Knezek <gabeknez@linux.microsoft.com>
Date:   Mon Jun 21 15:28:59 2021 -0700

    gpiolib: cdev: zero padding during conversion to gpioline_info_changed
    
    [ Upstream commit cb8f63b8cbf39845244f3ccae43bb7e63bd70543 ]
    
    When userspace requests a GPIO v1 line info changed event,
    lineinfo_watch_read() populates and returns the gpioline_info_changed
    structure. It contains 5 words of padding at the end which are not
    initialized before being returned to userspace.
    
    Zero the structure in gpio_v2_line_info_change_to_v1() before populating
    its contents.
    
    Fixes: aad955842d1c ("gpiolib: cdev: support GPIO_V2_GET_LINEINFO_IOCTL and GPIO_V2_GET_LINEINFO_WATCH_IOCTL")
    Signed-off-by: Gabriel Knezek <gabeknez@linux.microsoft.com>
    Reviewed-by: Kent Gibson <warthog618@gmail.com>
    Signed-off-by: Bartosz Golaszewski <bgolaszewski@baylibre.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5079a0fcda66ced207ea1b175ce725b36a2d0b11
Author: Heiner Kallweit <hkallweit1@gmail.com>
Date:   Sun Jun 6 15:55:55 2021 +0200

    i2c: i801: Ensure that SMBHSTSTS_INUSE_STS is cleared when leaving i801_access
    
    [ Upstream commit 065b6211a87746e196b56759a70c7851418dd741 ]
    
    As explained in [0] currently we may leave SMBHSTSTS_INUSE_STS set,
    thus potentially breaking ACPI/BIOS usage of the SMBUS device.
    
    Seems patch [0] needs a little bit more of review effort, therefore
    I'd suggest to apply a part of it as quick win. Just clearing
    SMBHSTSTS_INUSE_STS when leaving i801_access() should fix the
    referenced issue and leaves more time for discussing a more
    sophisticated locking handling.
    
    [0] https://www.spinics.net/lists/linux-i2c/msg51558.html
    
    Fixes: 01590f361e94 ("i2c: i801: Instantiate SPD EEPROMs automatically")
    Suggested-by: Hector Martin <marcan@marcan.st>
    Signed-off-by: Heiner Kallweit <hkallweit1@gmail.com>
    Reviewed-by: Hector Martin <marcan@marcan.st>
    Reviewed-by: Jean Delvare <jdelvare@suse.de>
    Tested-by: Jean Delvare <jdelvare@suse.de>
    Signed-off-by: Wolfram Sang <wsa@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 39eb61208e9d54d5aa1b1820b23c1c41bf2851ac
Author: Fabien Dessenne <fabien.dessenne@foss.st.com>
Date:   Thu Jun 17 16:46:29 2021 +0200

    pinctrl: stm32: fix the reported number of GPIO lines per bank
    
    [ Upstream commit 67e2996f72c71ebe4ac2fcbcf77e54479bb7aa11 ]
    
    Each GPIO bank supports a variable number of lines which is usually 16, but
    is less in some cases : this is specified by the last argument of the
    "gpio-ranges" bank node property.
    Report to the framework, the actual number of lines, so the libgpiod
    gpioinfo command lists the actually existing GPIO lines.
    
    Fixes: 1dc9d289154b ("pinctrl: stm32: add possibility to use gpio-ranges to declare bank range")
    Signed-off-by: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Link: https://lore.kernel.org/r/20210617144629.2557693-1-fabien.dessenne@foss.st.com
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 96bade7ca937b94f29795ebdbb675e0ac2509911
Author: Andy Shevchenko <andy.shevchenko@gmail.com>
Date:   Sun Jun 6 22:19:40 2021 +0300

    pinctrl: microchip-sgpio: Put fwnode in error case during ->probe()
    
    [ Upstream commit 76b7f8fae30a9249f820e019f1e62eca992751a2 ]
    
    device_for_each_child_node() bumps a reference counting of a returned variable.
    We have to balance it whenever we return to the caller.
    
    Fixes: 7e5ea974e61c ("pinctrl: pinctrl-microchip-sgpio: Add pinctrl driver for Microsemi Serial GPIO")
    Cc: Lars Povlsen <lars.povlsen@microchip.com>
    Signed-off-by: Andy Shevchenko <andy.shevchenko@gmail.com>
    Link: https://lore.kernel.org/r/20210606191940.29312-1-andy.shevchenko@gmail.com
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 19e15b517a7d59cf007e8f41c3570ed04f9ae89c
Author: Kan Liang <kan.liang@linux.intel.com>
Date:   Mon Apr 12 07:30:43 2021 -0700

    perf/x86: Track pmu in per-CPU cpu_hw_events
    
    [ Upstream commit 61e76d53c39bb768ad264d379837cfc56b9e35b4 ]
    
    Some platforms, e.g. Alder Lake, have hybrid architecture. In the same
    package, there may be more than one type of CPU. The PMU capabilities
    are different among different types of CPU. Perf will register a
    dedicated PMU for each type of CPU.
    
    Add a 'pmu' variable in the struct cpu_hw_events to track the dedicated
    PMU of the current CPU.
    
    Current x86_get_pmu() use the global 'pmu', which will be broken on a
    hybrid platform. Modify it to apply the 'pmu' of the specific CPU.
    
    Initialize the per-CPU 'pmu' variable with the global 'pmu'. There is
    nothing changed for the non-hybrid platforms.
    
    The is_x86_event() will be updated in the later patch ("perf/x86:
    Register hybrid PMUs") for hybrid platforms. For the non-hybrid
    platforms, nothing is changed here.
    
    Suggested-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/1618237865-33448-4-git-send-email-kan.liang@linux.intel.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8bfb7c12758ab95035758b7722a51c900f71f30e
Author: David Abdurachmanov <david.abdurachmanov@sifive.com>
Date:   Sat Jun 12 17:43:57 2021 -0700

    riscv: dts: fu740: fix cache-controller interrupts
    
    [ Upstream commit 7ede12b01b59dc67bef2e2035297dd2da5bfe427 ]
    
    The order of interrupt numbers is incorrect.
    
    The order for FU740 is: DirError, DataError, DataFail, DirFail
    
    From SiFive FU740-C000 Manual:
    19 - L2 Cache DirError
    20 - L2 Cache DirFail
    21 - L2 Cache DataError
    22 - L2 Cache DataFail
    
    Signed-off-by: David Abdurachmanov <david.abdurachmanov@sifive.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 736b50ef2e3dbbd2cfd587854aa5e71596ef692d
Author: Esben Haabendal <esben@geanix.com>
Date:   Fri Jun 18 12:52:38 2021 +0200

    net: ll_temac: Avoid ndo_start_xmit returning NETDEV_TX_BUSY
    
    [ Upstream commit f6396341194234e9b01cd7538bc2c6ac4501ab14 ]
    
    As documented in Documentation/networking/driver.rst, the ndo_start_xmit
    method must not return NETDEV_TX_BUSY under any normal circumstances, and
    as recommended, we simply stop the tx queue in advance, when there is a
    risk that the next xmit would cause a NETDEV_TX_BUSY return.
    
    Signed-off-by: Esben Haabendal <esben@geanix.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c34ef5b94b6a45a0d4d2433a1b8ccd2677f78aa0
Author: Esben Haabendal <esben@geanix.com>
Date:   Fri Jun 18 12:52:28 2021 +0200

    net: ll_temac: Add memory-barriers for TX BD access
    
    [ Upstream commit 28d9fab458b16bcd83f9dd07ede3d585c3e1a69e ]
    
    Add a couple of memory-barriers to ensure correct ordering of read/write
    access to TX BDs.
    
    In xmit_done, we should ensure that reading the additional BD fields are
    only done after STS_CTRL_APP0_CMPLT bit is set.
    
    When xmit_done marks the BD as free by setting APP0=0, we need to ensure
    that the other BD fields are reset first, so we avoid racing with the xmit
    path, which writes to the same fields.
    
    Finally, making sure to read APP0 of next BD after the current BD, ensures
    that we see all available buffers.
    
    Signed-off-by: Esben Haabendal <esben@geanix.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit db676e73666ade02c8e07a6aa7bfb8ab4e0a620e
Author: Mikel Rychliski <mikel@mikelr.com>
Date:   Fri Jun 11 17:48:23 2021 -0400

    PCI: Add AMD RS690 quirk to enable 64-bit DMA
    
    [ Upstream commit cacf994a91d3a55c0c2f853d6429cd7b86113915 ]
    
    Although the AMD RS690 chipset has 64-bit DMA support, BIOS implementations
    sometimes fail to configure the memory limit registers correctly.
    
    The Acer F690GVM mainboard uses this chipset and a Marvell 88E8056 NIC. The
    sky2 driver programs the NIC to use 64-bit DMA, which will not work:
    
      sky2 0000:02:00.0: error interrupt status=0x8
      sky2 0000:02:00.0 eth0: tx timeout
      sky2 0000:02:00.0 eth0: transmit ring 0 .. 22 report=0 done=0
    
    Other drivers required by this mainboard either don't support 64-bit DMA,
    or have it disabled using driver specific quirks. For example, the ahci
    driver has quirks to enable or disable 64-bit DMA depending on the BIOS
    version (see ahci_sb600_enable_64bit() in ahci.c). This ahci quirk matches
    against the SB600 SATA controller, but the real issue is almost certainly
    with the RS690 PCI host that it was commonly attached to.
    
    To avoid this issue in all drivers with 64-bit DMA support, fix the
    configuration of the PCI host. If the kernel is aware of physical memory
    above 4GB, but the BIOS never configured the PCI host with this
    information, update the registers with our values.
    
    [bhelgaas: drop PCI_DEVICE_ID_ATI_RS690 definition]
    Link: https://lore.kernel.org/r/20210611214823.4898-1-mikel@mikelr.com
    Signed-off-by: Mikel Rychliski <mikel@mikelr.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9a10de6de0ff7a344cb1826b08c68261d1ecd01a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Jun 16 23:41:26 2021 +0800

    recordmcount: Correct st_shndx handling
    
    [ Upstream commit fb780761e7bd9f2e94f5b9a296ead6b35b944206 ]
    
    One should only use st_shndx when >SHN_UNDEF and <SHN_LORESERVE. When
    SHN_XINDEX, then use .symtab_shndx. Otherwise use 0.
    
    This handles the case: st_shndx >= SHN_LORESERVE && st_shndx != SHN_XINDEX.
    
    Link: https://lore.kernel.org/lkml/20210607023839.26387-1-mark-pk.tsai@mediatek.com/
    Link: https://lkml.kernel.org/r/20210616154126.2794-1-mark-pk.tsai@mediatek.com
    
    Reported-by: Mark-PK Tsai <mark-pk.tsai@mediatek.com>
    Tested-by: Mark-PK Tsai <mark-pk.tsai@mediatek.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    [handle endianness of sym->st_shndx]
    Signed-off-by: Mark-PK Tsai <mark-pk.tsai@mediatek.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e57188c29d6345752d490be4ae29b6c0d1864920
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Fri Jun 18 13:41:45 2021 +0300

    mac80211: handle various extensible elements correctly
    
    [ Upstream commit 652e8363bbc7d149fa194a5cbf30b1001c0274b0 ]
    
    Various elements are parsed with a requirement to have an
    exact size, when really we should only check that they have
    the minimum size that we need. Check only that and therefore
    ignore any additional data that they might carry.
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Luca Coelho <luciano.coelho@intel.com>
    Link: https://lore.kernel.org/r/iwlwifi.20210618133832.cd101f8040a4.Iadf0e9b37b100c6c6e79c7b298cc657c2be9151a@changeid
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 01267d00e1c34273e16b4d282ea7b86647d96c77
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Fri Jun 18 13:41:49 2021 +0300

    mac80211: reset profile_periodicity/ema_ap
    
    [ Upstream commit bbc6f03ff26e7b71d6135a7b78ce40e7dee3d86a ]
    
    Apparently we never clear these values, so they'll remain set
    since the setting of them is conditional. Clear the values in
    the relevant other cases.
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Luca Coelho <luciano.coelho@intel.com>
    Link: https://lore.kernel.org/r/iwlwifi.20210618133832.316e32d136a9.I2a12e51814258e1e1b526103894f4b9f19a91c8d@changeid
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 961535de34950d3f1920c11a712c541c0a9018a4
Author: Kees Cook <keescook@chromium.org>
Date:   Thu Jun 17 10:09:53 2021 -0700

    net: qed: Fix memcpy() overflow of qed_dcbx_params()
    
    [ Upstream commit 1c200f832e14420fa770193f9871f4ce2df00d07 ]
    
    The source (&dcbx_info->operational.params) and dest
    (&p_hwfn->p_dcbx_info->set.config.params) are both struct qed_dcbx_params
    (560 bytes), not struct qed_dcbx_admin_params (564 bytes), which is used
    as the memcpy() size.
    
    However it seems that struct qed_dcbx_operational_params
    (dcbx_info->operational)'s layout matches struct qed_dcbx_admin_params
    (p_hwfn->p_dcbx_info->set.config)'s 4 byte difference (3 padding, 1 byte
    for "valid").
    
    On the assumption that the size is wrong (rather than the source structure
    type), adjust the memcpy() size argument to be 4 bytes smaller and add
    a BUILD_BUG_ON() to validate any changes to the structure sizes.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit bee7a6e2b9735f781b13b7f90546655bdaa2244f
Author: Fuad Tabba <tabba@google.com>
Date:   Tue Jun 15 16:04:43 2021 +0100

    KVM: selftests: Fix kvm_check_cap() assertion
    
    [ Upstream commit d8ac05ea13d789d5491a5920d70a05659015441d ]
    
    KVM_CHECK_EXTENSION ioctl can return any negative value on error,
    and not necessarily -1. Change the assertion to reflect that.
    
    Signed-off-by: Fuad Tabba <tabba@google.com>
    Message-Id: <20210615150443.1183365-1-tabba@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 4af8575846ca5581280ff05bbe4ec6f88bd6dc04
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 16 12:53:59 2021 -0700

    r8169: Avoid memcpy() over-reading of ETH_SS_STATS
    
    [ Upstream commit da5ac772cfe2a03058b0accfac03fad60c46c24d ]
    
    In preparation for FORTIFY_SOURCE performing compile-time and run-time
    field bounds checking for memcpy(), memmove(), and memset(), avoid
    intentionally reading across neighboring array fields.
    
    The memcpy() is copying the entire structure, not just the first array.
    Adjust the source argument so the compiler can do appropriate bounds
    checking.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 45c6af8237bf1d11932d6457ef2d09758f459459
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 16 12:53:33 2021 -0700

    sh_eth: Avoid memcpy() over-reading of ETH_SS_STATS
    
    [ Upstream commit 224004fbb033600715dbd626bceec10bfd9c58bc ]
    
    In preparation for FORTIFY_SOURCE performing compile-time and run-time
    field bounds checking for memcpy(), memmove(), and memset(), avoid
    intentionally reading across neighboring array fields.
    
    The memcpy() is copying the entire structure, not just the first array.
    Adjust the source argument so the compiler can do appropriate bounds
    checking.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 731225fad60679cc1759171d9b31f026f69ed134
Author: Kees Cook <keescook@chromium.org>
Date:   Wed Jun 16 12:53:03 2021 -0700

    r8152: Avoid memcpy() over-reading of ETH_SS_STATS
    
    [ Upstream commit 99718abdc00e86e4f286dd836408e2834886c16e ]
    
    In preparation for FORTIFY_SOURCE performing compile-time and run-time
    field bounds checking for memcpy(), memmove(), and memset(), avoid
    intentionally reading across neighboring array fields.
    
    The memcpy() is copying the entire structure, not just the first array.
    Adjust the source argument so the compiler can do appropriate bounds
    checking.
    
    Signed-off-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 86876b371ccbb57819e67e2d39735383ee863a79
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 16 06:42:02 2021 -0700

    net/packet: annotate accesses to po->ifindex
    
    [ Upstream commit e032f7c9c7cefffcfb79b9fc16c53011d2d9d11f ]
    
    Like prior patch, we need to annotate lockless accesses to po->ifindex
    For instance, packet_getname() is reading po->ifindex (twice) while
    another thread is able to change po->ifindex.
    
    KCSAN reported:
    
    BUG: KCSAN: data-race in packet_do_bind / packet_getname
    
    write to 0xffff888143ce3cbc of 4 bytes by task 25573 on cpu 1:
     packet_do_bind+0x420/0x7e0 net/packet/af_packet.c:3191
     packet_bind+0xc3/0xd0 net/packet/af_packet.c:3255
     __sys_bind+0x200/0x290 net/socket.c:1637
     __do_sys_bind net/socket.c:1648 [inline]
     __se_sys_bind net/socket.c:1646 [inline]
     __x64_sys_bind+0x3d/0x50 net/socket.c:1646
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    read to 0xffff888143ce3cbc of 4 bytes by task 25578 on cpu 0:
     packet_getname+0x5b/0x1a0 net/packet/af_packet.c:3525
     __sys_getsockname+0x10e/0x1a0 net/socket.c:1887
     __do_sys_getsockname net/socket.c:1902 [inline]
     __se_sys_getsockname net/socket.c:1899 [inline]
     __x64_sys_getsockname+0x3e/0x50 net/socket.c:1899
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    value changed: 0x00000000 -> 0x00000001
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 0 PID: 25578 Comm: syz-executor.5 Not tainted 5.13.0-rc6-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 598c3d47f69dde5cedd58b2b5b1bbf6814f0736f
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 16 06:42:01 2021 -0700

    net/packet: annotate accesses to po->bind
    
    [ Upstream commit c7d2ef5dd4b03ed0ee1d13bc0c55f9cf62d49bd6 ]
    
    tpacket_snd(), packet_snd(), packet_getname() and packet_seq_show()
    can read po->num without holding a lock. This means other threads
    can change po->num at the same time.
    
    KCSAN complained about this known fact [1]
    Add READ_ONCE()/WRITE_ONCE() to address the issue.
    
    [1] BUG: KCSAN: data-race in packet_do_bind / packet_sendmsg
    
    write to 0xffff888131a0dcc0 of 2 bytes by task 24714 on cpu 0:
     packet_do_bind+0x3ab/0x7e0 net/packet/af_packet.c:3181
     packet_bind+0xc3/0xd0 net/packet/af_packet.c:3255
     __sys_bind+0x200/0x290 net/socket.c:1637
     __do_sys_bind net/socket.c:1648 [inline]
     __se_sys_bind net/socket.c:1646 [inline]
     __x64_sys_bind+0x3d/0x50 net/socket.c:1646
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    read to 0xffff888131a0dcc0 of 2 bytes by task 24719 on cpu 1:
     packet_snd net/packet/af_packet.c:2899 [inline]
     packet_sendmsg+0x317/0x3570 net/packet/af_packet.c:3040
     sock_sendmsg_nosec net/socket.c:654 [inline]
     sock_sendmsg net/socket.c:674 [inline]
     ____sys_sendmsg+0x360/0x4d0 net/socket.c:2350
     ___sys_sendmsg net/socket.c:2404 [inline]
     __sys_sendmsg+0x1ed/0x270 net/socket.c:2433
     __do_sys_sendmsg net/socket.c:2442 [inline]
     __se_sys_sendmsg net/socket.c:2440 [inline]
     __x64_sys_sendmsg+0x42/0x50 net/socket.c:2440
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    value changed: 0x0000 -> 0x1200
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 24719 Comm: syz-executor.5 Not tainted 5.13.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e309e4631c5606dafa657e306fcf4f61d0a308b1
Author: Kristian Evensen <kristian.evensen@gmail.com>
Date:   Tue Jun 15 12:01:51 2021 +0200

    qmi_wwan: Do not call netif_rx from rx_fixup
    
    [ Upstream commit 057d49334c02a79af81c30a8d240e641bd6f1741 ]
    
    When the QMI_WWAN_FLAG_PASS_THROUGH is set, netif_rx() is called from
    qmi_wwan_rx_fixup(). When the call to netif_rx() is successful (which is
    most of the time), usbnet_skb_return() is called (from rx_process()).
    usbnet_skb_return() will then call netif_rx() a second time for the same
    skb.
    
    Simplify the code and avoid the redundant netif_rx() call by changing
    qmi_wwan_rx_fixup() to always return 1 when QMI_WWAN_FLAG_PASS_THROUGH
    is set. We then leave it up to the existing infrastructure to call
    netif_rx().
    
    Suggested-by: Bjørn Mork <bjorn@mork.no>
    Signed-off-by: Kristian Evensen <kristian.evensen@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e5e2010ac3e27efa1e6e830b250f491da82d51b4
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Mon May 31 12:34:24 2021 +0000

    bpf, selftests: Adjust few selftest outcomes wrt unreachable code
    
    [ Upstream commit 973377ffe8148180b2651825b92ae91988141b05 ]
    
    In almost all cases from test_verifier that have been changed in here, we've
    had an unreachable path with a load from a register which has an invalid
    address on purpose. This was basically to make sure that we never walk this
    path and to have the verifier complain if it would otherwise. Change it to
    match on the right error for unprivileged given we now test these paths
    under speculative execution.
    
    There's one case where we match on exact # of insns_processed. Due to the
    extra path, this will of course mismatch on unprivileged. Thus, restrict the
    test->insn_processed check to privileged-only.
    
    In one other case, we result in a 'pointer comparison prohibited' error. This
    is similarly due to verifying an 'invalid' branch where we end up with a value
    pointer on one side of the comparison.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: John Fastabend <john.fastabend@gmail.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e056cc440ae71fda770814a7aa865279fc8d6462
Author: Pavel Skripkin <paskripkin@gmail.com>
Date:   Sat Jun 12 17:51:22 2021 +0300

    net: caif: fix memory leak in ldisc_open
    
    [ Upstream commit 58af3d3d54e87bfc1f936e16c04ade3369d34011 ]
    
    Syzbot reported memory leak in tty_init_dev().
    The problem was in unputted tty in ldisc_open()
    
    static int ldisc_open(struct tty_struct *tty)
    {
    ...
            ser->tty = tty_kref_get(tty);
    ...
            result = register_netdevice(dev);
            if (result) {
                    rtnl_unlock();
                    free_netdev(dev);
                    return -ENODEV;
            }
    ...
    }
    
    Ser pointer is netdev private_data, so after free_netdev()
    this pointer goes away with unputted tty reference. So, fix
    it by adding tty_kref_put() before freeing netdev.
    
    Reported-and-tested-by: syzbot+f303e045423e617d2cad@syzkaller.appspotmail.com
    Signed-off-by: Pavel Skripkin <paskripkin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6a3354d38cefae7964ba7c7e7c5e358986f8fe49
Author: Khem Raj <raj.khem@gmail.com>
Date:   Sun Jun 6 15:09:40 2021 -0700

    riscv32: Use medany C model for modules
    
    [ Upstream commit 5d2388dbf84adebeb6d9742164be8d32728e4269 ]
    
    When CONFIG_CMODEL_MEDLOW is used it ends up generating riscv_hi20_rela
    relocations in modules which are not resolved during runtime and
    following errors would be seen
    
    [    4.802714] virtio_input: target 00000000c1539090 can not be addressed by the 32-bit offset from PC = 39148b7b
    [    4.854800] virtio_input: target 00000000c1539090 can not be addressed by the 32-bit offset from PC = 9774456d
    
    Signed-off-by: Khem Raj <raj.khem@gmail.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2ec33ddbc1203f9a57d374687ea15bf727068304
Author: Praneeth Bajjuri <praneeth@ti.com>
Date:   Wed Jun 9 19:43:42 2021 -0500

    net: phy: dp83867: perform soft reset and retain established link
    
    [ Upstream commit da9ef50f545f86ffe6ff786174d26500c4db737a ]
    
    Current logic is performing hard reset and causing the programmed
    registers to be wiped out.
    
    as per datasheet: https://www.ti.com/lit/ds/symlink/dp83867cr.pdf
    8.6.26 Control Register (CTRL)
    
    do SW_RESTART to perform a reset not including the registers,
    If performed when link is already present,
    it will drop the link and trigger re-auto negotiation.
    
    Signed-off-by: Praneeth Bajjuri <praneeth@ti.com>
    Signed-off-by: Geet Modi <geet.modi@ti.com>
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ad91e20dfffdbc0b6d80bbbc2150671fabbf27a5
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Jun 10 09:00:12 2021 -0700

    net/packet: annotate data race in packet_sendmsg()
    
    [ Upstream commit d1b5bee4c8be01585033be9b3a8878789285285f ]
    
    There is a known race in packet_sendmsg(), addressed
    in commit 32d3182cd2cd ("net/packet: fix race in tpacket_snd()")
    
    Now we have data_race(), we can use it to avoid a future KCSAN warning,
    as syzbot loves stressing af_packet sockets :)
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 231504bdfa03ce79ab34a25fccd484156481d4c5
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Jun 10 07:44:11 2021 -0700

    inet: annotate date races around sk->sk_txhash
    
    [ Upstream commit b71eaed8c04f72a919a9c44e83e4ee254e69e7f3 ]
    
    UDP sendmsg() path can be lockless, it is possible for another
    thread to re-connect an change sk->sk_txhash under us.
    
    There is no serious impact, but we can use READ_ONCE()/WRITE_ONCE()
    pair to document the race.
    
    BUG: KCSAN: data-race in __ip4_datagram_connect / skb_set_owner_w
    
    write to 0xffff88813397920c of 4 bytes by task 30997 on cpu 1:
     sk_set_txhash include/net/sock.h:1937 [inline]
     __ip4_datagram_connect+0x69e/0x710 net/ipv4/datagram.c:75
     __ip6_datagram_connect+0x551/0x840 net/ipv6/datagram.c:189
     ip6_datagram_connect+0x2a/0x40 net/ipv6/datagram.c:272
     inet_dgram_connect+0xfd/0x180 net/ipv4/af_inet.c:580
     __sys_connect_file net/socket.c:1837 [inline]
     __sys_connect+0x245/0x280 net/socket.c:1854
     __do_sys_connect net/socket.c:1864 [inline]
     __se_sys_connect net/socket.c:1861 [inline]
     __x64_sys_connect+0x3d/0x50 net/socket.c:1861
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    read to 0xffff88813397920c of 4 bytes by task 31039 on cpu 0:
     skb_set_hash_from_sk include/net/sock.h:2211 [inline]
     skb_set_owner_w+0x118/0x220 net/core/sock.c:2101
     sock_alloc_send_pskb+0x452/0x4e0 net/core/sock.c:2359
     sock_alloc_send_skb+0x2d/0x40 net/core/sock.c:2373
     __ip6_append_data+0x1743/0x21a0 net/ipv6/ip6_output.c:1621
     ip6_make_skb+0x258/0x420 net/ipv6/ip6_output.c:1983
     udpv6_sendmsg+0x160a/0x16b0 net/ipv6/udp.c:1527
     inet6_sendmsg+0x5f/0x80 net/ipv6/af_inet6.c:642
     sock_sendmsg_nosec net/socket.c:654 [inline]
     sock_sendmsg net/socket.c:674 [inline]
     ____sys_sendmsg+0x360/0x4d0 net/socket.c:2350
     ___sys_sendmsg net/socket.c:2404 [inline]
     __sys_sendmmsg+0x315/0x4b0 net/socket.c:2490
     __do_sys_sendmmsg net/socket.c:2519 [inline]
     __se_sys_sendmmsg net/socket.c:2516 [inline]
     __x64_sys_sendmmsg+0x53/0x60 net/socket.c:2516
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    value changed: 0xbca3c43d -> 0xfdb309e0
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 0 PID: 31039 Comm: syz-executor.2 Not tainted 5.13.0-rc3-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8e09e904ad15c9c9d45554de5128948be9851668
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Jun 10 07:27:37 2021 -0700

    net: annotate data race in sock_error()
    
    [ Upstream commit f13ef10059ccf5f4ed201cd050176df62ec25bb8 ]
    
    sock_error() is known to be racy. The code avoids
    an atomic operation is sk_err is zero, and this field
    could be changed under us, this is fine.
    
    Sysbot reported:
    
    BUG: KCSAN: data-race in sock_alloc_send_pskb / unix_release_sock
    
    write to 0xffff888131855630 of 4 bytes by task 9365 on cpu 1:
     unix_release_sock+0x2e9/0x6e0 net/unix/af_unix.c:550
     unix_release+0x2f/0x50 net/unix/af_unix.c:859
     __sock_release net/socket.c:599 [inline]
     sock_close+0x6c/0x150 net/socket.c:1258
     __fput+0x25b/0x4e0 fs/file_table.c:280
     ____fput+0x11/0x20 fs/file_table.c:313
     task_work_run+0xae/0x130 kernel/task_work.c:164
     tracehook_notify_resume include/linux/tracehook.h:189 [inline]
     exit_to_user_mode_loop kernel/entry/common.c:174 [inline]
     exit_to_user_mode_prepare+0x156/0x190 kernel/entry/common.c:208
     __syscall_exit_to_user_mode_work kernel/entry/common.c:290 [inline]
     syscall_exit_to_user_mode+0x20/0x40 kernel/entry/common.c:301
     do_syscall_64+0x56/0x90 arch/x86/entry/common.c:57
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    read to 0xffff888131855630 of 4 bytes by task 9385 on cpu 0:
     sock_error include/net/sock.h:2269 [inline]
     sock_alloc_send_pskb+0xe4/0x4e0 net/core/sock.c:2336
     unix_dgram_sendmsg+0x478/0x1610 net/unix/af_unix.c:1671
     unix_seqpacket_sendmsg+0xc2/0x100 net/unix/af_unix.c:2055
     sock_sendmsg_nosec net/socket.c:654 [inline]
     sock_sendmsg net/socket.c:674 [inline]
     ____sys_sendmsg+0x360/0x4d0 net/socket.c:2350
     __sys_sendmsg_sock+0x25/0x30 net/socket.c:2416
     io_sendmsg fs/io_uring.c:4367 [inline]
     io_issue_sqe+0x231a/0x6750 fs/io_uring.c:6135
     __io_queue_sqe+0xe9/0x360 fs/io_uring.c:6414
     __io_req_task_submit fs/io_uring.c:2039 [inline]
     io_async_task_func+0x312/0x590 fs/io_uring.c:5074
     __tctx_task_work fs/io_uring.c:1910 [inline]
     tctx_task_work+0x1d4/0x3d0 fs/io_uring.c:1924
     task_work_run+0xae/0x130 kernel/task_work.c:164
     tracehook_notify_signal include/linux/tracehook.h:212 [inline]
     handle_signal_work kernel/entry/common.c:145 [inline]
     exit_to_user_mode_loop kernel/entry/common.c:171 [inline]
     exit_to_user_mode_prepare+0xf8/0x190 kernel/entry/common.c:208
     __syscall_exit_to_user_mode_work kernel/entry/common.c:290 [inline]
     syscall_exit_to_user_mode+0x20/0x40 kernel/entry/common.c:301
     do_syscall_64+0x56/0x90 arch/x86/entry/common.c:57
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    value changed: 0x00000000 -> 0x00000068
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 0 PID: 9385 Comm: syz-executor.3 Not tainted 5.13.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit cb50cdafb80203739834d597f33107b4dc32d3a9
Author: Zheng Yongjun <zhengyongjun3@huawei.com>
Date:   Thu Jun 10 09:41:36 2021 +0800

    ping: Check return value of function 'ping_queue_rcv_skb'
    
    [ Upstream commit 9d44fa3e50cc91691896934d106c86e4027e61ca ]
    
    Function 'ping_queue_rcv_skb' not always return success, which will
    also return fail. If not check the wrong return value of it, lead to function
    `ping_rcv` return success.
    
    Signed-off-by: Zheng Yongjun <zhengyongjun3@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a2f974276fc2a33811d9ce3190c1bbdb05c02069
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 9 00:59:45 2021 -0700

    inet: annotate data race in inet_send_prepare() and inet_dgram_connect()
    
    [ Upstream commit dcd01eeac14486b56a790f5cce9b823440ba5b34 ]
    
    Both functions are known to be racy when reading inet_num
    as we do not want to grab locks for the common case the socket
    has been bound already. The race is resolved in inet_autobind()
    by reading again inet_num under the socket lock.
    
    syzbot reported:
    BUG: KCSAN: data-race in inet_send_prepare / udp_lib_get_port
    
    write to 0xffff88812cba150e of 2 bytes by task 24135 on cpu 0:
     udp_lib_get_port+0x4b2/0xe20 net/ipv4/udp.c:308
     udp_v6_get_port+0x5e/0x70 net/ipv6/udp.c:89
     inet_autobind net/ipv4/af_inet.c:183 [inline]
     inet_send_prepare+0xd0/0x210 net/ipv4/af_inet.c:807
     inet6_sendmsg+0x29/0x80 net/ipv6/af_inet6.c:639
     sock_sendmsg_nosec net/socket.c:654 [inline]
     sock_sendmsg net/socket.c:674 [inline]
     ____sys_sendmsg+0x360/0x4d0 net/socket.c:2350
     ___sys_sendmsg net/socket.c:2404 [inline]
     __sys_sendmmsg+0x315/0x4b0 net/socket.c:2490
     __do_sys_sendmmsg net/socket.c:2519 [inline]
     __se_sys_sendmmsg net/socket.c:2516 [inline]
     __x64_sys_sendmmsg+0x53/0x60 net/socket.c:2516
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    read to 0xffff88812cba150e of 2 bytes by task 24132 on cpu 1:
     inet_send_prepare+0x21/0x210 net/ipv4/af_inet.c:806
     inet6_sendmsg+0x29/0x80 net/ipv6/af_inet6.c:639
     sock_sendmsg_nosec net/socket.c:654 [inline]
     sock_sendmsg net/socket.c:674 [inline]
     ____sys_sendmsg+0x360/0x4d0 net/socket.c:2350
     ___sys_sendmsg net/socket.c:2404 [inline]
     __sys_sendmmsg+0x315/0x4b0 net/socket.c:2490
     __do_sys_sendmmsg net/socket.c:2519 [inline]
     __se_sys_sendmmsg net/socket.c:2516 [inline]
     __x64_sys_sendmmsg+0x53/0x60 net/socket.c:2516
     do_syscall_64+0x4a/0x90 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    value changed: 0x0000 -> 0x9db4
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 24132 Comm: syz-executor.2 Not tainted 5.13.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a655fe62b436efc87e68fb8cc6577a8d1b8c511c
Author: Austin Kim <austindh.kim@gmail.com>
Date:   Wed Jun 9 03:34:25 2021 +0100

    net: ethtool: clear heap allocations for ethtool function
    
    [ Upstream commit 80ec82e3d2c1fab42eeb730aaa7985494a963d3f ]
    
    Several ethtool functions leave heap uncleared (potentially) by
    drivers. This will leave the unused portion of heap unchanged and
    might copy the full contents back to userspace.
    
    Signed-off-by: Austin Kim <austindh.kim@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0529c16aca76cbc0a71eb1a351c19b85476e03d2
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Wed Jun 9 16:13:06 2021 +0200

    mac80211: drop multicast fragments
    
    [ Upstream commit a9799541ca34652d9996e45f80e8e03144c12949 ]
    
    These are not permitted by the spec, just drop them.
    
    Link: https://lore.kernel.org/r/20210609161305.23def022b750.Ibd6dd3cdce573dae262fcdc47f8ac52b883a9c50@changeid
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit df0e6c29a49f503d31a5ece4ec047c496c877c97
Author: Zheng Yongjun <zhengyongjun3@huawei.com>
Date:   Tue Jun 8 09:53:15 2021 +0800

    net: ipv4: Remove unneed BUG() function
    
    [ Upstream commit 5ac6b198d7e312bd10ebe7d58c64690dc59cc49a ]
    
    When 'nla_parse_nested_deprecated' failed, it's no need to
    BUG() here, return -EINVAL is ok.
    
    Signed-off-by: Zheng Yongjun <zhengyongjun3@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c12778caacf8f93dd2ec1de2ba7d7757907128a3
Author: Guillaume Ranquet <granquet@baylibre.com>
Date:   Thu May 13 21:26:42 2021 +0200

    dmaengine: mediatek: use GFP_NOWAIT instead of GFP_ATOMIC in prep_dma
    
    [ Upstream commit 9041575348b21ade1fb74d790f1aac85d68198c7 ]
    
    As recommended by the doc in:
    Documentation/drivers-api/dmaengine/provider.rst
    
    Use GFP_NOWAIT to not deplete the emergency pool.
    
    Signed-off-by: Guillaume Ranquet <granquet@baylibre.com>
    
    Link: https://lore.kernel.org/r/20210513192642.29446-4-granquet@baylibre.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e67423ed600172cd92a6a72bcbff06c5e3a171b4
Author: Guillaume Ranquet <granquet@baylibre.com>
Date:   Thu May 13 21:26:41 2021 +0200

    dmaengine: mediatek: do not issue a new desc if one is still current
    
    [ Upstream commit 2537b40b0a4f61d2c83900744fe89b09076be9c6 ]
    
    Avoid issuing a new desc if one is still being processed as this can
    lead to some desc never being marked as completed.
    
    Signed-off-by: Guillaume Ranquet <granquet@baylibre.com>
    
    Link: https://lore.kernel.org/r/20210513192642.29446-3-granquet@baylibre.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c11dd2d04e827709211067043ff20dda5c6c28ee
Author: Guillaume Ranquet <granquet@baylibre.com>
Date:   Thu May 13 21:26:40 2021 +0200

    dmaengine: mediatek: free the proper desc in desc_free handler
    
    [ Upstream commit 0a2ff58f9f8f95526ecb0ccd7517fefceb96f661 ]
    
    The desc_free handler assumed that the desc we want to free was always
     the current one associated with the channel.
    
    This is seldom the case and this is causing use after free crashes in
     multiple places (tx/rx/terminate...).
    
      BUG: KASAN: use-after-free in mtk_uart_apdma_rx_handler+0x120/0x304
    
      Call trace:
       dump_backtrace+0x0/0x1b0
       show_stack+0x24/0x34
       dump_stack+0xe0/0x150
       print_address_description+0x8c/0x55c
       __kasan_report+0x1b8/0x218
       kasan_report+0x14/0x20
       __asan_load4+0x98/0x9c
       mtk_uart_apdma_rx_handler+0x120/0x304
       mtk_uart_apdma_irq_handler+0x50/0x80
       __handle_irq_event_percpu+0xe0/0x210
       handle_irq_event+0x8c/0x184
       handle_fasteoi_irq+0x1d8/0x3ac
       __handle_domain_irq+0xb0/0x110
       gic_handle_irq+0x50/0xb8
       el0_irq_naked+0x60/0x6c
    
      Allocated by task 3541:
       __kasan_kmalloc+0xf0/0x1b0
       kasan_kmalloc+0x10/0x1c
       kmem_cache_alloc_trace+0x90/0x2dc
       mtk_uart_apdma_prep_slave_sg+0x6c/0x1a0
       mtk8250_dma_rx_complete+0x220/0x2e4
       vchan_complete+0x290/0x340
       tasklet_action_common+0x220/0x298
       tasklet_action+0x28/0x34
       __do_softirq+0x158/0x35c
    
      Freed by task 3541:
       __kasan_slab_free+0x154/0x224
       kasan_slab_free+0x14/0x24
       slab_free_freelist_hook+0xf8/0x15c
       kfree+0xb4/0x278
       mtk_uart_apdma_desc_free+0x34/0x44
       vchan_complete+0x1bc/0x340
       tasklet_action_common+0x220/0x298
       tasklet_action+0x28/0x34
       __do_softirq+0x158/0x35c
    
      The buggy address belongs to the object at ffff000063606800
       which belongs to the cache kmalloc-256 of size 256
      The buggy address is located 176 bytes inside of
       256-byte region [ffff000063606800, ffff000063606900)
      The buggy address belongs to the page:
      page:fffffe00016d8180 refcount:1 mapcount:0 mapping:ffff00000302f600 index:0x0 compound_mapcount: 0
      flags: 0xffff00000010200(slab|head)
      raw: 0ffff00000010200 dead000000000100 dead000000000122 ffff00000302f600
      raw: 0000000000000000 0000000080100010 00000001ffffffff 0000000000000000
      page dumped because: kasan: bad access detected
    
    Signed-off-by: Guillaume Ranquet <granquet@baylibre.com>
    
    Link: https://lore.kernel.org/r/20210513192642.29446-2-granquet@baylibre.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 069907508fe1672569bea265f6809105f6d9e1c8
Author: Zou Wei <zou_wei@huawei.com>
Date:   Mon May 31 14:36:03 2021 +0800

    dmaengine: rcar-dmac: Fix PM reference leak in rcar_dmac_probe()
    
    [ Upstream commit dea8464ddf553803382efb753b6727dbf3931d06 ]
    
    pm_runtime_get_sync will increment pm usage counter even it failed.
    Forgetting to putting operation will result in reference leak here.
    Fix it by replacing it with pm_runtime_resume_and_get to keep usage
    counter balanced.
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Zou Wei <zou_wei@huawei.com>
    Reviewed-by: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
    Reviewed-by: Geert Uytterhoeven <geert+renesas@glider.be>
    Link: https://lore.kernel.org/r/1622442963-54095-1-git-send-email-zou_wei@huawei.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d79b7bb9540bfc7272cfda88c07f2866d0633831
Author: Jiapeng Chong <jiapeng.chong@linux.alibaba.com>
Date:   Wed Jun 2 18:07:26 2021 +0800

    dmaengine: idxd: Fix missing error code in idxd_cdev_open()
    
    [ Upstream commit 99b18e88a1cf737ae924123d63b46d9a3d17b1af ]
    
    The error code is missing in this code scenario, add the error code
    '-EINVAL' to the return value 'rc'.
    
    Eliminate the follow smatch warning:
    
    drivers/dma/idxd/cdev.c:113 idxd_cdev_open() warn: missing error code
    'rc'.
    
    Reported-by: Abaci Robot <abaci@linux.alibaba.com>
    Signed-off-by: Jiapeng Chong <jiapeng.chong@linux.alibaba.com>
    Acked-by: Dave Jiang <dave.jiang@intel.com>
    Link: https://lore.kernel.org/r/1622628446-87909-1-git-send-email-jiapeng.chong@linux.alibaba.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c84ccd00b25521f349ceca3f0b36b2410635c225
Author: Du Cheng <ducheng2@gmail.com>
Date:   Wed Apr 28 14:39:41 2021 +0800

    cfg80211: call cfg80211_leave_ocb when switching away from OCB
    
    [ Upstream commit a64b6a25dd9f984ed05fade603a00e2eae787d2f ]
    
    If the userland switches back-and-forth between NL80211_IFTYPE_OCB and
    NL80211_IFTYPE_ADHOC via send_msg(NL80211_CMD_SET_INTERFACE), there is a
    chance where the cleanup cfg80211_leave_ocb() is not called. This leads
    to initialization of in-use memory (e.g. init u.ibss while in-use by
    u.ocb) due to a shared struct/union within ieee80211_sub_if_data:
    
    struct ieee80211_sub_if_data {
        ...
        union {
            struct ieee80211_if_ap ap;
            struct ieee80211_if_vlan vlan;
            struct ieee80211_if_managed mgd;
            struct ieee80211_if_ibss ibss; // <- shares address
            struct ieee80211_if_mesh mesh;
            struct ieee80211_if_ocb ocb; // <- shares address
            struct ieee80211_if_mntr mntr;
            struct ieee80211_if_nan nan;
        } u;
        ...
    }
    
    Therefore add handling of otype == NL80211_IFTYPE_OCB, during
    cfg80211_change_iface() to perform cleanup when leaving OCB mode.
    
    link to syzkaller bug:
    https://syzkaller.appspot.com/bug?id=0612dbfa595bf4b9b680ff7b4948257b8e3732d5
    
    Reported-by: syzbot+105896fac213f26056f9@syzkaller.appspotmail.com
    Signed-off-by: Du Cheng <ducheng2@gmail.com>
    Link: https://lore.kernel.org/r/20210428063941.105161-1-ducheng2@gmail.com
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7019c9f385b264a2d6f685028268422d55087e37
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Mon May 17 17:04:31 2021 +0200

    mac80211_hwsim: drop pending frames on stop
    
    [ Upstream commit bd18de517923903a177508fc8813f44e717b1c00 ]
    
    Syzbot reports that we may be able to get into a situation where
    mac80211 has pending ACK frames on shutdown with hwsim. It appears
    that the reason for this is that syzbot uses the wmediumd hooks to
    intercept/injection frames, and may shut down hwsim, removing the
    radio(s), while frames are pending in the air simulation.
    
    Clean out the pending queue when the interface is stopped, after
    this the frames can't be reported back to mac80211 properly anyway.
    
    Reported-by: syzbot+a063bbf0b15737362592@syzkaller.appspotmail.com
    Link: https://lore.kernel.org/r/20210517170429.b0f85ab0eda1.Ie42a6ec6b940c971f3441286aeaaae2fe368e29a@changeid
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 93e9f3fbafe3ebe8d060c11a425a08fad1885f23
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Mon May 17 16:47:17 2021 +0200

    mac80211: remove warning in ieee80211_get_sband()
    
    [ Upstream commit 0ee4d55534f82a0624701d0bb9fc2304d4529086 ]
    
    Syzbot reports that it's possible to hit this from userspace,
    by trying to add a station before any other connection setup
    has been done. Instead of trying to catch this in some other
    way simply remove the warning, that will appropriately reject
    the call from userspace.
    
    Reported-by: syzbot+7716dbc401d9a437890d@syzkaller.appspotmail.com
    Link: https://lore.kernel.org/r/20210517164715.f537da276d17.Id05f40ec8761d6a8cc2df87f1aa09c651988a586@changeid
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 105d84c27974802d878246a96c93927398753ae4
Author: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
Date:   Thu May 20 18:24:20 2021 +0300

    dmaengine: xilinx: dpdma: Limit descriptor IDs to 16 bits
    
    [ Upstream commit 9f007e7b6643799e2a6538a5fe04f51c371c6657 ]
    
    While the descriptor ID is stored in a 32-bit field in the hardware
    descriptor, only 16 bits are used by the hardware and are reported
    through the XILINX_DPDMA_CH_DESC_ID register. Failure to handle the
    wrap-around results in a descriptor ID mismatch after 65536 frames. Fix
    it.
    
    Signed-off-by: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
    Tested-by: Jianqiang Chen <jianqiang.chen@xilinx.com>
    Reviewed-by: Jianqiang Chen <jianqiang.chen@xilinx.com>
    Link: https://lore.kernel.org/r/20210520152420.23986-5-laurent.pinchart@ideasonboard.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e442acb8dfcf9059ff9b37e90d0252c8e21c0262
Author: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
Date:   Thu May 20 18:24:17 2021 +0300

    dmaengine: xilinx: dpdma: Add missing dependencies to Kconfig
    
    [ Upstream commit 32828b82fb875b06511918b139d3a3cd93d34262 ]
    
    The driver depends on both OF and IOMEM support, express those
    dependencies in Kconfig. This fixes a build failure on S390 reported by
    the 0day bot.
    
    Reported-by: kernel test robot <lkp@intel.com>
    Signed-off-by: Laurent Pinchart <laurent.pinchart@ideasonboard.com>
    Tested-by: Jianqiang Chen <jianqiang.chen@xilinx.com>
    Reviewed-by: Jianqiang Chen <jianqiang.chen@xilinx.com>
    Link: https://lore.kernel.org/r/20210520152420.23986-2-laurent.pinchart@ideasonboard.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3e7da85cf916ac12acb6dffee22bc9bb9a20913c
Author: Yu Kuai <yukuai3@huawei.com>
Date:   Mon May 17 16:18:24 2021 +0800

    dmaengine: stm32-mdma: fix PM reference leak in stm32_mdma_alloc_chan_resourc()
    
    [ Upstream commit 83eb4868d325b86e18509d0874e911497667cb54 ]
    
    pm_runtime_get_sync will increment pm usage counter even it failed.
    Forgetting to putting operation will result in reference leak here.
    Fix it by replacing it with pm_runtime_resume_and_get to keep usage
    counter balanced.
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Yu Kuai <yukuai3@huawei.com>
    Link: https://lore.kernel.org/r/20210517081826.1564698-2-yukuai3@huawei.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a300c3ff0c17a806f993e74ef2ddf2dc26eaf878
Author: Yu Kuai <yukuai3@huawei.com>
Date:   Mon May 17 16:18:26 2021 +0800

    dmaengine: zynqmp_dma: Fix PM reference leak in zynqmp_dma_alloc_chan_resourc()
    
    [ Upstream commit 8982d48af36d2562c0f904736b0fc80efc9f2532 ]
    
    pm_runtime_get_sync will increment pm usage counter even it failed.
    Forgetting to putting operation will result in reference leak here.
    Fix it by replacing it with pm_runtime_resume_and_get to keep usage
    counter balanced.
    
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Yu Kuai <yukuai3@huawei.com>
    Link: https://lore.kernel.org/r/20210517081826.1564698-4-yukuai3@huawei.com
    Signed-off-by: Vinod Koul <vkoul@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6d8af08a452e304d03f3c3e8cf379f27b2c1ff47
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Fri Jun 11 15:03:16 2021 +0200

    perf/x86/intel/lbr: Zero the xstate buffer on allocation
    
    [ Upstream commit 7f049fbdd57f6ea71dc741d903c19c73b2f70950 ]
    
    XRSTORS requires a valid xstate buffer to work correctly. XSAVES does not
    guarantee to write a fully valid buffer according to the SDM:
    
      "XSAVES does not write to any parts of the XSAVE header other than the
       XSTATE_BV and XCOMP_BV fields."
    
    XRSTORS triggers a #GP:
    
      "If bytes 63:16 of the XSAVE header are not all zero."
    
    It's dubious at best how this can work at all when the buffer is not zeroed
    before use.
    
    Allocate the buffers with __GFP_ZERO to prevent XRSTORS failure.
    
    Fixes: ce711ea3cab9 ("perf/x86/intel/lbr: Support XSAVES/XRSTORS for LBR context switch")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/87wnr0wo2z.ffs@nanos.tec.linutronix.de
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7ad4a4bfb8b7012577482342ac2bd66d31817d27
Author: Like Xu <like.xu@linux.intel.com>
Date:   Fri Apr 30 13:22:47 2021 +0800

    perf/x86/lbr: Remove cpuc->lbr_xsave allocation from atomic context
    
    [ Upstream commit 488e13a489e9707a7e81e1991fdd1f20c0f04689 ]
    
    If the kernel is compiled with the CONFIG_LOCKDEP option, the conditional
    might_sleep_if() deep in kmem_cache_alloc() will generate the following
    trace, and potentially cause a deadlock when another LBR event is added:
    
      [] BUG: sleeping function called from invalid context at include/linux/sched/mm.h:196
      [] Call Trace:
      []  kmem_cache_alloc+0x36/0x250
      []  intel_pmu_lbr_add+0x152/0x170
      []  x86_pmu_add+0x83/0xd0
    
    Make it symmetric with the release_lbr_buffers() call and mirror the
    existing DS buffers.
    
    Fixes: c085fb8774 ("perf/x86/intel/lbr: Support XSAVES for arch LBR read")
    Signed-off-by: Like Xu <like.xu@linux.intel.com>
    [peterz: simplified]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Kan Liang <kan.liang@linux.intel.com>
    Link: https://lkml.kernel.org/r/20210430052247.3079672-2-like.xu@linux.intel.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 49a122ae9c6627cccace69e59feb148ecbd2400a
Author: Zhen Lei <thunder.leizhen@huawei.com>
Date:   Thu May 13 21:46:38 2021 +0800

    drm/kmb: Fix error return code in kmb_hw_init()
    
    [ Upstream commit 6fd8f323b3e4e5290d02174559308669507c00dd ]
    
    When the call to platform_get_irq() to obtain the IRQ of the lcd fails, the
    returned error code should be propagated. However, we currently do not
    explicitly assign this error code to 'ret'. As a result, 0 was incorrectly
    returned.
    
    Fixes: 7f7b96a8a0a1 ("drm/kmb: Add support for KeemBay Display")
    Reported-by: Hulk Robot <hulkci@huawei.com>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Signed-off-by: Anitha Chrisanthus <anitha.chrisanthus@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20210513134639.6541-1-thunder.leizhen@huawei.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a8faa6a1112c7408171c24a87b2b9e4aeb983514
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 21 13:12:38 2021 +0200

    locking/lockdep: Improve noinstr vs errors
    
    [ Upstream commit 49faa77759b211fff344898edc23bb780707fff5 ]
    
    Better handle the failure paths.
    
      vmlinux.o: warning: objtool: debug_locks_off()+0x23: call to console_verbose() leaves .noinstr.text section
      vmlinux.o: warning: objtool: debug_locks_off()+0x19: call to __kasan_check_write() leaves .noinstr.text section
    
      debug_locks_off+0x19/0x40:
      instrument_atomic_write at include/linux/instrumented.h:86
      (inlined by) __debug_locks_off at include/linux/debug_locks.h:17
      (inlined by) debug_locks_off at lib/debug_locks.c:41
    
    Fixes: 6eebad1ad303 ("lockdep: __always_inline more for noinstr")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20210621120120.784404944@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 16349865b7a517b3cdefd60db27fa73ad777676e
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 21 13:12:36 2021 +0200

    x86/xen: Fix noinstr fail in exc_xen_unknown_trap()
    
    [ Upstream commit 4c9c26f1e67648f41f28f8c997c5c9467a3dbbe4 ]
    
    Fix:
    
      vmlinux.o: warning: objtool: exc_xen_unknown_trap()+0x7: call to printk() leaves .noinstr.text section
    
    Fixes: 2e92493637a0 ("x86/xen: avoid warning in Xen pv guest with CONFIG_AMD_MEM_ENCRYPT enabled")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20210621120120.606560778@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1455ac355c5fb8d9deb398e54d5116c9b2098085
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 21 13:12:35 2021 +0200

    x86/xen: Fix noinstr fail in xen_pv_evtchn_do_upcall()
    
    [ Upstream commit 84e60065df9ef03759115a7e48c04bbc0d292165 ]
    
    Fix:
    
      vmlinux.o: warning: objtool: xen_pv_evtchn_do_upcall()+0x23: call to irq_enter_rcu() leaves .noinstr.text section
    
    Fixes: 359f01d1816f ("x86/entry: Use run_sysvec_on_irqstack_cond() for XEN upcall")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20210621120120.532960208@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a48373603da835945528e85f21510ee648f702d6
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 21 13:12:34 2021 +0200

    x86/entry: Fix noinstr fail in __do_fast_syscall_32()
    
    [ Upstream commit 240001d4e3041832e8a2654adc3ccf1683132b92 ]
    
    Fix:
    
      vmlinux.o: warning: objtool: __do_fast_syscall_32()+0xf5: call to trace_hardirqs_off() leaves .noinstr.text section
    
    Fixes: 5d5675df792f ("x86/entry: Fix entry/exit mismatch on failed fast 32-bit syscalls")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20210621120120.467898710@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d923261e73d0ac084e908e4c07d63b8c4777682f
Author: Maxime Ripard <maxime@cerno.tech>
Date:   Tue May 25 11:10:59 2021 +0200

    drm/vc4: hdmi: Make sure the controller is powered in detect
    
    [ Upstream commit 9984d6664ce9dcbbc713962539eaf7636ea246c2 ]
    
    If the HPD GPIO is not available and drm_probe_ddc fails, we end up
    reading the HDMI_HOTPLUG register, but the controller might be powered
    off resulting in a CPU hang. Make sure we have the power domain and the
    HSM clock powered during the detect cycle to prevent the hang from
    happening.
    
    Fixes: 4f6e3d66ac52 ("drm/vc4: Add runtime PM support to the HDMI encoder driver")
    Signed-off-by: Maxime Ripard <maxime@cerno.tech>
    Reviewed-by: Dave Stevenson <dave.stevenson@raspberrypi.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20210525091059.234116-4-maxime@cerno.tech
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0a4f5173a8cb49c0e22c8c3f0e8b52a8b22ecd04
Author: Maxime Ripard <maxime@cerno.tech>
Date:   Tue May 25 11:10:58 2021 +0200

    drm/vc4: hdmi: Move the HSM clock enable to runtime_pm
    
    [ Upstream commit 411efa18e4b03840553ff58ad9b4621b82a30c04 ]
    
    In order to access the HDMI controller, we need to make sure the HSM
    clock is enabled. If we were to access it with the clock disabled, the
    CPU would completely hang, resulting in an hard crash.
    
    Since we have different code path that would require it, let's move that
    clock enable / disable to runtime_pm that will take care of the
    reference counting for us.
    
    Fixes: 4f6e3d66ac52 ("drm/vc4: Add runtime PM support to the HDMI encoder driver")
    Signed-off-by: Maxime Ripard <maxime@cerno.tech>
    Reviewed-by: Dave Stevenson <dave.stevenson@raspberrypi.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20210525091059.234116-3-maxime@cerno.tech
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 133ad06e0419eea137cce7b0c453b9c9622de161
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Tue Jun 22 17:35:18 2021 +0200

    Revert "PCI: PM: Do not read power state in pci_enable_device_flags()"
    
    [ Upstream commit 4d6035f9bf4ea12776322746a216e856dfe46698 ]
    
    Revert commit 4514d991d992 ("PCI: PM: Do not read power state in
    pci_enable_device_flags()") that is reported to cause PCI device
    initialization issues on some systems.
    
    BugLink: https://bugzilla.kernel.org/show_bug.cgi?id=213481
    Link: https://lore.kernel.org/linux-acpi/YNDoGICcg0V8HhpQ@eldamar.lan
    Reported-by: Michael <phyre@rogers.com>
    Reported-by: Salvatore Bonaccorso <carnil@debian.org>
    Fixes: 4514d991d992 ("PCI: PM: Do not read power state in pci_enable_device_flags()")
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0869bd265b8a5c2f04bacc8c3dbe9f5410cec4c9
Author: Haibo Chen <haibo.chen@nxp.com>
Date:   Thu Jun 10 17:24:33 2021 +0800

    spi: spi-nxp-fspi: move the register operation after the clock enable
    
    [ Upstream commit f422316c8e9d3c4aff3c56549dfb44a677d02f14 ]
    
    Move the register operation after the clock enable, otherwise system
    will stuck when this driver probe.
    
    Fixes: 71d80563b076 ("spi: spi-nxp-fspi: fix fspi panic by unexpected interrupts")
    Signed-off-by: Haibo Chen <haibo.chen@nxp.com>
    Link: https://lore.kernel.org/r/1623317073-25158-1-git-send-email-haibo.chen@nxp.com
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 82fde4cde569f203f8f75afae06fd390c7d1ef0f
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Mon May 3 13:49:17 2021 -0400

    psi: Fix psi state corruption when schedule() races with cgroup move
    
    commit d583d360a620e6229422b3455d0be082b8255f5e upstream.
    
    4117cebf1a9f ("psi: Optimize task switch inside shared cgroups")
    introduced a race condition that corrupts internal psi state. This
    manifests as kernel warnings, sometimes followed by bogusly high IO
    pressure:
    
      psi: task underflow! cpu=1 t=2 tasks=[0 0 0 0] clear=c set=0
      (schedule() decreasing RUNNING and ONCPU, both of which are 0)
    
      psi: incosistent task state! task=2412744:systemd cpu=17 psi_flags=e clear=3 set=0
      (cgroup_move_task() clearing MEMSTALL and IOWAIT, but task is MEMSTALL | RUNNING | ONCPU)
    
    What the offending commit does is batch the two psi callbacks in
    schedule() to reduce the number of cgroup tree updates. When prev is
    deactivated and removed from the runqueue, nothing is done in psi at
    first; when the task switch completes, TSK_RUNNING and TSK_IOWAIT are
    updated along with TSK_ONCPU.
    
    However, the deactivation and the task switch inside schedule() aren't
    atomic: pick_next_task() may drop the rq lock for load balancing. When
    this happens, cgroup_move_task() can run after the task has been
    physically dequeued, but the psi updates are still pending. Since it
    looks at the task's scheduler state, it doesn't move everything to the
    new cgroup that the task switch that follows is about to clear from
    it. cgroup_move_task() will leak the TSK_RUNNING count in the old
    cgroup, and psi_sched_switch() will underflow it in the new cgroup.
    
    A similar thing can happen for iowait. TSK_IOWAIT is usually set when
    a p->in_iowait task is dequeued, but again this update is deferred to
    the switch. cgroup_move_task() can see an unqueued p->in_iowait task
    and move a non-existent TSK_IOWAIT. This results in the inconsistent
    task state warning, as well as a counter underflow that will result in
    permanent IO ghost pressure being reported.
    
    Fix this bug by making cgroup_move_task() use task->psi_flags instead
    of looking at the potentially mismatching scheduler state.
    
    [ We used the scheduler state historically in order to not rely on
      task->psi_flags for anything but debugging. But that ship has sailed
      anyway, and this is simpler and more robust.
    
      We previously already batched TSK_ONCPU clearing with the
      TSK_RUNNING update inside the deactivation call from schedule(). But
      that ordering was safe and didn't result in TSK_ONCPU corruption:
      unlike most places in the scheduler, cgroup_move_task() only checked
      task_current() and handled TSK_ONCPU if the task was still queued. ]
    
    Fixes: 4117cebf1a9f ("psi: Optimize task switch inside shared cgroups")
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20210503174917.38579-1-hannes@cmpxchg.org
    Cc: Oleksandr Natalenko <oleksandr@natalenko.name>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d698344a97bdc295932c8e7f1876ace9d39bd928
Author: Neil Armstrong <narmstrong@baylibre.com>
Date:   Wed Jun 9 17:02:30 2021 +0200

    mmc: meson-gx: use memcpy_to/fromio for dram-access-quirk
    
    commit 103a5348c22c3fca8b96c735a9e353b8a0801842 upstream.
    
    It has been reported that usage of memcpy() to/from an iomem mapping is invalid,
    and a recent arm64 memcpy update [1] triggers a memory abort when dram-access-quirk
    is used on the G12A/G12B platforms.
    
    This adds a local sg_copy_to_buffer which makes usage of io versions of memcpy
    when dram-access-quirk is enabled.
    
    [1] 285133040e6c ("arm64: Import latest memcpy()/memmove() implementation")
    
    Fixes: acdc8e71d9bb ("mmc: meson-gx: add dram-access-quirk")
    Reported-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Suggested-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Neil Armstrong <narmstrong@baylibre.com>
    Tested-by: Marek Szyprowski <m.szyprowski@samsung.com>
    Link: https://lore.kernel.org/r/20210609150230.9291-1-narmstrong@baylibre.com
    Cc: stable@vger.kernel.org
    Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fb1039fb3b7f469f0199ca11265a96fb4970288f
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri May 14 11:26:37 2021 +0100

    ARM: 9081/1: fix gcc-10 thumb2-kernel regression
    
    commit dad7b9896a5dbac5da8275d5a6147c65c81fb5f2 upstream.
    
    When building the kernel wtih gcc-10 or higher using the
    CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y flag, the compiler picks a slightly
    different set of registers for the inline assembly in cpu_init() that
    subsequently results in a corrupt kernel stack as well as remaining in
    FIQ mode. If a banked register is used for the last argument, the wrong
    version of that register gets loaded into CPSR_c.  When building in Arm
    mode, the arguments are passed as immediate values and the bug cannot
    happen.
    
    This got introduced when Daniel reworked the FIQ handling and was
    technically always broken, but happened to work with both clang and gcc
    before gcc-10 as long as they picked one of the lower registers.
    This is probably an indication that still very few people build the
    kernel in Thumb2 mode.
    
    Marek pointed out the problem on IRC, Arnd narrowed it down to this
    inline assembly and Russell pinpointed the exact bug.
    
    Change the constraints to force the final mode switch to use a non-banked
    register for the argument to ensure that the correct constant gets loaded.
    Another alternative would be to always use registers for the constant
    arguments to avoid the #ifdef that has now become more complex.
    
    Cc: <stable@vger.kernel.org> # v3.18+
    Cc: Daniel Thompson <daniel.thompson@linaro.org>
    Reported-by: Marek Vasut <marek.vasut@gmail.com>
    Acked-by: Ard Biesheuvel <ardb@kernel.org>
    Fixes: c0e7f7ee717e ("ARM: 8150/3: fiq: Replace default FIQ handler")
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 83a0369de87e5bcf3b20fe7e14c5d8fecad9ec8e
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jun 21 14:29:14 2021 +0200

    drm/amdgpu: wait for moving fence after pinning
    
    commit 8ddf5b9bb479570a3825d70fecfb9399bc15700c upstream.
    
    We actually need to wait for the moving fence after pinning
    the BO to make sure that the pin is completed.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    References: https://lore.kernel.org/dri-devel/20210621151758.2347474-1-daniel.vetter@ffwll.ch/
    CC: stable@kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20210622114506.106349-3-christian.koenig@amd.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit abaafb91c935426d8d568f9320ba75ee3f374242
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jun 21 13:43:05 2021 +0200

    drm/radeon: wait for moving fence after pinning
    
    commit 4b41726aae563273bb4b4a9462ba51ce4d372f78 upstream.
    
    We actually need to wait for the moving fence after pinning
    the BO to make sure that the pin is completed.
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    References: https://lore.kernel.org/dri-devel/20210621151758.2347474-1-daniel.vetter@ffwll.ch/
    CC: stable@kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20210622114506.106349-2-christian.koenig@amd.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8361b40cc355eb08cb630dd5e0f91adb52aac4e5
Author: Christian König <christian.koenig@amd.com>
Date:   Mon Jun 21 13:36:35 2021 +0200

    drm/nouveau: wait for moving fence after pinning v2
    
    commit 17b11f71795abdce46f62a808f906857e525cea8 upstream.
    
    We actually need to wait for the moving fence after pinning
    the BO to make sure that the pin is completed.
    
    v2: grab the lock while waiting
    
    Signed-off-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    References: https://lore.kernel.org/dri-devel/20210621151758.2347474-1-daniel.vetter@ffwll.ch/
    CC: stable@kernel.org
    Link: https://patchwork.freedesktop.org/patch/msgid/20210622114506.106349-1-christian.koenig@amd.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 58bc23d2841724477935036411501d7a37252811
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Sun Jun 20 19:03:26 2021 +0800

    drm: add a locked version of drm_is_current_master
    
    commit 1815d9c86e3090477fbde066ff314a7e9721ee0f upstream.
    
    While checking the master status of the DRM file in
    drm_is_current_master(), the device's master mutex should be
    held. Without the mutex, the pointer fpriv->master may be freed
    concurrently by another process calling drm_setmaster_ioctl(). This
    could lead to use-after-free errors when the pointer is subsequently
    dereferenced in drm_lease_owner().
    
    The callers of drm_is_current_master() from drm_auth.c hold the
    device's master mutex, but external callers do not. Hence, we implement
    drm_is_current_master_locked() to be used within drm_auth.c, and
    modify drm_is_current_master() to grab the device's master mutex
    before checking the master status.
    
    Reported-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Reviewed-by: Emil Velikov <emil.l.velikov@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Link: https://patchwork.freedesktop.org/patch/msgid/20210620110327.4964-2-desmondcheongzx@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07553a027bf9b166877b9b700749d092b8f7e0e0
Author: Yifan Zhang <yifan1.zhang@amd.com>
Date:   Sat Jun 19 11:39:43 2021 +0800

    Revert "drm/amdgpu/gfx10: enlarge CP_MEC_DOORBELL_RANGE_UPPER to cover full doorbell."
    
    commit baacf52a473b24e10322b67757ddb92ab8d86717 upstream.
    
    This reverts commit 1c0b0efd148d5b24c4932ddb3fa03c8edd6097b3.
    
    Reason for revert: Side effect of enlarging CP_MEC_DOORBELL_RANGE may
    cause some APUs fail to enter gfxoff in certain user cases.
    
    Signed-off-by: Yifan Zhang <yifan1.zhang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c798a995cb39fe11fb71681306e4c74c348ff7a7
Author: Yifan Zhang <yifan1.zhang@amd.com>
Date:   Sat Jun 19 11:40:54 2021 +0800

    Revert "drm/amdgpu/gfx9: fix the doorbell missing when in CGPG issue."
    
    commit ee5468b9f1d3bf48082eed351dace14598e8ca39 upstream.
    
    This reverts commit 4cbbe34807938e6e494e535a68d5ff64edac3f20.
    
    Reason for revert: side effect of enlarging CP_MEC_DOORBELL_RANGE may
    cause some APUs fail to enter gfxoff in certain user cases.
    
    Signed-off-by: Yifan Zhang <yifan1.zhang@amd.com>
    Acked-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 404dd3af590ac67740eeb9c027879945bd2a3c13
Author: Mimi Zohar <zohar@linux.ibm.com>
Date:   Tue Jun 22 13:36:41 2021 +0200

    module: limit enabling module.sig_enforce
    
    [ Upstream commit 0c18f29aae7ce3dadd26d8ee3505d07cc982df75 ]
    
    Irrespective as to whether CONFIG_MODULE_SIG is configured, specifying
    "module.sig_enforce=1" on the boot command line sets "sig_enforce".
    Only allow "sig_enforce" to be set when CONFIG_MODULE_SIG is configured.
    
    This patch makes the presence of /sys/module/module/parameters/sig_enforce
    dependent on CONFIG_MODULE_SIG=y.
    
    Fixes: fda784e50aac ("module: export module signature enforcement status")
    Reported-by: Nayna Jain <nayna@linux.ibm.com>
    Tested-by: Mimi Zohar <zohar@linux.ibm.com>
    Tested-by: Jessica Yu <jeyu@kernel.org>
    Signed-off-by: Mimi Zohar <zohar@linux.ibm.com>
    Signed-off-by: Jessica Yu <jeyu@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>
