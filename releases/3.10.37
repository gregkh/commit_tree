commit f512eefd5cde0ad21bd99bbfe4dc70b62805838e
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Apr 14 06:42:31 2014 -0700

    Linux 3.10.37

commit d8996f63abe5a9d9b24f7a4df2c8459659d0e76f
Author: Stephen Boyd <sboyd@codeaurora.org>
Date:   Tue Aug 27 11:47:29 2013 -0700

    cpufreq: Fix timer/workqueue corruption due to double queueing
    
    commit 3617f2ca6d0eba48114308532945a7f1577816a4 upstream.
    
    When a CPU is hot removed we'll cancel all the delayed work items
    via gov_cancel_work(). Normally this will just cancels a delayed
    timer on each CPU that the policy is managing and the work won't
    run, but if the work is already running the workqueue code will
    wait for the work to finish before continuing to prevent the
    work items from re-queuing themselves like they normally do. This
    scheme will work most of the time, except for the case where the
    work function determines that it should adjust the delay for all
    other CPUs that the policy is managing. If this scenario occurs,
    the canceling CPU will cancel its own work but queue up the other
    CPUs works to run. For example:
    
     CPU0                                        CPU1
     ----                                        ----
     cpu_down()
      ...
      __cpufreq_remove_dev()
       cpufreq_governor_dbs()
        case CPUFREQ_GOV_STOP:
         gov_cancel_work(dbs_data, policy);
          cpu0 work is canceled
           timer is canceled
           cpu1 work is canceled                    <work runs>
           <waits for cpu1>                         od_dbs_timer()
                                                     gov_queue_work(*, *, true);
                                                      cpu0 work queued
                                                      cpu1 work queued
                                                      cpu2 work queued
                                                      ...
           cpu1 work is canceled
           cpu2 work is canceled
           ...
    
    At the end of the GOV_STOP case cpu0 still has a work queued to
    run although the code is expecting all of the works to be
    canceled. __cpufreq_remove_dev() will then proceed to
    re-initialize all the other CPUs works except for the CPU that is
    going down. The CPUFREQ_GOV_START case in cpufreq_governor_dbs()
    will trample over the queued work and debugobjects will spit out
    a warning:
    
    WARNING: at lib/debugobjects.c:260 debug_print_object+0x94/0xbc()
    ODEBUG: init active (active state 0) object type: timer_list hint: delayed_work_timer_fn+0x0/0x10
    Modules linked in:
    CPU: 0 PID: 1491 Comm: sh Tainted: G        W    3.10.0 #19
    [<c010c178>] (unwind_backtrace+0x0/0x11c) from [<c0109dec>] (show_stack+0x10/0x14)
    [<c0109dec>] (show_stack+0x10/0x14) from [<c01904cc>] (warn_slowpath_common+0x4c/0x6c)
    [<c01904cc>] (warn_slowpath_common+0x4c/0x6c) from [<c019056c>] (warn_slowpath_fmt+0x2c/0x3c)
    [<c019056c>] (warn_slowpath_fmt+0x2c/0x3c) from [<c0388a7c>] (debug_print_object+0x94/0xbc)
    [<c0388a7c>] (debug_print_object+0x94/0xbc) from [<c0388e34>] (__debug_object_init+0x2d0/0x340)
    [<c0388e34>] (__debug_object_init+0x2d0/0x340) from [<c019e3b0>] (init_timer_key+0x14/0xb0)
    [<c019e3b0>] (init_timer_key+0x14/0xb0) from [<c0635f78>] (cpufreq_governor_dbs+0x3e8/0x5f8)
    [<c0635f78>] (cpufreq_governor_dbs+0x3e8/0x5f8) from [<c06325a0>] (__cpufreq_governor+0xdc/0x1a4)
    [<c06325a0>] (__cpufreq_governor+0xdc/0x1a4) from [<c0633704>] (__cpufreq_remove_dev.isra.10+0x3b4/0x434)
    [<c0633704>] (__cpufreq_remove_dev.isra.10+0x3b4/0x434) from [<c08989f4>] (cpufreq_cpu_callback+0x60/0x80)
    [<c08989f4>] (cpufreq_cpu_callback+0x60/0x80) from [<c08a43c0>] (notifier_call_chain+0x38/0x68)
    [<c08a43c0>] (notifier_call_chain+0x38/0x68) from [<c01938e0>] (__cpu_notify+0x28/0x40)
    [<c01938e0>] (__cpu_notify+0x28/0x40) from [<c0892ad4>] (_cpu_down+0x7c/0x2c0)
    [<c0892ad4>] (_cpu_down+0x7c/0x2c0) from [<c0892d3c>] (cpu_down+0x24/0x40)
    [<c0892d3c>] (cpu_down+0x24/0x40) from [<c0893ea8>] (store_online+0x2c/0x74)
    [<c0893ea8>] (store_online+0x2c/0x74) from [<c04519d8>] (dev_attr_store+0x18/0x24)
    [<c04519d8>] (dev_attr_store+0x18/0x24) from [<c02a69d4>] (sysfs_write_file+0x100/0x148)
    [<c02a69d4>] (sysfs_write_file+0x100/0x148) from [<c0255c18>] (vfs_write+0xcc/0x174)
    [<c0255c18>] (vfs_write+0xcc/0x174) from [<c0255f70>] (SyS_write+0x38/0x64)
    [<c0255f70>] (SyS_write+0x38/0x64) from [<c0106120>] (ret_fast_syscall+0x0/0x30)
    
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>
    Acked-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Krzysztof Kozlowski <k.kozlowski@samsung.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ba17ca46b968001df16f672ffe694fd0a12512f2
Author: Xiaoguang Chen <chenxg@marvell.com>
Date:   Wed Jun 19 15:00:07 2013 +0800

    cpufreq: Fix governor start/stop race condition
    
    commit 95731ebb114c5f0c028459388560fc2a72fe5049 upstream.
    
    Cpufreq governors' stop and start operations should be carried out
    in sequence.  Otherwise, there will be unexpected behavior, like in
    the example below.
    
    Suppose there are 4 CPUs and policy->cpu=CPU0, CPU1/2/3 are linked
    to CPU0.  The normal sequence is:
    
     1) Current governor is userspace.  An application tries to set the
        governor to ondemand.  It will call __cpufreq_set_policy() in
        which it will stop the userspace governor and then start the
        ondemand governor.
    
     2) Current governor is userspace.  The online of CPU3 runs on CPU0.
        It will call cpufreq_add_policy_cpu() in which it will first
        stop the userspace governor, and then start it again.
    
    If the sequence of the above two cases interleaves, it becomes:
    
     1) Application stops userspace governor
     2)                                  Hotplug stops userspace governor
    
    which is a problem, because the governor shouldn't be stopped twice
    in a row.  What happens next is:
    
     3) Application starts ondemand governor
     4)                                  Hotplug starts a governor
    
    In step 4, the hotplug is supposed to start the userspace governor,
    but now the governor has been changed by the application to ondemand,
    so the ondemand governor is started once again, which is incorrect.
    
    The solution is to prevent policy governors from being stopped
    multiple times in a row.  A governor should only be stopped once for
    one policy.  After it has been stopped, no more governor stop
    operations should be executed.
    
    Also add a mutex to serialize governor operations.
    
    [rjw: Changelog.  And you owe me a beverage of my choice.]
    Signed-off-by: Xiaoguang Chen <chenxg@marvell.com>
    Acked-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Krzysztof Kozlowski <k.kozlowski@samsung.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 87f93ce8004df49c51813ac113047ac22bced3c9
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Thu Mar 27 18:14:40 2014 +0100

    crypto: ghash-clmulni-intel - use C implementation for setkey()
    
    commit 8ceee72808d1ae3fb191284afc2257a2be964725 upstream.
    
    The GHASH setkey() function uses SSE registers but fails to call
    kernel_fpu_begin()/kernel_fpu_end(). Instead of adding these calls, and
    then having to deal with the restriction that they cannot be called from
    interrupt context, move the setkey() implementation to the C domain.
    
    Note that setkey() does not use any particular SSE features and is not
    expected to become a performance bottleneck.
    
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Acked-by: H. Peter Anvin <hpa@linux.intel.com>
    Fixes: 0e1227d356e9b (crypto: ghash - Add PCLMULQDQ accelerated implementation)
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fb60550a0878602086f6a00e20553240270ad6aa
Author: Finn Thain <fthain@telegraphics.com.au>
Date:   Thu Mar 6 10:29:27 2014 +1100

    m68k: Skip futex_atomic_cmpxchg_inatomic() test
    
    commit e571c58f313d35c56e0018470e3375ddd1fd320e upstream.
    
    Skip the futex_atomic_cmpxchg_inatomic() test in futex_init(). It causes a
    fatal exception on 68030 (and presumably 68020 also).
    
    Signed-off-by: Finn Thain <fthain@telegraphics.com.au>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Link: http://lkml.kernel.org/r/alpine.LNX.2.00.1403061006440.5525@nippy.intranet
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f26c70a452dc0507bf7d3d2c3158ee7808e14f1c
Author: Heiko Carstens <heiko.carstens@de.ibm.com>
Date:   Sun Mar 2 13:09:47 2014 +0100

    futex: Allow architectures to skip futex_atomic_cmpxchg_inatomic() test
    
    commit 03b8c7b623c80af264c4c8d6111e5c6289933666 upstream.
    
    If an architecture has futex_atomic_cmpxchg_inatomic() implemented and there
    is no runtime check necessary, allow to skip the test within futex_init().
    
    This allows to get rid of some code which would always give the same result,
    and also allows the compiler to optimize a couple of if statements away.
    
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Cc: Finn Thain <fthain@telegraphics.com.au>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Link: http://lkml.kernel.org/r/20140302120947.GA3641@osiris
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [geert: Backported to v3.10..v3.13]
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 47c4534a109e45700d1d1c8467c2b5a618212d81
Author: Vineet Gupta <vgupta@synopsys.com>
Date:   Sat Apr 5 15:30:22 2014 +0530

    ARC: [nsimosci] Unbork console
    
    commit 61fb4bfc010b0d2940f7fd87acbce6a0f03217cb upstream.
    
    Despite the switch to right UART driver (prev patch), serial console
    still doesn't work due to missing CONFIG_SERIAL_OF_PLATFORM
    
    Also fix the default cmdline in DT to not refer to out-of-tree
    ARC framebuffer driver for console.
    
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Cc: Francois Bedard <Francois.Bedard@synopsys.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 74a834fb451d67910fc9e2fe8e611ff1e7568a55
Author: Mischa Jonker <mjonker@synopsys.com>
Date:   Thu May 16 19:36:08 2013 +0200

    ARC: [nsimosci] Change .dts to use generic 8250 UART
    
    commit 6eda477b3c54b8236868c8784e5e042ff14244f0 upstream.
    
    The Synopsys APB DW UART has a couple of special features that are not
    in the System C model. In 3.8, the 8250_dw driver didn't really use these
    features, but from 3.9 onwards, the 8250_dw driver has become incompatible
    with our model.
    
    Signed-off-by: Mischa Jonker <mjonker@synopsys.com>
    Signed-off-by: Vineet Gupta <vgupta@synopsys.com>
    Cc: Francois Bedard <Francois.Bedard@synopsys.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 752e4086d0b553125f416ebb1563f5e72febc01c
Author: Sasha Levin <sasha.levin@oracle.com>
Date:   Sat Mar 29 20:39:35 2014 -0400

    rds: prevent dereference of a NULL device in rds_iw_laddr_check
    
    [ Upstream commit bf39b4247b8799935ea91d90db250ab608a58e50 ]
    
    Binding might result in a NULL device which is later dereferenced
    without checking.
    
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ef533ea1fd707ca9815a1855bd5ff1af31695ea1
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Tue Apr 8 12:23:09 2014 +0300

    isdnloop: several buffer overflows
    
    [ Upstream commit 7563487cbf865284dcd35e9ef5a95380da046737 ]
    
    There are three buffer overflows addressed in this patch.
    
    1) In isdnloop_fake_err() we add an 'E' to a 60 character string and
    then copy it into a 60 character buffer.  I have made the destination
    buffer 64 characters and I'm changed the sprintf() to a snprintf().
    
    2) In isdnloop_parse_cmd(), p points to a 6 characters into a 60
    character buffer so we have 54 characters.  The ->eazlist[] is 11
    characters long.  I have modified the code to return if the source
    buffer is too long.
    
    3) In isdnloop_command() the cbuf[] array was 60 characters long but the
    max length of the string then can be up to 79 characters.  I made the
    cbuf array 80 characters long and changed the sprintf() to snprintf().
    I also removed the temporary "dial" buffer and changed it to use "p"
    directly.
    
    Unfortunately, we pass the "cbuf" string from isdnloop_command() to
    isdnloop_writecmd() which truncates anything over 60 characters to make
    it fit in card->omsg[].  (It can accept values up to 255 characters so
    long as there is a '\n' character every 60 characters).  For now I have
    just fixed the memory corruption bug and left the other problems in this
    driver alone.
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4a7a92aa5fa857a92b63507d3ef8ff0f668fbb21
Author: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
Date:   Wed Apr 2 12:48:42 2014 +0900

    isdnloop: Validate NUL-terminated strings from user.
    
    [ Upstream commit 77bc6bed7121936bb2e019a8c336075f4c8eef62 ]
    
    Return -EINVAL unless all of user-given strings are correctly
    NUL-terminated.
    
    Signed-off-by: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dbd3f730cf94e5ff51c196f6765a87e9e113ee64
Author: Pablo Neira <pablo@netfilter.org>
Date:   Tue Apr 1 19:38:44 2014 +0200

    netlink: don't compare the nul-termination in nla_strcmp
    
    [ Upstream commit 8b7b932434f5eee495b91a2804f5b64ebb2bc835 ]
    
    nla_strcmp compares the string length plus one, so it's implicitly
    including the nul-termination in the comparison.
    
     int nla_strcmp(const struct nlattr *nla, const char *str)
     {
            int len = strlen(str) + 1;
            ...
                    d = memcmp(nla_data(nla), str, len);
    
    However, if NLA_STRING is used, userspace can send us a string without
    the nul-termination. This is a problem since the string
    comparison will not match as the last byte may be not the
    nul-termination.
    
    Fix this by skipping the comparison of the nul-termination if the
    attribute data is nul-terminated. Suggested by Thomas Graf.
    
    Cc: Florian Westphal <fw@strlen.de>
    Cc: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2e6f312e108b9f5609d601c4988c479e5cc9330d
Author: Hannes Frederic Sowa <hannes@stressinduktion.org>
Date:   Mon Mar 31 20:14:10 2014 +0200

    ipv6: some ipv6 statistic counters failed to disable bh
    
    [ Upstream commit 43a43b6040165f7b40b5b489fe61a4cb7f8c4980 ]
    
    After commit c15b1ccadb323ea ("ipv6: move DAD and addrconf_verify
    processing to workqueue") some counters are now updated in process context
    and thus need to disable bh before doing so, otherwise deadlocks can
    happen on 32-bit archs. Fabio Estevam noticed this while while mounting
    a NFS volume on an ARM board.
    
    As a compensation for missing this I looked after the other *_STATS_BH
    and found three other calls which need updating:
    
    1) icmp6_send: ip6_fragment -> icmpv6_send -> icmp6_send (error handling)
    2) ip6_push_pending_frames: rawv6_sendmsg -> rawv6_push_pending_frames -> ...
       (only in case of icmp protocol with raw sockets in error handling)
    3) ping6_v6_sendmsg (error handling)
    
    Fixes: c15b1ccadb323ea ("ipv6: move DAD and addrconf_verify processing to workqueue")
    Reported-by: Fabio Estevam <festevam@gmail.com>
    Tested-by: Fabio Estevam <fabio.estevam@freescale.com>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 163cdad085c7c3aa77bbda931ebb2fd76ea2e50d
Author: Paul Durrant <Paul.Durrant@citrix.com>
Date:   Fri Mar 28 11:39:05 2014 +0000

    xen-netback: remove pointless clause from if statement
    
    [ Upstream commit 0576eddf24df716d8570ef8ca11452a9f98eaab2 ]
    
    This patch removes a test in start_new_rx_buffer() that checks whether
    a copy operation is less than MAX_BUFFER_OFFSET in length, since
    MAX_BUFFER_OFFSET is defined to be PAGE_SIZE and the only caller of
    start_new_rx_buffer() already limits copy operations to PAGE_SIZE or less.
    
    Signed-off-by: Paul Durrant <paul.durrant@citrix.com>
    Cc: Ian Campbell <ian.campbell@citrix.com>
    Cc: Wei Liu <wei.liu2@citrix.com>
    Cc: Sander Eikelenboom <linux@eikelenboom.it>
    Reported-By: Sander Eikelenboom <linux@eikelenboom.it>
    Tested-By: Sander Eikelenboom <linux@eikelenboom.it>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 57962c47ce49c5db9f719b8f2700f8034d54795e
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Thu Mar 27 12:53:37 2014 +0200

    vhost: validate vhost_get_vq_desc return value
    
    [ Upstream commit a39ee449f96a2cd44ce056d8a0a112211a9b1a1f ]
    
    vhost fails to validate negative error code
    from vhost_get_vq_desc causing
    a crash: we are using -EFAULT which is 0xfffffff2
    as vector size, which exceeds the allocated size.
    
    The code in question was introduced in commit
    8dd014adfea6f173c1ef6378f7e5e7924866c923
        vhost-net: mergeable buffers support
    
    CVE-2014-0055
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f78f1512ec2a6fca1ffd98c5b95757ec62be1389
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Thu Mar 27 12:00:26 2014 +0200

    vhost: fix total length when packets are too short
    
    [ Upstream commit d8316f3991d207fe32881a9ac20241be8fa2bad0 ]
    
    When mergeable buffers are disabled, and the
    incoming packet is too large for the rx buffer,
    get_rx_bufs returns success.
    
    This was intentional in order for make recvmsg
    truncate the packet and then handle_rx would
    detect err != sock_len and drop it.
    
    Unfortunately we pass the original sock_len to
    recvmsg - which means we use parts of iov not fully
    validated.
    
    Fix this up by detecting this overrun and doing packet drop
    immediately.
    
    CVE-2014-0077
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 48f77355b32ab30456a0d6fda1ee2d367b9a3d25
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Wed Mar 26 11:47:56 2014 -0400

    vlan: Set hard_header_len according to available acceleration
    
    [ Upstream commit fc0d48b8fb449ca007b2057328abf736cb516168 ]
    
    Currently, if the card supports CTAG acceleration we do not
    account for the vlan header even if we are configuring an
    8021AD vlan.  This may not be best since we'll do software
    tagging for 8021AD which will cause data copy on skb head expansion
    Configure the length based on available hw offload capabilities and
    vlan protocol.
    
    CC: Patrick McHardy <kaber@trash.net>
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2d4cf3d6f36d88d30ce2186179fe2aa7e5c06c2e
Author: Oliver Neukum <oneukum@suse.de>
Date:   Wed Mar 26 14:32:51 2014 +0100

    usbnet: include wait queue head in device structure
    
    [ Upstream commit 14a0d635d18d0fb552dcc979d6d25106e6541f2e ]
    
    This fixes a race which happens by freeing an object on the stack.
    Quoting Julius:
    > The issue is
    > that it calls usbnet_terminate_urbs() before that, which temporarily
    > installs a waitqueue in dev->wait in order to be able to wait on the
    > tasklet to run and finish up some queues. The waiting itself looks
    > okay, but the access to 'dev->wait' is totally unprotected and can
    > race arbitrarily. I think in this case usbnet_bh() managed to succeed
    > it's dev->wait check just before usbnet_terminate_urbs() sets it back
    > to NULL. The latter then finishes and the waitqueue_t structure on its
    > stack gets overwritten by other functions halfway through the
    > wake_up() call in usbnet_bh().
    
    The fix is to just not allocate the data structure on the stack.
    As dev->wait is abused as a flag it also takes a runtime PM change
    to fix this bug.
    
    Signed-off-by: Oliver Neukum <oneukum@suse.de>
    Reported-by: Grant Grundler <grundler@google.com>
    Tested-by: Grant Grundler <grundler@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8d4508813521a6e1abaab86a8525c29e91483cf0
Author: Vlad Yasevich <vyasevic@redhat.com>
Date:   Mon Mar 24 17:52:12 2014 -0400

    tg3: Do not include vlan acceleration features in vlan_features
    
    [ Upstream commit 51dfe7b944998eaeb2b34d314f3a6b16a5fd621b ]
    
    Including hardware acceleration features in vlan_features breaks
    stacked vlans (Q-in-Q) by marking the bottom vlan interface as
    capable of acceleration.  This causes one of the tags to be lost
    and the packets are sent with a sing vlan header.
    
    CC: Nithin Nayak Sujir <nsujir@broadcom.com>
    CC: Michael Chan <mchan@broadcom.com>
    Signed-off-by: Vlad Yasevich <vyasevic@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit debd53455f49ecd18b4cb1198e20416bd25bf46e
Author: Li RongQing <roy.qing.li@gmail.com>
Date:   Fri Mar 21 20:53:57 2014 +0800

    netpoll: fix the skb check in pkt_is_ns
    
    [ Not applicable upstream commit, the code here has been removed
      upstream. ]
    
    Neighbor Solicitation is ipv6 protocol, so we should check
    skb->protocol with ETH_P_IPV6
    
    Signed-off-by: Li RongQing <roy.qing.li@gmail.com>
    Cc: WANG Cong <amwang@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 29466c9fad0e72e57ded8dffabc68575d4399a4f
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Wed Mar 19 17:47:51 2014 +0100

    ip6mr: fix mfc notification flags
    
    [ Upstream commit f518338b16038beeb73e155e60d0f70beb9379f4 ]
    
    Commit 812e44dd1829 ("ip6mr: advertise new mfc entries via rtnl") reuses the
    function ip6mr_fill_mroute() to notify mfc events.
    But this function was used only for dump and thus was always setting the
    flag NLM_F_MULTI, which is wrong in case of a single notification.
    
    Libraries like libnl will wait forever for NLMSG_DONE.
    
    CC: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Acked-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 38c50cd4421b6d83ce58af63fdf105cf3fdc37e9
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Wed Mar 19 17:47:50 2014 +0100

    ipmr: fix mfc notification flags
    
    [ Upstream commit 65886f439ab0fdc2dff20d1fa87afb98c6717472 ]
    
    Commit 8cd3ac9f9b7b ("ipmr: advertise new mfc entries via rtnl") reuses the
    function ipmr_fill_mroute() to notify mfc events.
    But this function was used only for dump and thus was always setting the
    flag NLM_F_MULTI, which is wrong in case of a single notification.
    
    Libraries like libnl will wait forever for NLMSG_DONE.
    
    CC: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Acked-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c0669e49cf6fdee800568b7085af0bcaaf27b9b3
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Wed Mar 19 17:47:49 2014 +0100

    rtnetlink: fix fdb notification flags
    
    [ Upstream commit 1c104a6bebf3c16b6248408b84f91d09ac8a26b6 ]
    
    Commit 3ff661c38c84 ("net: rtnetlink notify events for FDB NTF_SELF adds and
    deletes") reuses the function nlmsg_populate_fdb_fill() to notify fdb events.
    But this function was used only for dump and thus was always setting the
    flag NLM_F_MULTI, which is wrong in case of a single notification.
    
    Libraries like libnl will wait forever for NLMSG_DONE.
    
    CC: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Acked-by: Thomas Graf <tgraf@suug.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c3c4a8c1e19205057f680ab3d73044462bd5303c
Author: David Stevens <dlstevens@us.ibm.com>
Date:   Tue Mar 18 12:32:29 2014 -0400

    vxlan: fix potential NULL dereference in arp_reduce()
    
    [ Upstream commit 7346135dcd3f9b57f30a5512094848c678d7143e ]
    
    This patch fixes a NULL pointer dereference in the event of an
    skb allocation failure in arp_reduce().
    
    Signed-Off-By: David L Stevens <dlstevens@us.ibm.com>
    Acked-by: Cong Wang <cwang@twopensource.com>
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8e5612a299431024c3b8c136ba4cb7c523dec934
Author: lucien <lucien.xin@gmail.com>
Date:   Mon Mar 17 12:51:01 2014 +0800

    ipv6: ip6_append_data_mtu do not handle the mtu of the second fragment properly
    
    [ Upstream commit e367c2d03dba4c9bcafad24688fadb79dd95b218 ]
    
    In ip6_append_data_mtu(), when the xfrm mode is not tunnel(such as
    transport),the ipsec header need to be added in the first fragment, so the mtu
    will decrease to reserve space for it, then the second fragment come, the mtu
    should be turn back, as the commit 0c1833797a5a6ec23ea9261d979aa18078720b74
    said.  however, in the commit a493e60ac4bbe2e977e7129d6d8cbb0dd236be, it use
    *mtu = min(*mtu, ...) to change the mtu, which lead to the new mtu is alway
    equal with the first fragment's. and cannot turn back.
    
    when I test through  ping6 -c1 -s5000 $ip (mtu=1280):
    ...frag (0|1232) ESP(spi=0x00002000,seq=0xb), length 1232
    ...frag (1232|1216)
    ...frag (2448|1216)
    ...frag (3664|1216)
    ...frag (4880|164)
    
    which should be:
    ...frag (0|1232) ESP(spi=0x00001000,seq=0x1), length 1232
    ...frag (1232|1232)
    ...frag (2464|1232)
    ...frag (3696|1232)
    ...frag (4928|116)
    
    so delete the min() when change back the mtu.
    
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Fixes: 75a493e60ac4bb ("ipv6: ip6_append_data_mtu did not care about pmtudisc and frag_size")
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9b12db3dd5abcf63b452296f34440dbdff6c16e5
Author: Heiner Kallweit <heiner.kallweit@web.de>
Date:   Wed Mar 12 22:13:19 2014 +0100

    ipv6: Avoid unnecessary temporary addresses being generated
    
    [ Upstream commit ecab67015ef6e3f3635551dcc9971cf363cc1cd5 ]
    
    tmp_prefered_lft is an offset to ifp->tstamp, not now. Therefore
    age needs to be added to the condition.
    
    Age calculation in ipv6_create_tempaddr is different from the one
    in addrconf_verify and doesn't consider ADDRCONF_TIMER_FUZZ_MINUS.
    This can cause age in ipv6_create_tempaddr to be less than the one
    in addrconf_verify and therefore unnecessary temporary address to
    be generated.
    Use age calculation as in addrconf_modify to avoid this.
    
    Signed-off-by: Heiner Kallweit <heiner.kallweit@web.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 29a322f4572bcb20bc800e40b7f156f4ce0766fb
Author: Matthew Leach <matthew.leach@arm.com>
Date:   Tue Mar 11 11:58:27 2014 +0000

    net: socket: error on a negative msg_namelen
    
    [ Upstream commit dbb490b96584d4e958533fb637f08b557f505657 ]
    
    When copying in a struct msghdr from the user, if the user has set the
    msg_namelen parameter to a negative value it gets clamped to a valid
    size due to a comparison between signed and unsigned values.
    
    Ensure the syscall errors when the user passes in a negative value.
    
    Signed-off-by: Matthew Leach <matthew.leach@arm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cbbb5a252da5584e9a48e412e69ea09b4dd34cac
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Mon Mar 10 09:50:11 2014 -0700

    tcp: tcp_release_cb() should release socket ownership
    
    [ Upstream commit c3f9b01849ef3bc69024990092b9f42e20df7797 ]
    
    Lars Persson reported following deadlock :
    
    -000 |M:0x0:0x802B6AF8(asm) <-- arch_spin_lock
    -001 |tcp_v4_rcv(skb = 0x8BD527A0) <-- sk = 0x8BE6B2A0
    -002 |ip_local_deliver_finish(skb = 0x8BD527A0)
    -003 |__netif_receive_skb_core(skb = 0x8BD527A0, ?)
    -004 |netif_receive_skb(skb = 0x8BD527A0)
    -005 |elk_poll(napi = 0x8C770500, budget = 64)
    -006 |net_rx_action(?)
    -007 |__do_softirq()
    -008 |do_softirq()
    -009 |local_bh_enable()
    -010 |tcp_rcv_established(sk = 0x8BE6B2A0, skb = 0x87D3A9E0, th = 0x814EBE14, ?)
    -011 |tcp_v4_do_rcv(sk = 0x8BE6B2A0, skb = 0x87D3A9E0)
    -012 |tcp_delack_timer_handler(sk = 0x8BE6B2A0)
    -013 |tcp_release_cb(sk = 0x8BE6B2A0)
    -014 |release_sock(sk = 0x8BE6B2A0)
    -015 |tcp_sendmsg(?, sk = 0x8BE6B2A0, ?, ?)
    -016 |sock_sendmsg(sock = 0x8518C4C0, msg = 0x87D8DAA8, size = 4096)
    -017 |kernel_sendmsg(?, ?, ?, ?, size = 4096)
    -018 |smb_send_kvec()
    -019 |smb_send_rqst(server = 0x87C4D400, rqst = 0x87D8DBA0)
    -020 |cifs_call_async()
    -021 |cifs_async_writev(wdata = 0x87FD6580)
    -022 |cifs_writepages(mapping = 0x852096E4, wbc = 0x87D8DC88)
    -023 |__writeback_single_inode(inode = 0x852095D0, wbc = 0x87D8DC88)
    -024 |writeback_sb_inodes(sb = 0x87D6D800, wb = 0x87E4A9C0, work = 0x87D8DD88)
    -025 |__writeback_inodes_wb(wb = 0x87E4A9C0, work = 0x87D8DD88)
    -026 |wb_writeback(wb = 0x87E4A9C0, work = 0x87D8DD88)
    -027 |wb_do_writeback(wb = 0x87E4A9C0, force_wait = 0)
    -028 |bdi_writeback_workfn(work = 0x87E4A9CC)
    -029 |process_one_work(worker = 0x8B045880, work = 0x87E4A9CC)
    -030 |worker_thread(__worker = 0x8B045880)
    -031 |kthread(_create = 0x87CADD90)
    -032 |ret_from_kernel_thread(asm)
    
    Bug occurs because __tcp_checksum_complete_user() enables BH, assuming
    it is running from softirq context.
    
    Lars trace involved a NIC without RX checksum support but other points
    are problematic as well, like the prequeue stuff.
    
    Problem is triggered by a timer, that found socket being owned by user.
    
    tcp_release_cb() should call tcp_write_timer_handler() or
    tcp_delack_timer_handler() in the appropriate context :
    
    BH disabled and socket lock held, but 'owned' field cleared,
    as if they were running from timer handlers.
    
    Fixes: 6f458dfb4092 ("tcp: improve latencies of timer triggered events")
    Reported-by: Lars Persson <lars.persson@axis.com>
    Tested-by: Lars Persson <lars.persson@axis.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 471e50f30749fbd9a410b29b6549aa26f76fc021
Author: Peter Boström <peter.bostrom@netrounds.com>
Date:   Mon Mar 10 16:17:15 2014 +0100

    vlan: Set correct source MAC address with TX VLAN offload enabled
    
    [ Upstream commit dd38743b4cc2f86be250eaf156cf113ba3dd531a ]
    
    With TX VLAN offload enabled the source MAC address for frames sent using the
    VLAN interface is currently set to the address of the real interface. This is
    wrong since the VLAN interface may be configured with a different address.
    
    The bug was introduced in commit 2205369a314e12fcec4781cc73ac9c08fc2b47de
    ("vlan: Fix header ops passthru when doing TX VLAN offload.").
    
    This patch sets the source address before calling the create function of the
    real interface.
    
    Signed-off-by: Peter Boström <peter.bostrom@netrounds.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8f41e6a828ce53021ebbf2594195a7ec8ee0628e
Author: Sabrina Dubroca <sd@queasysnail.net>
Date:   Thu Mar 6 17:51:57 2014 +0100

    ipv6: don't set DST_NOCOUNT for remotely added routes
    
    [ Upstream commit c88507fbad8055297c1d1e21e599f46960cbee39 ]
    
    DST_NOCOUNT should only be used if an authorized user adds routes
    locally. In case of routes which are added on behalf of router
    advertisments this flag must not get used as it allows an unlimited
    number of routes getting added remotely.
    
    Signed-off-by: Sabrina Dubroca <sd@queasysnail.net>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cb82e2ab0ee9944b55d97e42f66d07ce417c7119
Author: Anton Nayshtut <anton@swortex.com>
Date:   Wed Mar 5 08:30:08 2014 +0200

    ipv6: Fix exthdrs offload registration.
    
    [ Upstream commit d2d273ffabd315eecefce21a4391d44b6e156b73 ]
    
    Without this fix, ipv6_exthdrs_offload_init doesn't register IPPROTO_DSTOPTS
    offload, but returns 0 (as the IPPROTO_ROUTING registration actually succeeds).
    
    This then causes the ipv6_gso_segment to drop IPv6 packets with IPPROTO_DSTOPTS
    header.
    
    The issue detected and the fix verified by running MS HCK Offload LSO test on
    top of QEMU Windows guests, as this test sends IPv6 packets with
    IPPROTO_DSTOPTS.
    
    Signed-off-by: Anton Nayshtut <anton@swortex.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f423fefea41979114d6895a38f112505797aeb48
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Mar 25 18:42:27 2014 -0700

    net: unix: non blocking recvmsg() should not return -EINTR
    
    [ Upstream commit de1443916791d75fdd26becb116898277bb0273f ]
    
    Some applications didn't expect recvmsg() on a non blocking socket
    could return -EINTR. This possibility was added as a side effect
    of commit b3ca9b02b00704 ("net: fix multithreaded signal handling in
    unix recv routines").
    
    To hit this bug, you need to be a bit unlucky, as the u->readlock
    mutex is usually held for very small periods.
    
    Fixes: b3ca9b02b00704 ("net: fix multithreaded signal handling in unix recv routines")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Rainer Weikusat <rweikusat@mobileactivedefense.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 458b05e1e8b8034e2c9fee5f8170545343e08a3d
Author: Florian Westphal <fw@strlen.de>
Date:   Thu Mar 6 18:06:41 2014 +0100

    inet: frag: make sure forced eviction removes all frags
    
    [ Upstream commit e588e2f286ed7da011ed357c24c5b9a554e26595 ]
    
    Quoting Alexander Aring:
      While fragmentation and unloading of 6lowpan module I got this kernel Oops
      after few seconds:
    
      BUG: unable to handle kernel paging request at f88bbc30
      [..]
      Modules linked in: ipv6 [last unloaded: 6lowpan]
      Call Trace:
       [<c012af4c>] ? call_timer_fn+0x54/0xb3
       [<c012aef8>] ? process_timeout+0xa/0xa
       [<c012b66b>] run_timer_softirq+0x140/0x15f
    
    Problem is that incomplete frags are still around after unload; when
    their frag expire timer fires, we get crash.
    
    When a netns is removed (also done when unloading module), inet_frag
    calls the evictor with 'force' argument to purge remaining frags.
    
    The evictor loop terminates when accounted memory ('work') drops to 0
    or the lru-list becomes empty.  However, the mem accounting is done
    via percpu counters and may not be accurate, i.e. loop may terminate
    prematurely.
    
    Alter evictor to only stop once the lru list is empty when force is
    requested.
    
    Reported-by: Phoebe Buckheister <phoebe.buckheister@itwm.fraunhofer.de>
    Reported-by: Alexander Aring <alex.aring@gmail.com>
    Tested-by: Alexander Aring <alex.aring@gmail.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 47c044663922c0671a04df426c48b444a9a3a50d
Author: Linus Lüssing <linus.luessing@c0d3.blue>
Date:   Tue Mar 4 03:57:35 2014 +0100

    bridge: multicast: add sanity check for query source addresses
    
    [ Upstream commit 6565b9eeef194afbb3beec80d6dd2447f4091f8c ]
    
    MLD queries are supposed to have an IPv6 link-local source address
    according to RFC2710, section 4 and RFC3810, section 5.1.14. This patch
    adds a sanity check to ignore such broken MLD queries.
    
    Without this check, such malformed MLD queries can result in a
    denial of service: The queries are ignored by any MLD listener
    therefore they will not respond with an MLD report. However,
    without this patch these malformed MLD queries would enable the
    snooping part in the bridge code, potentially shutting down the
    according ports towards these hosts for multicast traffic as the
    bridge did not learn about these listeners.
    
    Reported-by: Jan Stancek <jstancek@redhat.com>
    Signed-off-by: Linus Lüssing <linus.luessing@web.de>
    Reviewed-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec494e10043dc71f30b9f32a9db15a6c2a9ae051
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Tue Mar 4 16:35:51 2014 +0100

    net: sctp: fix skb leakage in COOKIE ECHO path of chunk->auth_chunk
    
    [ Upstream commit c485658bae87faccd7aed540fd2ca3ab37992310 ]
    
    While working on ec0223ec48a9 ("net: sctp: fix sctp_sf_do_5_1D_ce to
    verify if we/peer is AUTH capable"), we noticed that there's a skb
    memory leakage in the error path.
    
    Running the same reproducer as in ec0223ec48a9 and by unconditionally
    jumping to the error label (to simulate an error condition) in
    sctp_sf_do_5_1D_ce() receive path lets kmemleak detector bark about
    the unfreed chunk->auth_chunk skb clone:
    
    Unreferenced object 0xffff8800b8f3a000 (size 256):
      comm "softirq", pid 0, jiffies 4294769856 (age 110.757s)
      hex dump (first 32 bytes):
        00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
        89 ab 75 5e d4 01 58 13 00 00 00 00 00 00 00 00  ..u^..X.........
      backtrace:
        [<ffffffff816660be>] kmemleak_alloc+0x4e/0xb0
        [<ffffffff8119f328>] kmem_cache_alloc+0xc8/0x210
        [<ffffffff81566929>] skb_clone+0x49/0xb0
        [<ffffffffa0467459>] sctp_endpoint_bh_rcv+0x1d9/0x230 [sctp]
        [<ffffffffa046fdbc>] sctp_inq_push+0x4c/0x70 [sctp]
        [<ffffffffa047e8de>] sctp_rcv+0x82e/0x9a0 [sctp]
        [<ffffffff815abd38>] ip_local_deliver_finish+0xa8/0x210
        [<ffffffff815a64af>] nf_reinject+0xbf/0x180
        [<ffffffffa04b4762>] nfqnl_recv_verdict+0x1d2/0x2b0 [nfnetlink_queue]
        [<ffffffffa04aa40b>] nfnetlink_rcv_msg+0x14b/0x250 [nfnetlink]
        [<ffffffff815a3269>] netlink_rcv_skb+0xa9/0xc0
        [<ffffffffa04aa7cf>] nfnetlink_rcv+0x23f/0x408 [nfnetlink]
        [<ffffffff815a2bd8>] netlink_unicast+0x168/0x250
        [<ffffffff815a2fa1>] netlink_sendmsg+0x2e1/0x3f0
        [<ffffffff8155cc6b>] sock_sendmsg+0x8b/0xc0
        [<ffffffff8155d449>] ___sys_sendmsg+0x369/0x380
    
    What happens is that commit bbd0d59809f9 clones the skb containing
    the AUTH chunk in sctp_endpoint_bh_rcv() when having the edge case
    that an endpoint requires COOKIE-ECHO chunks to be authenticated:
    
      ---------- INIT[RANDOM; CHUNKS; HMAC-ALGO] ---------->
      <------- INIT-ACK[RANDOM; CHUNKS; HMAC-ALGO] ---------
      ------------------ AUTH; COOKIE-ECHO ---------------->
      <-------------------- COOKIE-ACK ---------------------
    
    When we enter sctp_sf_do_5_1D_ce() and before we actually get to
    the point where we process (and subsequently free) a non-NULL
    chunk->auth_chunk, we could hit the "goto nomem_init" path from
    an error condition and thus leave the cloned skb around w/o
    freeing it.
    
    The fix is to centrally free such clones in sctp_chunk_destroy()
    handler that is invoked from sctp_chunk_free() after all refs have
    dropped; and also move both kfree_skb(chunk->auth_chunk) there,
    so that chunk->auth_chunk is either NULL (since sctp_chunkify()
    allocs new chunks through kmem_cache_zalloc()) or non-NULL with
    a valid skb pointer. chunk->skb and chunk->auth_chunk are the
    only skbs in the sctp_chunk structure that need to be handeled.
    
    While at it, we should use consume_skb() for both. It is the same
    as dev_kfree_skb() but more appropriately named as we are not
    a device but a protocol. Also, this effectively replaces the
    kfree_skb() from both invocations into consume_skb(). Functions
    are the same only that kfree_skb() assumes that the frame was
    being dropped after a failure (e.g. for tools like drop monitor),
    usage of consume_skb() seems more appropriate in function
    sctp_chunk_destroy() though.
    
    Fixes: bbd0d59809f9 ("[SCTP]: Implement the receive and verification of AUTH chunk")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Cc: Vlad Yasevich <yasevich@gmail.com>
    Cc: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f7a2e253a883ddea610b5d465f95d56a41fac325
Author: Nikolay Aleksandrov <nikolay@redhat.com>
Date:   Mon Mar 3 23:19:18 2014 +0100

    net: fix for a race condition in the inet frag code
    
    [ Upstream commit 24b9bf43e93e0edd89072da51cf1fab95fc69dec ]
    
    I stumbled upon this very serious bug while hunting for another one,
    it's a very subtle race condition between inet_frag_evictor,
    inet_frag_intern and the IPv4/6 frag_queue and expire functions
    (basically the users of inet_frag_kill/inet_frag_put).
    
    What happens is that after a fragment has been added to the hash chain
    but before it's been added to the lru_list (inet_frag_lru_add) in
    inet_frag_intern, it may get deleted (either by an expired timer if
    the system load is high or the timer sufficiently low, or by the
    fraq_queue function for different reasons) before it's added to the
    lru_list, then after it gets added it's a matter of time for the
    evictor to get to a piece of memory which has been freed leading to a
    number of different bugs depending on what's left there.
    
    I've been able to trigger this on both IPv4 and IPv6 (which is normal
    as the frag code is the same), but it's been much more difficult to
    trigger on IPv4 due to the protocol differences about how fragments
    are treated.
    
    The setup I used to reproduce this is: 2 machines with 4 x 10G bonded
    in a RR bond, so the same flow can be seen on multiple cards at the
    same time. Then I used multiple instances of ping/ping6 to generate
    fragmented packets and flood the machines with them while running
    other processes to load the attacked machine.
    
    *It is very important to have the _same flow_ coming in on multiple CPUs
    concurrently. Usually the attacked machine would die in less than 30
    minutes, if configured properly to have many evictor calls and timeouts
    it could happen in 10 minutes or so.
    
    An important point to make is that any caller (frag_queue or timer) of
    inet_frag_kill will remove both the timer refcount and the
    original/guarding refcount thus removing everything that's keeping the
    frag from being freed at the next inet_frag_put.  All of this could
    happen before the frag was ever added to the LRU list, then it gets
    added and the evictor uses a freed fragment.
    
    An example for IPv6 would be if a fragment is being added and is at
    the stage of being inserted in the hash after the hash lock is
    released, but before inet_frag_lru_add executes (or is able to obtain
    the lru lock) another overlapping fragment for the same flow arrives
    at a different CPU which finds it in the hash, but since it's
    overlapping it drops it invoking inet_frag_kill and thus removing all
    guarding refcounts, and afterwards freeing it by invoking
    inet_frag_put which removes the last refcount added previously by
    inet_frag_find, then inet_frag_lru_add gets executed by
    inet_frag_intern and we have a freed fragment in the lru_list.
    
    The fix is simple, just move the lru_add under the hash chain locked
    region so when a removing function is called it'll have to wait for
    the fragment to be added to the lru_list, and then it'll remove it (it
    works because the hash chain removal is done before the lru_list one
    and there's no window between the two list adds when the frag can get
    dropped). With this fix applied I couldn't kill the same machine in 24
    hours with the same setup.
    
    Fixes: 3ef0eb0db4bf ("net: frag, move LRU list maintenance outside of
    rwlock")
    
    CC: Florian Westphal <fw@strlen.de>
    CC: Jesper Dangaard Brouer <brouer@redhat.com>
    CC: David S. Miller <davem@davemloft.net>
    
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6ae69a801bb987433282fc6c8c18fe60c1dae6b4
Author: Daniel Fu <danifu@nvidia.com>
Date:   Fri Aug 30 19:48:22 2013 +0800

    cpuidle: Check the result of cpuidle_get_driver() against NULL
    
    commit 3b9c10e98021e1f92e6f8c7ce1778b86ba68db10 upstream.
    
    If the current CPU has no cpuidle driver, drv will be NULL in
    cpuidle_driver_ref().  Check if that is the case before trying
    to bump up the driver's refcount to prevent the kernel from
    crashing.
    
    [rjw: Subject and changelog]
    Signed-off-by: Daniel Fu <danifu@nvidia.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Cc: Mark Brown <broonie@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3246a0352e3d58380b9386570f1db1faf7edf8a8
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Mon Apr 29 14:15:51 2013 +0200

    kbuild: fix make headers_install when path is too long
    
    commit c0ff68f1611d6855a06d672989ad5cfea160a4eb upstream.
    
    If headers_install is executed from a deep/long directory structure, the
    shell's maximum argument length can be execeeded, which breaks the operation
    with:
    
    | make[2]: execvp: /bin/sh: Argument list too long
    | make[2]: ***
    
    Instead of passing each files name with the entire path, I give only the file
    name without the source path and give this path as a new argument to
    headers_install.pl.
    
    Because there is three possible paths, I have tree input-files list, one per
    path.
    
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Tested-by: Bruce Ashfield <bruce.ashfield@windriver.com>
    Signed-off-by: Michal Marek <mmarek@suse.cz>
    Cc: Wang Nan <wangnan0@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 45deaa3ba8c4e0767d35e979507e312ed60f17de
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Dec 11 19:39:19 2013 -0500

    powernow-k6: reorder frequencies
    
    commit 22c73795b101597051924556dce019385a1e2fa0 upstream.
    
    This patch reorders reported frequencies from the highest to the lowest,
    just like in other frequency drivers.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Acked-by: Viresh Kumar <viresh.kumar@linaro.org>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 59b61f4dd5ff067928db50270fedeef365f721de
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Dec 11 19:38:53 2013 -0500

    powernow-k6: correctly initialize default parameters
    
    commit d82b922a4acc1781d368aceac2f9da43b038cab2 upstream.
    
    The powernow-k6 driver used to read the initial multiplier from the
    powernow register. However, there is a problem with this:
    
    * If there was a frequency transition before, the multiplier read from the
      register corresponds to the current multiplier.
    * If there was no frequency transition since reset, the field in the
      register always reads as zero, regardless of the current multiplier that
      is set using switches on the mainboard and that the CPU is running at.
    
    The zero value corresponds to multiplier 4.5, so as a consequence, the
    powernow-k6 driver always assumes multiplier 4.5.
    
    For example, if we have 550MHz CPU with bus frequency 100MHz and
    multiplier 5.5, the powernow-k6 driver thinks that the multiplier is 4.5
    and bus frequency is 122MHz. The powernow-k6 driver then sets the
    multiplier to 4.5, underclocking the CPU to 450MHz, but reports the
    current frequency as 550MHz.
    
    There is no reliable way how to read the initial multiplier. I modified
    the driver so that it contains a table of known frequencies (based on
    parameters of existing CPUs and some common overclocking schemes) and sets
    the multiplier according to the frequency. If the frequency is unknown
    (because of unusual overclocking or underclocking), the user must supply
    the bus speed and maximum multiplier as module parameters.
    
    This patch should be backported to all stable kernels. If it doesn't
    apply cleanly, change it, or ask me to change it.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cfc83ee6948b5f8986222acfd0458a5f2d22edcd
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Wed Dec 11 19:38:32 2013 -0500

    powernow-k6: disable cache when changing frequency
    
    commit e20e1d0ac02308e2211306fc67abcd0b2668fb8b upstream.
    
    I found out that a system with k6-3+ processor is unstable during network
    server load. The system locks up or the network card stops receiving. The
    reason for the instability is the CPU frequency scaling.
    
    During frequency transition the processor is in "EPM Stop Grant" state.
    The documentation says that the processor doesn't respond to inquiry
    requests in this state. Consequently, coherency of processor caches and
    bus master devices is not maintained, causing the system instability.
    
    This patch flushes the cache during frequency transition. It fixes the
    instability.
    
    Other minor changes:
    * u64 invalue changed to unsigned long because the variable is 32-bit
    * move the logic to set the multiplier to a separate function
      powernow_k6_set_cpu_multiplier
    * preserve lower 5 bits of the powernow port instead of 4 (the voltage
      field has 5 bits)
    * mask interrupts when reading the multiplier, so that the port is not
      open during other activity (running other kernel code with the port open
      shouldn't cause any misbehavior, but we should better be safe and keep
      the port closed)
    
    This patch should be backported to all stable kernels. If it doesn't
    apply cleanly, change it, or ask me to change it.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 913a13b6da5172b6fbc526ed3702add554a8d06a
Author: Paul Moore <pmoore@redhat.com>
Date:   Wed Mar 19 16:46:18 2014 -0400

    selinux: correctly label /proc inodes in use before the policy is loaded
    
    commit f64410ec665479d7b4b77b7519e814253ed0f686 upstream.
    
    This patch is based on an earlier patch by Eric Paris, he describes
    the problem below:
    
      "If an inode is accessed before policy load it will get placed on a
       list of inodes to be initialized after policy load.  After policy
       load we call inode_doinit() which calls inode_doinit_with_dentry()
       on all inodes accessed before policy load.  In the case of inodes
       in procfs that means we'll end up at the bottom where it does:
    
         /* Default to the fs superblock SID. */
         isec->sid = sbsec->sid;
    
         if ((sbsec->flags & SE_SBPROC) && !S_ISLNK(inode->i_mode)) {
                 if (opt_dentry) {
                         isec->sclass = inode_mode_to_security_class(...)
                         rc = selinux_proc_get_sid(opt_dentry,
                                                   isec->sclass,
                                                   &sid);
                         if (rc)
                                 goto out_unlock;
                         isec->sid = sid;
                 }
         }
    
       Since opt_dentry is null, we'll never call selinux_proc_get_sid()
       and will leave the inode labeled with the label on the superblock.
       I believe a fix would be to mimic the behavior of xattrs.  Look
       for an alias of the inode.  If it can't be found, just leave the
       inode uninitialized (and pick it up later) if it can be found, we
       should be able to call selinux_proc_get_sid() ..."
    
    On a system exhibiting this problem, you will notice a lot of files in
    /proc with the generic "proc_t" type (at least the ones that were
    accessed early in the boot), for example:
    
       # ls -Z /proc/sys/kernel/shmmax | awk '{ print $4 " " $5 }'
       system_u:object_r:proc_t:s0 /proc/sys/kernel/shmmax
    
    However, with this patch in place we see the expected result:
    
       # ls -Z /proc/sys/kernel/shmmax | awk '{ print $4 " " $5 }'
       system_u:object_r:sysctl_kernel_t:s0 /proc/sys/kernel/shmmax
    
    Cc: Eric Paris <eparis@redhat.com>
    Signed-off-by: Paul Moore <pmoore@redhat.com>
    Acked-by: Eric Paris <eparis@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
