commit e01202b36f03f9284ffb51e911f6710d0a62c815
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Aug 6 16:23:04 2018 +0200

    Linux 4.9.118

commit 0ff94fb99e0ba3f60bb0e63f51db266a6b025d65
Author: Tony Battersby <tonyb@cybernetics.com>
Date:   Thu Jul 12 16:30:45 2018 -0400

    scsi: sg: fix minor memory leak in error path
    
    commit c170e5a8d222537e98aa8d4fddb667ff7a2ee114 upstream.
    
    Fix a minor memory leak when there is an error opening a /dev/sg device.
    
    Fixes: cc833acbee9d ("sg: O_EXCL and other lock handling")
    Cc: <stable@vger.kernel.org>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: Tony Battersby <tonyb@cybernetics.com>
    Reviewed-by: Bart Van Assche <bart.vanassche@wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e79a2db21eec75851baa05e62139f466e9d2c166
Author: Boris Brezillon <bbrezillon@kernel.org>
Date:   Tue Jul 24 15:36:01 2018 +0200

    drm/vc4: Reset ->{x, y}_scaling[1] when dealing with uniplanar formats
    
    commit a6a00918d4ad8718c3ccde38c02cec17f116b2fd upstream.
    
    This is needed to ensure ->is_unity is correct when the plane was
    previously configured to output a multi-planar format with scaling
    enabled, and is then being reconfigured to output a uniplanar format.
    
    Fixes: fc04023fafec ("drm/vc4: Add support for YUV planes.")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Boris Brezillon <boris.brezillon@bootlin.com>
    Reviewed-by: Eric Anholt <eric@anholt.net>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180724133601.32114-1-boris.brezillon@bootlin.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 804f510bf2182da8bdbe0135538c8f3f14670a67
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Jul 13 16:12:32 2018 +0800

    crypto: padlock-aes - Fix Nano workaround data corruption
    
    commit 46d8c4b28652d35dc6cfb5adf7f54e102fc04384 upstream.
    
    This was detected by the self-test thanks to Ard's chunking patch.
    
    I finally got around to testing this out on my ancient Via box.  It
    turns out that the workaround got the assembly wrong and we end up
    doing count + initial cycles of the loop instead of just count.
    
    This obviously causes corruption, either by overwriting the source
    that is yet to be processed, or writing over the end of the buffer.
    
    On CPUs that don't require the workaround only ECB is affected.
    On Nano CPUs both ECB and CBC are affected.
    
    This patch fixes it by doing the subtraction prior to the assembly.
    
    Fixes: a76c1c23d0c3 ("crypto: padlock-aes - work around Nano CPU...")
    Cc: <stable@vger.kernel.org>
    Reported-by: Jamie Heilman <jamie@audible.transient.net>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 020a90f653dd02dbbae389da91f510d5f33984dc
Author: Roman Kagan <rkagan@virtuozzo.com>
Date:   Thu Jul 19 21:59:07 2018 +0300

    kvm: x86: vmx: fix vpid leak
    
    commit 63aff65573d73eb8dda4732ad4ef222dd35e4862 upstream.
    
    VPID for the nested vcpu is allocated at vmx_create_vcpu whenever nested
    vmx is turned on with the module parameter.
    
    However, it's only freed if the L1 guest has executed VMXON which is not
    a given.
    
    As a result, on a system with nested==on every creation+deletion of an
    L1 vcpu without running an L2 guest results in leaking one vpid.  Since
    the total number of vpids is limited to 64k, they can eventually get
    exhausted, preventing L2 from starting.
    
    Delay allocation of the L2 vpid until VMXON emulation, thus matching its
    freeing.
    
    Fixes: 5c614b3583e7b6dab0c86356fa36c2bcbb8322a0
    Cc: stable@vger.kernel.org
    Signed-off-by: Roman Kagan <rkagan@virtuozzo.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1d433144592dffefbb9cbc9b0d853473c1b3157c
Author: Jiang Biao <jiang.biao2@zte.com.cn>
Date:   Wed Jul 18 10:29:28 2018 +0800

    virtio_balloon: fix another race between migration and ballooning
    
    commit 89da619bc18d79bca5304724c11d4ba3b67ce2c6 upstream.
    
    Kernel panic when with high memory pressure, calltrace looks like,
    
    PID: 21439 TASK: ffff881be3afedd0 CPU: 16 COMMAND: "java"
     #0 [ffff881ec7ed7630] machine_kexec at ffffffff81059beb
     #1 [ffff881ec7ed7690] __crash_kexec at ffffffff81105942
     #2 [ffff881ec7ed7760] crash_kexec at ffffffff81105a30
     #3 [ffff881ec7ed7778] oops_end at ffffffff816902c8
     #4 [ffff881ec7ed77a0] no_context at ffffffff8167ff46
     #5 [ffff881ec7ed77f0] __bad_area_nosemaphore at ffffffff8167ffdc
     #6 [ffff881ec7ed7838] __node_set at ffffffff81680300
     #7 [ffff881ec7ed7860] __do_page_fault at ffffffff8169320f
     #8 [ffff881ec7ed78c0] do_page_fault at ffffffff816932b5
     #9 [ffff881ec7ed78f0] page_fault at ffffffff8168f4c8
        [exception RIP: _raw_spin_lock_irqsave+47]
        RIP: ffffffff8168edef RSP: ffff881ec7ed79a8 RFLAGS: 00010046
        RAX: 0000000000000246 RBX: ffffea0019740d00 RCX: ffff881ec7ed7fd8
        RDX: 0000000000020000 RSI: 0000000000000016 RDI: 0000000000000008
        RBP: ffff881ec7ed79a8 R8: 0000000000000246 R9: 000000000001a098
        R10: ffff88107ffda000 R11: 0000000000000000 R12: 0000000000000000
        R13: 0000000000000008 R14: ffff881ec7ed7a80 R15: ffff881be3afedd0
        ORIG_RAX: ffffffffffffffff CS: 0010 SS: 0018
    
    It happens in the pagefault and results in double pagefault
    during compacting pages when memory allocation fails.
    
    Analysed the vmcore, the page leads to second pagefault is corrupted
    with _mapcount=-256, but private=0.
    
    It's caused by the race between migration and ballooning, and lock
    missing in virtballoon_migratepage() of virtio_balloon driver.
    This patch fix the bug.
    
    Fixes: e22504296d4f64f ("virtio_balloon: introduce migration primitives to balloon pages")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jiang Biao <jiang.biao2@zte.com.cn>
    Signed-off-by: Huang Chong <huang.chong@zte.com.cn>
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9a492f8c716465a8ed40590f7cbcd2ad6ff1b6c3
Author: Jeremy Cline <jcline@redhat.com>
Date:   Fri Jul 27 22:43:01 2018 +0000

    net: socket: fix potential spectre v1 gadget in socketcall
    
    commit c8e8cd579bb4265651df8223730105341e61a2d1 upstream.
    
    'call' is a user-controlled value, so sanitize the array index after the
    bounds check to avoid speculating past the bounds of the 'nargs' array.
    
    Found with the help of Smatch:
    
    net/socket.c:2508 __do_sys_socketcall() warn: potential spectre issue
    'nargs' [r] (local cap)
    
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Jeremy Cline <jcline@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 18d971807db59b4f31a4cdde30c2353f9d4048d1
Author: Anton Vasilyev <vasilyev@ispras.ru>
Date:   Fri Jul 27 18:50:42 2018 +0300

    can: ems_usb: Fix memory leak on ems_usb_disconnect()
    
    commit 72c05f32f4a5055c9c8fe889bb6903ec959c0aad upstream.
    
    ems_usb_probe() allocates memory for dev->tx_msg_buffer, but there
    is no its deallocation in ems_usb_disconnect().
    
    Found by Linux Driver Verification project (linuxtesting.org).
    
    Signed-off-by: Anton Vasilyev <vasilyev@ispras.ru>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Marc Kleine-Budde <mkl@pengutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 52cd8f3790cf1e71b6b38b63735042a014a3ff8a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Aug 2 08:43:35 2018 -0700

    squashfs: more metadata hardenings
    
    commit 71755ee5350b63fb1f283de8561cdb61b47f4d1d upstream.
    
    The squashfs fragment reading code doesn't actually verify that the
    fragment is inside the fragment table.  The end result _is_ verified to
    be inside the image when actually reading the fragment data, but before
    that is done, we may end up taking a page fault because the fragment
    table itself might not even exist.
    
    Another report from Anatoly and his endless squashfs image fuzzing.
    
    Reported-by: Анатолий Тросиненко <anatoly.trosinenko@gmail.com>
    Acked-by:: Phillip Lougher <phillip.lougher@gmail.com>,
    Cc: Willy Tarreau <w@1wt.eu>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3abef06039cb43e0fe44f3714969af0b9a744dc5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 30 14:27:15 2018 -0700

    squashfs: more metadata hardening
    
    commit d512584780d3e6a7cacb2f482834849453d444a1 upstream.
    
    Anatoly reports another squashfs fuzzing issue, where the decompression
    parameters themselves are in a compressed block.
    
    This causes squashfs_read_data() to be called in order to read the
    decompression options before the decompression stream having been set
    up, making squashfs go sideways.
    
    Reported-by: Anatoly Trosinenko <anatoly.trosinenko@gmail.com>
    Acked-by: Phillip Lougher <phillip.lougher@gmail.com>
    Cc: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9bd4fd4b744089f368f3d85655e904a76c93c25
Author: Jose Abreu <Jose.Abreu@synopsys.com>
Date:   Tue Jul 31 15:08:20 2018 +0100

    net: stmmac: Fix WoL for PCI-based setups
    
    [ Upstream commit b7d0f08e9129c45ed41bc0cfa8e77067881e45fd ]
    
    WoL won't work in PCI-based setups because we are not saving the PCI EP
    state before entering suspend state and not allowing D3 wake.
    
    Fix this by using a wrapper around stmmac_{suspend/resume} which
    correctly sets the PCI EP state.
    
    Signed-off-by: Jose Abreu <joabreu@synopsys.com>
    Cc: David S. Miller <davem@davemloft.net>
    Cc: Joao Pinto <jpinto@synopsys.com>
    Cc: Giuseppe Cavallaro <peppe.cavallaro@st.com>
    Cc: Alexandre Torgue <alexandre.torgue@st.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 67f0a2887bcb587d4116d5896aaea8432ad04696
Author: Jeremy Cline <jcline@redhat.com>
Date:   Tue Jul 31 21:13:16 2018 +0000

    netlink: Fix spectre v1 gadget in netlink_create()
    
    [ Upstream commit bc5b6c0b62b932626a135f516a41838c510c6eba ]
    
    'protocol' is a user-controlled value, so sanitize it after the bounds
    check to avoid using it for speculative out-of-bounds access to arrays
    indexed by it.
    
    This addresses the following accesses detected with the help of smatch:
    
    * net/netlink/af_netlink.c:654 __netlink_create() warn: potential
      spectre issue 'nlk_cb_mutex_keys' [w]
    
    * net/netlink/af_netlink.c:654 __netlink_create() warn: potential
      spectre issue 'nlk_cb_mutex_key_strings' [w]
    
    * net/netlink/af_netlink.c:685 netlink_create() warn: potential spectre
      issue 'nl_table' [w] (local cap)
    
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jeremy Cline <jcline@redhat.com>
    Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ab9a0f80bce707fa4f8b4d63ad1f3b2a89079caa
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jul 31 17:12:52 2018 -0700

    net: dsa: Do not suspend/resume closed slave_dev
    
    [ Upstream commit a94c689e6c9e72e722f28339e12dff191ee5a265 ]
    
    If a DSA slave network device was previously disabled, there is no need
    to suspend or resume it.
    
    Fixes: 2446254915a7 ("net: dsa: allow switch drivers to implement suspend/resume hooks")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d59dcdf13ee5b27a54940a05474230bda3a50edb
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Jul 30 21:50:29 2018 -0700

    ipv4: frags: handle possible skb truesize change
    
    [ Upstream commit 4672694bd4f1aebdab0ad763ae4716e89cb15221 ]
    
    ip_frag_queue() might call pskb_pull() on one skb that
    is already in the fragment queue.
    
    We need to take care of possible truesize change, or we
    might have an imbalance of the netns frags memory usage.
    
    IPv6 is immune to this bug, because RFC5722, Section 4,
    amended by Errata ID 3089 states :
    
      When reassembling an IPv6 datagram, if
      one or more its constituent fragments is determined to be an
      overlapping fragment, the entire datagram (and any constituent
      fragments) MUST be silently discarded.
    
    Fixes: 158f323b9868 ("net: adjust skb->truesize in pskb_expand_head()")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c5282a032fa2823b588b16f6f4bfa5fa2d350671
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Jul 30 20:09:11 2018 -0700

    inet: frag: enforce memory limits earlier
    
    [ Upstream commit 56e2c94f055d328f5f6b0a5c1721cca2f2d4e0a1 ]
    
    We currently check current frags memory usage only when
    a new frag queue is created. This allows attackers to first
    consume the memory budget (default : 4 MB) creating thousands
    of frag queues, then sending tiny skbs to exceed high_thresh
    limit by 2 to 3 order of magnitude.
    
    Note that before commit 648700f76b03 ("inet: frags: use rhashtables
    for reassembly units"), work queue could be starved under DOS,
    getting no cpu cycles.
    After commit 648700f76b03, only the per frag queue timer can eventually
    remove an incomplete frag queue and its skbs.
    
    Fixes: b13d3cbfb8e8 ("inet: frag: move eviction of queues to work queue")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Jann Horn <jannh@google.com>
    Cc: Florian Westphal <fw@strlen.de>
    Cc: Peter Oskolkov <posk@google.com>
    Cc: Paolo Abeni <pabeni@redhat.com>
    Acked-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7142fdb6a924bc4fb1f1661b585d01ff095ef41b
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Jul 31 06:30:54 2018 -0700

    bonding: avoid lockdep confusion in bond_get_stats()
    
    [ Upstream commit 7e2556e40026a1b0c16f37446ab398d5a5a892e4 ]
    
    syzbot found that the following sequence produces a LOCKDEP splat [1]
    
    ip link add bond10 type bond
    ip link add bond11 type bond
    ip link set bond11 master bond10
    
    To fix this, we can use the already provided nest_level.
    
    This patch also provides correct nesting for dev->addr_list_lock
    
    [1]
    WARNING: possible recursive locking detected
    4.18.0-rc6+ #167 Not tainted
    --------------------------------------------
    syz-executor751/4439 is trying to acquire lock:
    (____ptrval____) (&(&bond->stats_lock)->rlock){+.+.}, at: spin_lock include/linux/spinlock.h:310 [inline]
    (____ptrval____) (&(&bond->stats_lock)->rlock){+.+.}, at: bond_get_stats+0xb4/0x560 drivers/net/bonding/bond_main.c:3426
    
    but task is already holding lock:
    (____ptrval____) (&(&bond->stats_lock)->rlock){+.+.}, at: spin_lock include/linux/spinlock.h:310 [inline]
    (____ptrval____) (&(&bond->stats_lock)->rlock){+.+.}, at: bond_get_stats+0xb4/0x560 drivers/net/bonding/bond_main.c:3426
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
           CPU0
           ----
      lock(&(&bond->stats_lock)->rlock);
      lock(&(&bond->stats_lock)->rlock);
    
     *** DEADLOCK ***
    
     May be due to missing lock nesting notation
    
    3 locks held by syz-executor751/4439:
     #0: (____ptrval____) (rtnl_mutex){+.+.}, at: rtnl_lock+0x17/0x20 net/core/rtnetlink.c:77
     #1: (____ptrval____) (&(&bond->stats_lock)->rlock){+.+.}, at: spin_lock include/linux/spinlock.h:310 [inline]
     #1: (____ptrval____) (&(&bond->stats_lock)->rlock){+.+.}, at: bond_get_stats+0xb4/0x560 drivers/net/bonding/bond_main.c:3426
     #2: (____ptrval____) (rcu_read_lock){....}, at: bond_get_stats+0x0/0x560 include/linux/compiler.h:215
    
    stack backtrace:
    CPU: 0 PID: 4439 Comm: syz-executor751 Not tainted 4.18.0-rc6+ #167
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x2b4 lib/dump_stack.c:113
     print_deadlock_bug kernel/locking/lockdep.c:1765 [inline]
     check_deadlock kernel/locking/lockdep.c:1809 [inline]
     validate_chain kernel/locking/lockdep.c:2405 [inline]
     __lock_acquire.cold.64+0x1fb/0x486 kernel/locking/lockdep.c:3435
     lock_acquire+0x1e4/0x540 kernel/locking/lockdep.c:3924
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x2a/0x40 kernel/locking/spinlock.c:144
     spin_lock include/linux/spinlock.h:310 [inline]
     bond_get_stats+0xb4/0x560 drivers/net/bonding/bond_main.c:3426
     dev_get_stats+0x10f/0x470 net/core/dev.c:8316
     bond_get_stats+0x232/0x560 drivers/net/bonding/bond_main.c:3432
     dev_get_stats+0x10f/0x470 net/core/dev.c:8316
     rtnl_fill_stats+0x4d/0xac0 net/core/rtnetlink.c:1169
     rtnl_fill_ifinfo+0x1aa6/0x3fb0 net/core/rtnetlink.c:1611
     rtmsg_ifinfo_build_skb+0xc8/0x190 net/core/rtnetlink.c:3268
     rtmsg_ifinfo_event.part.30+0x45/0xe0 net/core/rtnetlink.c:3300
     rtmsg_ifinfo_event net/core/rtnetlink.c:3297 [inline]
     rtnetlink_event+0x144/0x170 net/core/rtnetlink.c:4716
     notifier_call_chain+0x180/0x390 kernel/notifier.c:93
     __raw_notifier_call_chain kernel/notifier.c:394 [inline]
     raw_notifier_call_chain+0x2d/0x40 kernel/notifier.c:401
     call_netdevice_notifiers_info+0x3f/0x90 net/core/dev.c:1735
     call_netdevice_notifiers net/core/dev.c:1753 [inline]
     netdev_features_change net/core/dev.c:1321 [inline]
     netdev_change_features+0xb3/0x110 net/core/dev.c:7759
     bond_compute_features.isra.47+0x585/0xa50 drivers/net/bonding/bond_main.c:1120
     bond_enslave+0x1b25/0x5da0 drivers/net/bonding/bond_main.c:1755
     bond_do_ioctl+0x7cb/0xae0 drivers/net/bonding/bond_main.c:3528
     dev_ifsioc+0x43c/0xb30 net/core/dev_ioctl.c:327
     dev_ioctl+0x1b5/0xcc0 net/core/dev_ioctl.c:493
     sock_do_ioctl+0x1d3/0x3e0 net/socket.c:992
     sock_ioctl+0x30d/0x680 net/socket.c:1093
     vfs_ioctl fs/ioctl.c:46 [inline]
     file_ioctl fs/ioctl.c:500 [inline]
     do_vfs_ioctl+0x1de/0x1720 fs/ioctl.c:684
     ksys_ioctl+0xa9/0xd0 fs/ioctl.c:701
     __do_sys_ioctl fs/ioctl.c:708 [inline]
     __se_sys_ioctl fs/ioctl.c:706 [inline]
     __x64_sys_ioctl+0x73/0xb0 fs/ioctl.c:706
     do_syscall_64+0x1b9/0x820 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    RIP: 0033:0x440859
    Code: e8 2c af 02 00 48 83 c4 18 c3 0f 1f 80 00 00 00 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 3b 10 fc ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007ffc51a92878 EFLAGS: 00000213 ORIG_RAX: 0000000000000010
    RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 0000000000440859
    RDX: 0000000020000040 RSI: 0000000000008990 RDI: 0000000000000003
    RBP: 0000000000000000 R08: 00000000004002c8 R09: 00000000004002c8
    R10: 00000000022d5880 R11: 0000000000000213 R12: 0000000000007390
    R13: 0000000000401db0 R14: 0000000000000000 R15: 0000000000000000
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Jay Vosburgh <j.vosburgh@gmail.com>
    Cc: Veaceslav Falico <vfalico@gmail.com>
    Cc: Andy Gospodarek <andy@greyhouse.net>
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 047f9d6a5672be91225422169f85f54df1d10c2c
Author: Boqun Feng <boqun.feng@gmail.com>
Date:   Thu Jun 15 12:18:28 2017 +0800

    sched/wait: Remove the lockless swait_active() check in swake_up*()
    
    commit 35a2897c2a306cca344ca5c0b43416707018f434 upstream.
    
    Steven Rostedt reported a potential race in RCU core because of
    swake_up():
    
            CPU0                            CPU1
            ----                            ----
                                    __call_rcu_core() {
    
                                     spin_lock(rnp_root)
                                     need_wake = __rcu_start_gp() {
                                      rcu_start_gp_advanced() {
                                       gp_flags = FLAG_INIT
                                      }
                                     }
    
     rcu_gp_kthread() {
       swait_event_interruptible(wq,
            gp_flags & FLAG_INIT) {
       spin_lock(q->lock)
    
                                    *fetch wq->task_list here! *
    
       list_add(wq->task_list, q->task_list)
       spin_unlock(q->lock);
    
       *fetch old value of gp_flags here *
    
                                     spin_unlock(rnp_root)
    
                                     rcu_gp_kthread_wake() {
                                      swake_up(wq) {
                                       swait_active(wq) {
                                        list_empty(wq->task_list)
    
                                       } * return false *
    
      if (condition) * false *
        schedule();
    
    In this case, a wakeup is missed, which could cause the rcu_gp_kthread
    waits for a long time.
    
    The reason of this is that we do a lockless swait_active() check in
    swake_up(). To fix this, we can either 1) add a smp_mb() in swake_up()
    before swait_active() to provide the proper order or 2) simply remove
    the swait_active() in swake_up().
    
    The solution 2 not only fixes this problem but also keeps the swait and
    wait API as close as possible, as wake_up() doesn't provide a full
    barrier and doesn't do a lockless check of the wait queue either.
    Moreover, there are users already using swait_active() to do their quick
    checks for the wait queues, so it make less sense that swake_up() and
    swake_up_all() do this on their own.
    
    This patch then removes the lockless swait_active() check in swake_up()
    and swake_up_all().
    
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Boqun Feng <boqun.feng@gmail.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Krister Johansen <kjlx@templeofstupid.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20170615041828.zk3a3sfyudm5p6nl@tardis
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: David Chen <david.chen@nutanix.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d4c9c7c1eef0074bc9d34203da6e5089e7c647e0
Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Date:   Thu Aug 24 11:19:33 2017 +0300

    pinctrl: intel: Read back TX buffer state
    
    commit d68b42e30bbacd24354d644f430d088435b15e83 upstream.
    
    In the same way as it's done in pinctrl-cherryview.c we would provide
    a readback TX buffer state.
    
    Fixes: 17fab473693 ("pinctrl: intel: Set pin direction properly")
    Reported-by: "Bourque, Francis" <francis.bourque@intel.com>
    Signed-off-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Acked-by: Mika Westerberg <mika.westerberg@linux.intel.com>
    Tested-by: "Bourque, Francis" <francis.bourque@intel.com>
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Cc: Anthony de Boer <adb@adb.ca>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 019ea5193fe4f9668671aa400a42b9305ad748c9
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 27 08:47:21 2018 -0700

    tcp: add one more quick ack after after ECN events
    
    [ Upstream commit 15ecbe94a45ef88491ca459b26efdd02f91edb6d ]
    
    Larry Brakmo proposal ( https://patchwork.ozlabs.org/patch/935233/
    tcp: force cwnd at least 2 in tcp_cwnd_reduction) made us rethink
    about our recent patch removing ~16 quick acks after ECN events.
    
    tcp_enter_quickack_mode(sk, 1) makes sure one immediate ack is sent,
    but in the case the sender cwnd was lowered to 1, we do not want
    to have a delayed ack for the next packet we will receive.
    
    Fixes: 522040ea5fdd ("tcp: do not aggressively quick ack after ECN events")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Neal Cardwell <ncardwell@google.com>
    Cc: Lawrence Brakmo <brakmo@fb.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 095ab5f46c0e084804c86406e45de3b01ac46058
Author: Yousuk Seung <ysseung@google.com>
Date:   Mon Jun 4 15:29:51 2018 -0700

    tcp: refactor tcp_ecn_check_ce to remove sk type cast
    
    [ Upstream commit f4c9f85f3b2cb7669830cd04d0be61192a4d2436 ]
    
    Refactor tcp_ecn_check_ce and __tcp_ecn_check_ce to accept struct sock*
    instead of tcp_sock* to clean up type casts. This is a pure refactor
    patch.
    
    Signed-off-by: Yousuk Seung <ysseung@google.com>
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 65d986cb5e14b686988258f8aa3784df7a3c969b
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon May 21 15:08:57 2018 -0700

    tcp: do not aggressively quick ack after ECN events
    
    [ Upstream commit 522040ea5fdd1c33bbf75e1d7c7c0422b96a94ef ]
    
    ECN signals currently forces TCP to enter quickack mode for
    up to 16 (TCP_MAX_QUICKACKS) following incoming packets.
    
    We believe this is not needed, and only sending one immediate ack
    for the current packet should be enough.
    
    This should reduce the extra load noticed in DCTCP environments,
    after congestion events.
    
    This is part 2 of our effort to reduce pure ACK packets.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 90cf17d66500d9d30a144449b78ada0d2ff2b9d1
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon May 21 15:08:56 2018 -0700

    tcp: add max_quickacks param to tcp_incr_quickack and tcp_enter_quickack_mode
    
    [ Upstream commit 9a9c9b51e54618861420093ae6e9b50a961914c5 ]
    
    We want to add finer control of the number of ACK packets sent after
    ECN events.
    
    This patch is not changing current behavior, it only enables following
    change.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8ca41e4efcfe241cad0fffe22e558399c0eabbd2
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu May 17 14:47:25 2018 -0700

    tcp: do not force quickack when receiving out-of-order packets
    
    [ Upstream commit a3893637e1eb0ef5eb1bbc52b3a8d2dfa317a35d ]
    
    As explained in commit 9f9843a751d0 ("tcp: properly handle stretch
    acks in slow start"), TCP stacks have to consider how many packets
    are acknowledged in one single ACK, because of GRO, but also
    because of ACK compression or losses.
    
    We plan to add SACK compression in the following patch, we
    must therefore not call tcp_enter_quickack_mode()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Acked-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b03ca669d5c152c26781ec821429564d98d5bd79
Author: Xiao Liang <xiliang@redhat.com>
Date:   Fri Jul 27 17:56:08 2018 +0800

    xen-netfront: wait xenbus state change when load module manually
    
    [ Upstream commit 822fb18a82abaf4ee7058793d95d340f5dab7bfc ]
    
    When loading module manually, after call xenbus_switch_state to initializes
    the state of the netfront device, the driver state did not change so fast
    that may lead no dev created in latest kernel. This patch adds wait to make
    sure xenbus knows the driver is not in closed/unknown state.
    
    Current state:
    [vm]# ethtool eth0
    Settings for eth0:
            Link detected: yes
    [vm]# modprobe -r xen_netfront
    [vm]# modprobe  xen_netfront
    [vm]# ethtool eth0
    Settings for eth0:
    Cannot get device settings: No such device
    Cannot get wake-on-lan settings: No such device
    Cannot get message level: No such device
    Cannot get link status: No such device
    No data available
    
    With the patch installed.
    [vm]# ethtool eth0
    Settings for eth0:
            Link detected: yes
    [vm]# modprobe -r xen_netfront
    [vm]# modprobe xen_netfront
    [vm]# ethtool eth0
    Settings for eth0:
            Link detected: yes
    
    Signed-off-by: Xiao Liang <xiliang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b3e349fd557f1fd9652d535e47b96da049cdbf2a
Author: Neal Cardwell <ncardwell@google.com>
Date:   Fri Jul 27 17:19:12 2018 -0400

    tcp_bbr: fix bw probing to raise in-flight data for very small BDPs
    
    [ Upstream commit 383d470936c05554219094a4d364d964cb324827 ]
    
    For some very small BDPs (with just a few packets) there was a
    quantization effect where the target number of packets in flight
    during the super-unity-gain (1.25x) phase of gain cycling was
    implicitly truncated to a number of packets no larger than the normal
    unity-gain (1.0x) phase of gain cycling. This meant that in multi-flow
    scenarios some flows could get stuck with a lower bandwidth, because
    they did not push enough packets inflight to discover that there was
    more bandwidth available. This was really only an issue in multi-flow
    LAN scenarios, where RTTs and BDPs are low enough for this to be an
    issue.
    
    This fix ensures that gain cycling can raise inflight for small BDPs
    by ensuring that in PROBE_BW mode target inflight values with a
    super-unity gain are always greater than inflight values with a gain
    <= 1. Importantly, this applies whether the inflight value is
    calculated for use as a cwnd value, or as a target inflight value for
    the end of the super-unity phase in bbr_is_next_cycle_phase() (both
    need to be bigger to ensure we can probe with more packets in flight
    reliably).
    
    This is a candidate fix for stable releases.
    
    Fixes: 0f8782ea1497 ("tcp_bbr: add BBR congestion control")
    Signed-off-by: Neal Cardwell <ncardwell@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Acked-by: Priyaranjan Jha <priyarjha@google.com>
    Reviewed-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f6488f40a8e40fa464a9433d5990c8ebfccdd72b
Author: Eugeniy Paltsev <Eugeniy.Paltsev@synopsys.com>
Date:   Thu Jul 26 15:05:37 2018 +0300

    NET: stmmac: align DMA stuff to largest cache line length
    
    [ Upstream commit 9939a46d90c6c76f4533d534dbadfa7b39dc6acc ]
    
    As for today STMMAC_ALIGN macro (which is used to align DMA stuff)
    relies on L1 line length (L1_CACHE_BYTES).
    This isn't correct in case of system with several cache levels
    which might have L1 cache line length smaller than L2 line. This
    can lead to sharing one cache line between DMA buffer and other
    data, so we can lose this data while invalidate DMA buffer before
    DMA transaction.
    
    Fix that by using SMP_CACHE_BYTES instead of L1_CACHE_BYTES for
    aligning.
    
    Signed-off-by: Eugeniy Paltsev <Eugeniy.Paltsev@synopsys.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 32363930dfd2eb8449d062cb590918021f8d7502
Author: Anton Vasilyev <vasilyev@ispras.ru>
Date:   Fri Jul 27 18:57:47 2018 +0300

    net: mdio-mux: bcm-iproc: fix wrong getter and setter pair
    
    [ Upstream commit b0753408aadf32c7ece9e6b765017881e54af833 ]
    
    mdio_mux_iproc_probe() uses platform_set_drvdata() to store md pointer
    in device, whereas mdio_mux_iproc_remove() restores md pointer by
    dev_get_platdata(&pdev->dev). This leads to wrong resources release.
    
    The patch replaces getter to platform_get_drvdata.
    
    Fixes: 98bc865a1ec8 ("net: mdio-mux: Add MDIO mux driver for iProc SoCs")
    Signed-off-by: Anton Vasilyev <vasilyev@ispras.ru>
    Reviewed-by: Andrew Lunn <andrew@lunn.ch>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9deaa19715d5c2b355fff98c4d54049d337311d
Author: Stefan Wahren <stefan.wahren@i2se.com>
Date:   Sat Jul 28 09:52:10 2018 +0200

    net: lan78xx: fix rx handling before first packet is send
    
    [ Upstream commit 136f55f660192ce04af091642efc75d85e017364 ]
    
    As long the bh tasklet isn't scheduled once, no packet from the rx path
    will be handled. Since the tx path also schedule the same tasklet
    this situation only persits until the first packet transmission.
    So fix this issue by scheduling the tasklet after link reset.
    
    Link: https://github.com/raspberrypi/linux/issues/2617
    Fixes: 55d7de9de6c3 ("Microchip's LAN7800 family USB 2/3 to 10/100/1000 Ethernet")
    Suggested-by: Floris Bos <bos@je-eigen-domein.nl>
    Signed-off-by: Stefan Wahren <stefan.wahren@i2se.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 31a9d4dd852843af8b815b2dc621c0142fa40f56
Author: tangpengpeng <tangpengpeng@higon.com>
Date:   Thu Jul 26 14:45:16 2018 +0800

    net: fix amd-xgbe flow-control issue
    
    [ Upstream commit 7f3fc7ddf719cd6faaf787722c511f6918ac6aab ]
    
    If we enable or disable xgbe flow-control by ethtool ,
    it does't work.Because the parameter is not properly
    assigned,so we need to adjust the assignment order
    of the parameters.
    
    Fixes: c1ce2f77366b ("amd-xgbe: Fix flow control setting logic")
    Signed-off-by: tangpengpeng <tangpengpeng@higon.com>
    Acked-by: Tom Lendacky <thomas.lendacky@amd.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6fff429df7c51b82d0b143c44a59ac38702a06a8
Author: Gal Pressman <pressmangal@gmail.com>
Date:   Thu Jul 26 23:40:33 2018 +0300

    net: ena: Fix use of uninitialized DMA address bits field
    
    [ Upstream commit 101f0cd4f2216d32f1b8a75a2154cf3997484ee2 ]
    
    UBSAN triggers the following undefined behaviour warnings:
    [...]
    [   13.236124] UBSAN: Undefined behaviour in drivers/net/ethernet/amazon/ena/ena_eth_com.c:468:22
    [   13.240043] shift exponent 64 is too large for 64-bit type 'long long unsigned int'
    [...]
    [   13.744769] UBSAN: Undefined behaviour in drivers/net/ethernet/amazon/ena/ena_eth_com.c:373:4
    [   13.748694] shift exponent 64 is too large for 64-bit type 'long long unsigned int'
    [...]
    
    When splitting the address to high and low, GENMASK_ULL is used to generate
    a bitmask with dma_addr_bits field from io_sq (in ena_com_prepare_tx and
    ena_com_add_single_rx_desc).
    The problem is that dma_addr_bits is not initialized with a proper value
    (besides being cleared in ena_com_create_io_queue).
    Assign dma_addr_bits the correct value that is stored in ena_dev when
    initializing the SQ.
    
    Fixes: 1738cd3ed342 ("net: ena: Add a driver for Amazon Elastic Network Adapters (ENA)")
    Signed-off-by: Gal Pressman <pressmangal@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e364f1a2ccc1c8d5dd0f43063c81507076c854a5
Author: Lorenzo Bianconi <lorenzo.bianconi@redhat.com>
Date:   Fri Jul 27 18:15:46 2018 +0200

    ipv4: remove BUG_ON() from fib_compute_spec_dst
    
    [ Upstream commit 9fc12023d6f51551d6ca9ed7e02ecc19d79caf17 ]
    
    Remove BUG_ON() from fib_compute_spec_dst routine and check
    in_dev pointer during flowi4 data structure initialization.
    fib_compute_spec_dst routine can be run concurrently with device removal
    where ip_ptr net_device pointer is set to NULL. This can happen
    if userspace enables pkt info on UDP rx socket and the device
    is removed while traffic is flowing
    
    Fixes: 35ebf65e851c ("ipv4: Create and use fib_compute_spec_dst() helper")
    Signed-off-by: Lorenzo Bianconi <lorenzo.bianconi@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
