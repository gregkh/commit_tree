commit 9c43548a7fb8220b13b0ff980989b44f37d54138
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Sat Jan 29 10:58:25 2022 +0100

    Linux 5.15.18
    
    Link: https://lore.kernel.org/r/20220127180259.078563735@linuxfoundation.org
    Tested-by: Florian Fainelli <f.fainelli@gmail.com>
    Tested-by: Shuah Khan <skhan@linuxfoundation.org>
    Tested-by: Ron Economos <re@w6rz.net>
    Tested-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Tested-by: Jon Hunter <jonathanh@nvidia.com>
    Tested-by: Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Tested-by: Fox Chen <foxhlchen@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6066977961fc6f437bc064f628cf9b0e4571c56c
Author: Mathias Krause <minipli@grsecurity.net>
Date:   Thu Jan 27 18:34:19 2022 +1000

    drm/vmwgfx: Fix stale file descriptors on failed usercopy
    
    commit a0f90c8815706981c483a652a6aefca51a5e191c upstream.
    
    A failing usercopy of the fence_rep object will lead to a stale entry in
    the file descriptor table as put_unused_fd() won't release it. This
    enables userland to refer to a dangling 'file' object through that still
    valid file descriptor, leading to all kinds of use-after-free
    exploitation scenarios.
    
    Fix this by deferring the call to fd_install() until after the usercopy
    has succeeded.
    
    Fixes: c906965dee22 ("drm/vmwgfx: Add export fence to file descriptor support")
    Signed-off-by: Mathias Krause <minipli@grsecurity.net>
    Signed-off-by: Zack Rusin <zackr@vmware.com>
    Signed-off-by: Dave Airlie <airlied@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9c82ce59362672e0e5b38cff1e9dbdb52ec62b4f
Author: Russell King <russell.king@oracle.com>
Date:   Fri Nov 5 16:50:45 2021 +0000

    arm64/bpf: Remove 128MB limit for BPF JIT programs
    
    commit b89ddf4cca43f1269093942cf5c4e457fd45c335 upstream.
    
    Commit 91fc957c9b1d ("arm64/bpf: don't allocate BPF JIT programs in module
    memory") restricts BPF JIT program allocation to a 128MB region to ensure
    BPF programs are still in branching range of each other. However this
    restriction should not apply to the aarch64 JIT, since BPF_JMP | BPF_CALL
    are implemented as a 64-bit move into a register and then a BLR instruction -
    which has the effect of being able to call anything without proximity
    limitation.
    
    The practical reason to relax this restriction on JIT memory is that 128MB of
    JIT memory can be quickly exhausted, especially where PAGE_SIZE is 64KB - one
    page is needed per program. In cases where seccomp filters are applied to
    multiple VMs on VM launch - such filters are classic BPF but converted to
    BPF - this can severely limit the number of VMs that can be launched. In a
    world where we support BPF JIT always on, turning off the JIT isn't always an
    option either.
    
    Fixes: 91fc957c9b1d ("arm64/bpf: don't allocate BPF JIT programs in module memory")
    Suggested-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Russell King <russell.king@oracle.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Tested-by: Alan Maguire <alan.maguire@oracle.com>
    Link: https://lore.kernel.org/bpf/1636131046-5982-2-git-send-email-alan.maguire@oracle.com
    Reviewed-by: Tom Saeger <tom.saeger@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7b6577cf9fe48d24d82df9362a077396a9d5cb27
Author: Harry Wentland <harry.wentland@amd.com>
Date:   Tue Jan 4 10:45:41 2022 -0500

    drm/amdgpu: Use correct VIEWPORT_DIMENSION for DCN2
    
    commit dc5d4aff2e99c312df8abbe1ee9a731d2913bc1b upstream.
    
    For some reason this file isn't using the appropriate register
    headers for DCN headers, which means that on DCN2 we're getting
    the VIEWPORT_DIMENSION offset wrong.
    
    This means that we're not correctly carving out the framebuffer
    memory correctly for a framebuffer allocated by EFI and
    therefore see corruption when loading amdgpu before the display
    driver takes over control of the framebuffer scanout.
    
    Fix this by checking the DCE_HWIP and picking the correct offset
    accordingly.
    
    Long-term we should expose this info from DC as GMC shouldn't
    need to know about DCN registers.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Harry Wentland <harry.wentland@amd.com>
    Reviewed-by: Huang Rui <ray.huang@amd.com>
    Acked-by: Christian König <christian.koenig@amd.com>
    Reviewed-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Mario Limonciello <mario.limonciello@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 145407e54fd15fd2a87ee7d6c66077e614036a9b
Author: Jan Kara <jack@suse.cz>
Date:   Mon Jan 10 19:19:23 2022 +0100

    select: Fix indefinitely sleeping task in poll_schedule_timeout()
    
    commit 68514dacf2715d11b91ca50d88de047c086fea9c upstream.
    
    A task can end up indefinitely sleeping in do_select() ->
    poll_schedule_timeout() when the following race happens:
    
      TASK1 (thread1)             TASK2                   TASK1 (thread2)
      do_select()
        setup poll_wqueues table
        with 'fd'
                                  write data to 'fd'
                                    pollwake()
                                      table->triggered = 1
                                                          closes 'fd' thread1 is
                                                            waiting for
        poll_schedule_timeout()
          - sees table->triggered
          table->triggered = 0
          return -EINTR
        loop back in do_select()
    
    But at this point when TASK1 loops back, the fdget() in the setup of
    poll_wqueues fails.  So now so we never find 'fd' is ready for reading
    and sleep in poll_schedule_timeout() indefinitely.
    
    Treat an fd that got closed as a fd on which some event happened.  This
    makes sure cannot block indefinitely in do_select().
    
    Another option would be to return -EBADF in this case but that has a
    potential of subtly breaking applications that excercise this behavior
    and it happens to work for them.  So returning fd as active seems like a
    safer choice.
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    CC: stable@vger.kernel.org
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c3156dbd5082c65b84936c8de47149799dee3ef8
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Sep 17 15:04:48 2021 -0700

    rcu: Tighten rcu_advance_cbs_nowake() checks
    
    commit 614ddad17f22a22e035e2ea37a04815f50362017 upstream.
    
    Currently, rcu_advance_cbs_nowake() checks that a grace period is in
    progress, however, that grace period could end just after the check.
    This commit rechecks that a grace period is still in progress while
    holding the rcu_node structure's lock.  The grace period cannot end while
    the current CPU's rcu_node structure's ->lock is held, thus avoiding
    false positives from the WARN_ON_ONCE().
    
    As Daniel Vacek noted, it is not necessary for the rcu_node structure
    to have a CPU that has not yet passed through its quiescent state.
    
    Tested-by: Guillaume Morin <guillaume@morinfr.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6ebe994b54a63f78e7bba65ac5ebaca7dfa88526
Author: Shakeel Butt <shakeelb@google.com>
Date:   Fri Jan 14 14:05:39 2022 -0800

    memcg: better bounds on the memcg stats updates
    
    commit 5b3be698a872c490dbed524f3e2463701ab21339 upstream.
    
    Commit 11192d9c124d ("memcg: flush stats only if updated") added
    tracking of memcg stats updates which is used by the readers to flush
    only if the updates are over a certain threshold.  However each
    individual update can correspond to a large value change for a given
    stat.  For example adding or removing a hugepage to an LRU changes the
    stat by thp_nr_pages (512 on x86_64).
    
    Treating the update related to THP as one can keep the stat off, in
    theory, by (thp_nr_pages * nr_cpus * CHARGE_BATCH) before flush.
    
    To handle such scenarios, this patch adds consideration of the stat
    update value as well instead of just the update event.  In addition let
    the asyn flusher unconditionally flush the stats to put time limit on
    the stats skew and hopefully a lot less readers would need to flush.
    
    Link: https://lkml.kernel.org/r/20211118065350.697046-1-shakeelb@google.com
    Signed-off-by: Shakeel Butt <shakeelb@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: "Michal Koutný" <mkoutny@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Ivan Babrou <ivan@cloudflare.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6c8076660d9cc281dbb0445c3967f1e1641f5115
Author: Shakeel Butt <shakeelb@google.com>
Date:   Fri Nov 5 13:37:34 2021 -0700

    memcg: unify memcg stat flushing
    
    commit fd25a9e0e23b995fd0ba5e2f00a1099452cbc3cf upstream.
    
    The memcg stats can be flushed in multiple context and potentially in
    parallel too.  For example multiple parallel user space readers for
    memcg stats will contend on the rstat locks with each other.  There is
    no need for that.  We just need one flusher and everyone else can
    benefit.
    
    In addition after aa48e47e3906 ("memcg: infrastructure to flush memcg
    stats") the kernel periodically flush the memcg stats from the root, so,
    the other flushers will potentially have much less work to do.
    
    Link: https://lkml.kernel.org/r/20211001190040.48086-2-shakeelb@google.com
    Signed-off-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: "Michal Koutný" <mkoutny@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Ivan Babrou <ivan@cloudflare.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7182935bd5ae2b7f747d6feb2b56b918ab26647c
Author: Shakeel Butt <shakeelb@google.com>
Date:   Fri Nov 5 13:37:31 2021 -0700

    memcg: flush stats only if updated
    
    commit 11192d9c124d58d66449b163ed0d2cdff03761a1 upstream.
    
    At the moment, the kernel flushes the memcg stats on every refault and
    also on every reclaim iteration.  Although rstat maintains per-cpu
    update tree but on the flush the kernel still has to go through all the
    cpu rstat update tree to check if there is anything to flush.  This
    patch adds the tracking on the stats update side to make flush side more
    clever by skipping the flush if there is no update.
    
    The stats update codepath is very sensitive performance wise for many
    workloads and benchmarks.  So, we can not follow what the commit
    aa48e47e3906 ("memcg: infrastructure to flush memcg stats") did which
    was triggering async flush through queue_work() and caused a lot
    performance regression reports.  That got reverted by the commit
    1f828223b799 ("memcg: flush lruvec stats in the refault").
    
    In this patch we kept the stats update codepath very minimal and let the
    stats reader side to flush the stats only when the updates are over a
    specific threshold.  For now the threshold is (nr_cpus * CHARGE_BATCH).
    
    To evaluate the impact of this patch, an 8 GiB tmpfs file is created on
    a system with swap-on-zram and the file was pushed to swap through
    memory.force_empty interface.  On reading the whole file, the memcg stat
    flush in the refault code path is triggered.  With this patch, we
    observed 63% reduction in the read time of 8 GiB file.
    
    Link: https://lkml.kernel.org/r/20211001190040.48086-1-shakeelb@google.com
    Signed-off-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Reviewed-by: "Michal Koutný" <mkoutny@suse.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Ivan Babrou <ivan@cloudflare.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2691be41fede058092c84455e3d52232e08a5990
Author: Manish Chopra <manishc@marvell.com>
Date:   Tue Jan 25 10:57:49 2022 -0800

    bnx2x: Invalidate fastpath HSI version for VFs
    
    commit 802d4d207e75d7208ff75adb712b556c1e91cf1c upstream
    
    Commit 0a6890b9b4df ("bnx2x: Utilize FW 7.13.15.0.")
    added validation for fastpath HSI versions for different
    client init which was not meant for SR-IOV VF clients, which
    resulted in firmware asserts when running VF clients with
    different fastpath HSI version.
    
    This patch along with the new firmware support in patch #1
    fixes this behavior in order to not validate fastpath HSI
    version for the VFs.
    
    Fixes: 0a6890b9b4df ("bnx2x: Utilize FW 7.13.15.0.")
    Signed-off-by: Manish Chopra <manishc@marvell.com>
    Signed-off-by: Prabhakar Kushwaha <pkushwaha@marvell.com>
    Signed-off-by: Alok Prasad <palok@marvell.com>
    Signed-off-by: Ariel Elior <aelior@marvell.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 66e1791cbeedce631dbad32bfb974c7f910fc8df
Author: Manish Chopra <manishc@marvell.com>
Date:   Tue Jan 25 10:57:48 2022 -0800

    bnx2x: Utilize firmware 7.13.21.0
    
    commit b7a49f73059fe6147b6b78e8f674ce0d21237432 upstream
    
    This new firmware addresses few important issues and enhancements
    as mentioned below -
    
    - Support direct invalidation of FP HSI Ver per function ID, required for
      invalidating FP HSI Ver prior to each VF start, as there is no VF start
    - BRB hardware block parity error detection support for the driver
    - Fix the FCOE underrun flow
    - Fix PSOD during FCoE BFS over the NIC ports after preboot driver
    - Maintains backward compatibility
    
    This patch incorporates this new firmware 7.13.21.0 in bnx2x driver.
    
    Signed-off-by: Manish Chopra <manishc@marvell.com>
    Signed-off-by: Prabhakar Kushwaha <pkushwaha@marvell.com>
    Signed-off-by: Alok Prasad <palok@marvell.com>
    Signed-off-by: Ariel Elior <aelior@marvell.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b168b1a0397ea64afc852e8f639be5bd920a79d9
Author: Pavel Begunkov <asml.silence@gmail.com>
Date:   Sun Jan 9 00:53:22 2022 +0000

    io_uring: fix not released cached task refs
    
    commit 3cc7fdb9f90a25ae92250bf9e6cf3b9556b230e9 upstream.
    
    tctx_task_work() may get run after io_uring cancellation and so there
    will be no one to put cached in tctx task refs that may have been added
    back by tw handlers using inline completion infra, Call
    io_uring_drop_tctx_refs() at the end of the main tw handler to release
    them.
    
    Cc: stable@vger.kernel.org # 5.15+
    Reported-by: Lukas Bulwahn <lukas.bulwahn@gmail.com>
    Fixes: e98e49b2bbf7 ("io_uring: extend task put optimisations")
    Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
    Link: https://lore.kernel.org/r/69f226b35fbdb996ab799a8bbc1c06bf634ccec1.1641688805.git.asml.silence@gmail.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f71c91ed1d4b4bfbbb55327b04dcc32b2d970f62
Author: Mario Limonciello <mario.limonciello@amd.com>
Date:   Fri Jan 7 15:40:10 2022 -0600

    drm/amd/display: reset dcn31 SMU mailbox on failures
    
    commit 83293f7f3d15fc56e86bd5067a2c88b6b233ac3a upstream.
    
    Otherwise future commands may fail as well leading to downstream
    problems that look like they stemmed from a timeout the first time
    but really didn't.
    
    Signed-off-by: Mario Limonciello <mario.limonciello@amd.com>
    Reviewed-by: Nicholas Kazlauskas <nicholas.kazlauskas@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8a17a077e7e9ecce25c95dbdb27843d2d6c2f0f7
Author: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
Date:   Tue Oct 19 13:27:10 2021 +0100

    drm/i915: Flush TLBs before releasing backing store
    
    commit 7938d61591d33394a21bdd7797a245b65428f44c upstream.
    
    We need to flush TLBs before releasing backing store otherwise userspace
    is able to encounter stale entries if a) it is not declaring access to
    certain buffers and b) it races with the backing store release from a
    such undeclared execution already executing on the GPU in parallel.
    
    The approach taken is to mark any buffer objects which were ever bound
    to the GPU and to trigger a serialized TLB flush when their backing
    store is released.
    
    Alternatively the flushing could be done on VMA unbind, at which point
    we would be able to ascertain whether there is potential a parallel GPU
    execution (which could race), but essentially it boils down to paying
    the cost of TLB flushes potentially needlessly at VMA unbind time (when
    the backing store is not known to be going away so not needed for
    safety), versus potentially needlessly at backing store relase time
    (since we at that point cannot tell whether there is anything executing
    on the GPU which uses that object).
    
    Thereforce simplicity of implementation has been chosen for now with
    scope to benchmark and refine later as required.
    
    Signed-off-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Reported-by: Sushma Venkatesh Reddy <sushma.venkatesh.reddy@intel.com>
    Reviewed-by: Daniel Vetter <daniel.vetter@ffwll.ch>
    Acked-by: Dave Airlie <airlied@redhat.com>
    Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
    Cc: Jon Bloomfield <jon.bloomfield@intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Jani Nikula <jani.nikula@intel.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
