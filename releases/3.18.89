commit 1e6e21c74c7c866db0abdfc452937724c3d80bdc
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Dec 20 10:01:34 2017 +0100

    Linux 3.18.89

commit 29d2c6506bc347732e509940c243a56891c12c1c
Author: Bin Liu <b-liu@ti.com>
Date:   Tue Dec 5 08:45:30 2017 -0600

    usb: musb: da8xx: fix babble condition handling
    
    commit bd3486ded7a0c313a6575343e6c2b21d14476645 upstream.
    
    When babble condition happens, the musb controller might automatically
    turns off VBUS. On DA8xx platform, the controller generates drvvbus
    interrupt for turning off VBUS along with the babble interrupt.
    
    In this case, we should handle the babble interrupt first and recover
    from the babble condition.
    
    This change ignores the drvvbus interrupt if babble interrupt is also
    generated at the same time, so the babble recovery routine works
    properly.
    
    Signed-off-by: Bin Liu <b-liu@ti.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07aa0bc0072e49c71caad90a3ab74aa34ccd64e4
Author: Miaoqing Pan <miaoqing@codeaurora.org>
Date:   Wed Sep 27 09:13:34 2017 +0800

    ath9k: fix tx99 potential info leak
    
    
    [ Upstream commit ee0a47186e2fa9aa1c56cadcea470ca0ba8c8692 ]
    
    When the user sets count to zero the string buffer would remain
    completely uninitialized which causes the kernel to parse its
    own stack data, potentially leading to an info leak. In addition
    to that, the string might be not terminated properly when the
    user data does not contain a 0-terminator.
    
    Signed-off-by: Miaoqing Pan <miaoqing@codeaurora.org>
    Reviewed-by: Christoph BÃ¶hmwalder <christoph@boehmwalder.at>
    Signed-off-by: Kalle Valo <kvalo@qca.qualcomm.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2d7c1288825f5c6fc85502d3a32bb1a9806354ff
Author: Alexander Duyck <alexander.h.duyck@intel.com>
Date:   Fri Oct 13 13:40:24 2017 -0700

    macvlan: Only deliver one copy of the frame to the macvlan interface
    
    
    [ Upstream commit dd6b9c2c332b40f142740d1b11fb77c653ff98ea ]
    
    This patch intoduces a slight adjustment for macvlan to address the fact
    that in source mode I was seeing two copies of any packet addressed to the
    macvlan interface being delivered where there should have been only one.
    
    The issue appears to be that one copy was delivered based on the source MAC
    address and then the second copy was being delivered based on the
    destination MAC address. To fix it I am just treating a unicast address
    match as though it is not a match since source based macvlan isn't supposed
    to be matching based on the destination MAC anyway.
    
    Fixes: 79cf79abce71 ("macvlan: add source mode")
    Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 58617c76ed62f0b9a9b6b5a9b791ee5314937d1e
Author: Jan Kara <jack@suse.cz>
Date:   Mon Oct 16 11:38:11 2017 +0200

    udf: Avoid overflow when session starts at large offset
    
    
    [ Upstream commit abdc0eb06964fe1d2fea6dd1391b734d0590365d ]
    
    When session starts beyond offset 2^31 the arithmetics in
    udf_check_vsd() would overflow. Make sure the computation is done in
    large enough type.
    
    Reported-by: Cezary Sliwa <sliwa@ifpan.edu.pl>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cae8f2343a45475d0ba606fdd457ffce8cb5db01
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Wed Oct 4 10:50:37 2017 +0300

    scsi: bfa: integer overflow in debugfs
    
    
    [ Upstream commit 3e351275655d3c84dc28abf170def9786db5176d ]
    
    We could allocate less memory than intended because we do:
    
            bfad->regdata = kzalloc(len << 2, GFP_KERNEL);
    
    The shift can overflow leading to a crash.  This is debugfs code so the
    impact is very small.  I fixed the network version of this in March with
    commit 13e2d5187f6b ("bna: integer overflow bug in debugfs").
    
    Fixes: ab2a9ba189e8 ("[SCSI] bfa: add debugfs support")
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 47e43e619077ec024130020aa34deb3d9deb9561
Author: Kurt Garloff <garloff@suse.de>
Date:   Tue Oct 17 09:10:45 2017 +0200

    scsi: scsi_devinfo: Add REPORTLUN2 to EMC SYMMETRIX blacklist entry
    
    
    [ Upstream commit 909cf3e16a5274fe2127cf3cea5c8dba77b2c412 ]
    
    All EMC SYMMETRIX support REPORT_LUNS, even if configured to report
    SCSI-2 for whatever reason.
    
    Signed-off-by: Kurt Garloff <garloff@suse.de>
    Signed-off-by: Hannes Reinecke <hare@suse.de>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 57886e81b8bbb5d9d15c6aaab70d5ce63674de36
Author: NeilBrown <neilb@suse.com>
Date:   Tue Oct 17 16:18:36 2017 +1100

    raid5: Set R5_Expanded on parity devices as well as data.
    
    
    [ Upstream commit 235b6003fb28f0dd8e7ed8fbdb088bb548291766 ]
    
    When reshaping a fully degraded raid5/raid6 to a larger
    nubmer of devices, the new device(s) are not in-sync
    and so that can make the newly grown stripe appear to be
    "failed".
    To avoid this, we set the R5_Expanded flag to say "Even though
    this device is not fully in-sync, this block is safe so
    don't treat the device as failed for this stripe".
    This flag is set for data devices, not not for parity devices.
    
    Consequently, if you have a RAID6 with two devices that are partly
    recovered and a spare, and start a reshape to include the spare,
    then when the reshape gets past the point where the recovery was
    up to, it will think the stripes are failed and will get into
    an infinite loop, failing to make progress.
    
    So when contructing parity on an EXPAND_READY stripe,
    set R5_Expanded.
    
    Reported-by: Curt <lightspd@gmail.com>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9df8ffc3035abc95311464775037d9690e8316a0
Author: Linus Walleij <linus.walleij@linaro.org>
Date:   Wed Oct 11 11:57:15 2017 +0200

    pinctrl: adi2: Fix Kconfig build problem
    
    
    [ Upstream commit 1c363531dd814dc4fe10865722bf6b0f72ce4673 ]
    
    The build robot is complaining on Blackfin:
    
    drivers/pinctrl/pinctrl-adi2.c: In function 'port_setup':
    >> drivers/pinctrl/pinctrl-adi2.c:221:21: error: dereferencing
       pointer to incomplete type 'struct gpio_port_t'
          writew(readw(&regs->port_fer) & ~BIT(offset),
                            ^~
    drivers/pinctrl/pinctrl-adi2.c: In function 'adi_gpio_ack_irq':
    >> drivers/pinctrl/pinctrl-adi2.c:266:18: error: dereferencing
    pointer to incomplete type 'struct bfin_pint_regs'
          if (readl(&regs->invert_set) & pintbit)
                         ^~
    It seems the driver need to include <asm/gpio.h> and <asm/irq.h>
    to compile.
    
    The Blackfin architecture was re-defining the Kconfig
    PINCTRL symbol which is not OK, so replaced this with
    PINCTRL_BLACKFIN_ADI2 which selects PINCTRL and PINCTRL_ADI2
    just like most arches do.
    
    Further, the old GPIO driver symbol GPIO_ADI was possible to
    select at the same time as selecting PINCTRL. This was not
    working because the arch-local <asm/gpio.h> header contains
    an explicit #ifndef PINCTRL clause making compilation break
    if you combine them. The same is true for DEBUG_MMRS.
    
    Make sure the ADI2 pinctrl driver is not selected at the same
    time as the old GPIO implementation. (This should be converted
    to use gpiolib or pincontrol and move to drivers/...) Also make
    sure the old GPIO_ADI driver or DEBUG_MMRS is not selected at
    the same time as the new PINCTRL implementation, and only make
    PINCTRL_ADI2 selectable for the Blackfin families that actually
    have it.
    
    This way it is still possible to add e.g. I2C-based pin
    control expanders on the Blackfin.
    
    Cc: Steven Miao <realmz6@gmail.com>
    Cc: Huanhuan Feng <huanhuan.feng@analog.com>
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ba3e1b3553c512d1f8c0f3c23e800d009983e898
Author: nixiaoming <nixiaoming@huawei.com>
Date:   Fri Sep 15 17:45:56 2017 +0800

    tty fix oops when rmmod 8250
    
    
    [ Upstream commit c79dde629d2027ca80329c62854a7635e623d527 ]
    
    After rmmod 8250.ko
    tty_kref_put starts kwork (release_one_tty) to release proc interface
    oops when accessing driver->driver_name in proc_tty_unregister_driver
    
    Use jprobe, found driver->driver_name point to 8250.ko
    static static struct uart_driver serial8250_reg
    .driver_name= serial,
    
    Use name in proc_dir_entry instead of driver->driver_name to fix oops
    
    test on linux 4.1.12:
    
    BUG: unable to handle kernel paging request at ffffffffa01979de
    IP: [<ffffffff81310f40>] strchr+0x0/0x30
    PGD 1a0d067 PUD 1a0e063 PMD 851c1f067 PTE 0
    Oops: 0000 [#1] PREEMPT SMP
    Modules linked in: ... ...  [last unloaded: 8250]
    CPU: 7 PID: 116 Comm: kworker/7:1 Tainted: G           O    4.1.12 #1
    Hardware name: Insyde RiverForest/Type2 - Board Product Name1, BIOS NE5KV904 12/21/2015
    Workqueue: events release_one_tty
    task: ffff88085b684960 ti: ffff880852884000 task.ti: ffff880852884000
    RIP: 0010:[<ffffffff81310f40>]  [<ffffffff81310f40>] strchr+0x0/0x30
    RSP: 0018:ffff880852887c90  EFLAGS: 00010282
    RAX: ffffffff81a5eca0 RBX: ffffffffa01979de RCX: 0000000000000004
    RDX: ffff880852887d10 RSI: 000000000000002f RDI: ffffffffa01979de
    RBP: ffff880852887cd8 R08: 0000000000000000 R09: ffff88085f5d94d0
    R10: 0000000000000195 R11: 0000000000000000 R12: ffffffffa01979de
    R13: ffff880852887d00 R14: ffffffffa01979de R15: ffff88085f02e840
    FS:  0000000000000000(0000) GS:ffff88085f5c0000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: ffffffffa01979de CR3: 0000000001a0c000 CR4: 00000000001406e0
    Stack:
     ffffffff812349b1 ffff880852887cb8 ffff880852887d10 ffff88085f5cd6c2
     ffff880852800a80 ffffffffa01979de ffff880852800a84 0000000000000010
     ffff88085bb28bd8 ffff880852887d38 ffffffff812354f0 ffff880852887d08
    Call Trace:
     [<ffffffff812349b1>] ? __xlate_proc_name+0x71/0xd0
     [<ffffffff812354f0>] remove_proc_entry+0x40/0x180
     [<ffffffff815f6811>] ? _raw_spin_lock_irqsave+0x41/0x60
     [<ffffffff813be520>] ? destruct_tty_driver+0x60/0xe0
     [<ffffffff81237c68>] proc_tty_unregister_driver+0x28/0x40
     [<ffffffff813be548>] destruct_tty_driver+0x88/0xe0
     [<ffffffff813be5bd>] tty_driver_kref_put+0x1d/0x20
     [<ffffffff813becca>] release_one_tty+0x5a/0xd0
     [<ffffffff81074159>] process_one_work+0x139/0x420
     [<ffffffff810745a1>] worker_thread+0x121/0x450
     [<ffffffff81074480>] ? process_scheduled_works+0x40/0x40
     [<ffffffff8107a16c>] kthread+0xec/0x110
     [<ffffffff81080000>] ? tg_rt_schedulable+0x210/0x220
     [<ffffffff8107a080>] ? kthread_freezable_should_stop+0x80/0x80
     [<ffffffff815f7292>] ret_from_fork+0x42/0x70
     [<ffffffff8107a080>] ? kthread_freezable_should_stop+0x80/0x80
    
    Signed-off-by: nixiaoming <nixiaoming@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a36596b1ac5832610a30f33ebf7813de99203b8d
Author: Alex Williamson <alex.williamson@redhat.com>
Date:   Wed Oct 11 15:35:56 2017 -0600

    PCI: Detach driver before procfs & sysfs teardown on device remove
    
    
    [ Upstream commit 16b6c8bb687cc3bec914de09061fcb8411951fda ]
    
    When removing a device, for example a VF being removed due to SR-IOV
    teardown, a "soft" hot-unplug via 'echo 1 > remove' in sysfs, or an actual
    hot-unplug, we first remove the procfs and sysfs attributes for the device
    before attempting to release the device from any driver bound to it.
    Unbinding the driver from the device can take time.  The device might need
    to write out data or it might be actively in use.  If it's in use by
    userspace through a vfio driver, the unbind might block until the user
    releases the device.  This leads to a potentially non-trivial amount of
    time where the device exists, but we've torn down the interfaces that
    userspace uses to examine devices, for instance lspci might generate this
    sort of error:
    
      pcilib: Cannot open /sys/bus/pci/devices/0000:01:0a.3/config
      lspci: Unable to read the standard configuration space header of device 0000:01:0a.3
    
    We don't seem to have any dependence on this teardown ordering in the
    kernel, so let's unbind the driver first, which is also more symmetric with
    the instantiation of the device in pci_bus_add_device().
    
    Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a5045f7d107784ae3d8c484e2086c343e4f41fb9
Author: Brian Foster <bfoster@redhat.com>
Date:   Thu Oct 26 09:31:16 2017 -0700

    xfs: fix log block underflow during recovery cycle verification
    
    
    [ Upstream commit 9f2a4505800607e537e9dd9dea4f55c4b0c30c7a ]
    
    It is possible for mkfs to format very small filesystems with too
    small of an internal log with respect to the various minimum size
    and block count requirements. If this occurs when the log happens to
    be smaller than the scan window used for cycle verification and the
    scan wraps the end of the log, the start_blk calculation in
    xlog_find_head() underflows and leads to an attempt to scan an
    invalid range of log blocks. This results in log recovery failure
    and a failed mount.
    
    Since there may be filesystems out in the wild with this kind of
    geometry, we cannot simply refuse to mount. Instead, cap the scan
    window for cycle verification to the size of the physical log. This
    ensures that the cycle verification proceeds as expected when the
    scan wraps the end of the log.
    
    Reported-by: Zorro Lang <zlang@redhat.com>
    Signed-off-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d4ec687b9721e56dedf152041c1ed19ffe34020c
Author: tang.junhui <tang.junhui@zte.com.cn>
Date:   Mon Oct 30 14:46:34 2017 -0700

    bcache: fix wrong cache_misses statistics
    
    
    [ Upstream commit c157313791a999646901b3e3c6888514ebc36d62 ]
    
    Currently, Cache missed IOs are identified by s->cache_miss, but actually,
    there are many situations that missed IOs are not assigned a value for
    s->cache_miss in cached_dev_cache_miss(), for example, a bypassed IO
    (s->iop.bypass = 1), or the cache_bio allocate failed. In these situations,
    it will go to out_put or out_submit, and s->cache_miss is null, which leads
    bch_mark_cache_accounting() to treat this IO as a hit IO.
    
    [ML: applied by 3-way merge]
    
    Signed-off-by: tang.junhui <tang.junhui@zte.com.cn>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Reviewed-by: Coly Li <colyli@suse.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5df0ce4b14be6bd7ecbebc72bee58b2059333228
Author: Liang Chen <liangchen.linux@gmail.com>
Date:   Mon Oct 30 14:46:35 2017 -0700

    bcache: explicitly destroy mutex while exiting
    
    
    [ Upstream commit 330a4db89d39a6b43f36da16824eaa7a7509d34d ]
    
    mutex_destroy does nothing most of time, but it's better to call
    it to make the code future proof and it also has some meaning
    for like mutex debug.
    
    As Coly pointed out in a previous review, bcache_exit() may not be
    able to handle all the references properly if userspace registers
    cache and backing devices right before bch_debug_init runs and
    bch_debug_init failes later. So not exposing userspace interface
    until everything is ready to avoid that issue.
    
    Signed-off-by: Liang Chen <liangchen.linux@gmail.com>
    Reviewed-by: Michael Lyle <mlyle@lyle.org>
    Reviewed-by: Coly Li <colyli@suse.de>
    Reviewed-by: Eric Wheeler <bcache@linux.ewheeler.net>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 00dd6166c1975a230d780b0f2bdd1750a598f679
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Sep 20 08:30:04 2017 -0500

    GFS2: Take inode off order_write list when setting jdata flag
    
    
    [ Upstream commit cc555b09d8c3817aeebda43a14ab67049a5653f7 ]
    
    This patch fixes a deadlock caused when the jdata flag is set for
    inodes that are already on the ordered write list. Since it is
    on the ordered write list, log_flush calls gfs2_ordered_write which
    calls filemap_fdatawrite. But since the inode had the jdata flag
    set, that calls gfs2_jdata_writepages, which tries to start a new
    transaction. A new transaction cannot be started because it tries
    to acquire the log_flush rwsem which is already locked by the log
    flush operation.
    
    The bottom line is: We cannot switch an inode from ordered to jdata
    until we eliminate any ordered data pages (via log flush) or any
    log_flush operation afterward will create the circular dependency
    above. So we need to flush the log before setting the diskflags to
    switch the file mode, then we need to remove the inode from the
    ordered writes list.
    
    Before this patch, the log flush was done for jdata->ordered, but
    that's wrong. If we're going from jdata to ordered, we don't need
    to call gfs2_log_flush because the call to filemap_fdatawrite will
    do it for us:
    
       filemap_fdatawrite() -> __filemap_fdatawrite_range()
          __filemap_fdatawrite_range() -> do_writepages()
             do_writepages() -> gfs2_jdata_writepages()
                gfs2_jdata_writepages() -> gfs2_log_flush()
    
    This patch modifies function do_gfs2_set_flags so that if a file
    has its jdata flag set, and it's already on the ordered write list,
    the log will be flushed and it will be removed from the list
    before setting the flag.
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Acked-by: Abhijith Das <adas@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9aa8bbc15ab1a58fe5b790fec31d237b0d88d0e5
Author: Daniel Lezcano <daniel.lezcano@linaro.org>
Date:   Thu Oct 19 19:05:58 2017 +0200

    thermal/drivers/step_wise: Fix temperature regulation misbehavior
    
    
    [ Upstream commit 07209fcf33542c1ff1e29df2dbdf8f29cdaacb10 ]
    
    There is a particular situation when the cooling device is cpufreq and the heat
    dissipation is not efficient enough where the temperature increases little by
    little until reaching the critical threshold and leading to a SoC reset.
    
    The behavior is reproducible on a hikey6220 with bad heat dissipation (eg.
    stacked with other boards).
    
    Running a simple C program doing while(1); for each CPU of the SoC makes the
    temperature to reach the passive regulation trip point and ends up to the
    maximum allowed temperature followed by a reset.
    
    This issue has been also reported by running the libhugetlbfs test suite.
    
    What is observed is a ping pong between two cpu frequencies, 1.2GHz and 900MHz
    while the temperature continues to grow.
    
    It appears the step wise governor calls get_target_state() the first time with
    the throttle set to true and the trend to 'raising'. The code selects logically
    the next state, so the cpu frequency decreases from 1.2GHz to 900MHz, so far so
    good. The temperature decreases immediately but still stays greater than the
    trip point, then get_target_state() is called again, this time with the
    throttle set to true *and* the trend to 'dropping'. From there the algorithm
    assumes we have to step down the state and the cpu frequency jumps back to
    1.2GHz. But the temperature is still higher than the trip point, so
    get_target_state() is called with throttle=1 and trend='raising' again, we jump
    to 900MHz, then get_target_state() is called with throttle=1 and
    trend='dropping', we jump to 1.2GHz, etc ... but the temperature does not
    stabilizes and continues to increase.
    
    [  237.922654] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=1,throttle=1
    [  237.922678] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=1,throttle=1
    [  237.922690] thermal cooling_device0: cur_state=0
    [  237.922701] thermal cooling_device0: old_target=0, target=1
    [  238.026656] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=2,throttle=1
    [  238.026680] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=2,throttle=1
    [  238.026694] thermal cooling_device0: cur_state=1
    [  238.026707] thermal cooling_device0: old_target=1, target=0
    [  238.134647] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=1,throttle=1
    [  238.134667] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=1,throttle=1
    [  238.134679] thermal cooling_device0: cur_state=0
    [  238.134690] thermal cooling_device0: old_target=0, target=1
    
    In this situation the temperature continues to increase while the trend is
    oscillating between 'dropping' and 'raising'. We need to keep the current state
    untouched if the throttle is set, so the temperature can decrease or a higher
    state could be selected, thus preventing this oscillation.
    
    Keeping the next_target untouched when 'throttle' is true at 'dropping' time
    fixes the issue.
    
    The following traces show the governor does not change the next state if
    trend==2 (dropping) and throttle==1.
    
    [ 2306.127987] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=1,throttle=1
    [ 2306.128009] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=1,throttle=1
    [ 2306.128021] thermal cooling_device0: cur_state=0
    [ 2306.128031] thermal cooling_device0: old_target=0, target=1
    [ 2306.231991] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=2,throttle=1
    [ 2306.232016] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=2,throttle=1
    [ 2306.232030] thermal cooling_device0: cur_state=1
    [ 2306.232042] thermal cooling_device0: old_target=1, target=1
    [ 2306.335982] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=0,throttle=1
    [ 2306.336006] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=0,throttle=1
    [ 2306.336021] thermal cooling_device0: cur_state=1
    [ 2306.336034] thermal cooling_device0: old_target=1, target=1
    [ 2306.439984] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=2,throttle=1
    [ 2306.440008] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=2,throttle=0
    [ 2306.440022] thermal cooling_device0: cur_state=1
    [ 2306.440034] thermal cooling_device0: old_target=1, target=0
    
    [ ...Â ]
    
    After a while, if the temperature continues to increase, the next state becomes
    2 which is 720MHz on the hikey. That results in the temperature stabilizing
    around the trip point.
    
    [ 2455.831982] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=1,throttle=1
    [ 2455.832006] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=1,throttle=0
    [ 2455.832019] thermal cooling_device0: cur_state=1
    [ 2455.832032] thermal cooling_device0: old_target=1, target=1
    [ 2455.935985] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=0,throttle=1
    [ 2455.936013] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=0,throttle=0
    [ 2455.936027] thermal cooling_device0: cur_state=1
    [ 2455.936040] thermal cooling_device0: old_target=1, target=1
    [ 2456.043984] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=0,throttle=1
    [ 2456.044009] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=0,throttle=0
    [ 2456.044023] thermal cooling_device0: cur_state=1
    [ 2456.044036] thermal cooling_device0: old_target=1, target=1
    [ 2456.148001] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=1,throttle=1
    [ 2456.148028] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=1,throttle=1
    [ 2456.148042] thermal cooling_device0: cur_state=1
    [ 2456.148055] thermal cooling_device0: old_target=1, target=2
    [ 2456.252009] thermal thermal_zone0: Trip0[type=1,temp=65000]:trend=2,throttle=1
    [ 2456.252041] thermal thermal_zone0: Trip1[type=1,temp=75000]:trend=2,throttle=0
    [ 2456.252058] thermal cooling_device0: cur_state=2
    [ 2456.252075] thermal cooling_device0: old_target=2, target=1
    
    IOW, this change is needed to keep the state for a cooling device if the
    temperature trend is oscillating while the temperature increases slightly.
    
    Without this change, the situation above leads to a catastrophic crash by a
    hardware reset on hikey. This issue has been reported to happen on an OMAP
    dra7xx also.
    
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Keerthy <j-keerthy@ti.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Leo Yan <leo.yan@linaro.org>
    Tested-by: Keerthy <j-keerthy@ti.com>
    Reviewed-by: Keerthy <j-keerthy@ti.com>
    Signed-off-by: Eduardo Valentin <edubezval@gmail.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4c1eff22ffb3df2c626e958b04edb296f57935ef
Author: Gao Feng <gfree.wind@vip.163.com>
Date:   Tue Oct 31 18:25:37 2017 +0800

    ppp: Destroy the mutex when cleanup
    
    
    [ Upstream commit f02b2320b27c16b644691267ee3b5c110846f49e ]
    
    The mutex_destroy only makes sense when enable DEBUG_MUTEX. For the
    good readbility, it's better to invoke it in exit func when the init
    func invokes mutex_init.
    
    Signed-off-by: Gao Feng <gfree.wind@vip.163.com>
    Acked-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 069848c7547bc103d805bda93bd3dfb8189adbfa
Author: MichaÅ MirosÅaw <mirq-linux@rere.qmqm.pl>
Date:   Tue Sep 19 04:48:10 2017 +0200

    clk: tegra: Fix cclk_lp divisor register
    
    
    [ Upstream commit 54eff2264d3e9fd7e3987de1d7eba1d3581c631e ]
    
    According to comments in code and common sense, cclk_lp uses its
    own divisor, not cclk_g's.
    
    Fixes: b08e8c0ecc42 ("clk: tegra: add clock support for Tegra30")
    Signed-off-by: MichaÅ MirosÅaw <mirq-linux@rere.qmqm.pl>
    Acked-By: Peter De Schrijver <pdeschrijver@nvidia.com>
    Signed-off-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 340a510c65d98f0ae90629db2bd5432c41cf676c
Author: Jan Kara <jack@suse.cz>
Date:   Fri Nov 3 12:21:21 2017 +0100

    mm: Handle 0 flags in _calc_vm_trans() macro
    
    
    [ Upstream commit 592e254502041f953e84d091eae2c68cba04c10b ]
    
    _calc_vm_trans() does not handle the situation when some of the passed
    flags are 0 (which can happen if these VM flags do not make sense for
    the architecture). Improve the _calc_vm_trans() macro to return 0 in
    such situation. Since all passed flags are constant, this does not add
    any runtime overhead.
    
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5ae69f4575f0de451d5517a901824240aa552ccf
Author: Suzuki K Poulose <suzuki.poulose@arm.com>
Date:   Fri Nov 3 11:45:18 2017 +0000

    arm-ccn: perf: Prevent module unload while PMU is in use
    
    
    [ Upstream commit c7f5828bf77dcbd61d51f4736c1d5aa35663fbb4 ]
    
    When the PMU driver is built as a module, the perf expects the
    pmu->module to be valid, so that the driver is prevented from
    being unloaded while it is in use. Fix the CCN pmu driver to
    fill in this field.
    
    Fixes: a33b0daab73a0 ("bus: ARM CCN PMU driver")
    Cc: Pawel Moll <pawel.moll@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Acked-by: Mark Rutland <mark.rutland@arm.com>
    Signed-off-by: Suzuki K Poulose <suzuki.poulose@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8948ed2f5fe4e6d567ba74426c8de6bdb46f8a1a
Author: Jiang Yi <jiangyilism@gmail.com>
Date:   Fri Aug 11 11:29:44 2017 +0800

    target/file: Do not return error for UNMAP if length is zero
    
    
    [ Upstream commit 594e25e73440863981032d76c9b1e33409ceff6e ]
    
    The function fd_execute_unmap() in target_core_file.c calles
    
    ret = file->f_op->fallocate(file, mode, pos, len);
    
    Some filesystems implement fallocate() to return error if
    length is zero (e.g. btrfs) but according to SCSI Block
    Commands spec UNMAP should return success for zero length.
    
    Signed-off-by: Jiang Yi <jiangyilism@gmail.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e6da104cbddcfa80c3afae7be60d259799909431
Author: tangwenji <tang.wenji@zte.com.cn>
Date:   Thu Aug 24 19:59:37 2017 +0800

    target:fix condition return in core_pr_dump_initiator_port()
    
    
    [ Upstream commit 24528f089d0a444070aa4f715ace537e8d6bf168 ]
    
    When is pr_reg->isid_present_at_reg is false,this function should return.
    
    This fixes a regression originally introduced by:
    
      commit d2843c173ee53cf4c12e7dfedc069a5bc76f0ac5
      Author: Andy Grover <agrover@redhat.com>
      Date:   Thu May 16 10:40:55 2013 -0700
    
          target: Alter core_pr_dump_initiator_port for ease of use
    
    Signed-off-by: tangwenji <tang.wenji@zte.com.cn>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 75d2d7e7906c8f28bc0bbc4445de4cc750a52a3a
Author: tangwenji <tang.wenji@zte.com.cn>
Date:   Fri Sep 15 16:03:13 2017 +0800

    iscsi-target: fix memory leak in lio_target_tiqn_addtpg()
    
    
    [ Upstream commit 12d5a43b2dffb6cd28062b4e19024f7982393288 ]
    
    tpg must free when call core_tpg_register() return fail
    
    Signed-off-by: tangwenji <tang.wenji@zte.com.cn>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8867d3f1bb32ae974c92b76529769d424d32c451
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Tue Oct 31 11:03:17 2017 -0700

    target/iscsi: Fix a race condition in iscsit_add_reject_from_cmd()
    
    
    [ Upstream commit cfe2b621bb18d86e93271febf8c6e37622da2d14 ]
    
    Avoid that cmd->se_cmd.se_tfo is read after a command has already been
    freed.
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Mike Christie <mchristi@redhat.com>
    Reviewed-by: Hannes Reinecke <hare@suse.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 55bae20a7382543719207c84bf9e17487777ced8
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Wed Oct 18 11:16:47 2017 +0200

    powerpc/ipic: Fix status get and status clear
    
    
    [ Upstream commit 6b148a7ce72a7f87c81cbcde48af014abc0516a9 ]
    
    IPIC Status is provided by register IPIC_SERSR and not by IPIC_SERMR
    which is the mask register.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b1a66b1947e5c201f8c6860e11607faf80f9b6bc
Author: William A. Kennington III <wak@google.com>
Date:   Fri Sep 22 16:58:00 2017 -0700

    powerpc/opal: Fix EBUSY bug in acquiring tokens
    
    
    [ Upstream commit 71e24d7731a2903b1ae2bba2b2971c654d9c2aa6 ]
    
    The current code checks the completion map to look for the first token
    that is complete. In some cases, a completion can come in but the
    token can still be on lease to the caller processing the completion.
    If this completed but unreleased token is the first token found in the
    bitmap by another tasks trying to acquire a token, then the
    __test_and_set_bit call will fail since the token will still be on
    lease. The acquisition will then fail with an EBUSY.
    
    This patch reorganizes the acquisition code to look at the
    opal_async_token_map for an unleased token. If the token has no lease
    it must have no outstanding completions so we should never see an
    EBUSY, unless we have leased out too many tokens. Since
    opal_async_get_token_inrerruptible is protected by a semaphore, we
    will practically never see EBUSY anymore.
    
    Fixes: 8d7248232208 ("powerpc/powernv: Infrastructure to support OPAL async completion")
    Signed-off-by: William A. Kennington III <wak@google.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b4c9f0c128359d0b20c6be9ea1c125dda492417a
Author: Shriya <shriyak@linux.vnet.ibm.com>
Date:   Fri Oct 13 10:06:41 2017 +0530

    powerpc/powernv/cpufreq: Fix the frequency read by /proc/cpuinfo
    
    
    [ Upstream commit cd77b5ce208c153260ed7882d8910f2395bfaabd ]
    
    The call to /proc/cpuinfo in turn calls cpufreq_quick_get() which
    returns the last frequency requested by the kernel, but may not
    reflect the actual frequency the processor is running at. This patch
    makes a call to cpufreq_get() instead which returns the current
    frequency reported by the hardware.
    
    Fixes: fb5153d05a7d ("powerpc: powernv: Implement ppc_md.get_proc_freq()")
    Signed-off-by: Shriya <shriyak@linux.vnet.ibm.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0e8096628d11b521d3ed66c349d7bde4678909d7
Author: Qiang <zhengqiang10@huawei.com>
Date:   Thu Sep 28 11:54:34 2017 +0800

    PCI/PME: Handle invalid data when reading Root Status
    
    
    [ Upstream commit 3ad3f8ce50914288731a3018b27ee44ab803e170 ]
    
    PCIe PME and native hotplug share the same interrupt number, so hotplug
    interrupts are also processed by PME.  In some cases, e.g., a Link Down
    interrupt, a device may be present but unreachable, so when we try to
    read its Root Status register, the read fails and we get all ones data
    (0xffffffff).
    
    Previously, we interpreted that data as PCI_EXP_RTSTA_PME being set, i.e.,
    "some device has asserted PME," so we scheduled pcie_pme_work_fn().  This
    caused an infinite loop because pcie_pme_work_fn() tried to handle PME
    requests until PCI_EXP_RTSTA_PME is cleared, but with the link down,
    PCI_EXP_RTSTA_PME can't be cleared.
    
    Check for the invalid 0xffffffff data everywhere we read the Root Status
    register.
    
    1469d17dd341 ("PCI: pciehp: Handle invalid data when reading from
    non-existent devices") added similar checks in the hotplug driver.
    
    Signed-off-by: Qiang Zheng <zhengqiang10@huawei.com>
    [bhelgaas: changelog, also check in pcie_pme_work_fn(), use "~0" to follow
    other similar checks]
    Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
    
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 044cc5ec17d93236c5f61dbcf1222651a23825bf
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Thu Nov 9 18:09:28 2017 +0100

    video: fbdev: au1200fb: Return an error code if a memory allocation fails
    
    
    [ Upstream commit 8cae353e6b01ac3f18097f631cdbceb5ff28c7f3 ]
    
    'ret' is known to be 0 at this point.
    In case of memory allocation error in 'framebuffer_alloc()', return
    -ENOMEM instead.
    
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 16793c323d1667a16bea348fe16d83f88b93161d
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Thu Nov 9 18:09:28 2017 +0100

    video: fbdev: au1200fb: Release some resources if a memory allocation fails
    
    
    [ Upstream commit 451f130602619a17c8883dd0b71b11624faffd51 ]
    
    We should go through the error handling code instead of returning -ENOMEM
    directly.
    
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9a907ea5f7dbccc3b2cc810ad606d3c87919460b
Author: Ladislav Michl <ladis@linux-mips.org>
Date:   Thu Nov 9 18:09:30 2017 +0100

    video: udlfb: Fix read EDID timeout
    
    
    [ Upstream commit c98769475575c8a585f5b3952f4b5f90266f699b ]
    
    While usb_control_msg function expects timeout in miliseconds, a value
    of HZ is used. Replace it with USB_CTRL_GET_TIMEOUT and also fix error
    message which looks like:
    udlfb: Read EDID byte 78 failed err ffffff92
    as error is either negative errno or number of bytes transferred use %d
    format specifier.
    
    Returned EDID is in second byte, so return error when less than two bytes
    are received.
    
    Fixes: 18dffdf8913a ("staging: udlfb: enhance EDID and mode handling support")
    Signed-off-by: Ladislav Michl <ladis@linux-mips.org>
    Cc: Bernie Thompson <bernie@plugable.com>
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b3146dbdd20de973514d276101da6f8ae8872b30
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Thu Nov 9 18:09:33 2017 +0100

    fbdev: controlfb: Add missing modes to fix out of bounds access
    
    
    [ Upstream commit ac831a379d34109451b3c41a44a20ee10ecb615f ]
    
    Dan's static analysis says:
    
        drivers/video/fbdev/controlfb.c:560 control_setup()
        error: buffer overflow 'control_mac_modes' 20 <= 21
    
    Indeed, control_mac_modes[] has only 20 elements, while VMODE_MAX is 22,
    which may lead to an out of bounds read when parsing vmode commandline
    options.
    
    The bug was introduced in v2.4.5.6, when 2 new modes were added to
    macmodes.h, but control_mac_modes[] wasn't updated:
    
    https://kernel.opensuse.org/cgit/kernel/diff/include/video/macmodes.h?h=v2.5.2&id=29f279c764808560eaceb88fef36cbc35c529aad
    
    Augment control_mac_modes[] with the two new video modes to fix this.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Dan Carpenter <dan.carpenter@oracle.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d523df492e12dcc47b3f3ffe506eb5fb9f6a3273
Author: Mike Christie <mchristi@redhat.com>
Date:   Wed Mar 1 23:13:26 2017 -0600

    target: Use system workqueue for ALUA transitions
    
    
    [ Upstream commit 207ee84133c00a8a2a5bdec94df4a5b37d78881c ]
    
    If tcmu-runner is processing a STPG and needs to change the kernel's
    ALUA state then we cannot use the same work queue for task management
    requests and ALUA transitions, because we could deadlock. The problem
    occurs when a STPG times out before tcmu-runner is able to
    call into target_tg_pt_gp_alua_access_state_store->
    core_alua_do_port_transition -> core_alua_do_transition_tg_pt ->
    queue_work. In this case, the tmr is on the work queue waiting for
    the STPG to complete, but the STPG transition is now queued behind
    the waiting tmr.
    
    Note:
    This bug will also be fixed by this patch:
    http://www.spinics.net/lists/target-devel/msg14560.html
    which switches the tmr code to use the system workqueues.
    
    For both, I am not sure if we need a dedicated workqueue since
    it is not a performance path and I do not think we need WQ_MEM_RECLAIM
    to make forward progress to free up memory like the block layer does.
    
    Signed-off-by: Mike Christie <mchristi@redhat.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f23c756da69845cc186c28f1df966c0fdbad8551
Author: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
Date:   Fri Mar 10 16:45:44 2017 -0500

    btrfs: add missing memset while reading compressed inline extents
    
    
    [ Upstream commit e1699d2d7bf6e6cce3e1baff19f9dd4595a58664 ]
    
    This is a story about 4 distinct (and very old) btrfs bugs.
    
    Commit c8b978188c ("Btrfs: Add zlib compression support") added
    three data corruption bugs for inline extents (bugs #1-3).
    
    Commit 93c82d5750 ("Btrfs: zero page past end of inline file items")
    fixed bug #1:  uncompressed inline extents followed by a hole and more
    extents could get non-zero data in the hole as they were read.  The fix
    was to add a memset in btrfs_get_extent to zero out the hole.
    
    Commit 166ae5a418 ("btrfs: fix inline compressed read err corruption")
    fixed bug #2:  compressed inline extents which contained non-zero bytes
    might be replaced with zero bytes in some cases.  This patch removed an
    unhelpful memset from uncompress_inline, but the case where memset is
    required was missed.
    
    There is also a memset in the decompression code, but this only covers
    decompressed data that is shorter than the ram_bytes from the extent
    ref record.  This memset doesn't cover the region between the end of the
    decompressed data and the end of the page.  It has also moved around a
    few times over the years, so there's no single patch to refer to.
    
    This patch fixes bug #3:  compressed inline extents followed by a hole
    and more extents could get non-zero data in the hole as they were read
    (i.e. bug #3 is the same as bug #1, but s/uncompressed/compressed/).
    The fix is the same:  zero out the hole in the compressed case too,
    by putting a memset back in uncompress_inline, but this time with
    correct parameters.
    
    The last and oldest bug, bug #0, is the cause of the offending inline
    extent/hole/extent pattern.  Bug #0 is a subtle and mostly-harmless quirk
    of behavior somewhere in the btrfs write code.  In a few special cases,
    an inline extent and hole are allowed to persist where they normally
    would be combined with later extents in the file.
    
    A fast reproducer for bug #0 is presented below.  A few offending extents
    are also created in the wild during large rsync transfers with the -S
    flag.  A Linux kernel build (git checkout; make allyesconfig; make -j8)
    will produce a handful of offending files as well.  Once an offending
    file is created, it can present different content to userspace each
    time it is read.
    
    Bug #0 is at least 4 and possibly 8 years old.  I verified every vX.Y
    kernel back to v3.5 has this behavior.  There are fossil records of this
    bug's effects in commits all the way back to v2.6.32.  I have no reason
    to believe bug #0 wasn't present at the beginning of btrfs compression
    support in v2.6.29, but I can't easily test kernels that old to be sure.
    
    It is not clear whether bug #0 is worth fixing.  A fix would likely
    require injecting extra reads into currently write-only paths, and most
    of the exceptional cases caused by bug #0 are already handled now.
    
    Whether we like them or not, bug #0's inline extents followed by holes
    are part of the btrfs de-facto disk format now, and we need to be able
    to read them without data corruption or an infoleak.  So enough about
    bug #0, let's get back to bug #3 (this patch).
    
    An example of on-disk structure leading to data corruption found in
    the wild:
    
            item 61 key (606890 INODE_ITEM 0) itemoff 9662 itemsize 160
                    inode generation 50 transid 50 size 47424 nbytes 49141
                    block group 0 mode 100644 links 1 uid 0 gid 0
                    rdev 0 flags 0x0(none)
            item 62 key (606890 INODE_REF 603050) itemoff 9642 itemsize 20
                    inode ref index 3 namelen 10 name: DB_File.so
            item 63 key (606890 EXTENT_DATA 0) itemoff 8280 itemsize 1362
                    inline extent data size 1341 ram 4085 compress(zlib)
            item 64 key (606890 EXTENT_DATA 4096) itemoff 8227 itemsize 53
                    extent data disk byte 5367308288 nr 20480
                    extent data offset 0 nr 45056 ram 45056
                    extent compression(zlib)
    
    Different data appears in userspace during each read of the 11 bytes
    between 4085 and 4096.  The extent in item 63 is not long enough to
    fill the first page of the file, so a memset is required to fill the
    space between item 63 (ending at 4085) and item 64 (beginning at 4096)
    with zero.
    
    Here is a reproducer from Liu Bo, which demonstrates another method
    of creating the same inline extent and hole pattern:
    
    Using 'page_poison=on' kernel command line (or enable
    CONFIG_PAGE_POISONING) run the following:
    
            # touch foo
            # chattr +c foo
            # xfs_io -f -c "pwrite -W 0 1000" foo
            # xfs_io -f -c "falloc 4 8188" foo
            # od -x foo
            # echo 3 >/proc/sys/vm/drop_caches
            # od -x foo
    
    This produce the following on my box:
    
    Correct output:  file contains 1000 data bytes followed
    by zeros:
    
            0000000 cdcd cdcd cdcd cdcd cdcd cdcd cdcd cdcd
            *
            0001740 cdcd cdcd cdcd cdcd 0000 0000 0000 0000
            0001760 0000 0000 0000 0000 0000 0000 0000 0000
            *
            0020000
    
    Actual output:  the data after the first 1000 bytes
    will be different each run:
    
            0000000 cdcd cdcd cdcd cdcd cdcd cdcd cdcd cdcd
            *
            0001740 cdcd cdcd cdcd cdcd 6c63 7400 635f 006d
            0001760 5f74 6f43 7400 435f 0053 5f74 7363 7400
            0002000 435f 0056 5f74 6164 7400 645f 0062 5f74
            (...)
    
    Signed-off-by: Zygo Blaxell <ce3g8jdj@umail.furryterror.org>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: Chris Mason <clm@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7480adadb8ba2bc82af61fc4f1fe0a91ed5c8331
Author: Olga Kornievskaia <kolga@netapp.com>
Date:   Wed Mar 8 14:39:15 2017 -0500

    NFSv4.1 respect server's max size in CREATE_SESSION
    
    
    [ Upstream commit 033853325fe3bdc70819a8b97915bd3bca41d3af ]
    
    Currently client doesn't respect max sizes server returns in CREATE_SESSION.
    nfs4_session_set_rwsize() gets called and server->rsize, server->wsize are 0
    so they never get set to the sizes returned by the server.
    
    Signed-off-by: Olga Kornievskaia <kolga@netapp.com>
    Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1062f3998ecba87df9211e6bcc0a16baf001a19a
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Wed Mar 15 22:53:37 2017 +0100

    perf symbols: Fix symbols__fixup_end heuristic for corner cases
    
    
    [ Upstream commit e7ede72a6d40cb3a30c087142d79381ca8a31dab ]
    
    The current symbols__fixup_end() heuristic for the last entry in the rb
    tree is suboptimal as it leads to not being able to recognize the symbol
    in the call graph in a couple of corner cases, for example:
    
     i) If the symbol has a start address (f.e. exposed via kallsyms)
        that is at a page boundary, then the roundup(curr->start, 4096)
        for the last entry will result in curr->start == curr->end with
        a symbol length of zero.
    
    ii) If the symbol has a start address that is shortly before a page
        boundary, then also here, curr->end - curr->start will just be
        very few bytes, where it's unrealistic that we could perform a
        match against.
    
    Instead, change the heuristic to roundup(curr->start, 4096) + 4096, so
    that we can catch such corner cases and have a better chance to find
    that specific symbol. It's still just best effort as the real end of the
    symbol is unknown to us (and could even be at a larger offset than the
    current range), but better than the current situation.
    
    Alexei reported that he recently run into case i) with a JITed eBPF
    program (these are all page aligned) as the last symbol which wasn't
    properly shown in the call graph (while other eBPF program symbols in
    the rb tree were displayed correctly). Since this is a generic issue,
    lets try to improve the heuristic a bit.
    
    Reported-and-Tested-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Fixes: 2e538c4a1847 ("perf tools: Improve kernel/modules symbol lookup")
    Link: http://lkml.kernel.org/r/bb5c80d27743be6f12afc68405f1956a330e1bc9.1489614365.git.daniel@iogearbox.net
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dea197784167ddcd4a53f63b194f1a0c0ebf36e9
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 16 16:27:48 2017 +0000

    afs: Fix afs_kill_pages()
    
    
    [ Upstream commit 7286a35e893176169b09715096a4aca557e2ccd2 ]
    
    Fix afs_kill_pages() in two ways:
    
     (1) If a writeback has been partially flushed, then if we try and kill the
         pages it contains, some of them may no longer be undergoing writeback
         and end_page_writeback() will assert.
    
         Fix this by checking to see whether the page in question is actually
         undergoing writeback before ending that writeback.
    
     (2) The loop that scans for pages to kill doesn't increase the first page
         index, and so the loop may not terminate, but it will try to process
         the same pages over and over again.
    
         Fix this by increasing the first page index to one after the last page
         we processed.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b1718fdda0f2d47634c0e8e96b0a77cfc34d4424
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 16 16:27:48 2017 +0000

    afs: Fix page leak in afs_write_begin()
    
    
    [ Upstream commit 6d06b0d25209c80e99c1e89700f1e09694a3766b ]
    
    afs_write_begin() leaks a ref and a lock on a page if afs_fill_page()
    fails.  Fix the leak by unlocking and releasing the page in the error path.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b422c709f72bec2787723aa7c2afdca4246df2f3
Author: Marc Dionne <marc.dionne@auristor.com>
Date:   Thu Mar 16 16:27:47 2017 +0000

    afs: Populate and use client modification time
    
    
    [ Upstream commit ab94f5d0dd6fd82e7eeca5e7c8096eaea0a0261f ]
    
    The inode timestamps should be set from the client time
    in the status received from the server, rather than the
    server time which is meant for internal server use.
    
    Set AFS_SET_MTIME and populate the mtime for operations
    that take an input status, such as file/dir creation
    and StoreData.  If an input time is not provided the
    server will set the vnode times based on the current server
    time.
    
    In a situation where the server has some skew with the
    client, this could lead to the client seeing a timestamp
    in the future for a file that it just created or wrote.
    
    Signed-off-by: Marc Dionne <marc.dionne@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 916426b19350c36e0a4a8a9b4e457e1099b9505e
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 16 16:27:47 2017 +0000

    afs: Fix the maths in afs_fs_store_data()
    
    
    [ Upstream commit 146a1192783697810b63a1e41c4d59fc93387340 ]
    
    afs_fs_store_data() works out of the size of the write it's going to make,
    but it uses 32-bit unsigned subtraction in one place that gets
    automatically cast to loff_t.
    
    However, if to < offset, then the number goes negative, but as the result
    isn't signed, this doesn't get sign-extended to 64-bits when placed in a
    loff_t.
    
    Fix by casting the operands to loff_t.
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 14a74dccf0f3d8be25768ea7ce7d8b0a48279d64
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 16 16:27:45 2017 +0000

    afs: Flush outstanding writes when an fd is closed
    
    
    [ Upstream commit 58fed94dfb17e89556b5705f20f90e5b2971b6a1 ]
    
    Flush outstanding writes in afs when an fd is closed.  This is what NFS and
    CIFS do.
    
    Reported-by: Marc Dionne <marc.c.dionne@gmail.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 24a7a4f0f8ddf3746f5fb7f07888fed8fde625aa
Author: Marc Dionne <marc.dionne@auristor.com>
Date:   Thu Mar 16 16:27:44 2017 +0000

    afs: Adjust mode bits processing
    
    
    [ Upstream commit 627f46943ff90bcc32ddeb675d881c043c6fa2ae ]
    
    Mode bits for an afs file should not be enforced in the usual
    way.
    
    For files, the absence of user bits can restrict file access
    with respect to what is granted by the server.
    
    These bits apply regardless of the owner or the current uid; the
    rest of the mode bits (group, other) are ignored.
    
    Signed-off-by: Marc Dionne <marc.dionne@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 15fbd461977aa362d04cab42e9f3ea28935f999c
Author: Marc Dionne <marc.dionne@auristor.com>
Date:   Thu Mar 16 16:27:43 2017 +0000

    afs: Populate group ID from vnode status
    
    
    [ Upstream commit 6186f0788b31f44affceeedc7b48eb10faea120d ]
    
    The group was hard coded to GLOBAL_ROOT_GID; use the group
    ID that was received from the server.
    
    Signed-off-by: Marc Dionne <marc.dionne@auristor.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28cd05a2efe27f5ea1c2b1c5ffef8d350a5ef1eb
Author: David Howells <dhowells@redhat.com>
Date:   Thu Mar 16 16:27:43 2017 +0000

    afs: Fix missing put_page()
    
    
    [ Upstream commit 29c8bbbd6e21daa0997d1c3ee886b897ee7ad652 ]
    
    In afs_writepages_region(), inside the loop where we find dirty pages to
    deal with, one of the if-statements is missing a put_page().
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1e7f83cd53feb19a9bf7ca680ff2edf85647b692
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Wed Mar 15 21:11:46 2017 -0400

    drm/radeon: reinstate oland workaround for sclk
    
    
    [ Upstream commit 66822d815ae61ecb2d9dba9031517e8a8476969d ]
    
    Higher sclks seem to be unstable on some boards.
    
    bug: https://bugs.freedesktop.org/show_bug.cgi?id=100222
    
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8a0c5968d934e59319ac109b673e3ce0d2aef193
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Thu Mar 2 15:10:59 2017 +0100

    sched/deadline: Use deadline instead of period when calculating overflow
    
    
    [ Upstream commit 2317d5f1c34913bac5971d93d69fb6c31bb74670 ]
    
    I was testing Daniel's changes with his test case, and tweaked it a
    little. Instead of having the runtime equal to the deadline, I
    increased the deadline ten fold.
    
    Daniel's test case had:
    
            attr.sched_runtime  = 2 * 1000 * 1000;          /* 2 ms */
            attr.sched_deadline = 2 * 1000 * 1000;          /* 2 ms */
            attr.sched_period   = 2 * 1000 * 1000 * 1000;   /* 2 s */
    
    To make it more interesting, I changed it to:
    
            attr.sched_runtime  =  2 * 1000 * 1000;         /* 2 ms */
            attr.sched_deadline = 20 * 1000 * 1000;         /* 20 ms */
            attr.sched_period   =  2 * 1000 * 1000 * 1000;  /* 2 s */
    
    The results were rather surprising. The behavior that Daniel's patch
    was fixing came back. The task started using much more than .1% of the
    CPU. More like 20%.
    
    Looking into this I found that it was due to the dl_entity_overflow()
    constantly returning true. That's because it uses the relative period
    against relative runtime vs the absolute deadline against absolute
    runtime.
    
      runtime / (deadline - t) > dl_runtime / dl_period
    
    There's even a comment mentioning this, and saying that when relative
    deadline equals relative period, that the equation is the same as using
    deadline instead of period. That comment is backwards! What we really
    want is:
    
      runtime / (deadline - t) > dl_runtime / dl_deadline
    
    We care about if the runtime can make its deadline, not its period. And
    then we can say "when the deadline equals the period, the equation is
    the same as using dl_period instead of dl_deadline".
    
    After correcting this, now when the task gets enqueued, it can throttle
    correctly, and Daniel's fix to the throttling of sleeping deadline
    tasks works even when the runtime and deadline are not the same.
    
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Daniel Bristot de Oliveira <bristot@redhat.com>
    Cc: Juri Lelli <juri.lelli@arm.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Luca Abeni <luca.abeni@santannapisa.it>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Romulo Silva de Oliveira <romulo.deoliveira@ufsc.br>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tommaso Cucinotta <tommaso.cucinotta@sssup.it>
    Link: http://lkml.kernel.org/r/02135a27f1ae3fe5fd032568a5a2f370e190e8d7.1488392936.git.bristot@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6bcc81fd8f24d964a3ea58e065fe3aad2b6942f1
Author: Alex Deucher <alexander.deucher@amd.com>
Date:   Tue Mar 14 14:42:03 2017 -0400

    drm/radeon/si: add dpm quirk for Oland
    
    
    [ Upstream commit 0f424de1fd9bc4ab24bd1fe5430ab5618e803e31 ]
    
    OLAND 0x1002:0x6604 0x1028:0x066F 0x00 seems to have problems
    with higher sclks.
    
    Acked-by: Christian KÃ¶nig <christian.koenig@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6debc3f440ad213935e6b09200b918c6a0f7bba0
Author: Stafford Horne <shorne@gmail.com>
Date:   Mon Mar 13 07:44:45 2017 +0900

    openrisc: fix issue handling 8 byte get_user calls
    
    
    [ Upstream commit 154e67cd8e8f964809d0e75e44bb121b169c75b3 ]
    
    Was getting the following error with allmodconfig:
    
      ERROR: "__get_user_bad" [lib/test_user_copy.ko] undefined!
    
    This was simply a missing break statement, causing an unwanted fall
    through.
    
    Signed-off-by: Stafford Horne <shorne@gmail.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8111e1b213c4d3ff584668a873004791b4151255
Author: Vlad Yasevich <vyasevich@gmail.com>
Date:   Tue Mar 14 08:58:08 2017 -0400

    net: Resend IGMP memberships upon peer notification.
    
    
    [ Upstream commit 37c343b4f4e70e9dc328ab04903c0ec8d154c1a4 ]
    
    When we notify peers of potential changes,  it's also good to update
    IGMP memberships.  For example, during VM migration, updating IGMP
    memberships will redirect existing multicast streams to the VM at the
    new location.
    
    Signed-off-by: Vladislav Yasevich <vyasevic@redhat.com>
    Acked-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1f08ebd8815e18e47c028cf8652ddea2cf6a88d7
Author: Matthias Kaehlcke <mka@chromium.org>
Date:   Mon Mar 13 14:30:29 2017 -0700

    dmaengine: Fix array index out of bounds warning in __get_unmap_pool()
    
    
    [ Upstream commit 23f963e91fd81f44f6b316b1c24db563354c6be8 ]
    
    This fixes the following warning when building with clang and
    CONFIG_DMA_ENGINE_RAID=n :
    
    drivers/dma/dmaengine.c:1102:11: error: array index 2 is past the end of the array (which contains 1 element) [-Werror,-Warray-bounds]
                    return &unmap_pool[2];
                            ^          ~
    drivers/dma/dmaengine.c:1083:1: note: array 'unmap_pool' declared here
    static struct dmaengine_unmap_pool unmap_pool[] = {
    ^
    drivers/dma/dmaengine.c:1104:11: error: array index 3 is past the end of the array (which contains 1 element) [-Werror,-Warray-bounds]
                    return &unmap_pool[3];
                            ^          ~
    drivers/dma/dmaengine.c:1083:1: note: array 'unmap_pool' declared here
    static struct dmaengine_unmap_pool unmap_pool[] = {
    
    Signed-off-by: Matthias Kaehlcke <mka@chromium.org>
    Reviewed-by: Dan Williams <dan.j.williams@intel.com>
    Signed-off-by: Vinod Koul <vinod.koul@intel.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 78dbf84bec784539abf8753b89058118f9e4e059
Author: Johan Hovold <johan@kernel.org>
Date:   Mon Mar 13 13:42:03 2017 +0100

    net: wimax/i2400m: fix NULL-deref at probe
    
    
    [ Upstream commit 6e526fdff7be4f13b24f929a04c0e9ae6761291e ]
    
    Make sure to check the number of endpoints to avoid dereferencing a
    NULL-pointer or accessing memory beyond the endpoint array should a
    malicious device lack the expected endpoints.
    
    The endpoints are specifically dereferenced in the i2400m_bootrom_init
    path during probe (e.g. in i2400mu_tx_bulk_out).
    
    Fixes: f398e4240fce ("i2400m/USB: probe/disconnect, dev init/shutdown
    and reset backends")
    Cc: Inaky Perez-Gonzalez <inaky@linux.intel.com>
    
    Signed-off-by: Johan Hovold <johan@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 97a63f608dd59c0750c899e536c59f7e112a5a44
Author: Dmitry Torokhov <dmitry.torokhov@gmail.com>
Date:   Tue Feb 28 17:14:41 2017 -0800

    Input: i8042 - add TUXEDO BU1406 (N24_25BU) to the nomux list
    
    
    [ Upstream commit a4c2a13129f7c5bcf81704c06851601593303fd5 ]
    
    TUXEDO BU1406 does not implement active multiplexing mode properly,
    and takes around 550 ms in i8042_set_mux_mode(). Given that the
    device does not have external AUX port, there is no downside in
    disabling the MUX mode.
    
    Reported-by: Paul Menzel <pmenzel@molgen.mpg.de>
    Suggested-by: Vojtech Pavlik <vojtech@suse.cz>
    Reviewed-by: Marcos Paulo de Souza <marcos.souza.org@gmail.com>
    Signed-off-by: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c1ecb5aba022bc00434642a70e085eb86e92952d
Author: NeilBrown <neilb@suse.com>
Date:   Fri Mar 10 11:36:39 2017 +1100

    NFSD: fix nfsd_reset_versions for NFSv4.
    
    
    [ Upstream commit 800a938f0bf9130c8256116649c0cc5806bfb2fd ]
    
    If you write "-2 -3 -4" to the "versions" file, it will
    notice that no versions are enabled, and nfsd_reset_versions()
    is called.
    This enables all major versions, not no minor versions.
    So we lose the invariant that NFSv4 is only advertised when
    at least one minor is enabled.
    
    Fix the code to explicitly enable minor versions for v4,
    change it to use nfsd_vers() to test and set, and simplify
    the code.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: J. Bruce Fields <bfields@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 537546e6e440a2f5a0636880fc6d4a497d65016a
Author: NeilBrown <neilb@suse.com>
Date:   Fri Mar 10 11:36:39 2017 +1100

    NFSD: fix nfsd_minorversion(.., NFSD_AVAIL)
    
    
    [ Upstream commit 928c6fb3a9bfd6c5b287aa3465226add551c13c0 ]
    
    Current code will return 1 if the version is supported,
    and -1 if it isn't.
    This is confusing and inconsistent with the one place where this
    is used.
    So change to return 1 if it is supported, and zero if not.
    i.e. an error is never returned.
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: J. Bruce Fields <bfields@redhat.com>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f73422f3a6e833ec44f0f37211781eab50223f71
Author: Doug Berger <opendmb@gmail.com>
Date:   Thu Mar 9 16:58:48 2017 -0800

    net: bcmgenet: Power up the internal PHY before probing the MII
    
    
    [ Upstream commit 6be371b053dc86f11465cc1abce2e99bda0a0574 ]
    
    When using the internal PHY it must be powered up when the MII is probed
    or the PHY will not be detected.  Since the PHY is powered up at reset
    this has not been a problem.  However, when the kernel is restarted with
    kexec the PHY will likely be powered down when the kernel starts so it
    will not be detected and the Ethernet link will not be established.
    
    This commit explicitly powers up the internal PHY when the GENET driver
    is probed to correct this behavior.
    
    Fixes: 1c1008c793fa ("net: bcmgenet: add main driver file")
    Signed-off-by: Doug Berger <opendmb@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1a34a1137f7693d9dbd3ad108dd9a13fa44cdc57
Author: Doug Berger <opendmb@gmail.com>
Date:   Thu Mar 9 16:58:44 2017 -0800

    net: bcmgenet: correct MIB access of UniMAC RUNT counters
    
    
    [ Upstream commit 1ad3d225e5a40ca6c586989b4baaca710544c15a ]
    
    The gap between the Tx status counters and the Rx RUNT counters is now
    being added to allow correct reporting of the registers.
    
    Fixes: 1c1008c793fa ("net: bcmgenet: add main driver file")
    Signed-off-by: Doug Berger <opendmb@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bbfc83efb91c5f1f3b393367356105d3a6f5f17a
Author: Doug Berger <opendmb@gmail.com>
Date:   Thu Mar 9 16:58:43 2017 -0800

    net: bcmgenet: correct the RBUF_OVFL_CNT and RBUF_ERR_CNT MIB values
    
    
    [ Upstream commit ffff71328a3c321f7c14cc1edd33577717037744 ]
    
    The location of the RBUF overflow and error counters has moved between
    different version of the GENET MAC.  This commit corrects the driver to
    read from the correct locations depending on the version of the GENET
    MAC.
    
    Fixes: 1c1008c793fa ("net: bcmgenet: add main driver file")
    Signed-off-by: Doug Berger <opendmb@gmail.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b5ed9b970a89a5f6fcbeaaf50e281e9606aae958
Author: Javier Martinez Canillas <javier@osg.samsung.com>
Date:   Wed Feb 22 15:23:22 2017 -0300

    usb: phy: isp1301: Add OF device ID table
    
    
    [ Upstream commit fd567653bdb908009b650f079bfd4b63169e2ac4 ]
    
    The driver doesn't have a struct of_device_id table but supported devices
    are registered via Device Trees. This is working on the assumption that a
    I2C device registered via OF will always match a legacy I2C device ID and
    that the MODALIAS reported will always be of the form i2c:<device>.
    
    But this could change in the future so the correct approach is to have an
    OF device ID table if the devices are registered via OF.
    
    Signed-off-by: Javier Martinez Canillas <javier@osg.samsung.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 406e7e045fb87d29a3ec4293898e76821427edc3
Author: Ilan peer <ilan.peer@intel.com>
Date:   Mon Dec 26 18:17:36 2016 +0200

    mac80211: Fix addition of mesh configuration element
    
    commit 57629915d568c522ac1422df7bba4bee5b5c7a7c upstream.
    
    The code was setting the capabilities byte to zero,
    after it was already properly set previously. Fix it.
    
    The bug was found while debugging hwsim mesh tests failures
    that happened since the commit mentioned below.
    
    Fixes: 76f43b4c0a93 ("mac80211: Remove invalid flag operations in mesh TSF synchronization")
    Signed-off-by: Ilan Peer <ilan.peer@intel.com>
    Reviewed-by: Masashi Honma <masashi.honma@gmail.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Cc: Richard SchÃ¼tz <rschuetz@uni-koblenz.de>
    Cc: Mathias Kretschmer <mathias.kretschmer@fit.fraunhofer.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 337cde8f541783dbc7fb0f974cd82798ba77794c
Author: David Howells <dhowells@redhat.com>
Date:   Mon Oct 19 11:20:28 2015 +0100

    KEYS: Don't permit request_key() to construct a new keyring
    
    commit 911b79cde95c7da0ec02f48105358a36636b7a71 upstream.
    
    If request_key() is used to find a keyring, only do the search part - don't
    do the construction part if the keyring was not found by the search.  We
    don't really want keyrings in the negative instantiated state since the
    rejected/negative instantiation error value in the payload is unioned with
    keyring metadata.
    
    Now the kernel gives an error:
    
            request_key("keyring", "#selinux,bdekeyring", "keyring", KEY_SPEC_USER_SESSION_KEYRING) = -1 EPERM (Operation not permitted)
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bd154dc611b343418d45753c3e101492a7ca13fa
Author: David Jeffery <djeffery@redhat.com>
Date:   Thu Feb 12 16:45:31 2015 +0000

    Don't leak a key reference if request_key() tries to use a revoked keyring
    
    commit d0709f1e66e8066c4ac6a54620ec116aa41937c0 upstream.
    
    If a request_key() call to allocate and fill out a key attempts to insert the
    key structure into a revoked keyring, the key will leak, using memory and part
    of the user's key quota until the system reboots. This is from a failure of
    construct_alloc_key() to decrement the key's reference count after the attempt
    to insert into the requested keyring is rejected.
    
    key_put() needs to be called in the link_prealloc_failed callpath to ensure
    the unused key is released.
    
    Signed-off-by: David Jeffery <djeffery@redhat.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: James Morris <james.l.morris@oracle.com>
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 66d63dc137c9b04cf1b9a3102ce79ca15b139764
Author: Chandan Rajendra <chandan@linux.vnet.ibm.com>
Date:   Mon Dec 11 15:00:57 2017 -0500

    ext4: fix crash when a directory's i_size is too small
    
    commit 9d5afec6b8bd46d6ed821aa1579634437f58ef1f upstream.
    
    On a ppc64 machine, when mounting a fuzzed ext2 image (generated by
    fsfuzzer) the following call trace is seen,
    
    VFS: brelse: Trying to free free buffer
    WARNING: CPU: 1 PID: 6913 at /root/repos/linux/fs/buffer.c:1165 .__brelse.part.6+0x24/0x40
    .__brelse.part.6+0x20/0x40 (unreliable)
    .ext4_find_entry+0x384/0x4f0
    .ext4_lookup+0x84/0x250
    .lookup_slow+0xdc/0x230
    .walk_component+0x268/0x400
    .path_lookupat+0xec/0x2d0
    .filename_lookup+0x9c/0x1d0
    .vfs_statx+0x98/0x140
    .SyS_newfstatat+0x48/0x80
    system_call+0x58/0x6c
    
    This happens because the directory that ext4_find_entry() looks up has
    inode->i_size that is less than the block size of the filesystem. This
    causes 'nblocks' to have a value of zero. ext4_bread_batch() ends up not
    reading any of the directory file's blocks. This renders the entries in
    bh_use[] array to continue to have garbage data. buffer_uptodate() on
    bh_use[0] can then return a zero value upon which brelse() function is
    invoked.
    
    This commit fixes the bug by returning -ENOENT when the directory file
    has no associated blocks.
    
    Reported-by: Abdul Haleem <abdhalee@linux.vnet.ibm.com>
    Signed-off-by: Chandan Rajendra <chandan@linux.vnet.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d5ba16a80d96c1df57b98487143fed90374d5514
Author: Mathias Nyman <mathias.nyman@linux.intel.com>
Date:   Fri Dec 8 18:10:05 2017 +0200

    xhci: Don't add a virt_dev to the devs array before it's fully allocated
    
    commit 5d9b70f7d52eb14bb37861c663bae44de9521c35 upstream.
    
    Avoid null pointer dereference if some function is walking through the
    devs array accessing members of a new virt_dev that is mid allocation.
    
    Add the virt_dev to xhci->devs[i] _after_ the virt_device and all its
    members are properly allocated.
    
    issue found by KASAN: null-ptr-deref in xhci_find_slot_id_by_port
    
    "Quick analysis suggests that xhci_alloc_virt_device() is not mutex
    protected. If so, there is a time frame where xhci->devs[slot_id] is set
    but not fully initialized. Specifically, xhci->devs[i]->udev can be NULL."
    
    Signed-off-by: Mathias Nyman <mathias.nyman@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f749066bec4019a7a5f7eee22b56314958161c1e
Author: Shuah Khan <shuah@kernel.org>
Date:   Thu Dec 7 14:16:50 2017 -0700

    usbip: fix stub_send_ret_submit() vulnerability to null transfer_buffer
    
    commit be6123df1ea8f01ee2f896a16c2b7be3e4557a5a upstream.
    
    stub_send_ret_submit() handles urb with a potential null transfer_buffer,
    when it replays a packet with potential malicious data that could contain
    a null buffer. Add a check for the condition when actual_length > 0 and
    transfer_buffer is null.
    
    Reported-by: Secunia Research <vuln@secunia.com>
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dd3ad5f60d520da135bf4dce5adcecf400e2db64
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Tue Dec 12 14:25:13 2017 -0500

    USB: core: prevent malicious bNumInterfaces overflow
    
    commit 48a4ff1c7bb5a32d2e396b03132d20d552c0eca7 upstream.
    
    A malicious USB device with crafted descriptors can cause the kernel
    to access unallocated memory by setting the bNumInterfaces value too
    high in a configuration descriptor.  Although the value is adjusted
    during parsing, this adjustment is skipped in one of the error return
    paths.
    
    This patch prevents the problem by setting bNumInterfaces to 0
    initially.  The existing code already sets it to the proper value
    after parsing is complete.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a342e5368eeab3beb6ea156a53ccece114e9d883
Author: David Kozub <zub@linux.fjfi.cvut.cz>
Date:   Tue Dec 5 22:40:04 2017 +0100

    USB: uas and storage: Add US_FL_BROKEN_FUA for another JMicron JMS567 ID
    
    commit 62354454625741f0569c2cbe45b2d192f8fd258e upstream.
    
    There is another JMS567-based USB3 UAS enclosure (152d:0578) that fails
    with the following error:
    
    [sda] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE
    [sda] tag#0 Sense Key : Illegal Request [current]
    [sda] tag#0 Add. Sense: Invalid field in cdb
    
    The issue occurs both with UAS (occasionally) and mass storage
    (immediately after mounting a FS on a disk in the enclosure).
    
    Enabling US_FL_BROKEN_FUA quirk solves this issue.
    
    This patch adds an UNUSUAL_DEV with US_FL_BROKEN_FUA for the enclosure
    for both UAS and mass storage.
    
    Signed-off-by: David Kozub <zub@linux.fjfi.cvut.cz>
    Acked-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5bcc2f7c8d3f095d04a420c862128e5db5d2003d
Author: NeilBrown <neilb@suse.com>
Date:   Thu Dec 14 15:32:38 2017 -0800

    autofs: fix careless error in recent commit
    
    commit 302ec300ef8a545a7fc7f667e5fd743b091c2eeb upstream.
    
    Commit ecc0c469f277 ("autofs: don't fail mount for transient error") was
    meant to replace an 'if' with a 'switch', but instead added the 'switch'
    leaving the case in place.
    
    Link: http://lkml.kernel.org/r/87zi6wstmw.fsf@notabene.neil.brown.name
    Fixes: ecc0c469f277 ("autofs: don't fail mount for transient error")
    Reported-by: Ben Hutchings <ben.hutchings@codethink.co.uk>
    Signed-off-by: NeilBrown <neilb@suse.com>
    Cc: Ian Kent <raven@themaw.net>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ebd52f8b6422b920b4d1697d90679a2bb4b48a0b
Author: Eric Biggers <ebiggers@google.com>
Date:   Tue Nov 28 20:56:59 2017 -0800

    crypto: salsa20 - fix blkcipher_walk API usage
    
    commit ecaaab5649781c5a0effdaf298a925063020500e upstream.
    
    When asked to encrypt or decrypt 0 bytes, both the generic and x86
    implementations of Salsa20 crash in blkcipher_walk_done(), either when
    doing 'kfree(walk->buffer)' or 'free_page((unsigned long)walk->page)',
    because walk->buffer and walk->page have not been initialized.
    
    The bug is that Salsa20 is calling blkcipher_walk_done() even when
    nothing is in 'walk.nbytes'.  But blkcipher_walk_done() is only meant to
    be called when a nonzero number of bytes have been provided.
    
    The broken code is part of an optimization that tries to make only one
    call to salsa20_encrypt_bytes() to process inputs that are not evenly
    divisible by 64 bytes.  To fix the bug, just remove this "optimization"
    and use the blkcipher_walk API the same way all the other users do.
    
    Reproducer:
    
        #include <linux/if_alg.h>
        #include <sys/socket.h>
        #include <unistd.h>
    
        int main()
        {
                int algfd, reqfd;
                struct sockaddr_alg addr = {
                        .salg_type = "skcipher",
                        .salg_name = "salsa20",
                };
                char key[16] = { 0 };
    
                algfd = socket(AF_ALG, SOCK_SEQPACKET, 0);
                bind(algfd, (void *)&addr, sizeof(addr));
                reqfd = accept(algfd, 0, 0);
                setsockopt(algfd, SOL_ALG, ALG_SET_KEY, key, sizeof(key));
                read(reqfd, key, sizeof(key));
        }
    
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Fixes: eb6f13eb9f81 ("[CRYPTO] salsa20_generic: Fix multi-page processing")
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 252b343a9789151293ad1da4a1ac0851bf31a22e
Author: Eric Biggers <ebiggers@google.com>
Date:   Tue Nov 28 18:01:38 2017 -0800

    crypto: hmac - require that the underlying hash algorithm is unkeyed
    
    commit af3ff8045bbf3e32f1a448542e73abb4c8ceb6f1 upstream.
    
    Because the HMAC template didn't check that its underlying hash
    algorithm is unkeyed, trying to use "hmac(hmac(sha3-512-generic))"
    through AF_ALG or through KEYCTL_DH_COMPUTE resulted in the inner HMAC
    being used without having been keyed, resulting in sha3_update() being
    called without sha3_init(), causing a stack buffer overflow.
    
    This is a very old bug, but it seems to have only started causing real
    problems when SHA-3 support was added (requires CONFIG_CRYPTO_SHA3)
    because the innermost hash's state is ->import()ed from a zeroed buffer,
    and it just so happens that other hash algorithms are fine with that,
    but SHA-3 is not.  However, there could be arch or hardware-dependent
    hash algorithms also affected; I couldn't test everything.
    
    Fix the bug by introducing a function crypto_shash_alg_has_setkey()
    which tests whether a shash algorithm is keyed.  Then update the HMAC
    template to require that its underlying hash algorithm is unkeyed.
    
    Here is a reproducer:
    
        #include <linux/if_alg.h>
        #include <sys/socket.h>
    
        int main()
        {
            int algfd;
            struct sockaddr_alg addr = {
                .salg_type = "hash",
                .salg_name = "hmac(hmac(sha3-512-generic))",
            };
            char key[4096] = { 0 };
    
            algfd = socket(AF_ALG, SOCK_SEQPACKET, 0);
            bind(algfd, (const struct sockaddr *)&addr, sizeof(addr));
            setsockopt(algfd, SOL_ALG, ALG_SET_KEY, key, sizeof(key));
        }
    
    Here was the KASAN report from syzbot:
    
        BUG: KASAN: stack-out-of-bounds in memcpy include/linux/string.h:341  [inline]
        BUG: KASAN: stack-out-of-bounds in sha3_update+0xdf/0x2e0  crypto/sha3_generic.c:161
        Write of size 4096 at addr ffff8801cca07c40 by task syzkaller076574/3044
    
        CPU: 1 PID: 3044 Comm: syzkaller076574 Not tainted 4.14.0-mm1+ #25
        Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS  Google 01/01/2011
        Call Trace:
          __dump_stack lib/dump_stack.c:17 [inline]
          dump_stack+0x194/0x257 lib/dump_stack.c:53
          print_address_description+0x73/0x250 mm/kasan/report.c:252
          kasan_report_error mm/kasan/report.c:351 [inline]
          kasan_report+0x25b/0x340 mm/kasan/report.c:409
          check_memory_region_inline mm/kasan/kasan.c:260 [inline]
          check_memory_region+0x137/0x190 mm/kasan/kasan.c:267
          memcpy+0x37/0x50 mm/kasan/kasan.c:303
          memcpy include/linux/string.h:341 [inline]
          sha3_update+0xdf/0x2e0 crypto/sha3_generic.c:161
          crypto_shash_update+0xcb/0x220 crypto/shash.c:109
          shash_finup_unaligned+0x2a/0x60 crypto/shash.c:151
          crypto_shash_finup+0xc4/0x120 crypto/shash.c:165
          hmac_finup+0x182/0x330 crypto/hmac.c:152
          crypto_shash_finup+0xc4/0x120 crypto/shash.c:165
          shash_digest_unaligned+0x9e/0xd0 crypto/shash.c:172
          crypto_shash_digest+0xc4/0x120 crypto/shash.c:186
          hmac_setkey+0x36a/0x690 crypto/hmac.c:66
          crypto_shash_setkey+0xad/0x190 crypto/shash.c:64
          shash_async_setkey+0x47/0x60 crypto/shash.c:207
          crypto_ahash_setkey+0xaf/0x180 crypto/ahash.c:200
          hash_setkey+0x40/0x90 crypto/algif_hash.c:446
          alg_setkey crypto/af_alg.c:221 [inline]
          alg_setsockopt+0x2a1/0x350 crypto/af_alg.c:254
          SYSC_setsockopt net/socket.c:1851 [inline]
          SyS_setsockopt+0x189/0x360 net/socket.c:1830
          entry_SYSCALL_64_fastpath+0x1f/0x96
    
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: Eric Biggers <ebiggers@google.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
