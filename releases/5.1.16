commit 8584aaf1c3262ca17d1e4a614ede9179ef462bb0
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Wed Jul 3 13:13:45 2019 +0200

    Linux 5.1.16

commit 25998210bb2c905d66590703ad11fdcb0cb3e55f
Author: Jean-Philippe Brucker <jean-philippe@linaro.org>
Date:   Fri May 24 13:52:19 2019 +0100

    arm64: insn: Fix ldadd instruction encoding
    
    commit c5e2edeb01ae9ffbdde95bdcdb6d3614ba1eb195 upstream.
    
    GCC 8.1.0 reports that the ldadd instruction encoding, recently added to
    insn.c, doesn't match the mask and couldn't possibly be identified:
    
     linux/arch/arm64/include/asm/insn.h: In function 'aarch64_insn_is_ldadd':
     linux/arch/arm64/include/asm/insn.h:280:257: warning: bitwise comparison always evaluates to false [-Wtautological-compare]
    
    Bits [31:30] normally encode the size of the instruction (1 to 8 bytes)
    and the current instruction value only encodes the 4- and 8-byte
    variants. At the moment only the BPF JIT needs this instruction, and
    doesn't require the 1- and 2-byte variants, but to be consistent with
    our other ldr and str instruction encodings, clear the size field in the
    insn value.
    
    Fixes: 34b8ab091f9ef57a ("bpf, arm64: use more scalable stadd over ldxr / stxr loop in xadd")
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Reported-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Signed-off-by: Yoshihiro Shimoda <yoshihiro.shimoda.uh@renesas.com>
    Signed-off-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cf9513b45f6408f12e84fca6a7bf83f62ac9d1bc
Author: Xin Long <lucien.xin@gmail.com>
Date:   Mon Jun 17 21:34:15 2019 +0800

    tipc: pass tunnel dev as NULL to udp_tunnel(6)_xmit_skb
    
    commit c3bcde026684c62d7a2b6f626dc7cf763833875c upstream.
    
    udp_tunnel(6)_xmit_skb() called by tipc_udp_xmit() expects a tunnel device
    to count packets on dev->tstats, a perpcu variable. However, TIPC is using
    udp tunnel with no tunnel device, and pass the lower dev, like veth device
    that only initializes dev->lstats(a perpcu variable) when creating it.
    
    Later iptunnel_xmit_stats() called by ip(6)tunnel_xmit() thinks the dev as
    a tunnel device, and uses dev->tstats instead of dev->lstats. tstats' each
    pointer points to a bigger struct than lstats, so when tstats->tx_bytes is
    increased, other percpu variable's members could be overwritten.
    
    syzbot has reported quite a few crashes due to fib_nh_common percpu member
    'nhc_pcpu_rth_output' overwritten, call traces are like:
    
      BUG: KASAN: slab-out-of-bounds in rt_cache_valid+0x158/0x190
      net/ipv4/route.c:1556
        rt_cache_valid+0x158/0x190 net/ipv4/route.c:1556
        __mkroute_output net/ipv4/route.c:2332 [inline]
        ip_route_output_key_hash_rcu+0x819/0x2d50 net/ipv4/route.c:2564
        ip_route_output_key_hash+0x1ef/0x360 net/ipv4/route.c:2393
        __ip_route_output_key include/net/route.h:125 [inline]
        ip_route_output_flow+0x28/0xc0 net/ipv4/route.c:2651
        ip_route_output_key include/net/route.h:135 [inline]
      ...
    
    or:
    
      kasan: GPF could be caused by NULL-ptr deref or user memory access
      RIP: 0010:dst_dev_put+0x24/0x290 net/core/dst.c:168
        <IRQ>
        rt_fibinfo_free_cpus net/ipv4/fib_semantics.c:200 [inline]
        free_fib_info_rcu+0x2e1/0x490 net/ipv4/fib_semantics.c:217
        __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
        rcu_do_batch kernel/rcu/tree.c:2437 [inline]
        invoke_rcu_callbacks kernel/rcu/tree.c:2716 [inline]
        rcu_process_callbacks+0x100a/0x1ac0 kernel/rcu/tree.c:2697
      ...
    
    The issue exists since tunnel stats update is moved to iptunnel_xmit by
    Commit 039f50629b7f ("ip_tunnel: Move stats update to iptunnel_xmit()"),
    and here to fix it by passing a NULL tunnel dev to udp_tunnel(6)_xmit_skb
    so that the packets counting won't happen on dev->tstats.
    
    Reported-by: syzbot+9d4c12bfd45a58738d0a@syzkaller.appspotmail.com
    Reported-by: syzbot+a9e23ea2aa21044c2798@syzkaller.appspotmail.com
    Reported-by: syzbot+c4c4b2bb358bb936ad7e@syzkaller.appspotmail.com
    Reported-by: syzbot+0290d2290a607e035ba1@syzkaller.appspotmail.com
    Reported-by: syzbot+a43d8d4e7e8a7a9e149e@syzkaller.appspotmail.com
    Reported-by: syzbot+a47c5f4c6c00fc1ed16e@syzkaller.appspotmail.com
    Fixes: 039f50629b7f ("ip_tunnel: Move stats update to iptunnel_xmit()")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b74063b5f16ab816dece79eec1830870d472aa43
Author: Amir Goldstein <amir73il@gmail.com>
Date:   Wed Jun 19 13:34:44 2019 +0300

    fanotify: update connector fsid cache on add mark
    
    commit c285a2f01d692ef48d7243cf1072897bbd237407 upstream.
    
    When implementing connector fsid cache, we only initialized the cache
    when the first mark added to object was added by FAN_REPORT_FID group.
    We forgot to update conn->fsid when the second mark is added by
    FAN_REPORT_FID group to an already attached connector without fsid
    cache.
    
    Reported-and-tested-by: syzbot+c277e8e2f46414645508@syzkaller.appspotmail.com
    Fixes: 77115225acc6 ("fanotify: cache fsid in fsnotify_mark_connector")
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 993a0821eb5b810bff67152a8005e1107f07a69d
Author: Jason Gunthorpe <jgg@ziepe.ca>
Date:   Sun May 12 21:57:57 2019 -0300

    RDMA: Directly cast the sockaddr union to sockaddr
    
    commit 641114d2af312d39ca9bbc2369d18a5823da51c6 upstream.
    
    gcc 9 now does allocation size tracking and thinks that passing the member
    of a union and then accessing beyond that member's bounds is an overflow.
    
    Instead of using the union member, use the entire union with a cast to
    get to the sockaddr. gcc will now know that the memory extends the full
    size of the union.
    
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 41dd902f6ec7bfc2185e27c5c0f6ef7cb158bc1f
Author: Will Deacon <will@kernel.org>
Date:   Wed Apr 10 11:51:54 2019 +0100

    futex: Update comments and docs about return values of arch futex code
    
    commit 427503519739e779c0db8afe876c1b33f3ac60ae upstream.
    
    The architecture implementations of 'arch_futex_atomic_op_inuser()' and
    'futex_atomic_cmpxchg_inatomic()' are permitted to return only -EFAULT,
    -EAGAIN or -ENOSYS in the case of failure.
    
    Update the comments in the asm-generic/ implementation and also a stray
    reference in the robust futex documentation.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 272ca3913c8eaaa92086df6f78f108f2546e277d
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Fri Apr 26 21:48:22 2019 +0200

    bpf, arm64: use more scalable stadd over ldxr / stxr loop in xadd
    
    commit 34b8ab091f9ef57a2bb3c8c8359a0a03a8abf2f9 upstream.
    
    Since ARMv8.1 supplement introduced LSE atomic instructions back in 2016,
    lets add support for STADD and use that in favor of LDXR / STXR loop for
    the XADD mapping if available. STADD is encoded as an alias for LDADD with
    XZR as the destination register, therefore add LDADD to the instruction
    encoder along with STADD as special case and use it in the JIT for CPUs
    that advertise LSE atomics in CPUID register. If immediate offset in the
    BPF XADD insn is 0, then use dst register directly instead of temporary
    one.
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Jean-Philippe Brucker <jean-philippe.brucker@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fac9c64326dd2176d59a97a7046b34de3edce2f9
Author: Will Deacon <will@kernel.org>
Date:   Wed Apr 10 11:49:11 2019 +0100

    arm64: futex: Avoid copying out uninitialised stack in failed cmpxchg()
    
    commit 8e4e0ac02b449297b86498ac24db5786ddd9f647 upstream.
    
    Returning an error code from futex_atomic_cmpxchg_inatomic() indicates
    that the caller should not make any use of *uval, and should instead act
    upon on the value of the error code. Although this is implemented
    correctly in our futex code, we needlessly copy uninitialised stack to
    *uval in the error case, which can easily be avoided.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bb3fb093b41f10315e93ca2974164243958a6f51
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Fri May 31 15:29:11 2019 -0700

    bpf: udp: ipv6: Avoid running reuseport's bpf_prog from __udp6_lib_err
    
    commit 4ac30c4b3659efac031818c418beb51e630d512d upstream.
    
    __udp6_lib_err() may be called when handling icmpv6 message. For example,
    the icmpv6 toobig(type=2).  __udp6_lib_lookup() is then called
    which may call reuseport_select_sock().  reuseport_select_sock() will
    call into a bpf_prog (if there is one).
    
    reuseport_select_sock() is expecting the skb->data pointing to the
    transport header (udphdr in this case).  For example, run_bpf_filter()
    is pulling the transport header.
    
    However, in the __udp6_lib_err() path, the skb->data is pointing to the
    ipv6hdr instead of the udphdr.
    
    One option is to pull and push the ipv6hdr in __udp6_lib_err().
    Instead of doing this, this patch follows how the original
    commit 538950a1b752 ("soreuseport: setsockopt SO_ATTACH_REUSEPORT_[CE]BPF")
    was done in IPv4, which has passed a NULL skb pointer to
    reuseport_select_sock().
    
    Fixes: 538950a1b752 ("soreuseport: setsockopt SO_ATTACH_REUSEPORT_[CE]BPF")
    Cc: Craig Gallek <kraig@google.com>
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Acked-by: Craig Gallek <kraig@google.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit da6dab6373b223a3f05df6b2236a3ffa81ed7cb8
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Fri May 31 15:29:13 2019 -0700

    bpf: udp: Avoid calling reuseport's bpf_prog from udp_gro
    
    commit 257a525fe2e49584842c504a92c27097407f778f upstream.
    
    When the commit a6024562ffd7 ("udp: Add GRO functions to UDP socket")
    added udp[46]_lib_lookup_skb to the udp_gro code path, it broke
    the reuseport_select_sock() assumption that skb->data is pointing
    to the transport header.
    
    This patch follows an earlier __udp6_lib_err() fix by
    passing a NULL skb to avoid calling the reuseport's bpf_prog.
    
    Fixes: a6024562ffd7 ("udp: Add GRO functions to UDP socket")
    Cc: Tom Herbert <tom@herbertland.com>
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 591c18e3aed16fde52cfdfc4af094b2cfd5dd0f2
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Fri Jun 7 01:48:57 2019 +0200

    bpf: fix unconnected udp hooks
    
    commit 983695fa676568fc0fe5ddd995c7267aabc24632 upstream.
    
    Intention of cgroup bind/connect/sendmsg BPF hooks is to act transparently
    to applications as also stated in original motivation in 7828f20e3779 ("Merge
    branch 'bpf-cgroup-bind-connect'"). When recently integrating the latter
    two hooks into Cilium to enable host based load-balancing with Kubernetes,
    I ran into the issue that pods couldn't start up as DNS got broken. Kubernetes
    typically sets up DNS as a service and is thus subject to load-balancing.
    
    Upon further debugging, it turns out that the cgroupv2 sendmsg BPF hooks API
    is currently insufficient and thus not usable as-is for standard applications
    shipped with most distros. To break down the issue we ran into with a simple
    example:
    
      # cat /etc/resolv.conf
      nameserver 147.75.207.207
      nameserver 147.75.207.208
    
    For the purpose of a simple test, we set up above IPs as service IPs and
    transparently redirect traffic to a different DNS backend server for that
    node:
    
      # cilium service list
      ID   Frontend            Backend
      1    147.75.207.207:53   1 => 8.8.8.8:53
      2    147.75.207.208:53   1 => 8.8.8.8:53
    
    The attached BPF program is basically selecting one of the backends if the
    service IP/port matches on the cgroup hook. DNS breaks here, because the
    hooks are not transparent enough to applications which have built-in msg_name
    address checks:
    
      # nslookup 1.1.1.1
      ;; reply from unexpected source: 8.8.8.8#53, expected 147.75.207.207#53
      ;; reply from unexpected source: 8.8.8.8#53, expected 147.75.207.208#53
      ;; reply from unexpected source: 8.8.8.8#53, expected 147.75.207.207#53
      [...]
      ;; connection timed out; no servers could be reached
    
      # dig 1.1.1.1
      ;; reply from unexpected source: 8.8.8.8#53, expected 147.75.207.207#53
      ;; reply from unexpected source: 8.8.8.8#53, expected 147.75.207.208#53
      ;; reply from unexpected source: 8.8.8.8#53, expected 147.75.207.207#53
      [...]
    
      ; <<>> DiG 9.11.3-1ubuntu1.7-Ubuntu <<>> 1.1.1.1
      ;; global options: +cmd
      ;; connection timed out; no servers could be reached
    
    For comparison, if none of the service IPs is used, and we tell nslookup
    to use 8.8.8.8 directly it works just fine, of course:
    
      # nslookup 1.1.1.1 8.8.8.8
      1.1.1.1.in-addr.arpa  name = one.one.one.one.
    
    In order to fix this and thus act more transparent to the application,
    this needs reverse translation on recvmsg() side. A minimal fix for this
    API is to add similar recvmsg() hooks behind the BPF cgroups static key
    such that the program can track state and replace the current sockaddr_in{,6}
    with the original service IP. From BPF side, this basically tracks the
    service tuple plus socket cookie in an LRU map where the reverse NAT can
    then be retrieved via map value as one example. Side-note: the BPF cgroups
    static key should be converted to a per-hook static key in future.
    
    Same example after this fix:
    
      # cilium service list
      ID   Frontend            Backend
      1    147.75.207.207:53   1 => 8.8.8.8:53
      2    147.75.207.208:53   1 => 8.8.8.8:53
    
    Lookups work fine now:
    
      # nslookup 1.1.1.1
      1.1.1.1.in-addr.arpa    name = one.one.one.one.
    
      Authoritative answers can be found from:
    
      # dig 1.1.1.1
    
      ; <<>> DiG 9.11.3-1ubuntu1.7-Ubuntu <<>> 1.1.1.1
      ;; global options: +cmd
      ;; Got answer:
      ;; ->>HEADER<<- opcode: QUERY, status: NXDOMAIN, id: 51550
      ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1
    
      ;; OPT PSEUDOSECTION:
      ; EDNS: version: 0, flags:; udp: 512
      ;; QUESTION SECTION:
      ;1.1.1.1.                       IN      A
    
      ;; AUTHORITY SECTION:
      .                       23426   IN      SOA     a.root-servers.net. nstld.verisign-grs.com. 2019052001 1800 900 604800 86400
    
      ;; Query time: 17 msec
      ;; SERVER: 147.75.207.207#53(147.75.207.207)
      ;; WHEN: Tue May 21 12:59:38 UTC 2019
      ;; MSG SIZE  rcvd: 111
    
    And from an actual packet level it shows that we're using the back end
    server when talking via 147.75.207.20{7,8} front end:
    
      # tcpdump -i any udp
      [...]
      12:59:52.698732 IP foo.42011 > google-public-dns-a.google.com.domain: 18803+ PTR? 1.1.1.1.in-addr.arpa. (38)
      12:59:52.698735 IP foo.42011 > google-public-dns-a.google.com.domain: 18803+ PTR? 1.1.1.1.in-addr.arpa. (38)
      12:59:52.701208 IP google-public-dns-a.google.com.domain > foo.42011: 18803 1/0/0 PTR one.one.one.one. (67)
      12:59:52.701208 IP google-public-dns-a.google.com.domain > foo.42011: 18803 1/0/0 PTR one.one.one.one. (67)
      [...]
    
    In order to be flexible and to have same semantics as in sendmsg BPF
    programs, we only allow return codes in [1,1] range. In the sendmsg case
    the program is called if msg->msg_name is present which can be the case
    in both, connected and unconnected UDP.
    
    The former only relies on the sockaddr_in{,6} passed via connect(2) if
    passed msg->msg_name was NULL. Therefore, on recvmsg side, we act in similar
    way to call into the BPF program whenever a non-NULL msg->msg_name was
    passed independent of sk->sk_state being TCP_ESTABLISHED or not. Note
    that for TCP case, the msg->msg_name is ignored in the regular recvmsg
    path and therefore not relevant.
    
    For the case of ip{,v6}_recv_error() paths, picked up via MSG_ERRQUEUE,
    the hook is not called. This is intentional as it aligns with the same
    semantics as in case of TCP cgroup BPF hooks right now. This might be
    better addressed in future through a different bpf_attach_type such
    that this case can be distinguished from the regular recvmsg paths,
    for example.
    
    Fixes: 1cedee13d25a ("bpf: Hooks for sys_sendmsg")
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Andrey Ignatov <rdna@fb.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Martynas Pumputis <m@lambda.lt>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2a9fedc1ef4be2acb4fd4674f405c21c811e1505
Author: Matt Mullins <mmullins@fb.com>
Date:   Tue Jun 11 14:53:04 2019 -0700

    bpf: fix nested bpf tracepoints with per-cpu data
    
    commit 9594dc3c7e71b9f52bee1d7852eb3d4e3aea9e99 upstream.
    
    BPF_PROG_TYPE_RAW_TRACEPOINTs can be executed nested on the same CPU, as
    they do not increment bpf_prog_active while executing.
    
    This enables three levels of nesting, to support
      - a kprobe or raw tp or perf event,
      - another one of the above that irq context happens to call, and
      - another one in nmi context
    (at most one of which may be a kprobe or perf event).
    
    Fixes: 20b9d7ac4852 ("bpf: avoid excessive stack usage for perf_sample_data")
    Signed-off-by: Matt Mullins <mmullins@fb.com>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Acked-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7cec89761822f911527ba89ffda314fa4c0fad67
Author: Jonathan Lemon <jonathan.lemon@gmail.com>
Date:   Sat Jun 8 12:54:19 2019 -0700

    bpf: lpm_trie: check left child of last leftmost node for NULL
    
    commit da2577fdd0932ea4eefe73903f1130ee366767d2 upstream.
    
    If the leftmost parent node of the tree has does not have a child
    on the left side, then trie_get_next_key (and bpftool map dump) will
    not look at the child on the right.  This leads to the traversal
    missing elements.
    
    Lookup is not affected.
    
    Update selftest to handle this case.
    
    Reproducer:
    
     bpftool map create /sys/fs/bpf/lpm type lpm_trie key 6 \
         value 1 entries 256 name test_lpm flags 1
     bpftool map update pinned /sys/fs/bpf/lpm key  8 0 0 0  0   0 value 1
     bpftool map update pinned /sys/fs/bpf/lpm key 16 0 0 0  0 128 value 2
     bpftool map dump   pinned /sys/fs/bpf/lpm
    
    Returns only 1 element. (2 expected)
    
    Fixes: b471f2f1de8b ("bpf: implement MAP_GET_NEXT_KEY command for LPM_TRIE")
    Signed-off-by: Jonathan Lemon <jonathan.lemon@gmail.com>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7108c83502e822e52052eea7d13f9d3d8bc8dea0
Author: Martynas Pumputis <m@lambda.lt>
Date:   Wed Jun 12 18:05:40 2019 +0200

    bpf: simplify definition of BPF_FIB_LOOKUP related flags
    
    commit b1d6c15b9d824a58c5415673f374fac19e8eccdf upstream.
    
    Previously, the BPF_FIB_LOOKUP_{DIRECT,OUTPUT} flags in the BPF UAPI
    were defined with the help of BIT macro. This had the following issues:
    
    - In order to use any of the flags, a user was required to depend
      on <linux/bits.h>.
    - No other flag in bpf.h uses the macro, so it seems that an unwritten
      convention is to use (1 << (nr)) to define BPF-related flags.
    
    Fixes: 87f5fc7e48dd ("bpf: Provide helper to do forwarding lookups in kernel FIB table")
    Signed-off-by: Martynas Pumputis <m@lambda.lt>
    Acked-by: Andrii Nakryiko <andriin@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03c3e507e90eb4fc528ed52e77d9f9ae8e4edd64
Author: Dmitry Bogdanov <dmitry.bogdanov@aquantia.com>
Date:   Sat Jun 22 08:46:37 2019 +0000

    net: aquantia: fix vlans not working over bridged network
    
    [ Upstream commit 48dd73d08d4dda47ee31cc8611fb16840fc16803 ]
    
    In configuration of vlan over bridge over aquantia device
    it was found that vlan tagged traffic is dropped on chip.
    
    The reason is that bridge device enables promisc mode,
    but in atlantic chip vlan filters will still apply.
    So we have to corellate promisc settings with vlan configuration.
    
    The solution is to track in a separate state variable the
    need of vlan forced promisc. And also consider generic
    promisc configuration when doing vlan filter config.
    
    Fixes: 7975d2aff5af ("net: aquantia: add support of rx-vlan-filter offload")
    Signed-off-by: Dmitry Bogdanov <dmitry.bogdanov@aquantia.com>
    Signed-off-by: Igor Russkikh <igor.russkikh@aquantia.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9590d1d1b033cb3c1211a90c66b928a141d6b129
Author: Fei Li <lifei.shirley@bytedance.com>
Date:   Mon Jun 17 21:26:36 2019 +0800

    tun: wake up waitqueues after IFF_UP is set
    
    [ Upstream commit 72b319dc08b4924a29f5e2560ef6d966fa54c429 ]
    
    Currently after setting tap0 link up, the tun code wakes tx/rx waited
    queues up in tun_net_open() when .ndo_open() is called, however the
    IFF_UP flag has not been set yet. If there's already a wait queue, it
    would fail to transmit when checking the IFF_UP flag in tun_sendmsg().
    Then the saving vhost_poll_start() will add the wq into wqh until it
    is waken up again. Although this works when IFF_UP flag has been set
    when tun_chr_poll detects; this is not true if IFF_UP flag has not
    been set at that time. Sadly the latter case is a fatal error, as
    the wq will never be waken up in future unless later manually
    setting link up on purpose.
    
    Fix this by moving the wakeup process into the NETDEV_UP event
    notifying process, this makes sure IFF_UP has been set before all
    waited queues been waken up.
    
    Signed-off-by: Fei Li <lifei.shirley@bytedance.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a54c0c1d392138f2012c1f644c434cbeed4cac77
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Jun 25 00:28:19 2019 +0800

    tipc: check msg->req data len in tipc_nl_compat_bearer_disable
    
    [ Upstream commit 4f07b80c973348a99b5d2a32476a2e7877e94a05 ]
    
    This patch is to fix an uninit-value issue, reported by syzbot:
    
      BUG: KMSAN: uninit-value in memchr+0xce/0x110 lib/string.c:981
      Call Trace:
        __dump_stack lib/dump_stack.c:77 [inline]
        dump_stack+0x191/0x1f0 lib/dump_stack.c:113
        kmsan_report+0x130/0x2a0 mm/kmsan/kmsan.c:622
        __msan_warning+0x75/0xe0 mm/kmsan/kmsan_instr.c:310
        memchr+0xce/0x110 lib/string.c:981
        string_is_valid net/tipc/netlink_compat.c:176 [inline]
        tipc_nl_compat_bearer_disable+0x2a1/0x480 net/tipc/netlink_compat.c:449
        __tipc_nl_compat_doit net/tipc/netlink_compat.c:327 [inline]
        tipc_nl_compat_doit+0x3ac/0xb00 net/tipc/netlink_compat.c:360
        tipc_nl_compat_handle net/tipc/netlink_compat.c:1178 [inline]
        tipc_nl_compat_recv+0x1b1b/0x27b0 net/tipc/netlink_compat.c:1281
    
    TLV_GET_DATA_LEN() may return a negtive int value, which will be
    used as size_t (becoming a big unsigned long) passed into memchr,
    cause this issue.
    
    Similar to what it does in tipc_nl_compat_bearer_enable(), this
    fix is to return -EINVAL when TLV_GET_DATA_LEN() is negtive in
    tipc_nl_compat_bearer_disable(), as well as in
    tipc_nl_compat_link_stat_dump() and tipc_nl_compat_link_reset_stats().
    
    v1->v2:
      - add the missing Fixes tags per Eric's request.
    
    Fixes: 0762216c0ad2 ("tipc: fix uninit-value in tipc_nl_compat_bearer_enable")
    Fixes: 8b66fee7f8ee ("tipc: fix uninit-value in tipc_nl_compat_link_reset_stats")
    Reported-by: syzbot+30eaa8bf392f7fafffaf@syzkaller.appspotmail.com
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec7fafa68f287c290c08a07765cbb0772e3d7229
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Jun 20 18:39:28 2019 +0800

    tipc: change to use register_pernet_device
    
    [ Upstream commit c492d4c74dd3f87559883ffa0f94a8f1ae3fe5f5 ]
    
    This patch is to fix a dst defcnt leak, which can be reproduced by doing:
    
      # ip net a c; ip net a s; modprobe tipc
      # ip net e s ip l a n eth1 type veth peer n eth1 netns c
      # ip net e c ip l s lo up; ip net e c ip l s eth1 up
      # ip net e s ip l s lo up; ip net e s ip l s eth1 up
      # ip net e c ip a a 1.1.1.2/8 dev eth1
      # ip net e s ip a a 1.1.1.1/8 dev eth1
      # ip net e c tipc b e m udp n u1 localip 1.1.1.2
      # ip net e s tipc b e m udp n u1 localip 1.1.1.1
      # ip net d c; ip net d s; rmmod tipc
    
    and it will get stuck and keep logging the error:
    
      unregister_netdevice: waiting for lo to become free. Usage count = 1
    
    The cause is that a dst is held by the udp sock's sk_rx_dst set on udp rx
    path with udp_early_demux == 1, and this dst (eventually holding lo dev)
    can't be released as bearer's removal in tipc pernet .exit happens after
    lo dev's removal, default_device pernet .exit.
    
     "There are two distinct types of pernet_operations recognized: subsys and
      device.  At creation all subsys init functions are called before device
      init functions, and at destruction all device exit functions are called
      before subsys exit function."
    
    So by calling register_pernet_device instead to register tipc_net_ops, the
    pernet .exit() will be invoked earlier than loopback dev's removal when a
    netns is being destroyed, as fou/gue does.
    
    Note that vxlan and geneve udp tunnels don't have this issue, as the udp
    sock is released in their device ndo_stop().
    
    This fix is also necessary for tipc dst_cache, which will hold dsts on tx
    path and I will introduce in my next patch.
    
    Reported-by: Li Shuang <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a061216af44be711890d0153b4305553c98d9528
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jun 27 00:03:39 2019 +0800

    team: Always enable vlan tx offload
    
    [ Upstream commit ee4297420d56a0033a8593e80b33fcc93fda8509 ]
    
    We should rather have vlan_tci filled all the way down
    to the transmitting netdevice and let it do the hw/sw
    vlan implementation.
    
    Suggested-by: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6c616a135a6d9b8ff2f5aa65b6c0999530228058
Author: Xin Long <lucien.xin@gmail.com>
Date:   Tue Jun 25 00:21:45 2019 +0800

    sctp: change to hold sk after auth shkey is created successfully
    
    [ Upstream commit 25bff6d5478b2a02368097015b7d8eb727c87e16 ]
    
    Now in sctp_endpoint_init(), it holds the sk then creates auth
    shkey. But when the creation fails, it doesn't release the sk,
    which causes a sk defcnf leak,
    
    Here to fix it by only holding the sk when auth shkey is created
    successfully.
    
    Fixes: a29a5bd4f5c3 ("[SCTP]: Implement SCTP-AUTH initializations.")
    Reported-by: syzbot+afabda3890cc2f765041@syzkaller.appspotmail.com
    Reported-by: syzbot+276ca1c77a19977c0130@syzkaller.appspotmail.com
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Neil Horman <nhorman@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0962d139f22a4e889e686b86806767b99eda8086
Author: Dirk van der Merwe <dirk.vandermerwe@netronome.com>
Date:   Sun Jun 23 21:26:58 2019 -0700

    net/tls: fix page double free on TX cleanup
    
    [ Upstream commit 9354544cbccf68da1b047f8fb7b47630e3c8a59d ]
    
    With commit 94850257cf0f ("tls: Fix tls_device handling of partial records")
    a new path was introduced to cleanup partial records during sk_proto_close.
    This path does not handle the SW KTLS tx_list cleanup.
    
    This is unnecessary though since the free_resources calls for both
    SW and offload paths will cleanup a partial record.
    
    The visible effect is the following warning, but this bug also causes
    a page double free.
    
        WARNING: CPU: 7 PID: 4000 at net/core/stream.c:206 sk_stream_kill_queues+0x103/0x110
        RIP: 0010:sk_stream_kill_queues+0x103/0x110
        RSP: 0018:ffffb6df87e07bd0 EFLAGS: 00010206
        RAX: 0000000000000000 RBX: ffff8c21db4971c0 RCX: 0000000000000007
        RDX: ffffffffffffffa0 RSI: 000000000000001d RDI: ffff8c21db497270
        RBP: ffff8c21db497270 R08: ffff8c29f4748600 R09: 000000010020001a
        R10: ffffb6df87e07aa0 R11: ffffffff9a445600 R12: 0000000000000007
        R13: 0000000000000000 R14: ffff8c21f03f2900 R15: ffff8c21f03b8df0
        Call Trace:
         inet_csk_destroy_sock+0x55/0x100
         tcp_close+0x25d/0x400
         ? tcp_check_oom+0x120/0x120
         tls_sk_proto_close+0x127/0x1c0
         inet_release+0x3c/0x60
         __sock_release+0x3d/0xb0
         sock_close+0x11/0x20
         __fput+0xd8/0x210
         task_work_run+0x84/0xa0
         do_exit+0x2dc/0xb90
         ? release_sock+0x43/0x90
         do_group_exit+0x3a/0xa0
         get_signal+0x295/0x720
         do_signal+0x36/0x610
         ? SYSC_recvfrom+0x11d/0x130
         exit_to_usermode_loop+0x69/0xb0
         do_syscall_64+0x173/0x180
         entry_SYSCALL_64_after_hwframe+0x3d/0xa2
        RIP: 0033:0x7fe9b9abc10d
        RSP: 002b:00007fe9b19a1d48 EFLAGS: 00000246 ORIG_RAX: 00000000000000ca
        RAX: fffffffffffffe00 RBX: 0000000000000006 RCX: 00007fe9b9abc10d
        RDX: 0000000000000002 RSI: 0000000000000080 RDI: 00007fe948003430
        RBP: 00007fe948003410 R08: 00007fe948003430 R09: 0000000000000000
        R10: 0000000000000000 R11: 0000000000000246 R12: 00005603739d9080
        R13: 00007fe9b9ab9f90 R14: 00007fe948003430 R15: 0000000000000000
    
    Fixes: 94850257cf0f ("tls: Fix tls_device handling of partial records")
    Signed-off-by: Dirk van der Merwe <dirk.vandermerwe@netronome.com>
    Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a6902fe436d068f8afeb34a0ac5dfdf2d99abd8d
Author: Roland Hii <roland.king.guan.hii@intel.com>
Date:   Wed Jun 19 22:41:48 2019 +0800

    net: stmmac: set IC bit when transmitting frames with HW timestamp
    
    [ Upstream commit d0bb82fd60183868f46c8ccc595a3d61c3334a18 ]
    
    When transmitting certain PTP frames, e.g. SYNC and DELAY_REQ, the
    PTP daemon, e.g. ptp4l, is polling the driver for the frame transmit
    hardware timestamp. The polling will most likely timeout if the tx
    coalesce is enabled due to the Interrupt-on-Completion (IC) bit is
    not set in tx descriptor for those frames.
    
    This patch will ignore the tx coalesce parameter and set the IC bit
    when transmitting PTP frames which need to report out the frame
    transmit hardware timestamp to user space.
    
    Fixes: f748be531d70 ("net: stmmac: Rework coalesce timer and fix multi-queue races")
    Signed-off-by: Roland Hii <roland.king.guan.hii@intel.com>
    Signed-off-by: Ong Boon Leong <boon.leong.ong@intel.com>
    Signed-off-by: Voon Weifeng <weifeng.voon@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ac086d4c5d0f54c3412472d343268df132b55328
Author: Roland Hii <roland.king.guan.hii@intel.com>
Date:   Wed Jun 19 22:13:48 2019 +0800

    net: stmmac: fixed new system time seconds value calculation
    
    [ Upstream commit a1e5388b4d5fc78688e5e9ee6641f779721d6291 ]
    
    When ADDSUB bit is set, the system time seconds field is calculated as
    the complement of the seconds part of the update value.
    
    For example, if 3.000000001 seconds need to be subtracted from the
    system time, this field is calculated as
    2^32 - 3 = 4294967296 - 3 = 0x100000000 - 3 = 0xFFFFFFFD
    
    Previously, the 0x100000000 is mistakenly written as 100000000.
    
    This is further simplified from
      sec = (0x100000000ULL - sec);
    to
      sec = -sec;
    
    Fixes: ba1ffd74df74 ("stmmac: fix PTP support for GMAC4")
    Signed-off-by: Roland Hii <roland.king.guan.hii@intel.com>
    Signed-off-by: Ong Boon Leong <boon.leong.ong@intel.com>
    Signed-off-by: Voon Weifeng <weifeng.voon@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 505c925823144996daa030e4bbe26660569a0609
Author: JingYi Hou <houjingyi647@gmail.com>
Date:   Mon Jun 17 14:56:05 2019 +0800

    net: remove duplicate fetch in sock_getsockopt
    
    [ Upstream commit d0bae4a0e3d8c5690a885204d7eb2341a5b4884d ]
    
    In sock_getsockopt(), 'optlen' is fetched the first time from userspace.
    'len < 0' is then checked. Then in condition 'SO_MEMINFO', 'optlen' is
    fetched the second time from userspace.
    
    If change it between two fetches may cause security problems or unexpected
    behaivor, and there is no reason to fetch it a second time.
    
    To fix this, we need to remove the second fetch.
    
    Signed-off-by: JingYi Hou <houjingyi647@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 65b2a8047939229a9e767b82d741bee4f8ac6b53
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Jun 24 02:38:20 2019 -0700

    net/packet: fix memory leak in packet_set_ring()
    
    [ Upstream commit 55655e3d1197fff16a7a05088fb0e5eba50eac55 ]
    
    syzbot found we can leak memory in packet_set_ring(), if user application
    provides buggy parameters.
    
    Fixes: 7f953ab2ba46 ("af_packet: TX_RING support for TPACKET_V3")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Sowmini Varadhan <sowmini.varadhan@oracle.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c79ab459bea42f66f5c4d161dc41f9d8e40ab4ff
Author: Stephen Suryaputra <ssuryaextr@gmail.com>
Date:   Mon Jun 24 20:14:06 2019 -0400

    ipv4: Use return value of inet_iif() for __raw_v4_lookup in the while loop
    
    [ Upstream commit 38c73529de13e1e10914de7030b659a2f8b01c3b ]
    
    In commit 19e4e768064a8 ("ipv4: Fix raw socket lookup for local
    traffic"), the dif argument to __raw_v4_lookup() is coming from the
    returned value of inet_iif() but the change was done only for the first
    lookup. Subsequent lookups in the while loop still use skb->dev->ifIndex.
    
    Fixes: 19e4e768064a8 ("ipv4: Fix raw socket lookup for local traffic")
    Signed-off-by: Stephen Suryaputra <ssuryaextr@gmail.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bc4fdb7d73ba4b4ecd9e12686ab64a6cdb3f2bb1
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Wed Jun 26 16:08:44 2019 +0800

    bonding: Always enable vlan tx offload
    
    [ Upstream commit 30d8177e8ac776d89d387fad547af6a0f599210e ]
    
    We build vlan on top of bonding interface, which vlan offload
    is off, bond mode is 802.3ad (LACP) and xmit_hash_policy is
    BOND_XMIT_POLICY_ENCAP34.
    
    Because vlan tx offload is off, vlan tci is cleared and skb push
    the vlan header in validate_xmit_vlan() while sending from vlan
    devices. Then in bond_xmit_hash, __skb_flow_dissect() fails to
    get information from protocol headers encapsulated within vlan,
    because 'nhoff' is points to IP header, so bond hashing is based
    on layer 2 info, which fails to distribute packets across slaves.
    
    This patch always enable bonding's vlan tx offload, pass the vlan
    packets to the slave devices with vlan tci, let them to handle
    vlan implementation.
    
    Fixes: 278339a42a1b ("bonding: propogate vlan_features to bonding master")
    Suggested-by: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Jiri Pirko <jiri@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c14a0de97597f2022e83abb5cbb0144c231a4a33
Author: Neil Horman <nhorman@tuxdriver.com>
Date:   Tue Jun 25 17:57:49 2019 -0400

    af_packet: Block execution of tasks waiting for transmit to complete in AF_PACKET
    
    [ Upstream commit 89ed5b519004a7706f50b70f611edbd3aaacff2c ]
    
    When an application is run that:
    a) Sets its scheduler to be SCHED_FIFO
    and
    b) Opens a memory mapped AF_PACKET socket, and sends frames with the
    MSG_DONTWAIT flag cleared, its possible for the application to hang
    forever in the kernel.  This occurs because when waiting, the code in
    tpacket_snd calls schedule, which under normal circumstances allows
    other tasks to run, including ksoftirqd, which in some cases is
    responsible for freeing the transmitted skb (which in AF_PACKET calls a
    destructor that flips the status bit of the transmitted frame back to
    available, allowing the transmitting task to complete).
    
    However, when the calling application is SCHED_FIFO, its priority is
    such that the schedule call immediately places the task back on the cpu,
    preventing ksoftirqd from freeing the skb, which in turn prevents the
    transmitting task from detecting that the transmission is complete.
    
    We can fix this by converting the schedule call to a completion
    mechanism.  By using a completion queue, we force the calling task, when
    it detects there are no more frames to send, to schedule itself off the
    cpu until such time as the last transmitted skb is freed, allowing
    forward progress to be made.
    
    Tested by myself and the reporter, with good results
    
    Change Notes:
    
    V1->V2:
            Enhance the sleep logic to support being interruptible and
    allowing for honoring to SK_SNDTIMEO (Willem de Bruijn)
    
    V2->V3:
            Rearrage the point at which we wait for the completion queue, to
    avoid needing to check for ph/skb being null at the end of the loop.
    Also move the complete call to the skb destructor to avoid needing to
    modify __packet_set_status.  Also gate calling complete on
    packet_read_pending returning zero to avoid multiple calls to complete.
    (Willem de Bruijn)
    
            Move timeo computation within loop, to re-fetch the socket
    timeout since we also use the timeo variable to record the return code
    from the wait_for_complete call (Neil Horman)
    
    V3->V4:
            Willem has requested that the control flow be restored to the
    previous state.  Doing so lets us eliminate the need for the
    po->wait_on_complete flag variable, and lets us get rid of the
    packet_next_frame function, but introduces another complexity.
    Specifically, but using the packet pending count, we can, if an
    applications calls sendmsg multiple times with MSG_DONTWAIT set, each
    set of transmitted frames, when complete, will cause
    tpacket_destruct_skb to issue a complete call, for which there will
    never be a wait_on_completion call.  This imbalance will lead to any
    future call to wait_for_completion here to return early, when the frames
    they sent may not have completed.  To correct this, we need to re-init
    the completion queue on every call to tpacket_snd before we enter the
    loop so as to ensure we wait properly for the frames we send in this
    iteration.
    
            Change the timeout and interrupted gotos to out_put rather than
    out_status so that we don't try to free a non-existant skb
            Clean up some extra newlines (Willem de Bruijn)
    
    Reviewed-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: Neil Horman <nhorman@tuxdriver.com>
    Reported-by: Matteo Croce <mcroce@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0730644e5602b5573401e091442acbee7e5778a1
Author: Paul Burton <paulburton@kernel.org>
Date:   Wed Jun 5 09:34:10 2019 +0100

    irqchip/mips-gic: Use the correct local interrupt map registers
    
    commit 6d4d367d0e9ffab4d64a3436256a6a052dc1195d upstream.
    
    The MIPS GIC contains a block of registers used to map local interrupts
    to a particular CPU interrupt pin. Since these registers are found at a
    consecutive range of addresses we access them using an index, via the
    (read|write)_gic_v[lo]_map accessor functions. We currently use values
    from enum mips_gic_local_interrupt as those indices.
    
    Unfortunately whilst enum mips_gic_local_interrupt provides the correct
    offsets for bits in the pending & mask registers, the ordering of the
    map registers is subtly different... Compared with the ordering of
    pending & mask bits, the map registers move the FDC from the end of the
    list to index 3 after the timer interrupt. As a result the performance
    counter & software interrupts are therefore at indices 4-6 rather than
    indices 3-5.
    
    Notably this causes problems with performance counter interrupts being
    incorrectly mapped on some systems, and presumably will also cause
    problems for FDC interrupts.
    
    Introduce a function to map from enum mips_gic_local_interrupt to the
    index of the corresponding map register, and use it to ensure we access
    the map registers for the correct interrupts.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Fixes: a0dc5cb5e31b ("irqchip: mips-gic: Simplify gic_local_irq_domain_map()")
    Fixes: da61fcf9d62a ("irqchip: mips-gic: Use irq_cpu_online to (un)mask all-VP(E) IRQs")
    Reported-and-tested-by: Archer Yan <ayan@wavecomp.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jason Cooper <jason@lakedaemon.net>
    Cc: stable@vger.kernel.org # v4.14+
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5dfe49ca70e10eef208b6d4a673f34d01bff0293
Author: Trond Myklebust <trondmy@gmail.com>
Date:   Mon Jun 24 19:15:44 2019 -0400

    SUNRPC: Fix up calculation of client message length
    
    commit 7e3d3620974b743b91b1f9d0660061b1de20174c upstream.
    
    In the case where a record marker was used, xs_sendpages() needs
    to return the length of the payload + record marker so that we
    operate correctly in the case of a partial transmission.
    When the callers check return value, they therefore need to
    take into account the record marker length.
    
    Fixes: 06b5fc3ad94e ("Merge tag 'nfs-rdma-for-5.1-1'...")
    Cc: stable@vger.kernel.org # 5.1+
    Signed-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>
    Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b187fae6ee297f3bba913cfc8b6c2181bccae3dd
Author: Geert Uytterhoeven <geert@linux-m68k.org>
Date:   Thu May 16 09:09:35 2019 +0200

    cpu/speculation: Warn on unsupported mitigations= parameter
    
    commit 1bf72720281770162c87990697eae1ba2f1d917a upstream.
    
    Currently, if the user specifies an unsupported mitigation strategy on the
    kernel command line, it will be ignored silently.  The code will fall back
    to the default strategy, possibly leaving the system more vulnerable than
    expected.
    
    This may happen due to e.g. a simple typo, or, for a stable kernel release,
    because not all mitigation strategies have been backported.
    
    Inform the user by printing a message.
    
    Fixes: 98af8452945c5565 ("cpu/speculation: Add 'mitigations=' cmdline option")
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Jiri Kosina <jkosina@suse.cz>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/20190516070935.22546-1-geert@linux-m68k.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 82d0f7b68d939aa67b6adcb449a7753cbeee36b8
Author: Trond Myklebust <trondmy@gmail.com>
Date:   Tue Jun 25 16:41:16 2019 -0400

    NFS/flexfiles: Use the correct TCP timeout for flexfiles I/O
    
    commit 68f461593f76bd5f17e87cdd0bea28f4278c7268 upstream.
    
    Fix a typo where we're confusing the default TCP retrans value
    (NFS_DEF_TCP_RETRANS) for the default TCP timeout value.
    
    Fixes: 15d03055cf39f ("pNFS/flexfiles: Set reasonable default ...")
    Cc: stable@vger.kernel.org # 4.8+
    Signed-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>
    Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b5961ecad7121fec138ebee7d9eba4863f9dc6e7
Author: Ard Biesheuvel <ardb@kernel.org>
Date:   Sun Jun 9 20:17:44 2019 +0200

    efi/memreserve: deal with memreserve entries in unmapped memory
    
    commit 18df7577adae6c6c778bf774b3aebcacbc1fb439 upstream.
    
    Ensure that the EFI memreserve entries can be accessed, even if they
    are located in memory that the kernel (e.g., a crashkernel) omits from
    the linear map.
    
    Fixes: 80424b02d42b ("efi: Reduce the amount of memblock reservations ...")
    Cc: <stable@vger.kernel.org> # 5.0+
    Reported-by: Jonathan Richardson <jonathan.richardson@broadcom.com>
    Reviewed-by: Jonathan Richardson <jonathan.richardson@broadcom.com>
    Tested-by: Jonathan Richardson <jonathan.richardson@broadcom.com>
    Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 994f9a520c1ba3a5d8d585888da4e27ff9abfeb0
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Fri May 24 10:12:46 2019 -0400

    mm: fix page cache convergence regression
    
    commit 7b785645e8f13e17cbce492708cf6e7039d32e46 upstream.
    
    Since a28334862993 ("page cache: Finish XArray conversion"), on most
    major Linux distributions, the page cache doesn't correctly transition
    when the hot data set is changing, and leaves the new pages thrashing
    indefinitely instead of kicking out the cold ones.
    
    On a freshly booted, freshly ssh'd into virtual machine with 1G RAM
    running stock Arch Linux:
    
    [root@ham ~]# ./reclaimtest.sh
    + dd of=workingset-a bs=1M count=0 seek=600
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + ./mincore workingset-a
    153600/153600 workingset-a
    + dd of=workingset-b bs=1M count=0 seek=600
    + cat workingset-b
    + cat workingset-b
    + cat workingset-b
    + cat workingset-b
    + ./mincore workingset-a workingset-b
    104029/153600 workingset-a
    120086/153600 workingset-b
    + cat workingset-b
    + cat workingset-b
    + cat workingset-b
    + cat workingset-b
    + ./mincore workingset-a workingset-b
    104029/153600 workingset-a
    120268/153600 workingset-b
    
    workingset-b is a 600M file on a 1G host that is otherwise entirely
    idle. No matter how often it's being accessed, it won't get cached.
    
    While investigating, I noticed that the non-resident information gets
    aggressively reclaimed - /proc/vmstat::workingset_nodereclaim. This is
    a problem because a workingset transition like this relies on the
    non-resident information tracked in the page cache tree of evicted
    file ranges: when the cache faults are refaults of recently evicted
    cache, we challenge the existing active set, and that allows a new
    workingset to establish itself.
    
    Tracing the shrinker that maintains this memory revealed that all page
    cache tree nodes were allocated to the root cgroup. This is a problem,
    because 1) the shrinker sizes the amount of non-resident information
    it keeps to the size of the cgroup's other memory and 2) on most major
    Linux distributions, only kernel threads live in the root cgroup and
    everything else gets put into services or session groups:
    
    [root@ham ~]# cat /proc/self/cgroup
    0::/user.slice/user-0.slice/session-c1.scope
    
    As a result, we basically maintain no non-resident information for the
    workloads running on the system, thus breaking the caching algorithm.
    
    Looking through the code, I found the culprit in the above-mentioned
    patch: when switching from the radix tree to xarray, it dropped the
    __GFP_ACCOUNT flag from the tree node allocations - the flag that
    makes sure the allocated memory gets charged to and tracked by the
    cgroup of the calling process - in this case, the one doing the fault.
    
    To fix this, allow xarray users to specify per-tree flag that makes
    xarray allocate nodes using __GFP_ACCOUNT. Then restore the page cache
    tree annotation to request such cgroup tracking for the cache nodes.
    
    With this patch applied, the page cache correctly converges on new
    workingsets again after just a few iterations:
    
    [root@ham ~]# ./reclaimtest.sh
    + dd of=workingset-a bs=1M count=0 seek=600
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + cat workingset-a
    + ./mincore workingset-a
    153600/153600 workingset-a
    + dd of=workingset-b bs=1M count=0 seek=600
    + cat workingset-b
    + ./mincore workingset-a workingset-b
    124607/153600 workingset-a
    87876/153600 workingset-b
    + cat workingset-b
    + ./mincore workingset-a workingset-b
    81313/153600 workingset-a
    133321/153600 workingset-b
    + cat workingset-b
    + ./mincore workingset-a workingset-b
    63036/153600 workingset-a
    153600/153600 workingset-b
    
    Cc: stable@vger.kernel.org # 4.20+
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9b901ec94de5181f936858dfb2c7f28ebe70e5a7
Author: Reinette Chatre <reinette.chatre@intel.com>
Date:   Wed Jun 19 13:27:16 2019 -0700

    x86/resctrl: Prevent possible overrun during bitmap operations
    
    commit 32f010deab575199df4ebe7b6aec20c17bb7eccd upstream.
    
    While the DOC at the beginning of lib/bitmap.c explicitly states that
    "The number of valid bits in a given bitmap does _not_ need to be an
    exact multiple of BITS_PER_LONG.", some of the bitmap operations do
    indeed access BITS_PER_LONG portions of the provided bitmap no matter
    the size of the provided bitmap.
    
    For example, if find_first_bit() is provided with an 8 bit bitmap the
    operation will access BITS_PER_LONG bits from the provided bitmap. While
    the operation ensures that these extra bits do not affect the result,
    the memory is still accessed.
    
    The capacity bitmasks (CBMs) are typically stored in u32 since they
    can never exceed 32 bits. A few instances exist where a bitmap_*
    operation is performed on a CBM by simply pointing the bitmap operation
    to the stored u32 value.
    
    The consequence of this pattern is that some bitmap_* operations will
    access out-of-bounds memory when interacting with the provided CBM.
    
    This same issue has previously been addressed with commit 49e00eee0061
    ("x86/intel_rdt: Fix out-of-bounds memory access in CBM tests")
    but at that time not all instances of the issue were fixed.
    
    Fix this by using an unsigned long to store the capacity bitmask data
    that is passed to bitmap functions.
    
    Fixes: e651901187ab ("x86/intel_rdt: Introduce "bit_usage" to display cache allocations details")
    Fixes: f4e80d67a527 ("x86/intel_rdt: Resctrl files reflect pseudo-locked information")
    Fixes: 95f0b77efa57 ("x86/intel_rdt: Initialize new resource group with sane defaults")
    Signed-off-by: Reinette Chatre <reinette.chatre@intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Fenghua Yu <fenghua.yu@intel.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: stable <stable@vger.kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Tony Luck <tony.luck@intel.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/58c9b6081fd9bf599af0dfc01a6fdd335768efef.1560975645.git.reinette.chatre@intel.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3c762ccd9d57fbe34d4439cc167ea59803b3fb05
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 18 22:31:40 2019 +0200

    x86/microcode: Fix the microcode load on CPU hotplug for real
    
    commit 5423f5ce5ca410b3646f355279e4e937d452e622 upstream.
    
    A recent change moved the microcode loader hotplug callback into the early
    startup phase which is running with interrupts disabled. It missed that
    the callbacks invoke sysfs functions which might sleep causing nice 'might
    sleep' splats with proper debugging enabled.
    
    Split the callbacks and only load the microcode in the early startup phase
    and move the sysfs handling back into the later threaded and preemptible
    bringup phase where it was before.
    
    Fixes: 78f4e932f776 ("x86/microcode, cpuhotplug: Add a microcode loader CPU hotplug callback")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: stable@vger.kernel.org
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1906182228350.1766@nanos.tec.linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6aec2bbd7839c9d45609e78198dac3ddc9b91750
Author: Alejandro Jimenez <alejandro.j.jimenez@oracle.com>
Date:   Mon Jun 10 13:20:10 2019 -0400

    x86/speculation: Allow guests to use SSBD even if host does not
    
    commit c1f7fec1eb6a2c86d01bc22afce772c743451d88 upstream.
    
    The bits set in x86_spec_ctrl_mask are used to calculate the guest's value
    of SPEC_CTRL that is written to the MSR before VMENTRY, and control which
    mitigations the guest can enable.  In the case of SSBD, unless the host has
    enabled SSBD always on mode (by passing "spec_store_bypass_disable=on" in
    the kernel parameters), the SSBD bit is not set in the mask and the guest
    can not properly enable the SSBD always on mitigation mode.
    
    This has been confirmed by running the SSBD PoC on a guest using the SSBD
    always on mitigation mode (booted with kernel parameter
    "spec_store_bypass_disable=on"), and verifying that the guest is vulnerable
    unless the host is also using SSBD always on mode. In addition, the guest
    OS incorrectly reports the SSB vulnerability as mitigated.
    
    Always set the SSBD bit in x86_spec_ctrl_mask when the host CPU supports
    it, allowing the guest to use SSBD whether or not the host has chosen to
    enable the mitigation in any of its modes.
    
    Fixes: be6fcb5478e9 ("x86/bugs: Rework spec_ctrl base and mask logic")
    Signed-off-by: Alejandro Jimenez <alejandro.j.jimenez@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Liam Merwick <liam.merwick@oracle.com>
    Reviewed-by: Mark Kanda <mark.kanda@oracle.com>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: bp@alien8.de
    Cc: rkrcmar@redhat.com
    Cc: kvm@vger.kernel.org
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/1560187210-11054-1-git-send-email-alejandro.j.jimenez@oracle.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e5fb2093f9e86abe7c742465a8e9908951c463d2
Author: Jan Kara <jack@suse.cz>
Date:   Wed Jun 19 09:05:41 2019 +0200

    scsi: vmw_pscsi: Fix use-after-free in pvscsi_queue_lck()
    
    commit 240b4cc8fd5db138b675297d4226ec46594d9b3b upstream.
    
    Once we unlock adapter->hw_lock in pvscsi_queue_lck() nothing prevents just
    queued scsi_cmnd from completing and freeing the request. Thus cmd->cmnd[0]
    dereference can dereference already freed request leading to kernel crashes
    or other issues (which one of our customers observed). Store cmd->cmnd[0]
    in a local variable before unlocking adapter->hw_lock to fix the issue.
    
    CC: <stable@vger.kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Ewan D. Milne <emilne@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ddae0798dd1183183694977c2632e686ed317b06
Author: Jens Axboe <axboe@kernel.dk>
Date:   Fri Jun 21 10:20:18 2019 -0600

    io_uring: ensure req->file is cleared on allocation
    
    commit 60c112b0ada09826cc4ae6a4e55df677f76f1313 upstream.
    
    Stephen reports:
    
    I hit the following General Protection Fault when testing io_uring via
    the io_uring engine in fio. This was on a VM running 5.2-rc5 and the
    latest version of fio. The issue occurs for both null_blk and fake NVMe
    drives. I have not tested bare metal or real NVMe SSDs. The fio script
    used is given below.
    
    [io_uring]
    time_based=1
    runtime=60
    filename=/dev/nvme2n1 (note /dev/nullb0 also fails)
    ioengine=io_uring
    bs=4k
    rw=readwrite
    direct=1
    fixedbufs=1
    sqthread_poll=1
    sqthread_poll_cpu=0
    
    general protection fault: 0000 [#1] SMP PTI
    CPU: 0 PID: 872 Comm: io_uring-sq Not tainted 5.2.0-rc5-cpacket-io-uring #1
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
    RIP: 0010:fput_many+0x7/0x90
    Code: 01 48 85 ff 74 17 55 48 89 e5 53 48 8b 1f e8 a0 f9 ff ff 48 85 db 48 89 df 75 f0 5b 5d f3 c3 0f 1f 40 00 0f 1f 44 00 00 89 f6 <f0> 48 29 77 38 74 01 c3 55 48 89 e5 53 48 89 fb 65 48 \
    
    RSP: 0018:ffffadeb817ebc50 EFLAGS: 00010246
    RAX: 0000000000000004 RBX: ffff8f46ad477480 RCX: 0000000000001805
    RDX: 0000000000000000 RSI: 0000000000000001 RDI: f18b51b9a39552b5
    RBP: ffffadeb817ebc58 R08: ffff8f46b7a318c0 R09: 000000000000015d
    R10: ffffadeb817ebce8 R11: 0000000000000020 R12: ffff8f46ad4cd000
    R13: 00000000fffffff7 R14: ffffadeb817ebe30 R15: 0000000000000004
    FS:  0000000000000000(0000) GS:ffff8f46b7a00000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 000055828f0bbbf0 CR3: 0000000232176004 CR4: 00000000003606f0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    Call Trace:
     ? fput+0x13/0x20
     io_free_req+0x20/0x40
     io_put_req+0x1b/0x20
     io_submit_sqe+0x40a/0x680
     ? __switch_to_asm+0x34/0x70
     ? __switch_to_asm+0x40/0x70
     io_submit_sqes+0xb9/0x160
     ? io_submit_sqes+0xb9/0x160
     ? __switch_to_asm+0x40/0x70
     ? __switch_to_asm+0x34/0x70
     ? __schedule+0x3f2/0x6a0
     ? __switch_to_asm+0x34/0x70
     io_sq_thread+0x1af/0x470
     ? __switch_to_asm+0x34/0x70
     ? wait_woken+0x80/0x80
     ? __switch_to+0x85/0x410
     ? __switch_to_asm+0x40/0x70
     ? __switch_to_asm+0x34/0x70
     ? __schedule+0x3f2/0x6a0
     kthread+0x105/0x140
     ? io_submit_sqes+0x160/0x160
     ? kthread+0x105/0x140
     ? io_submit_sqes+0x160/0x160
     ? kthread_destroy_worker+0x50/0x50
     ret_from_fork+0x35/0x40
    
    which occurs because using a kernel side submission thread isn't valid
    without using fixed files (registered through io_uring_register()). This
    causes io_uring to put the request after logging an error, but before
    the file field is set in the request. If it happens to be non-zero, we
    attempt to fput() garbage.
    
    Fix this by ensuring that req->file is initialized when the request is
    allocated.
    
    Cc: stable@vger.kernel.org # 5.1+
    Reported-by: Stephen Bates <sbates@raithlin.com>
    Tested-by: Stephen Bates <sbates@raithlin.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 25df4ce382c963f0c28fefd0bcbd49bd44ce9fdc
Author: zhangyi (F) <yi.zhang@huawei.com>
Date:   Wed Jun 5 21:27:08 2019 +0800

    dm log writes: make sure super sector log updates are written in order
    
    commit 211ad4b733037f66f9be0a79eade3da7ab11cbb8 upstream.
    
    Currently, although we submit super bios in order (and super.nr_entries
    is incremented by each logged entry), submit_bio() is async so each
    super sector may not be written to log device in order and then the
    final nr_entries may be smaller than it should be.
    
    This problem can be reproduced by the xfstests generic/455 with ext4:
    
      QA output created by 455
     -Silence is golden
     +mark 'end' does not exist
    
    Fix this by serializing submission of super sectors to make sure each
    is written to the log disk in order.
    
    Fixes: 0e9cebe724597 ("dm: add log writes target")
    Cc: stable@vger.kernel.org
    Signed-off-by: zhangyi (F) <yi.zhang@huawei.com>
    Suggested-by: Josef Bacik <josef@toxicpanda.com>
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6e17b11ffedd6e935c507c39b92e9c8ddb88c3c9
Author: Gen Zhang <blackgod016574@gmail.com>
Date:   Wed May 29 09:33:20 2019 +0800

    dm init: fix incorrect uses of kstrndup()
    
    commit dec7e6494e1aea6bf676223da3429cd17ce0af79 upstream.
    
    Fix 2 kstrndup() calls with incorrect argument order.
    
    Fixes: 6bbc923dfcf5 ("dm: add support to directly boot to a mapped device")
    Cc: stable@vger.kernel.org # v5.1
    Signed-off-by: Gen Zhang <blackgod016574@gmail.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e3d6fe0b33dfa707a37d0cd750bb2d191c3a64dc
Author: Huang Ying <ying.huang@intel.com>
Date:   Fri Jun 28 12:07:18 2019 -0700

    mm, swap: fix THP swap out
    
    commit 1a5f439c7c02837d943e528d46501564d4226757 upstream.
    
    0-Day test system reported some OOM regressions for several THP
    (Transparent Huge Page) swap test cases.  These regressions are bisected
    to 6861428921b5 ("block: always define BIO_MAX_PAGES as 256").  In the
    commit, BIO_MAX_PAGES is set to 256 even when THP swap is enabled.  So the
    bio_alloc(gfp_flags, 512) in get_swap_bio() may fail when swapping out
    THP.  That causes the OOM.
    
    As in the patch description of 6861428921b5 ("block: always define
    BIO_MAX_PAGES as 256"), THP swap should use multi-page bvec to write THP
    to swap space.  So the issue is fixed via doing that in get_swap_bio().
    
    BTW: I remember I have checked the THP swap code when 6861428921b5
    ("block: always define BIO_MAX_PAGES as 256") was merged, and thought the
    THP swap code needn't to be changed.  But apparently, I was wrong.  I
    should have done this at that time.
    
    Link: http://lkml.kernel.org/r/20190624075515.31040-1-ying.huang@intel.com
    Fixes: 6861428921b5 ("block: always define BIO_MAX_PAGES as 256")
    Signed-off-by: "Huang, Ying" <ying.huang@intel.com>
    Reviewed-by: Ming Lei <ming.lei@redhat.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 00553cdd3377b0ff11a0d4e39e0b824049eab013
Author: Colin Ian King <colin.king@canonical.com>
Date:   Fri Jun 28 12:07:05 2019 -0700

    mm/page_idle.c: fix oops because end_pfn is larger than max_pfn
    
    commit 7298e3b0a149c91323b3205d325e942c3b3b9ef6 upstream.
    
    Currently the calcuation of end_pfn can round up the pfn number to more
    than the actual maximum number of pfns, causing an Oops.  Fix this by
    ensuring end_pfn is never more than max_pfn.
    
    This can be easily triggered when on systems where the end_pfn gets
    rounded up to more than max_pfn using the idle-page stress-ng stress test:
    
    sudo stress-ng --idle-page 0
    
      BUG: unable to handle kernel paging request at 00000000000020d8
      #PF error: [normal kernel read fault]
      PGD 0 P4D 0
      Oops: 0000 [#1] SMP PTI
      CPU: 1 PID: 11039 Comm: stress-ng-idle- Not tainted 5.0.0-5-generic #6-Ubuntu
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014
      RIP: 0010:page_idle_get_page+0xc8/0x1a0
      Code: 0f b1 0a 75 7d 48 8b 03 48 89 c2 48 c1 e8 33 83 e0 07 48 c1 ea 36 48 8d 0c 40 4c 8d 24 88 49 c1 e4 07 4c 03 24 d5 00 89 c3 be <49> 8b 44 24 58 48 8d b8 80 a1 02 00 e8 07 d5 77 00 48 8b 53 08 48
      RSP: 0018:ffffafd7c672fde8 EFLAGS: 00010202
      RAX: 0000000000000005 RBX: ffffe36341fff700 RCX: 000000000000000f
      RDX: 0000000000000284 RSI: 0000000000000275 RDI: 0000000001fff700
      RBP: ffffafd7c672fe00 R08: ffffa0bc34056410 R09: 0000000000000276
      R10: ffffa0bc754e9b40 R11: ffffa0bc330f6400 R12: 0000000000002080
      R13: ffffe36341fff700 R14: 0000000000080000 R15: ffffa0bc330f6400
      FS: 00007f0ec1ea5740(0000) GS:ffffa0bc7db00000(0000) knlGS:0000000000000000
      CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      CR2: 00000000000020d8 CR3: 0000000077d68000 CR4: 00000000000006e0
      Call Trace:
        page_idle_bitmap_write+0x8c/0x140
        sysfs_kf_bin_write+0x5c/0x70
        kernfs_fop_write+0x12e/0x1b0
        __vfs_write+0x1b/0x40
        vfs_write+0xab/0x1b0
        ksys_write+0x55/0xc0
        __x64_sys_write+0x1a/0x20
        do_syscall_64+0x5a/0x110
        entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Link: http://lkml.kernel.org/r/20190618124352.28307-1-colin.king@canonical.com
    Fixes: 33c3fc71c8cf ("mm: introduce idle page tracking")
    Signed-off-by: Colin Ian King <colin.king@canonical.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Stephen Rothwell <sfr@canb.auug.org.au>
    Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 59d44003b0a91800abc17bfe4fdb00682bfdc364
Author: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Date:   Fri Jun 28 12:06:56 2019 -0700

    mm: hugetlb: soft-offline: dissolve_free_huge_page() return zero on !PageHuge
    
    commit faf53def3b143df11062d87c12afe6afeb6f8cc7 upstream.
    
    madvise(MADV_SOFT_OFFLINE) often returns -EBUSY when calling soft offline
    for hugepages with overcommitting enabled.  That was caused by the
    suboptimal code in current soft-offline code.  See the following part:
    
        ret = migrate_pages(&pagelist, new_page, NULL, MPOL_MF_MOVE_ALL,
                                MIGRATE_SYNC, MR_MEMORY_FAILURE);
        if (ret) {
                ...
        } else {
                /*
                 * We set PG_hwpoison only when the migration source hugepage
                 * was successfully dissolved, because otherwise hwpoisoned
                 * hugepage remains on free hugepage list, then userspace will
                 * find it as SIGBUS by allocation failure. That's not expected
                 * in soft-offlining.
                 */
                ret = dissolve_free_huge_page(page);
                if (!ret) {
                        if (set_hwpoison_free_buddy_page(page))
                                num_poisoned_pages_inc();
                }
        }
        return ret;
    
    Here dissolve_free_huge_page() returns -EBUSY if the migration source page
    was freed into buddy in migrate_pages(), but even in that case we actually
    has a chance that set_hwpoison_free_buddy_page() succeeds.  So that means
    current code gives up offlining too early now.
    
    dissolve_free_huge_page() checks that a given hugepage is suitable for
    dissolving, where we should return success for !PageHuge() case because
    the given hugepage is considered as already dissolved.
    
    This change also affects other callers of dissolve_free_huge_page(), which
    are cleaned up together.
    
    [n-horiguchi@ah.jp.nec.com: v3]
      Link: http://lkml.kernel.org/r/1560761476-4651-3-git-send-email-n-horiguchi@ah.jp.nec.comLink: http://lkml.kernel.org/r/1560154686-18497-3-git-send-email-n-horiguchi@ah.jp.nec.com
    Fixes: 6bc9b56433b76 ("mm: fix race on soft-offlining")
    Signed-off-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Reported-by: Chen, Jerry T <jerry.t.chen@intel.com>
    Tested-by: Chen, Jerry T <jerry.t.chen@intel.com>
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Reviewed-by: Oscar Salvador <osalvador@suse.de>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Xishi Qiu <xishi.qiuxishi@alibaba-inc.com>
    Cc: "Chen, Jerry T" <jerry.t.chen@intel.com>
    Cc: "Zhuo, Qiuxu" <qiuxu.zhuo@intel.com>
    Cc: <stable@vger.kernel.org>    [4.19+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 897b17e012adce36976ce76f1ca36f2831927159
Author: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Date:   Fri Jun 28 12:06:53 2019 -0700

    mm: soft-offline: return -EBUSY if set_hwpoison_free_buddy_page() fails
    
    commit b38e5962f8ed0d2a2b28a887fc2221f7f41db119 upstream.
    
    The pass/fail of soft offline should be judged by checking whether the
    raw error page was finally contained or not (i.e.  the result of
    set_hwpoison_free_buddy_page()), but current code do not work like
    that.  It might lead us to misjudge the test result when
    set_hwpoison_free_buddy_page() fails.
    
    Without this fix, there are cases where madvise(MADV_SOFT_OFFLINE) may
    not offline the original page and will not return an error.
    
    Link: http://lkml.kernel.org/r/1560154686-18497-2-git-send-email-n-horiguchi@ah.jp.nec.com
    Signed-off-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Fixes: 6bc9b56433b76 ("mm: fix race on soft-offlining")
    Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
    Reviewed-by: Oscar Salvador <osalvador@suse.de>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Xishi Qiu <xishi.qiuxishi@alibaba-inc.com>
    Cc: "Chen, Jerry T" <jerry.t.chen@intel.com>
    Cc: "Zhuo, Qiuxu" <qiuxu.zhuo@intel.com>
    Cc: <stable@vger.kernel.org>    [4.19+]
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec73bed9027f26336ab9f4a40970324e42e478a5
Author: Ville Syrjälä <ville.syrjala@linux.intel.com>
Date:   Wed Mar 27 12:13:21 2019 +0200

    drm/i915: Skip modeset for cdclk changes if possible
    
    commit 59f9e9cab3a1e6762fb707d0d829b982930f1349 upstream.
    
    If we have only a single active pipe and the cdclk change only requires
    the cd2x divider to be updated bxt+ can do the update with forcing a full
    modeset on the pipe. Try to hook that up.
    
    v2:
    - Wait for vblank after an optimized CDCLK change.
    - Avoid optimization if the pipe needs a modeset (or was disabled).
    - Split CDCLK change to a pre/post plane update step.
    v3:
    - Use correct version of CDCLK state as old state. (Ville)
    - Remove unused intel_cdclk_can_skip_modeset()
    v4:
    - For consistency call intel_set_cdclk_post_plane_update() only during
      modesets (and not fastsets).
    v5:
    - Remove the logic to update the CD2X divider on-the-fly on ICL, since
      only a divider of 1 is supported there. Clint also noticed that the
      pipe select bits in CDCLK_CTL are oddly defined on ICL, it's not clear
      yet whether that's only an error in the specification.
    
    Signed-off-by: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Signed-off-by: Abhay Kumar <abhay.kumar@intel.com>
    Tested-by: Abhay Kumar <abhay.kumar@intel.com>
    Signed-off-by: Imre Deak <imre.deak@intel.com>
    Reviewed-by: Clint Taylor <Clinton.A.Taylor@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190327101321.3095-1-imre.deak@intel.com
    Signed-off-by: Jian-Hong Pan <jian-hong@endlessm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 994f9ddbd1a5fbfea297b5760f862d3e866e1149
Author: Imre Deak <imre.deak@intel.com>
Date:   Wed Mar 20 15:54:38 2019 +0200

    drm/i915: Remove redundant store of logical CDCLK state
    
    commit 2b21dfbeee725778daed2c3dd45a3fc808176feb upstream.
    
    We copied the original state into the atomic state already earlier in
    the function, so no need to do it a second time.
    
    Cc: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Signed-off-by: Imre Deak <imre.deak@intel.com>
    Reviewed-by: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190320135439.12201-3-imre.deak@intel.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Jian-Hong Pan <jian-hong@endlessm.com>

commit ca2d66597e7456c0cbfd68067db14239730a4fac
Author: Imre Deak <imre.deak@intel.com>
Date:   Wed Mar 20 15:54:37 2019 +0200

    drm/i915: Save the old CDCLK atomic state
    
    commit 48d9f87ddd2108663fd866b254e05d422243cc56 upstream.
    
    The old state will be needed by an upcoming patch to determine if the
    commit increases or decreases CDCLK, so move the old state to the atomic
    state (while keeping the new one in dev_priv). cdclk.logical and
    cdclk.actual in the atomic state isn't used atm anywhere after the
    atomic check phase, so this should be safe.
    
    v2:
    - Use swap() instead of opencoding it. (Ville)
    
    Suggested-by: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Cc: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Signed-off-by: Imre Deak <imre.deak@intel.com>
    Reviewed-by: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190320135439.12201-2-imre.deak@intel.com
    Signed-off-by: Jian-Hong Pan <jian-hong@endlessm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 64e3d1c9f0e8001d0bd5ecedc0641b88755d255c
Author: Ville Syrjälä <ville.syrjala@linux.intel.com>
Date:   Wed Mar 20 15:54:36 2019 +0200

    drm/i915: Force 2*96 MHz cdclk on glk/cnl when audio power is enabled
    
    commit 905801fe72377b4dc53c6e13eea1a91c6a4aa0c4 upstream.
    
    CDCLK has to be at least twice the BLCK regardless of audio. Audio
    driver has to probe using this hook and increase the clock even in
    absence of any display.
    
    v2: Use atomic refcount for get_power, put_power so that we can
        call each once(Abhay).
    v3: Reset power well 2 to avoid any transaction on iDisp link
        during cdclk change(Abhay).
    v4: Remove Power well 2 reset workaround(Ville).
    v5: Remove unwanted Power well 2 register defined in v4(Abhay).
    v6:
    - Use a dedicated flag instead of state->modeset for min CDCLK changes
    - Make get/put audio power domain symmetric
    - Rebased on top of intel_wakeref tracking changes.
    
    Signed-off-by: Ville Syrjälä <ville.syrjala@linux.intel.com>
    Signed-off-by: Abhay Kumar <abhay.kumar@intel.com>
    Tested-by: Abhay Kumar <abhay.kumar@intel.com>
    Signed-off-by: Imre Deak <imre.deak@intel.com>
    Reviewed-by: Clint Taylor <Clinton.A.Taylor@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190320135439.12201-1-imre.deak@intel.com
    Cc: <stable@vger.kernel.org> # 5.1.x
    Signed-off-by: Jian-Hong Pan <jian-hong@endlessm.com>
    Buglink: https://bugzilla.kernel.org/show_bug.cgi?id=203623
    Buglink: https://bugs.freedesktop.org/show_bug.cgi?id=110916
    Link: https://www.spinics.net/lists/stable/msg310910.html
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 261b9429c577f913d3a5c60aa914901ed699e97a
Author: Dinh Nguyen <dinguyen@kernel.org>
Date:   Fri Jun 7 10:12:46 2019 -0500

    clk: socfpga: stratix10: fix divider entry for the emac clocks
    
    commit 74684cce5ebd567b01e9bc0e9a1945c70a32f32f upstream.
    
    The fixed dividers for the emac clocks should be 2 not 4.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Dinh Nguyen <dinguyen@kernel.org>
    Signed-off-by: Stephen Boyd <sboyd@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 87cdb0596c561b150683cdad0f9bdf0faa4d7424
Author: Jon Hunter <jonathanh@nvidia.com>
Date:   Wed Jun 5 15:01:39 2019 +0100

    clk: tegra210: Fix default rates for HDA clocks
    
    commit 9caec6620f25b6d15646bbdb93062c872ba3b56f upstream.
    
    Currently the default clock rates for the HDA and HDA2CODEC_2X clocks
    are both 19.2MHz. However, the default rates for these clocks should
    actually be 51MHz and 48MHz, respectively. The current clock settings
    results in a distorted output during audio playback. Correct the default
    clock rates for these clocks by specifying them in the clock init table
    for Tegra210.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Jon Hunter <jonathanh@nvidia.com>
    Acked-by: Thierry Reding <treding@nvidia.com>
    Signed-off-by: Stephen Boyd <sboyd@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ecace84283e77c2ac21ba0ef398fc433636fe686
Author: Jann Horn <jannh@google.com>
Date:   Fri Jun 28 12:06:46 2019 -0700

    fs/binfmt_flat.c: make load_flat_shared_library() work
    
    commit 867bfa4a5fcee66f2b25639acae718e8b28b25a5 upstream.
    
    load_flat_shared_library() is broken: It only calls load_flat_file() if
    prepare_binprm() returns zero, but prepare_binprm() returns the number of
    bytes read - so this only happens if the file is empty.
    
    Instead, call into load_flat_file() if the number of bytes read is
    non-negative. (Even if the number of bytes is zero - in that case,
    load_flat_file() will see nullbytes and return a nice -ENOEXEC.)
    
    In addition, remove the code related to bprm creds and stop using
    prepare_binprm() - this code is loading a library, not a main executable,
    and it only actually uses the members "buf", "file" and "filename" of the
    linux_binprm struct. Instead, call kernel_read() directly.
    
    Link: http://lkml.kernel.org/r/20190524201817.16509-1-jannh@google.com
    Fixes: 287980e49ffc ("remove lots of IS_ERR_VALUE abuses")
    Signed-off-by: Jann Horn <jannh@google.com>
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Greg Ungerer <gerg@linux-m68k.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 41ceb21b7dc18e9369e9b903b46b8334744f5cfb
Author: zhong jiang <zhongjiang@huawei.com>
Date:   Fri Jun 28 12:06:43 2019 -0700

    mm/mempolicy.c: fix an incorrect rebind node in mpol_rebind_nodemask
    
    commit 29b190fa774dd1b72a1a6f19687d55dc72ea83be upstream.
    
    mpol_rebind_nodemask() is called for MPOL_BIND and MPOL_INTERLEAVE
    mempoclicies when the tasks's cpuset's mems_allowed changes.  For
    policies created without MPOL_F_STATIC_NODES or MPOL_F_RELATIVE_NODES,
    it works by remapping the policy's allowed nodes (stored in v.nodes)
    using the previous value of mems_allowed (stored in
    w.cpuset_mems_allowed) as the domain of map and the new mems_allowed
    (passed as nodes) as the range of the map (see the comment of
    bitmap_remap() for details).
    
    The result of remapping is stored back as policy's nodemask in v.nodes,
    and the new value of mems_allowed should be stored in
    w.cpuset_mems_allowed to facilitate the next rebind, if it happens.
    
    However, 213980c0f23b ("mm, mempolicy: simplify rebinding mempolicies
    when updating cpusets") introduced a bug where the result of remapping
    is stored in w.cpuset_mems_allowed instead.  Thus, a mempolicy's
    allowed nodes can evolve in an unexpected way after a series of
    rebinding due to cpuset mems_allowed changes, possibly binding to a
    wrong node or a smaller number of nodes which may e.g.  overload them.
    This patch fixes the bug so rebinding again works as intended.
    
    [vbabka@suse.cz: new changlog]
      Link: http://lkml.kernel.org/r/ef6a69c6-c052-b067-8f2c-9d615c619bb9@suse.cz
    Link: http://lkml.kernel.org/r/1558768043-23184-1-git-send-email-zhongjiang@huawei.com
    Fixes: 213980c0f23b ("mm, mempolicy: simplify rebinding mempolicies when updating cpusets")
    Signed-off-by: zhong jiang <zhongjiang@huawei.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Oscar Salvador <osalvador@suse.de>
    Cc: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Ralph Campbell <rcampbell@nvidia.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f1fb34c22786829fb58564d36609a05483ea9002
Author: John Ogness <john.ogness@linutronix.de>
Date:   Fri Jun 28 12:06:40 2019 -0700

    fs/proc/array.c: allow reporting eip/esp for all coredumping threads
    
    commit cb8f381f1613cafe3aec30809991cd56e7135d92 upstream.
    
    0a1eb2d474ed ("fs/proc: Stop reporting eip and esp in /proc/PID/stat")
    stopped reporting eip/esp and fd7d56270b52 ("fs/proc: Report eip/esp in
    /prod/PID/stat for coredumping") reintroduced the feature to fix a
    regression with userspace core dump handlers (such as minicoredumper).
    
    Because PF_DUMPCORE is only set for the primary thread, this didn't fix
    the original problem for secondary threads.  Allow reporting the eip/esp
    for all threads by checking for PF_EXITING as well.  This is set for all
    the other threads when they are killed.  coredump_wait() waits for all the
    tasks to become inactive before proceeding to invoke a core dumper.
    
    Link: http://lkml.kernel.org/r/87y32p7i7a.fsf@linutronix.de
    Link: http://lkml.kernel.org/r/20190522161614.628-1-jlu@pengutronix.de
    Fixes: fd7d56270b526ca3 ("fs/proc: Report eip/esp in /prod/PID/stat for coredumping")
    Signed-off-by: John Ogness <john.ogness@linutronix.de>
    Reported-by: Jan Luebbe <jlu@pengutronix.de>
    Tested-by: Jan Luebbe <jlu@pengutronix.de>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4d750447128f20c74fb89b3bdff8fc7fb7ccdec9
Author: Bjørn Mork <bjorn@mork.no>
Date:   Mon Jun 24 18:45:11 2019 +0200

    qmi_wwan: Fix out-of-bounds read
    
    [ Upstream commit 904d88d743b0c94092c5117955eab695df8109e8 ]
    
    The syzbot reported
    
     Call Trace:
      __dump_stack lib/dump_stack.c:77 [inline]
      dump_stack+0xca/0x13e lib/dump_stack.c:113
      print_address_description+0x67/0x231 mm/kasan/report.c:188
      __kasan_report.cold+0x1a/0x32 mm/kasan/report.c:317
      kasan_report+0xe/0x20 mm/kasan/common.c:614
      qmi_wwan_probe+0x342/0x360 drivers/net/usb/qmi_wwan.c:1417
      usb_probe_interface+0x305/0x7a0 drivers/usb/core/driver.c:361
      really_probe+0x281/0x660 drivers/base/dd.c:509
      driver_probe_device+0x104/0x210 drivers/base/dd.c:670
      __device_attach_driver+0x1c2/0x220 drivers/base/dd.c:777
      bus_for_each_drv+0x15c/0x1e0 drivers/base/bus.c:454
    
    Caused by too many confusing indirections and casts.
    id->driver_info is a pointer stored in a long.  We want the
    pointer here, not the address of it.
    
    Thanks-to: Hillf Danton <hdanton@sina.com>
    Reported-by: syzbot+b68605d7fadd21510de1@syzkaller.appspotmail.com
    Cc: Kristian Evensen <kristian.evensen@gmail.com>
    Fixes: e4bf63482c30 ("qmi_wwan: Add quirk for Quectel dynamic config")
    Signed-off-by: Bjørn Mork <bjorn@mork.no>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0d1d924485133dca882e8fcebc9003acd7188724
Author: Sasha Levin <sashal@kernel.org>
Date:   Tue Jun 25 07:36:40 2019 -0400

    Revert "x86/uaccess, ftrace: Fix ftrace_likely_update() vs. SMAP"
    
    This reverts commit b65b70ba068b7cdbfeb65eee87cce84a74618603, which was
    upstream commit 4a6c91fbdef846ec7250b82f2eeeb87ac5f18cf9.
    
    On Tue, Jun 25, 2019 at 09:39:45AM +0200, Sebastian Andrzej Siewior wrote:
    >Please backport commit e74deb11931ff682b59d5b9d387f7115f689698e to
    >stable _or_ revert the backport of commit 4a6c91fbdef84 ("x86/uaccess,
    >ftrace: Fix ftrace_likely_update() vs. SMAP"). It uses
    >user_access_{save|restore}() which has been introduced in the following
    >commit.
    
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 507ad93ad22b58d1690c65851f4b2b7dd9965ef8
Author: Nathan Chancellor <natechancellor@gmail.com>
Date:   Tue Jun 11 10:19:32 2019 -0700

    arm64: Don't unconditionally add -Wno-psabi to KBUILD_CFLAGS
    
    commit fa63da2ab046b885a7f70291aafc4e8ce015429b upstream.
    
    This is a GCC only option, which warns about ABI changes within GCC, so
    unconditionally adding it breaks Clang with tons of:
    
    warning: unknown warning option '-Wno-psabi' [-Wunknown-warning-option]
    
    and link time failures:
    
    ld.lld: error: undefined symbol: __efistub___stack_chk_guard
    >>> referenced by arm-stub.c:73
    (/home/nathan/cbl/linux/drivers/firmware/efi/libstub/arm-stub.c:73)
    >>>               arm-stub.stub.o:(__efistub_install_memreserve_table)
    in archive ./drivers/firmware/efi/libstub/lib.a
    
    These failures come from the lack of -fno-stack-protector, which is
    added via cc-option in drivers/firmware/efi/libstub/Makefile. When an
    unknown flag is added to KBUILD_CFLAGS, clang will noisily warn that it
    is ignoring the option like above, unlike gcc, who will just error.
    
    $ echo "int main() { return 0; }" > tmp.c
    
    $ clang -Wno-psabi tmp.c; echo $?
    warning: unknown warning option '-Wno-psabi' [-Wunknown-warning-option]
    1 warning generated.
    0
    
    $ gcc -Wsometimes-uninitialized tmp.c; echo $?
    gcc: error: unrecognized command line option
    ‘-Wsometimes-uninitialized’; did you mean ‘-Wmaybe-uninitialized’?
    1
    
    For cc-option to work properly with clang and behave like gcc, -Werror
    is needed, which was done in commit c3f0d0bc5b01 ("kbuild, LLVMLinux:
    Add -Werror to cc-option to support clang").
    
    $ clang -Werror -Wno-psabi tmp.c; echo $?
    error: unknown warning option '-Wno-psabi'
    [-Werror,-Wunknown-warning-option]
    1
    
    As a consequence of this, when an unknown flag is unconditionally added
    to KBUILD_CFLAGS, it will cause cc-option to always fail and those flags
    will never get added:
    
    $ clang -Werror -Wno-psabi -fno-stack-protector tmp.c; echo $?
    error: unknown warning option '-Wno-psabi'
    [-Werror,-Wunknown-warning-option]
    1
    
    This can be seen when compiling the whole kernel as some warnings that
    are normally disabled (see below) show up. The full list of flags
    missing from drivers/firmware/efi/libstub are the following (gathered
    from diffing .arm64-stub.o.cmd):
    
    -fno-delete-null-pointer-checks
    -Wno-address-of-packed-member
    -Wframe-larger-than=2048
    -Wno-unused-const-variable
    -fno-strict-overflow
    -fno-merge-all-constants
    -fno-stack-check
    -Werror=date-time
    -Werror=incompatible-pointer-types
    -ffreestanding
    -fno-stack-protector
    
    Use cc-disable-warning so that it gets disabled for GCC and does nothing
    for Clang.
    
    Fixes: ebcc5928c5d9 ("arm64: Silence gcc warnings about arch ABI drift")
    Link: https://github.com/ClangBuiltLinux/linux/issues/511
    Reported-by: Qian Cai <cai@lca.pw>
    Acked-by: Dave Martin <Dave.Martin@arm.com>
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
