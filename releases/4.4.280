commit 78806dfb3f529da96c390c04605d9d2c793f0af9
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Aug 10 17:39:42 2021 +0200

    Linux 4.4.280
    
    Link: https://lore.kernel.org/r/20210808072217.322468704@linuxfoundation.org
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Tested-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a75966d76de46cb6af37921fa71bc99659fd946f
Author: Anna-Maria Gleixner <anna-maria@linutronix.de>
Date:   Mon Aug 2 21:46:24 2021 +0800

    rcu: Update documentation of rcu_read_unlock()
    
    [ Upstream commit ec84b27f9b3b569f9235413d1945a2006b97b0aa ]
    
    Since commit b4abf91047cf ("rtmutex: Make wait_lock irq safe") the
    explanation in rcu_read_unlock() documentation about irq unsafe rtmutex
    wait_lock is no longer valid.
    
    Remove it to prevent kernel developers reading the documentation to rely on
    it.
    
    Suggested-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Anna-Maria Gleixner <anna-maria@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: bigeasy@linutronix.de
    Link: https://lkml.kernel.org/r/20180525090507.22248-2-anna-maria@linutronix.de
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 66edc0dded9863962505c42c0f726db97204ed4e
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 2 21:46:23 2021 +0800

    futex,rt_mutex: Fix rt_mutex_cleanup_proxy_lock()
    
    [ Upstream commit 04dc1b2fff4e96cb4142227fbdc63c8871ad4ed9 ]
    
    Markus reported that the glibc/nptl/tst-robustpi8 test was failing after
    commit:
    
      cfafcd117da0 ("futex: Rework futex_lock_pi() to use rt_mutex_*_proxy_lock()")
    
    The following trace shows the problem:
    
     ld-linux-x86-64-2161  [019] ....   410.760971: SyS_futex: 00007ffbeb76b028: 80000875  op=FUTEX_LOCK_PI
     ld-linux-x86-64-2161  [019] ...1   410.760972: lock_pi_update_atomic: 00007ffbeb76b028: curval=80000875 uval=80000875 newval=80000875 ret=0
     ld-linux-x86-64-2165  [011] ....   410.760978: SyS_futex: 00007ffbeb76b028: 80000875  op=FUTEX_UNLOCK_PI
     ld-linux-x86-64-2165  [011] d..1   410.760979: do_futex: 00007ffbeb76b028: curval=80000875 uval=80000875 newval=80000871 ret=0
     ld-linux-x86-64-2165  [011] ....   410.760980: SyS_futex: 00007ffbeb76b028: 80000871 ret=0000
     ld-linux-x86-64-2161  [019] ....   410.760980: SyS_futex: 00007ffbeb76b028: 80000871 ret=ETIMEDOUT
    
    Task 2165 does an UNLOCK_PI, assigning the lock to the waiter task 2161
    which then returns with -ETIMEDOUT. That wrecks the lock state, because now
    the owner isn't aware it acquired the lock and removes the pending robust
    list entry.
    
    If 2161 is killed, the robust list will not clear out this futex and the
    subsequent acquire on this futex will then (correctly) result in -ESRCH
    which is unexpected by glibc, triggers an internal assertion and dies.
    
    Task 2161                       Task 2165
    
    rt_mutex_wait_proxy_lock()
       timeout();
       /* T2161 is still queued in  the waiter list */
       return -ETIMEDOUT;
    
                                    futex_unlock_pi()
                                    spin_lock(hb->lock);
                                    rtmutex_unlock()
                                      remove_rtmutex_waiter(T2161);
                                       mark_lock_available();
                                    /* Make the next waiter owner of the user space side */
                                    futex_uval = 2161;
                                    spin_unlock(hb->lock);
    spin_lock(hb->lock);
    rt_mutex_cleanup_proxy_lock()
      if (rtmutex_owner() !== current)
         ...
         return FAIL;
    ....
    return -ETIMEOUT;
    
    This means that rt_mutex_cleanup_proxy_lock() needs to call
    try_to_take_rt_mutex() so it can take over the rtmutex correctly which was
    assigned by the waker. If the rtmutex is owned by some other task then this
    call is harmless and just confirmes that the waiter is not able to acquire
    it.
    
    While there, fix what looks like a merge error which resulted in
    rt_mutex_cleanup_proxy_lock() having two calls to
    fixup_rt_mutex_waiters() and rt_mutex_wait_proxy_lock() not having any.
    Both should have one, since both potentially touch the waiter list.
    
    Fixes: 38d589f2fd08 ("futex,rt_mutex: Restructure rt_mutex_finish_proxy_lock()")
    Reported-by: Markus Trippelsdorf <markus@trippelsdorf.de>
    Bug-Spotted-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Florian Weimer <fweimer@redhat.com>
    Cc: Darren Hart <dvhart@infradead.org>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Markus Trippelsdorf <markus@trippelsdorf.de>
    Link: http://lkml.kernel.org/r/20170519154850.mlomgdsd26drq5j6@hirez.programming.kicks-ass.net
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9b8d748d4bb027f9c2aa7ce03801d270dc0819e5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 2 21:46:22 2021 +0800

    futex: Avoid freeing an active timer
    
    [ Upstream commit 97181f9bd57405b879403763284537e27d46963d ]
    
    Alexander reported a hrtimer debug_object splat:
    
      ODEBUG: free active (active state 0) object type: hrtimer hint: hrtimer_wakeup (kernel/time/hrtimer.c:1423)
    
      debug_object_free (lib/debugobjects.c:603)
      destroy_hrtimer_on_stack (kernel/time/hrtimer.c:427)
      futex_lock_pi (kernel/futex.c:2740)
      do_futex (kernel/futex.c:3399)
      SyS_futex (kernel/futex.c:3447 kernel/futex.c:3415)
      do_syscall_64 (arch/x86/entry/common.c:284)
      entry_SYSCALL64_slow_path (arch/x86/entry/entry_64.S:249)
    
    Which was caused by commit:
    
      cfafcd117da0 ("futex: Rework futex_lock_pi() to use rt_mutex_*_proxy_lock()")
    
    ... losing the hrtimer_cancel() in the shuffle. Where previously the
    hrtimer_cancel() was done by rt_mutex_slowlock() we now need to do it
    manually.
    
    Reported-by: Alexander Levin <alexander.levin@verizon.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Fixes: cfafcd117da0 ("futex: Rework futex_lock_pi() to use rt_mutex_*_proxy_lock()")
    Link: http://lkml.kernel.org/r/alpine.DEB.2.20.1704101802370.2906@nanos
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6255b40352498beb0309c99367542302711231e4
Author: Mike Galbraith <efault@gmx.de>
Date:   Mon Aug 2 21:46:21 2021 +0800

    futex: Handle transient "ownerless" rtmutex state correctly
    
    [ Upstream commit 9f5d1c336a10c0d24e83e40b4c1b9539f7dba627 ]
    
    Gratian managed to trigger the BUG_ON(!newowner) in fixup_pi_state_owner().
    This is one possible chain of events leading to this:
    
    Task Prio       Operation
    T1   120        lock(F)
    T2   120        lock(F)   -> blocks (top waiter)
    T3   50 (RT)    lock(F)   -> boosts T1 and blocks (new top waiter)
    XX              timeout/  -> wakes T2
                    signal
    T1   50         unlock(F) -> wakes T3 (rtmutex->owner == NULL, waiter bit is set)
    T2   120        cleanup   -> try_to_take_mutex() fails because T3 is the top waiter
                                 and the lower priority T2 cannot steal the lock.
                              -> fixup_pi_state_owner() sees newowner == NULL -> BUG_ON()
    
    The comment states that this is invalid and rt_mutex_real_owner() must
    return a non NULL owner when the trylock failed, but in case of a queued
    and woken up waiter rt_mutex_real_owner() == NULL is a valid transient
    state. The higher priority waiter has simply not yet managed to take over
    the rtmutex.
    
    The BUG_ON() is therefore wrong and this is just another retry condition in
    fixup_pi_state_owner().
    
    Drop the locks, so that T3 can make progress, and then try the fixup again.
    
    Gratian provided a great analysis, traces and a reproducer. The analysis is
    to the point, but it confused the hell out of that tglx dude who had to
    page in all the futex horrors again. Condensed version is above.
    
    [ tglx: Wrote comment and changelog ]
    
    Fixes: c1e2f0eaf015 ("futex: Avoid violating the 10th rule of futex")
    Reported-by: Gratian Crisan <gratian.crisan@ni.com>
    Signed-off-by: Mike Galbraith <efault@gmx.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/87a6w6x7bb.fsf@ni.com
    Link: https://lore.kernel.org/r/87sg9pkvf7.fsf@nanos.tec.linutronix.de
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6ef8ca1e4f08745b1e56b289bf418474becc937b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 2 21:46:20 2021 +0800

    rtmutex: Make wait_lock irq safe
    
    [ Upstream commit b4abf91047cf054f203dcfac97e1038388826937 ]
    
    Sasha reported a lockdep splat about a potential deadlock between RCU boosting
    rtmutex and the posix timer it_lock.
    
    CPU0                                    CPU1
    
    rtmutex_lock(&rcu->rt_mutex)
      spin_lock(&rcu->rt_mutex.wait_lock)
                                            local_irq_disable()
                                            spin_lock(&timer->it_lock)
                                            spin_lock(&rcu->mutex.wait_lock)
    --> Interrupt
        spin_lock(&timer->it_lock)
    
    This is caused by the following code sequence on CPU1
    
         rcu_read_lock()
         x = lookup();
         if (x)
            spin_lock_irqsave(&x->it_lock);
         rcu_read_unlock();
         return x;
    
    We could fix that in the posix timer code by keeping rcu read locked across
    the spinlocked and irq disabled section, but the above sequence is common and
    there is no reason not to support it.
    
    Taking rt_mutex.wait_lock irq safe prevents the deadlock.
    
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1f705af703b314e969264de54f3bcdfffabf2cf5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 2 21:46:19 2021 +0800

    futex: Futex_unlock_pi() determinism
    
    [ Upstream commit bebe5b514345f09be2c15e414d076b02ecb9cce8 ]
    
    The problem with returning -EAGAIN when the waiter state mismatches is that
    it becomes very hard to proof a bounded execution time on the
    operation. And seeing that this is a RT operation, this is somewhat
    important.
    
    While in practise; given the previous patch; it will be very unlikely to
    ever really take more than one or two rounds, proving so becomes rather
    hard.
    
    However, now that modifying wait_list is done while holding both hb->lock
    and wait_lock, the scenario can be avoided entirely by acquiring wait_lock
    while still holding hb-lock. Doing a hand-over, without leaving a hole.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: juri.lelli@arm.com
    Cc: bigeasy@linutronix.de
    Cc: xlpang@redhat.com
    Cc: rostedt@goodmis.org
    Cc: mathieu.desnoyers@efficios.com
    Cc: jdesfossez@efficios.com
    Cc: dvhart@infradead.org
    Cc: bristot@redhat.com
    Link: http://lkml.kernel.org/r/20170322104152.112378812@infradead.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b5dac38eb0ff3cbef23afd36d6822291a2a757a5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 2 21:46:18 2021 +0800

    futex: Rework futex_lock_pi() to use rt_mutex_*_proxy_lock()
    
    [ Upstream commit cfafcd117da0216520568c195cb2f6cd1980c4bb ]
    
    By changing futex_lock_pi() to use rt_mutex_*_proxy_lock() all wait_list
    modifications are done under both hb->lock and wait_lock.
    
    This closes the obvious interleave pattern between futex_lock_pi() and
    futex_unlock_pi(), but not entirely so. See below:
    
    Before:
    
    futex_lock_pi()                 futex_unlock_pi()
      unlock hb->lock
    
                                      lock hb->lock
                                      unlock hb->lock
    
                                      lock rt_mutex->wait_lock
                                      unlock rt_mutex_wait_lock
                                        -EAGAIN
    
      lock rt_mutex->wait_lock
      list_add
      unlock rt_mutex->wait_lock
    
      schedule()
    
      lock rt_mutex->wait_lock
      list_del
      unlock rt_mutex->wait_lock
    
                                      <idem>
                                        -EAGAIN
    
      lock hb->lock
    
    After:
    
    futex_lock_pi()                 futex_unlock_pi()
    
      lock hb->lock
      lock rt_mutex->wait_lock
      list_add
      unlock rt_mutex->wait_lock
      unlock hb->lock
    
      schedule()
                                      lock hb->lock
                                      unlock hb->lock
      lock hb->lock
      lock rt_mutex->wait_lock
      list_del
      unlock rt_mutex->wait_lock
    
                                      lock rt_mutex->wait_lock
                                      unlock rt_mutex_wait_lock
                                        -EAGAIN
    
      unlock hb->lock
    
    It does however solve the earlier starvation/live-lock scenario which got
    introduced with the -EAGAIN since unlike the before scenario; where the
    -EAGAIN happens while futex_unlock_pi() doesn't hold any locks; in the
    after scenario it happens while futex_unlock_pi() actually holds a lock,
    and then it is serialized on that lock.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: juri.lelli@arm.com
    Cc: bigeasy@linutronix.de
    Cc: xlpang@redhat.com
    Cc: rostedt@goodmis.org
    Cc: mathieu.desnoyers@efficios.com
    Cc: jdesfossez@efficios.com
    Cc: dvhart@infradead.org
    Cc: bristot@redhat.com
    Link: http://lkml.kernel.org/r/20170322104152.062785528@infradead.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 89cb69dd360a0a582dbe3c3bd75ddac1ba830a9a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 2 21:46:17 2021 +0800

    futex: Pull rt_mutex_futex_unlock() out from under hb->lock
    
    [ Upstream commit 16ffa12d742534d4ff73e8b3a4e81c1de39196f0 ]
    
    There's a number of 'interesting' problems, all caused by holding
    hb->lock while doing the rt_mutex_unlock() equivalient.
    
    Notably:
    
     - a PI inversion on hb->lock; and,
    
     - a SCHED_DEADLINE crash because of pointer instability.
    
    The previous changes:
    
     - changed the locking rules to cover {uval,pi_state} with wait_lock.
    
     - allow to do rt_mutex_futex_unlock() without dropping wait_lock; which in
       turn allows to rely on wait_lock atomicity completely.
    
     - simplified the waiter conundrum.
    
    It's now sufficient to hold rtmutex::wait_lock and a reference on the
    pi_state to protect the state consistency, so hb->lock can be dropped
    before calling rt_mutex_futex_unlock().
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: juri.lelli@arm.com
    Cc: bigeasy@linutronix.de
    Cc: xlpang@redhat.com
    Cc: rostedt@goodmis.org
    Cc: mathieu.desnoyers@efficios.com
    Cc: jdesfossez@efficios.com
    Cc: dvhart@infradead.org
    Cc: bristot@redhat.com
    Link: http://lkml.kernel.org/r/20170322104151.900002056@infradead.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 50801cdc86003c4e20b9ae668cf2659d0218cfcc
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 2 21:46:16 2021 +0800

    futex,rt_mutex: Introduce rt_mutex_init_waiter()
    
    [ Upstream commit 50809358dd7199aa7ce232f6877dd09ec30ef374 ]
    
    Since there's already two copies of this code, introduce a helper now
    before adding a third one.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: juri.lelli@arm.com
    Cc: bigeasy@linutronix.de
    Cc: xlpang@redhat.com
    Cc: rostedt@goodmis.org
    Cc: mathieu.desnoyers@efficios.com
    Cc: jdesfossez@efficios.com
    Cc: dvhart@infradead.org
    Cc: bristot@redhat.com
    Link: http://lkml.kernel.org/r/20170322104151.950039479@infradead.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 52937382542020d72bd8708dc10ac829d8b06ffe
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Aug 2 21:46:15 2021 +0800

    futex: Cleanup refcounting
    
    [ Upstream commit bf92cf3a5100f5a0d5f9834787b130159397cb22 ]
    
    Add a put_pit_state() as counterpart for get_pi_state() so the refcounting
    becomes consistent.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: juri.lelli@arm.com
    Cc: bigeasy@linutronix.de
    Cc: xlpang@redhat.com
    Cc: rostedt@goodmis.org
    Cc: mathieu.desnoyers@efficios.com
    Cc: jdesfossez@efficios.com
    Cc: dvhart@infradead.org
    Cc: bristot@redhat.com
    Link: http://lkml.kernel.org/r/20170322104151.801778516@infradead.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bd0c1ed954159c6457feb246b7682144d782829a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 2 21:46:14 2021 +0800

    futex: Rename free_pi_state() to put_pi_state()
    
    [ Upstream commit 29e9ee5d48c35d6cf8afe09bdf03f77125c9ac11 ]
    
    free_pi_state() is confusing as it is in fact only freeing/caching the
    pi state when the last reference is gone. Rename it to put_pi_state()
    which reflects better what it is doing.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Darren Hart <darren@dvhart.com>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Bhuvanesh_Surachari@mentor.com
    Cc: Andy Lowe <Andy_Lowe@mentor.com>
    Link: http://lkml.kernel.org/r/20151219200607.259636467@linutronix.de
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
